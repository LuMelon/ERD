{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.losses import Reduction\n",
    "\n",
    "class RL_GRU2:\n",
    "    def __init__(self, input_dim, hidden_dim, max_seq_len, max_word_len, class_num, action_num, sent_num):\n",
    "        self.input_x = tf.placeholder(tf.float32, [None, max_seq_len, max_word_len, input_dim], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, class_num], name=\"input_y\")\n",
    "        self.x_len = tf.placeholder(tf.int32, [None], name=\"x_len\")\n",
    "\n",
    "        self.sent_x = tf.placeholder(tf.float32, [None, max_word_len, input_dim], name=\"sent_x\")\n",
    "        self.sent_y = tf.placeholder(tf.float32, [None, sent_num], name=\"sent_y\")\n",
    "        \n",
    "        self.init_states = tf.placeholder(tf.float32, [None, hidden_dim], name=\"topics\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        self.rl_state = tf.placeholder(tf.float32, [None, hidden_dim], name=\"rl_states\")\n",
    "        self.rl_input = tf.placeholder(tf.float32, [None, max_word_len, input_dim], name=\"rl_input\")\n",
    "        self.action = tf.placeholder(tf.float32, [None, action_num], name=\"action\")\n",
    "        self.reward = tf.placeholder(tf.float32, [None], name=\"reward\")\n",
    "\n",
    "        output_dim = hidden_dim\n",
    "\n",
    "        # shared pooling layer\n",
    "        self.w_t = tf.Variable(tf.random_uniform([input_dim, output_dim], -1.0, 1.0), name=\"w_t\")\n",
    "        self.b_t = tf.Variable(tf.constant(0.01, shape=[output_dim]), name=\"b_t\")\n",
    "        #[batchsize, max_seq_len, max_word_len, input_dim] --> [batchsize, max_seq_len, output_dim]\n",
    "        pooled_input_x = self.shared_pooling_layer(self.input_x, input_dim, max_seq_len, max_word_len, output_dim) # replace the shared_pooling_layer with a sentiment analysis model\n",
    "        pooled_rl_input = self.shared_pooling_layer(self.rl_input, input_dim, 1, max_word_len, output_dim)\n",
    "        pooled_rl_input = tf.reshape(pooled_rl_input, [-1, output_dim])\n",
    "\n",
    "        # dropout layer\n",
    "        pooled_input_x_dp = tf.nn.dropout(pooled_input_x, self.dropout_keep_prob)\n",
    "\n",
    "        # df model\n",
    "        df_cell = rnn.GRUCell(output_dim)\n",
    "        df_cell = rnn.DropoutWrapper(df_cell, output_keep_prob=self.dropout_keep_prob)\n",
    "\n",
    "        w_tp = tf.constant(0.0, shape=[hidden_dim, output_dim], name=\"w_tp\")\n",
    "        self.df_state = tf.matmul(self.init_states, w_tp, name=\"df_state\") # w_tp is not an Variable?\n",
    "\n",
    "        df_outputs, df_last_state = tf.nn.dynamic_rnn(df_cell, pooled_input_x_dp, self.x_len, initial_state=self.df_state, dtype=tf.float32)\n",
    "\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        w_ps = tf.Variable(tf.truncated_normal([output_dim, class_num], stddev=0.1)) #\n",
    "        b_ps = tf.Variable(tf.constant(0.01, shape=[class_num])) #\n",
    "        l2_loss += tf.nn.l2_loss(w_ps) \n",
    "        l2_loss += tf.nn.l2_loss(b_ps) \n",
    "\n",
    "        self.pre_scores = tf.nn.xw_plus_b(df_last_state, w_ps, b_ps, name=\"p_scores\")\n",
    "        self.predictions = tf.argmax(self.pre_scores, 1, name=\"predictions\")\n",
    "\n",
    "        r_outputs = tf.reshape(df_outputs, [-1, output_dim]) #[batchsize*max_seq_len, output_dim]\n",
    "        scores_seq = tf.nn.softmax(tf.nn.xw_plus_b(r_outputs, w_ps, b_ps)) # [batchsize * max_seq_len, class_num] \n",
    "        self.out_seq = tf.reshape(scores_seq, [-1, max_seq_len, class_num], name=\"out_seq\") #[batchsize, max_seq_len, class_num]\n",
    "\n",
    "        df_losses = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.pre_scores, labels=self.input_y)\n",
    "        self.loss = tf.reduce_mean(df_losses) + 0.1 * l2_loss\n",
    "\n",
    "        correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "\n",
    "        # rl model\n",
    "        self.rl_output, self.rl_new_state = df_cell(pooled_rl_input, self.rl_state)\n",
    "\n",
    "        w_ss1 = tf.Variable(tf.truncated_normal([output_dim, 64], stddev=0.01))\n",
    "        b_ss1 = tf.Variable(tf.constant(0.01, shape=[64]))\n",
    "        rl_h1 = tf.nn.relu(tf.nn.xw_plus_b(self.rl_state, w_ss1, b_ss1))  # replace the process here\n",
    "\n",
    "        w_ss2 = tf.Variable(tf.truncated_normal([64, action_num], stddev=0.01))\n",
    "        b_ss2 = tf.Variable(tf.constant(0.01, shape=[action_num]))\n",
    "\n",
    "        self.stopScore = tf.nn.xw_plus_b(rl_h1, w_ss2, b_ss2, name=\"stopScore\")\n",
    "\n",
    "        self.isStop = tf.argmax(self.stopScore, 1, name=\"isStop\")\n",
    "\n",
    "        out_action = tf.reduce_sum(tf.multiply(self.stopScore, self.action), reduction_indices=1)\n",
    "        self.rl_cost = tf.reduce_mean(tf.square(self.reward - out_action), name=\"rl_cost\")\n",
    "\n",
    "        \n",
    "        # Sentiment Analysis Task\n",
    "        self.pooled_feat = self.SentCNN(self.sent_x)\n",
    "        classifier = tf.layers.Dense(sent_num, activation= tf.nn.relu, trainable=True)\n",
    "        self.sent_scores = tf.nn.softmax(classifier(self.pooled_feat), axis=1)\n",
    "        self.sent_pred = tf.argmax(self.sent_scores, 1, name=\"predictions\")\n",
    "        self.sent_loss = tf.losses.softmax_cross_entropy(\n",
    "                        self.sent_y,\n",
    "                        self.sent_scores,\n",
    "                        weights=1.0,\n",
    "                        label_smoothing=0,\n",
    "                        scope=None,\n",
    "                        loss_collection=tf.GraphKeys.LOSSES,\n",
    "                        reduction=Reduction.SUM_BY_NONZERO_WEIGHTS\n",
    "                    )\n",
    "        sent_correct_predictions = tf.equal(self.sent_pred, tf.argmax(self.sent_y, 1))\n",
    "        self.sent_acc = tf.reduce_mean(tf.cast(sent_correct_predictions, \"float\"), name=\"accuracy\")\n",
    "\n",
    "\n",
    "    def shared_pooling_layer(self, inputs, input_dim, max_seq_len, max_word_len, output_dim):\n",
    "        t_inputs = tf.reshape(inputs, [-1, input_dim])\n",
    "        # t_h = tf.nn.xw_plus_b(t_inputs, self.w_t, self.b_t)\n",
    "        t_h = tf.matmul(t_inputs, self.w_t)\n",
    "        t_h = tf.reshape(t_h, [-1, max_word_len, output_dim])\n",
    "        t_h_expended = tf.expand_dims(t_h, -1)\n",
    "        pooled = tf.nn.max_pool(\n",
    "            t_h_expended,\n",
    "            ksize=[1, max_word_len, 1, 1],\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "            name=\"max_pool\"\n",
    "        )\n",
    "        outs = tf.reshape(pooled, [-1, max_seq_len, output_dim])\n",
    "        return outs\n",
    "\n",
    "    def pooling_layer(self, inputs, input_dim, max_seq_len, max_word_len, output_dim):\n",
    "        t_inputs = tf.reshape(inputs, [-1, input_dim])\n",
    "        w = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1))\n",
    "        b = tf.Variable(tf.constant(0.01, shape=[output_dim]))\n",
    "\n",
    "        h = tf.nn.xw_plus_b(t_inputs, w, b)\n",
    "        hs = tf.reshape(h, [-1, max_word_len, output_dim])\n",
    "\n",
    "        inputs_expended = tf.expand_dims(hs, -1)\n",
    "        # [seq, words, out] --> [seq, words, out, 1] --> [seq, 1, out, 1] --> [1, seq, out]\n",
    "        pooled = tf.nn.max_pool(\n",
    "            inputs_expended,\n",
    "            ksize=[1, max_word_len, 1, 1],\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "            name=\"max_pool\"\n",
    "        )\n",
    "        cnn_outs = tf.reshape(pooled, [-1, max_seq_len, output_dim]) \n",
    "        return cnn_outs\n",
    "\n",
    "    def SentCNN(self, input_x):\n",
    "        num_filters = 256\n",
    "        kernel_size = 5\n",
    "        conv_input = tf.layers.conv1d(input_x, num_filters, kernel_size, strides=1, padding='valid', name='conv2', trainable=True)\n",
    "        feature_map = tf.nn.relu(conv_input) # [batchsize, conv_feats, filters]\n",
    "        pooled_feat = tf.reduce_max(feature_map, 1) #[batchsize, 1, filters]\n",
    "\n",
    "        return pooled_feat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "\n",
    "class Chars2Vec:\n",
    "    def __init__(self, emb_dim, char_to_ix):\n",
    "        if not isinstance(emb_dim, int) or emb_dim < 1:\n",
    "            raise TypeError(\"parameter 'emb_dim' must be a positive integer\")\n",
    "\n",
    "        if not isinstance(char_to_ix, dict):\n",
    "            raise TypeError(\"parameter 'char_to_ix' must be a dictionary\")\n",
    "            \n",
    "        self.char_to_ix = char_to_ix\n",
    "        self.ix_to_char = {char_to_ix[ch]: ch for ch in char_to_ix}\n",
    "        self.vocab_size = len(self.char_to_ix)\n",
    "        self.emb_dim = emb_dim\n",
    "        self.cache = {}\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_rnn\")\n",
    "        \n",
    "    def embedding(self, input_x, x_len, batch_size):\n",
    "        lstm_cell_1 = rnn.GRUCell(self.emb_dim, name = 'layer1')\n",
    "        lstm_cell_1 = rnn.DropoutWrapper(lstm_cell_1, output_keep_prob=self.dropout_keep_prob)\n",
    "        lstm_cell_2 = rnn.GRUCell(self.emb_dim, name = 'layer2')\n",
    "        lstm_cell_2 = rnn.DropoutWrapper(lstm_cell_2, output_keep_prob=self.dropout_keep_prob)\n",
    "        init_state = tf.constant(0.0, shape=[batch_size, self.emb_dim])\n",
    "        hiddens_1, hiddens_1_final = tf.nn.dynamic_rnn(lstm_cell_1, input_x, x_len, initial_state=init_state, dtype=tf.float32)\n",
    "        hiddens_2, hiddens_2_final = tf.nn.dynamic_rnn(lstm_cell_2, hiddens_1, x_len, initial_state=hiddens_1_final, dtype=tf.float32)\n",
    "        return hiddens_2_final\n",
    "    \n",
    "    def PredSimilar(self, input1, input2, x1_len, x2_len, batch_size):\n",
    "        embed_1 = self.embedding(input1, x1_len, batch_size)\n",
    "        embed_2 = self.embedding(input2, x2_len, batch_size)\n",
    "        sub = embed_1 - embed_2\n",
    "        sub = sub*sub\n",
    "        RegLayer = tf.layers.Dense(1, activation= tf.nn.sigmoid, trainable=True)\n",
    "        pred = RegLayer(sub)\n",
    "        return pred\n",
    "    \n",
    "    def TrainModel(self, word_pairs, targets, max_epochs, patience, validation_split, batch_size):\n",
    "        if not isinstance(word_pairs, list) and not isinstance(word_pairs, np.ndarray):\n",
    "            raise TypeError(\"parameters 'word_pairs' must be a list or numpy.ndarray\")\n",
    "\n",
    "        if not isinstance(targets, list) and not isinstance(targets, np.ndarray):\n",
    "            raise TypeError(\"parameters 'targets' must be a list or numpy.ndarray\")\n",
    "    \n",
    "        assert len(word_pairs) == len(targets)\n",
    "        if isinstance(targets, list) and not isinstance(targets, np.ndarray):\n",
    "            targets = np.array(targets)\n",
    "    \n",
    "        def word2emb_list(word):\n",
    "            emb_list = []\n",
    "            for t in range(len(word)):\n",
    "                if word[t] in self.char_to_ix:\n",
    "                    x = np.zeros(self.vocab_size).tolist()\n",
    "                    x[self.char_to_ix[word[t]]] = 1\n",
    "                    emb_list.append(x)\n",
    "                else:\n",
    "                    emb_list.append(np.zeros(self.vocab_size).tolist())\n",
    "            return emb_list\n",
    "        \n",
    "        x_1, x_2 = [], []\n",
    "        for pair_words in word_pairs:\n",
    "            if not isinstance(pair_words[0], str) or not isinstance(pair_words[1], str):\n",
    "                raise TypeError(\"word must be a string\")\n",
    "            first_word = pair_words[0].lower()\n",
    "            second_word = pair_words[1].lower()\n",
    "            emb_list_1 = word2emb_list(first_word)\n",
    "            emb_list_2 = word2emb_list(second_word)\n",
    "            x_1.append(np.array(emb_list_1))\n",
    "            x_2.append(np.array(emb_list_2))\n",
    "        x1_len = np.array([len(word) for word in x_1])\n",
    "        x2_len = np.array([len(word) for word in x_2])\n",
    "        max_word_len = max(max(), max())\n",
    "        x_1 = keras.preprocessing.sequence.pad_sequences(x_1, maxlen=max_word_len, dtype='int32', padding='pro', truncating='pre', value=0.0)\n",
    "        x_2 = keras.preprocessing.sequence.pad_sequences(x_2, maxlen=max_word_len, dtype='int32', padding='pro', truncating='pre', value=0.0)\n",
    "        #shuffle the data\n",
    "        data_size = len(targets)\n",
    "        idxs = random.sample(range(data_size), data_size)\n",
    "        x_1 = x_1[idxs]\n",
    "        x_2 = x_2[idxs]\n",
    "        targets = targets[idxs]\n",
    "        # train:validation:test = 5:1:2\n",
    "        split_1 = int((5*data_size)/8)\n",
    "        split_2 = int((6*data_size)/8)\n",
    "        train_idxs = idxs[:split_1]\n",
    "        val_idxs = idxs[split_1:split_2]\n",
    "        test_idxs =  idxs[split_2:]\n",
    "        \n",
    "        max_iter = int(split_1 / batch_size) + 1\n",
    "        \n",
    "        #Tensor Graph\n",
    "        batch_X1 = tf.placeholder(tf.float32, [None, max_word_len, self.vocab_size], name=\"X_1\")\n",
    "        batch_X2 = tf.placeholder(tf.float32, [None, max_word_len, self.vocab_size], name=\"X_2\")\n",
    "        batch_Y = tf.placeholder(tf.float32, [None])\n",
    "        preds = self.PredSimilar(batch_X1, batch_X2)\n",
    "        loss = tf.reduce_sum(tf.pow(batch_Y-preds, 2), axis=0)\n",
    "        train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=4)\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        min_val_loss = 0\n",
    "        for i in range(max_epochs):\n",
    "            for j in range(max_iter):\n",
    "                batch_idxs = [train_idxs[j*batch_size + k] if (j*batch_size + k)<split_1 else train_idxs[(j*batch_size + k)%split_1] for k in range(batch_size)]\n",
    "                feed_dict = {batch_X1:x_1[batch_idxs], batch_X2:x_2[batch_idxs], batch_Y:targets[batch_idxs]}\n",
    "                _, batch_loss = sess.run([train_op, loss], feed_dict)\n",
    "                print(\" Step: \" + str(j) + \" Training loss: \" + batch_loss)\n",
    "            \n",
    "            val_loss = 0\n",
    "            for j in range(split_1, split_2, batch_size):\n",
    "                batch_idxs = list(range(j, max(j+batch_size, split_2), 1))\n",
    "                feed_dict = {batch_X1:x_1[batch_idxs], batch_X2:x_2[batch_idxs], batch_Y:targets[batch_idxs]}\n",
    "                batch_loss = sess.run(loss, feed_dict)\n",
    "                val_loss += batch_loss\n",
    "            print(\"Epochs: \" + str(i) + \"Validation loss: \" + batch_loss)\n",
    "            \n",
    "            if i == 1:\n",
    "                min_val_loss = val_loss\n",
    "            else:\n",
    "                if min_val_loss > val_loss:\n",
    "                    saver.save(sess, \"char2vec_saved/model\"+str(i))\n",
    "                    print(\"char2vec_saved/model \"+str(i)+\" saved\")\n",
    "        # test loss\n",
    "        for j in range(split_2, data_size, batch_size):\n",
    "            batch_idxs = list(range(j, max(j+batch_size, data_size), 1))\n",
    "            feed_dict = {batch_X1:x_1[batch_idxs], batch_X2:x_2[batch_idxs], batch_Y:targets[batch_idxs]}\n",
    "            batch_loss = sess.run(loss, feed_dict)\n",
    "            val_loss += batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['f', 'k', 'n', '7', '’', '8', 'c', '9', 'b', ')', '(', 's', 'm', 'e', 'g', '4', ',', 'j', '”', '1', 'z', 't', '2', ' ', 'i', '–', 'o', 'l', '.', '!', 'd', 'u', 'a', '0', 'y', '-', 'x', 'w', '“', 'v', 'q', '&', ':', '6', 'r', 'h', 'p', '3', '5']\n",
    "char_2_ix = {c:ix for (ix, c) in enumerate(chars)}\n",
    "\n",
    "model = Chars2Vec(300, char_2_ix)\n",
    "\n",
    "zs = np.zeros([3, 9, len(chars)], dtype='float32')\n",
    "for i in range(len(zs)):\n",
    "    for j in range(zs.shape[1]):\n",
    "        zs[i][j][random.randint(0,9)]=1\n",
    "\n",
    "X_S1 = tf.convert_to_tensor(zs, name='X_S1')\n",
    "X_S2 = tf.convert_to_tensor(zs, name='X_S2')\n",
    "x_len1 = tf.convert_to_tensor(np.ones([int(X_S1.shape[0])])*int(X_S1.shape[1]))\n",
    "x_len2 = tf.convert_to_tensor(np.array([9-i for i in range(3)]), name='X_len2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0810 22:26:28.301170 140536060004160 deprecation.py:323] From <ipython-input-1-66d307aea7ac>:23: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0810 22:26:28.305463 140536060004160 deprecation.py:323] From <ipython-input-1-66d307aea7ac>:28: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0810 22:26:28.340988 140536060004160 deprecation.py:506] From /home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0810 22:26:28.347064 140536060004160 deprecation.py:506] From /home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0810 22:26:28.355510 140536060004160 deprecation.py:506] From /home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0810 22:26:28.480541 140536060004160 deprecation.py:323] From /home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# vec1 = model.embedding(X_S1, x_len1, len(zs))\n",
    "vec2 = model.embedding(X_S2, x_len2, len(zs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/layer1/gates/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-1-66d307aea7ac>\", line 28, in embedding\n    hiddens_1, hiddens_1_final = tf.nn.dynamic_rnn(lstm_cell_1, input_x, x_len, initial_state=init_state, dtype=tf.float32)\n  File \"<ipython-input-3-1b0cfcf0b871>\", line 2, in <module>\n    vec2 = model.embedding(X_S2, x_len2, len(zs))\n  File \"/home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-725f74e6f2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvec3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_S2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-66d307aea7ac>\u001b[0m in \u001b[0;36membedding\u001b[0;34m(self, input_x, x_len, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlstm_cell_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropoutWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_keep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0minit_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mhiddens_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens_1_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mhiddens_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens_2_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhiddens_1_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhiddens_2_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3499\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3501\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3012\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3013\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2935\u001b[0m         expand_composites=True)\n\u001b[1;32m   2936\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3454\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3455\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3456\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    880\u001b[0m           \u001b[0mcall_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m           \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m           skip_conditionals=True)\n\u001b[0m\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_rnn_step\u001b[0;34m(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;31m# steps.  This is faster when max_seq_len is equal to the number of unrolls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m# (which is typical for dynamic_rnn).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0mnew_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     return self._call_wrapped_cell(\n\u001b[0;32m-> 1159\u001b[0;31m         inputs, state, cell_call_fn=self.cell.__call__, scope=scope)\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_call_wrapped_cell\u001b[0;34m(self, inputs, state, cell_call_fn, **kwargs)\u001b[0m\n\u001b[1;32m   1434\u001b[0m       inputs = self._dropout(inputs, \"input\", self._recurrent_input_noise,\n\u001b[1;32m   1435\u001b[0m                              self._input_keep_prob)\n\u001b[0;32m-> 1436\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_should_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_keep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0;31m# Identify which subsets of the state to perform dropout on and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 385\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m       \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;34m\"gates/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         initializer=self._kernel_initializer)\n\u001b[0m\u001b[1;32m    559\u001b[0m     self._gate_bias = self.add_variable(\n\u001b[1;32m    560\u001b[0m         \u001b[0;34m\"gates/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_BIAS_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1482\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     \u001b[0;34m\"\"\"Alias for `add_weight`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1494\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1237\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    560\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    512\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 864\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    865\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable rnn/layer1/gates/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-1-66d307aea7ac>\", line 28, in embedding\n    hiddens_1, hiddens_1_final = tf.nn.dynamic_rnn(lstm_cell_1, input_x, x_len, initial_state=init_state, dtype=tf.float32)\n  File \"<ipython-input-3-1b0cfcf0b871>\", line 2, in <module>\n    vec2 = model.embedding(X_S2, x_len2, len(zs))\n  File \"/home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "vec3 = model.embedding(X_S2, x_len2, len(zs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.51419984e-02  2.13891268e-02  3.31077129e-02 -2.10912200e-03\n",
      "   1.85334142e-02 -2.13842485e-02  1.70879215e-02 -2.24037841e-02\n",
      "  -2.46302709e-02  9.78733413e-03  7.99910445e-03  5.05236816e-03\n",
      "   6.02034815e-02 -2.72581843e-03 -2.36835219e-02 -4.12596725e-02\n",
      "   3.05082212e-04 -2.31418684e-02 -7.98030570e-03  2.30648667e-02\n",
      "  -9.65827890e-03  2.07140632e-02 -3.09601780e-02 -2.18294188e-02\n",
      "   1.95513852e-02  8.35482590e-03 -3.13163246e-03  2.02843770e-02\n",
      "   1.63879432e-02 -9.89894941e-03 -1.25068184e-02 -7.14694262e-02\n",
      "   4.09551337e-02 -1.79147106e-02 -2.11598780e-02 -1.61592010e-02\n",
      "   3.15513909e-02 -3.78101878e-02 -1.89091489e-02 -2.20310017e-02\n",
      "  -2.23376863e-02  1.91728584e-02  9.29436181e-04  1.17969618e-03\n",
      "  -5.27444556e-02  1.09635275e-02  2.34819930e-02 -8.22268613e-03\n",
      "  -2.43859366e-04  9.50446259e-03  3.31880040e-02 -3.71786021e-02\n",
      "   2.34874785e-02  8.37863050e-03  4.73898137e-04 -3.68349291e-02\n",
      "   5.85855450e-03  1.37222628e-03  6.01969985e-03  2.47659497e-02\n",
      "   4.22504172e-02 -1.54334586e-02 -2.12557483e-02  8.53758771e-03\n",
      "   1.25632063e-02 -1.40561620e-02  3.10596675e-02 -1.75164826e-02\n",
      "   1.32597936e-03  2.35407166e-02  1.08723296e-02  8.48845020e-03\n",
      "   5.20295985e-02 -1.81982107e-02 -5.71414735e-03  1.00318238e-03\n",
      "  -1.27808163e-02 -1.09910173e-02  2.64188536e-02 -1.29870872e-03\n",
      "   2.35863458e-02  6.08532354e-02  3.81131866e-03 -3.11646983e-03\n",
      "   2.48617828e-02  1.44915376e-02  2.50170827e-02 -2.22891159e-02\n",
      "   1.22133447e-02 -2.86253239e-03  1.59108639e-02  5.80316503e-03\n",
      "  -8.36999342e-03 -2.71970010e-03 -3.58091928e-02 -3.45524661e-02\n",
      "  -1.96907949e-02  3.97806382e-03  2.87910551e-02  2.06744671e-02\n",
      "  -5.64529514e-03  3.30089107e-02  2.44723521e-02 -9.74412728e-03\n",
      "  -5.59279397e-02 -2.20817551e-02 -1.58568118e-02 -2.97994935e-03\n",
      "   7.80645385e-03  2.28035334e-03  1.51435863e-02  1.24084204e-02\n",
      "  -1.65453870e-02  1.87154617e-02  8.05422198e-03 -5.74643351e-03\n",
      "   1.22543788e-02 -1.41578112e-02 -4.75790873e-02 -1.01329945e-03\n",
      "  -1.70126017e-02  1.33647081e-02  5.13065234e-03  3.87076777e-03\n",
      "  -1.70013420e-02 -7.01330742e-03 -5.35272956e-02 -4.53928858e-02\n",
      "   2.52407454e-02  6.26227818e-03  1.34507921e-02  1.60013046e-02\n",
      "   1.40081365e-02 -2.35203244e-02 -1.58473365e-02 -1.32691637e-02\n",
      "  -6.20070286e-03  7.84873031e-03 -1.76111069e-02 -2.59879343e-02\n",
      "  -3.18943150e-03 -1.10243959e-02  3.37331207e-03 -2.77869496e-02\n",
      "   9.85674281e-03  2.37078425e-02  2.29480490e-02 -4.48438078e-02\n",
      "  -1.32978447e-02 -1.07815266e-02  9.53658484e-03  1.51176974e-02\n",
      "  -1.13873426e-02  7.29690166e-03 -7.40868179e-03  7.17574134e-02\n",
      "  -3.61306220e-02  2.58983187e-02 -7.89941195e-03  1.70581862e-02\n",
      "   3.59817669e-02  2.31018700e-02  8.15910846e-03 -1.50957536e-02\n",
      "   2.13660188e-02  1.50307948e-02 -6.13358570e-03  1.35291861e-02\n",
      "   3.48057374e-02  1.61977066e-03  2.21607834e-03  2.14924179e-02\n",
      "  -2.06032246e-02  7.84500688e-03 -1.54981744e-02 -9.97462310e-03\n",
      "   2.48117782e-02  1.69695914e-02 -2.06813011e-02 -1.74553543e-02\n",
      "  -3.67194824e-02  2.76031438e-02 -1.59758218e-02 -1.31528387e-02\n",
      "  -2.21220106e-02 -1.11611122e-02  8.49183928e-03 -4.44230344e-03\n",
      "   2.58770422e-03  9.79128852e-03 -1.32100133e-03 -1.81626342e-02\n",
      "   6.89438405e-03  5.18347993e-02 -3.82825686e-03  1.88915282e-02\n",
      "   2.61729062e-02  2.37532705e-02 -3.08803879e-02 -5.62518649e-03\n",
      "  -6.52131531e-03  1.53209707e-02  2.94391904e-02  3.64124961e-02\n",
      "  -5.30625926e-03 -1.49588231e-02  2.24782042e-02 -1.66361034e-02\n",
      "  -2.24943515e-02 -1.23328073e-02 -3.02824639e-02 -2.78104618e-02\n",
      "  -6.03365572e-03 -7.20747467e-03  4.45110500e-02 -1.80718917e-02\n",
      "   2.07312452e-03 -2.95281820e-02 -3.24219987e-02  2.18644016e-03\n",
      "  -9.35701653e-04 -5.39723132e-03  1.84085090e-02 -1.19533930e-02\n",
      "  -2.21914444e-02 -5.82566205e-03  7.13450415e-03  1.95119958e-02\n",
      "   1.03486385e-02  2.01414153e-02  1.95664167e-02 -5.39270118e-02\n",
      "   1.82849281e-02  3.56031470e-02  2.07794495e-02  2.96568908e-02\n",
      "  -2.08537793e-03  3.78693757e-03 -1.37864258e-02  9.45893768e-03\n",
      "   1.53583782e-02  2.71227211e-02  2.20802985e-02 -6.25195727e-03\n",
      "   3.97555456e-02 -2.90971436e-02  1.83464133e-03  6.47441484e-03\n",
      "  -1.35179013e-02 -6.82838075e-03 -6.64652418e-03 -2.59136688e-02\n",
      "  -7.78861810e-03 -2.99205887e-03 -8.51956382e-03 -2.09082663e-02\n",
      "   1.60882287e-02 -5.04290219e-03 -2.41868235e-02 -1.29089421e-02\n",
      "   5.23361284e-03 -2.95721702e-02 -9.73011716e-04  4.72698407e-03\n",
      "   3.83764990e-02  2.74344180e-02 -3.61288432e-03 -3.48581150e-02\n",
      "   1.53649179e-03 -2.85342131e-02  3.27550806e-02 -3.40058468e-05\n",
      "   6.37941109e-03  3.15723792e-02  1.44345015e-02 -2.44751424e-02\n",
      "  -1.82674695e-02  1.01237902e-02 -1.28853191e-02  2.01799516e-02\n",
      "   1.16079662e-03  5.41512445e-02  1.40051469e-02  4.26546410e-02\n",
      "   1.48777431e-03 -2.57126093e-02  1.42551651e-02 -8.64908751e-03\n",
      "  -2.09678672e-02 -1.24108810e-02  2.16097068e-02  9.53138154e-03\n",
      "   2.81430893e-02 -2.66306475e-03  7.86311226e-04  5.47958771e-03\n",
      "  -3.12594660e-02 -6.53414009e-03 -7.37245986e-03 -4.02336847e-03]\n",
      " [-1.45226680e-02  1.08796740e-02 -8.81869718e-03  7.00329337e-03\n",
      "  -5.82041591e-03  8.85458756e-03  1.54305045e-02 -1.24492748e-02\n",
      "  -2.46488042e-02 -5.56536764e-03  1.37128755e-02 -2.12029628e-02\n",
      "   4.56074774e-02  1.89268924e-02  1.88230835e-02 -2.02977192e-03\n",
      "  -2.70006876e-03  9.44907032e-03 -1.09022418e-02 -1.03505142e-02\n",
      "   9.01048444e-03  2.35129520e-02 -5.68126841e-03 -1.99530683e-02\n",
      "  -1.07516383e-03  5.99143701e-03  6.65077940e-03  1.41477082e-02\n",
      "   1.92939863e-02 -1.88913289e-03  7.30559463e-03 -8.78202263e-03\n",
      "   2.57426240e-02  6.63139019e-03  1.86412979e-03 -2.91027827e-03\n",
      "  -4.93680779e-03 -2.32113991e-02 -1.33059155e-02 -2.93641966e-02\n",
      "  -9.81037878e-03  2.36832313e-02 -1.74004603e-02  5.47188893e-03\n",
      "  -2.40523554e-02  1.53487539e-02  2.28373129e-02 -9.21966229e-03\n",
      "   2.04751268e-02 -1.25561589e-02  1.74773373e-02 -1.22320708e-02\n",
      "   1.31354546e-02  2.01431587e-02  3.09717190e-03 -2.47582197e-02\n",
      "   9.03311744e-03  5.43962605e-03  2.46338956e-02  1.91612989e-02\n",
      "   1.39836138e-02 -1.76001713e-02 -2.67848726e-02  5.21395821e-03\n",
      "   2.29426175e-02 -1.59558430e-02  4.25286777e-03 -1.05035277e-02\n",
      "   7.53949210e-03  4.54009324e-02  3.78754586e-02  3.88417244e-02\n",
      "   1.61531419e-02  1.25985197e-03  2.99928756e-03 -7.38376984e-03\n",
      "  -2.34572217e-02 -9.96111985e-03  1.84899587e-02  1.60317495e-02\n",
      "   6.60610944e-03  2.72306092e-02  2.62038317e-03  5.14434325e-03\n",
      "   1.67611509e-03  7.97825214e-03  8.81321914e-03 -2.53588259e-02\n",
      "  -1.38600706e-03 -3.48164812e-02  1.78543441e-02  1.06730675e-02\n",
      "   8.14836100e-03 -9.80399735e-03 -1.10866213e-02 -2.56483629e-02\n",
      "  -9.89537500e-03  1.05503667e-02  3.05749150e-03 -3.37363034e-03\n",
      "  -7.85504002e-03  2.98008136e-02 -3.45073314e-03 -4.73918021e-03\n",
      "  -7.44615309e-03 -2.79978923e-02 -2.34745797e-02  3.83490184e-03\n",
      "   2.59860642e-02 -1.52098387e-02  7.95498211e-03  1.53632611e-02\n",
      "  -1.71276741e-02  3.29740532e-03 -2.23132707e-02  9.25959647e-03\n",
      "  -2.99988920e-03 -4.56158072e-03 -1.35952253e-02 -6.47015637e-03\n",
      "  -2.28502806e-02  1.35576185e-02 -3.51494327e-02  2.70713419e-02\n",
      "  -1.28827095e-02 -1.52236002e-03  2.82904599e-04 -3.32928970e-02\n",
      "  -3.07597686e-03  3.94849852e-02 -8.28979816e-03  9.10693686e-03\n",
      "  -1.96702704e-02 -5.70623670e-04  5.54192765e-03 -1.13705965e-02\n",
      "  -1.75603095e-03  6.78906776e-03 -2.58090384e-02  1.15353358e-03\n",
      "  -3.56569979e-03 -1.18158404e-02  1.53687615e-02  5.14274044e-03\n",
      "   1.36807635e-02  2.09223758e-02 -3.93483788e-05 -8.61410052e-03\n",
      "   1.38057442e-02 -1.79633703e-02  1.68987624e-02  2.78050341e-02\n",
      "  -5.03900740e-03  1.04939975e-02 -1.55616347e-02  3.38351466e-02\n",
      "  -1.50775220e-02  2.45491341e-02 -3.38786328e-03  5.27573004e-03\n",
      "   2.68898904e-02  2.54523829e-02  1.82070658e-02 -1.04738399e-02\n",
      "  -2.50469288e-03  9.86702275e-03 -8.16788152e-03  1.00384951e-02\n",
      "   1.86475646e-02  3.39444983e-03  1.22418590e-02  4.04511299e-03\n",
      "  -1.29255150e-02 -2.68430933e-02 -2.69709751e-02 -9.69671831e-03\n",
      "   1.19904196e-02  1.94397068e-03 -2.46058055e-03 -3.76695022e-02\n",
      "   2.19195131e-02  1.99569482e-03  3.89691582e-03 -9.37708188e-03\n",
      "  -1.83835812e-02  1.85487175e-03  1.92436539e-02 -2.40532346e-02\n",
      "   8.45196657e-03  1.32708605e-02 -2.26946604e-02  2.96261162e-04\n",
      "  -1.60277716e-03  2.49801278e-02 -1.22400280e-02  1.94353610e-02\n",
      "  -3.57150957e-02  3.97356078e-02 -7.34337885e-03  2.55292244e-02\n",
      "  -3.50704463e-03  1.40157193e-02  1.90194901e-02  2.57549677e-02\n",
      "  -2.29673777e-02 -2.09172387e-02  3.03097088e-02  6.51465775e-03\n",
      "  -9.90256947e-03  1.25061190e-02 -8.12479574e-03 -2.01852731e-02\n",
      "  -1.25103220e-02 -1.06744319e-02  2.50211507e-02 -1.28355753e-02\n",
      "  -2.37942897e-02  6.60387333e-03 -4.51861545e-02 -2.52997987e-02\n",
      "  -1.44446185e-02 -2.34871376e-02 -1.52201103e-02 -1.17628053e-02\n",
      "  -7.26489164e-03  3.18065844e-03  4.54726582e-03  9.84920282e-03\n",
      "  -1.98508240e-03 -2.17977948e-02  1.03809815e-02 -2.24148110e-02\n",
      "   1.72260264e-03  6.25554705e-03 -1.86556228e-03  1.57595687e-02\n",
      "   3.14417947e-03 -7.18052499e-03  9.73371789e-03  4.97715455e-03\n",
      "   6.84081228e-04  5.05960546e-03 -6.54119207e-03  2.20960025e-02\n",
      "  -1.62357986e-02  8.91664904e-03 -2.09552087e-02 -1.58351660e-02\n",
      "  -9.82075650e-03  1.13849258e-02 -1.66506544e-02 -1.41430199e-02\n",
      "   1.17683243e-02 -1.62844360e-03 -2.42238096e-03 -1.12224631e-02\n",
      "   3.63391684e-03 -1.27230957e-02  2.67035794e-03 -1.59988888e-02\n",
      "   1.13584762e-02 -1.56253837e-02  7.42130913e-03  3.49073373e-02\n",
      "   6.62877783e-03 -9.53839347e-03  1.83868054e-02 -2.62389425e-02\n",
      "   2.56571639e-02 -9.92638990e-03 -2.87270285e-02 -2.06519067e-02\n",
      "   2.10264921e-02 -1.02554206e-02  2.41132658e-02 -3.20784040e-02\n",
      "  -9.73635633e-03 -6.03062660e-03 -1.16851553e-02  1.99209023e-02\n",
      "  -2.18216293e-02  1.37928352e-02 -1.65251847e-02  3.63102108e-02\n",
      "   4.84154513e-03  2.16063764e-03  3.70288640e-02  8.93945864e-04\n",
      "  -2.67993961e-03 -1.24607449e-02  1.96913891e-02 -4.75240732e-03\n",
      "   1.22686587e-02 -7.43941590e-03  7.71822967e-03 -5.79440559e-04\n",
      "  -9.24979895e-03  2.08953172e-02  1.85083435e-03 -1.21936444e-02]\n",
      " [-8.32583383e-03 -1.23561770e-02 -6.23731036e-03 -1.38305910e-02\n",
      "  -9.87764727e-03  1.48653481e-02  2.19723489e-02  9.80291329e-03\n",
      "  -1.66341867e-02 -2.75616255e-02  2.37630121e-02 -2.46519111e-02\n",
      "   3.23570147e-02  4.31065187e-02  1.40168853e-02 -1.65416114e-02\n",
      "   2.54608924e-03  6.07933942e-03 -7.83149619e-03  9.14535299e-03\n",
      "  -1.94442980e-02  1.32369362e-02 -1.55770089e-02 -7.21313152e-03\n",
      "   2.35469081e-04  7.82562885e-03  9.92035121e-03  1.64007042e-02\n",
      "   1.76411532e-02  3.30495872e-02 -1.79780573e-02 -2.20923871e-03\n",
      "  -2.75067752e-04  1.99641157e-02  3.10081453e-03 -6.55612908e-03\n",
      "  -5.32921031e-03 -8.69134255e-03 -1.29841622e-02 -3.36116701e-02\n",
      "   6.72742492e-03 -1.41940417e-03 -3.57339568e-02 -3.12882243e-03\n",
      "  -8.28498323e-03  2.10498925e-02  1.05753802e-02 -1.00137135e-02\n",
      "   1.91020351e-02 -3.68227363e-02 -1.02309342e-02 -5.72777959e-03\n",
      "   9.76403803e-03  1.83702894e-02 -4.04311530e-03 -1.59305800e-02\n",
      "   6.38633873e-03 -1.85995037e-03  5.15430048e-02  3.19662094e-02\n",
      "   2.60634907e-02  1.04565155e-02 -2.03955770e-02  9.96664260e-03\n",
      "  -2.69373553e-03 -2.41925903e-02 -1.09911291e-02 -2.58241259e-02\n",
      "   1.65198017e-02  3.10332850e-02  4.45526186e-03  2.86956280e-02\n",
      "  -1.36708049e-03 -8.97501409e-03 -1.36114862e-02 -5.64709771e-03\n",
      "  -2.43705660e-02 -7.78378639e-03  6.27360772e-03  2.90497094e-02\n",
      "   5.86786494e-03  1.93520468e-02  1.81896407e-02  3.53438896e-03\n",
      "  -3.73141491e-04  7.74416234e-03  8.52061994e-03 -2.68667731e-02\n",
      "  -3.30567965e-03 -3.62508446e-02 -2.67097098e-03  7.25304615e-03\n",
      "   2.31587086e-02  1.93363545e-03 -3.96313891e-03 -1.84423998e-02\n",
      "  -6.98036281e-03  1.63643975e-02  2.66241049e-03 -1.83102749e-02\n",
      "   1.05435112e-02  1.10726682e-02  1.57758668e-02 -5.72053995e-03\n",
      "   1.39961950e-04 -2.00421847e-02 -8.50533880e-03  6.18015509e-03\n",
      "   1.22760534e-02  5.64316940e-03  3.69179249e-03  7.74053391e-03\n",
      "  -1.35393338e-02  1.40997469e-02 -8.32779333e-03  2.68636774e-02\n",
      "  -1.85897537e-02 -5.29728690e-03 -2.14100089e-02 -1.83767881e-02\n",
      "  -1.45614808e-02  3.26009933e-03 -1.77344140e-02  2.86730714e-02\n",
      "  -2.34046169e-02  1.83253102e-02  4.36243461e-03 -2.90890448e-02\n",
      "  -4.95260535e-03  4.77008596e-02  2.99357483e-03 -2.82403477e-03\n",
      "  -3.47106382e-02 -7.56356865e-03 -2.49880785e-03 -2.61322092e-02\n",
      "   1.48291383e-02  1.32986289e-02 -1.45693338e-02  2.97896266e-02\n",
      "  -1.21172015e-02 -4.63385461e-03 -1.68535905e-03  3.75981964e-02\n",
      "   2.82225781e-03  8.89418647e-03 -1.33448895e-02 -1.15160253e-02\n",
      "   3.27057987e-02 -1.42046530e-02  1.37463491e-02  1.78591646e-02\n",
      "  -5.25485072e-03  2.91020647e-02 -2.58631743e-02  1.79850385e-02\n",
      "  -2.83556432e-03 -4.50246036e-03 -1.67879416e-03 -3.33395461e-03\n",
      "   1.91216283e-02  3.98004875e-02 -7.13684363e-04 -9.52368602e-03\n",
      "  -8.25574435e-03  1.43895112e-03  6.37725275e-03  4.33616340e-03\n",
      "   2.29660589e-02  3.39219882e-03 -1.72225181e-02 -9.47669148e-03\n",
      "  -1.83780268e-02 -2.60679014e-02 -1.22761652e-02 -1.67804249e-02\n",
      "   3.45969275e-02  2.06508692e-02 -9.90262069e-03 -4.18633372e-02\n",
      "   1.42274201e-02 -3.60580999e-03 -1.09387550e-03  3.56900133e-03\n",
      "  -2.19186358e-02 -1.50556518e-02  2.11467855e-02 -2.16222778e-02\n",
      "   1.68333203e-02  1.51712941e-02 -3.49790119e-02  3.67036387e-02\n",
      "  -1.78820062e-02  9.79995169e-03 -8.61424371e-04  3.34528275e-02\n",
      "  -6.87644258e-02  3.89969908e-02  2.32625101e-02 -3.98146361e-03\n",
      "  -1.80686936e-02  3.22771445e-02  1.07594975e-03  1.07247652e-02\n",
      "  -1.97494142e-02 -7.71216769e-03  7.31046079e-03  1.26805119e-02\n",
      "   6.66190404e-04  1.86243188e-03  3.84185985e-02 -7.14949099e-03\n",
      "  -2.74789371e-02 -1.39957238e-02 -1.26229716e-03 -8.28762725e-03\n",
      "  -2.26532184e-02  8.01599585e-04 -2.39007398e-02 -4.06358838e-02\n",
      "  -1.23769846e-02 -3.84693518e-02 -1.58408396e-02 -1.84648926e-03\n",
      "  -9.38885473e-03  3.02674342e-03  2.94070393e-02  1.34680290e-02\n",
      "   2.42915889e-03 -7.17028789e-03  1.60329323e-02  5.21231350e-03\n",
      "  -1.01957656e-02 -1.63004603e-02 -1.97092537e-04  2.12277677e-02\n",
      "   1.19646592e-02 -1.16621349e-02  1.95152462e-02  1.33006852e-02\n",
      "   2.67575122e-02 -2.61869021e-02  4.75334330e-03 -4.29440150e-03\n",
      "  -6.65683020e-03  5.71342278e-03 -7.72947725e-03 -9.48377047e-03\n",
      "  -3.59016024e-02  1.13571612e-02 -4.76749893e-03 -3.81343556e-03\n",
      "   1.42287835e-02  2.31695524e-03 -8.75484198e-03  4.52176062e-03\n",
      "   9.35985614e-03 -1.83631908e-02 -1.17430631e-02 -2.20152307e-02\n",
      "  -1.08513876e-03 -4.17842809e-03  9.87029076e-03  3.97494100e-02\n",
      "   7.42903678e-03 -2.36824900e-02  9.16628167e-03 -2.30093207e-02\n",
      "   5.26432097e-02 -1.19137149e-02 -4.07605469e-02 -1.24093173e-02\n",
      "   1.20504294e-03  1.44931842e-02  1.91289932e-02 -3.62265110e-02\n",
      "  -1.68226520e-03  2.45732022e-04  5.77116152e-03  2.23395508e-02\n",
      "  -3.25207375e-02 -9.56720789e-04 -1.47071164e-02  9.82304290e-03\n",
      "   2.81085316e-02  5.77302556e-03  1.79443955e-02 -6.93957973e-03\n",
      "  -7.73878908e-03 -5.08179422e-04  5.19540673e-03 -1.62506029e-02\n",
      "   2.55048387e-02 -2.22917907e-02  1.35257700e-02  6.84876367e-03\n",
      "  -1.42153446e-03  1.60585847e-02  1.60550885e-02 -3.04329768e-03]]\n"
     ]
    }
   ],
   "source": [
    "vec1 = sess.run(vec, feed_dict={model.dropout_keep_prob:1.0})\n",
    "print(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.51419984e-02  2.13891268e-02  3.31077129e-02 -2.10912200e-03\n",
      "   1.85334142e-02 -2.13842485e-02  1.70879215e-02 -2.24037841e-02\n",
      "  -2.46302709e-02  9.78733413e-03  7.99910445e-03  5.05236816e-03\n",
      "   6.02034815e-02 -2.72581843e-03 -2.36835219e-02 -4.12596725e-02\n",
      "   3.05082212e-04 -2.31418684e-02 -7.98030570e-03  2.30648667e-02\n",
      "  -9.65827890e-03  2.07140632e-02 -3.09601780e-02 -2.18294188e-02\n",
      "   1.95513852e-02  8.35482590e-03 -3.13163246e-03  2.02843770e-02\n",
      "   1.63879432e-02 -9.89894941e-03 -1.25068184e-02 -7.14694262e-02\n",
      "   4.09551337e-02 -1.79147106e-02 -2.11598780e-02 -1.61592010e-02\n",
      "   3.15513909e-02 -3.78101878e-02 -1.89091489e-02 -2.20310017e-02\n",
      "  -2.23376863e-02  1.91728584e-02  9.29436181e-04  1.17969618e-03\n",
      "  -5.27444556e-02  1.09635275e-02  2.34819930e-02 -8.22268613e-03\n",
      "  -2.43859366e-04  9.50446259e-03  3.31880040e-02 -3.71786021e-02\n",
      "   2.34874785e-02  8.37863050e-03  4.73898137e-04 -3.68349291e-02\n",
      "   5.85855450e-03  1.37222628e-03  6.01969985e-03  2.47659497e-02\n",
      "   4.22504172e-02 -1.54334586e-02 -2.12557483e-02  8.53758771e-03\n",
      "   1.25632063e-02 -1.40561620e-02  3.10596675e-02 -1.75164826e-02\n",
      "   1.32597936e-03  2.35407166e-02  1.08723296e-02  8.48845020e-03\n",
      "   5.20295985e-02 -1.81982107e-02 -5.71414735e-03  1.00318238e-03\n",
      "  -1.27808163e-02 -1.09910173e-02  2.64188536e-02 -1.29870872e-03\n",
      "   2.35863458e-02  6.08532354e-02  3.81131866e-03 -3.11646983e-03\n",
      "   2.48617828e-02  1.44915376e-02  2.50170827e-02 -2.22891159e-02\n",
      "   1.22133447e-02 -2.86253239e-03  1.59108639e-02  5.80316503e-03\n",
      "  -8.36999342e-03 -2.71970010e-03 -3.58091928e-02 -3.45524661e-02\n",
      "  -1.96907949e-02  3.97806382e-03  2.87910551e-02  2.06744671e-02\n",
      "  -5.64529514e-03  3.30089107e-02  2.44723521e-02 -9.74412728e-03\n",
      "  -5.59279397e-02 -2.20817551e-02 -1.58568118e-02 -2.97994935e-03\n",
      "   7.80645385e-03  2.28035334e-03  1.51435863e-02  1.24084204e-02\n",
      "  -1.65453870e-02  1.87154617e-02  8.05422198e-03 -5.74643351e-03\n",
      "   1.22543788e-02 -1.41578112e-02 -4.75790873e-02 -1.01329945e-03\n",
      "  -1.70126017e-02  1.33647081e-02  5.13065234e-03  3.87076777e-03\n",
      "  -1.70013420e-02 -7.01330742e-03 -5.35272956e-02 -4.53928858e-02\n",
      "   2.52407454e-02  6.26227818e-03  1.34507921e-02  1.60013046e-02\n",
      "   1.40081365e-02 -2.35203244e-02 -1.58473365e-02 -1.32691637e-02\n",
      "  -6.20070286e-03  7.84873031e-03 -1.76111069e-02 -2.59879343e-02\n",
      "  -3.18943150e-03 -1.10243959e-02  3.37331207e-03 -2.77869496e-02\n",
      "   9.85674281e-03  2.37078425e-02  2.29480490e-02 -4.48438078e-02\n",
      "  -1.32978447e-02 -1.07815266e-02  9.53658484e-03  1.51176974e-02\n",
      "  -1.13873426e-02  7.29690166e-03 -7.40868179e-03  7.17574134e-02\n",
      "  -3.61306220e-02  2.58983187e-02 -7.89941195e-03  1.70581862e-02\n",
      "   3.59817669e-02  2.31018700e-02  8.15910846e-03 -1.50957536e-02\n",
      "   2.13660188e-02  1.50307948e-02 -6.13358570e-03  1.35291861e-02\n",
      "   3.48057374e-02  1.61977066e-03  2.21607834e-03  2.14924179e-02\n",
      "  -2.06032246e-02  7.84500688e-03 -1.54981744e-02 -9.97462310e-03\n",
      "   2.48117782e-02  1.69695914e-02 -2.06813011e-02 -1.74553543e-02\n",
      "  -3.67194824e-02  2.76031438e-02 -1.59758218e-02 -1.31528387e-02\n",
      "  -2.21220106e-02 -1.11611122e-02  8.49183928e-03 -4.44230344e-03\n",
      "   2.58770422e-03  9.79128852e-03 -1.32100133e-03 -1.81626342e-02\n",
      "   6.89438405e-03  5.18347993e-02 -3.82825686e-03  1.88915282e-02\n",
      "   2.61729062e-02  2.37532705e-02 -3.08803879e-02 -5.62518649e-03\n",
      "  -6.52131531e-03  1.53209707e-02  2.94391904e-02  3.64124961e-02\n",
      "  -5.30625926e-03 -1.49588231e-02  2.24782042e-02 -1.66361034e-02\n",
      "  -2.24943515e-02 -1.23328073e-02 -3.02824639e-02 -2.78104618e-02\n",
      "  -6.03365572e-03 -7.20747467e-03  4.45110500e-02 -1.80718917e-02\n",
      "   2.07312452e-03 -2.95281820e-02 -3.24219987e-02  2.18644016e-03\n",
      "  -9.35701653e-04 -5.39723132e-03  1.84085090e-02 -1.19533930e-02\n",
      "  -2.21914444e-02 -5.82566205e-03  7.13450415e-03  1.95119958e-02\n",
      "   1.03486385e-02  2.01414153e-02  1.95664167e-02 -5.39270118e-02\n",
      "   1.82849281e-02  3.56031470e-02  2.07794495e-02  2.96568908e-02\n",
      "  -2.08537793e-03  3.78693757e-03 -1.37864258e-02  9.45893768e-03\n",
      "   1.53583782e-02  2.71227211e-02  2.20802985e-02 -6.25195727e-03\n",
      "   3.97555456e-02 -2.90971436e-02  1.83464133e-03  6.47441484e-03\n",
      "  -1.35179013e-02 -6.82838075e-03 -6.64652418e-03 -2.59136688e-02\n",
      "  -7.78861810e-03 -2.99205887e-03 -8.51956382e-03 -2.09082663e-02\n",
      "   1.60882287e-02 -5.04290219e-03 -2.41868235e-02 -1.29089421e-02\n",
      "   5.23361284e-03 -2.95721702e-02 -9.73011716e-04  4.72698407e-03\n",
      "   3.83764990e-02  2.74344180e-02 -3.61288432e-03 -3.48581150e-02\n",
      "   1.53649179e-03 -2.85342131e-02  3.27550806e-02 -3.40058468e-05\n",
      "   6.37941109e-03  3.15723792e-02  1.44345015e-02 -2.44751424e-02\n",
      "  -1.82674695e-02  1.01237902e-02 -1.28853191e-02  2.01799516e-02\n",
      "   1.16079662e-03  5.41512445e-02  1.40051469e-02  4.26546410e-02\n",
      "   1.48777431e-03 -2.57126093e-02  1.42551651e-02 -8.64908751e-03\n",
      "  -2.09678672e-02 -1.24108810e-02  2.16097068e-02  9.53138154e-03\n",
      "   2.81430893e-02 -2.66306475e-03  7.86311226e-04  5.47958771e-03\n",
      "  -3.12594660e-02 -6.53414009e-03 -7.37245986e-03 -4.02336847e-03]\n",
      " [-1.45226680e-02  1.08796740e-02 -8.81869718e-03  7.00329337e-03\n",
      "  -5.82041591e-03  8.85458756e-03  1.54305045e-02 -1.24492748e-02\n",
      "  -2.46488042e-02 -5.56536764e-03  1.37128755e-02 -2.12029628e-02\n",
      "   4.56074774e-02  1.89268924e-02  1.88230835e-02 -2.02977192e-03\n",
      "  -2.70006876e-03  9.44907032e-03 -1.09022418e-02 -1.03505142e-02\n",
      "   9.01048444e-03  2.35129520e-02 -5.68126841e-03 -1.99530683e-02\n",
      "  -1.07516383e-03  5.99143701e-03  6.65077940e-03  1.41477082e-02\n",
      "   1.92939863e-02 -1.88913289e-03  7.30559463e-03 -8.78202263e-03\n",
      "   2.57426240e-02  6.63139019e-03  1.86412979e-03 -2.91027827e-03\n",
      "  -4.93680779e-03 -2.32113991e-02 -1.33059155e-02 -2.93641966e-02\n",
      "  -9.81037878e-03  2.36832313e-02 -1.74004603e-02  5.47188893e-03\n",
      "  -2.40523554e-02  1.53487539e-02  2.28373129e-02 -9.21966229e-03\n",
      "   2.04751268e-02 -1.25561589e-02  1.74773373e-02 -1.22320708e-02\n",
      "   1.31354546e-02  2.01431587e-02  3.09717190e-03 -2.47582197e-02\n",
      "   9.03311744e-03  5.43962605e-03  2.46338956e-02  1.91612989e-02\n",
      "   1.39836138e-02 -1.76001713e-02 -2.67848726e-02  5.21395821e-03\n",
      "   2.29426175e-02 -1.59558430e-02  4.25286777e-03 -1.05035277e-02\n",
      "   7.53949210e-03  4.54009324e-02  3.78754586e-02  3.88417244e-02\n",
      "   1.61531419e-02  1.25985197e-03  2.99928756e-03 -7.38376984e-03\n",
      "  -2.34572217e-02 -9.96111985e-03  1.84899587e-02  1.60317495e-02\n",
      "   6.60610944e-03  2.72306092e-02  2.62038317e-03  5.14434325e-03\n",
      "   1.67611509e-03  7.97825214e-03  8.81321914e-03 -2.53588259e-02\n",
      "  -1.38600706e-03 -3.48164812e-02  1.78543441e-02  1.06730675e-02\n",
      "   8.14836100e-03 -9.80399735e-03 -1.10866213e-02 -2.56483629e-02\n",
      "  -9.89537500e-03  1.05503667e-02  3.05749150e-03 -3.37363034e-03\n",
      "  -7.85504002e-03  2.98008136e-02 -3.45073314e-03 -4.73918021e-03\n",
      "  -7.44615309e-03 -2.79978923e-02 -2.34745797e-02  3.83490184e-03\n",
      "   2.59860642e-02 -1.52098387e-02  7.95498211e-03  1.53632611e-02\n",
      "  -1.71276741e-02  3.29740532e-03 -2.23132707e-02  9.25959647e-03\n",
      "  -2.99988920e-03 -4.56158072e-03 -1.35952253e-02 -6.47015637e-03\n",
      "  -2.28502806e-02  1.35576185e-02 -3.51494327e-02  2.70713419e-02\n",
      "  -1.28827095e-02 -1.52236002e-03  2.82904599e-04 -3.32928970e-02\n",
      "  -3.07597686e-03  3.94849852e-02 -8.28979816e-03  9.10693686e-03\n",
      "  -1.96702704e-02 -5.70623670e-04  5.54192765e-03 -1.13705965e-02\n",
      "  -1.75603095e-03  6.78906776e-03 -2.58090384e-02  1.15353358e-03\n",
      "  -3.56569979e-03 -1.18158404e-02  1.53687615e-02  5.14274044e-03\n",
      "   1.36807635e-02  2.09223758e-02 -3.93483788e-05 -8.61410052e-03\n",
      "   1.38057442e-02 -1.79633703e-02  1.68987624e-02  2.78050341e-02\n",
      "  -5.03900740e-03  1.04939975e-02 -1.55616347e-02  3.38351466e-02\n",
      "  -1.50775220e-02  2.45491341e-02 -3.38786328e-03  5.27573004e-03\n",
      "   2.68898904e-02  2.54523829e-02  1.82070658e-02 -1.04738399e-02\n",
      "  -2.50469288e-03  9.86702275e-03 -8.16788152e-03  1.00384951e-02\n",
      "   1.86475646e-02  3.39444983e-03  1.22418590e-02  4.04511299e-03\n",
      "  -1.29255150e-02 -2.68430933e-02 -2.69709751e-02 -9.69671831e-03\n",
      "   1.19904196e-02  1.94397068e-03 -2.46058055e-03 -3.76695022e-02\n",
      "   2.19195131e-02  1.99569482e-03  3.89691582e-03 -9.37708188e-03\n",
      "  -1.83835812e-02  1.85487175e-03  1.92436539e-02 -2.40532346e-02\n",
      "   8.45196657e-03  1.32708605e-02 -2.26946604e-02  2.96261162e-04\n",
      "  -1.60277716e-03  2.49801278e-02 -1.22400280e-02  1.94353610e-02\n",
      "  -3.57150957e-02  3.97356078e-02 -7.34337885e-03  2.55292244e-02\n",
      "  -3.50704463e-03  1.40157193e-02  1.90194901e-02  2.57549677e-02\n",
      "  -2.29673777e-02 -2.09172387e-02  3.03097088e-02  6.51465775e-03\n",
      "  -9.90256947e-03  1.25061190e-02 -8.12479574e-03 -2.01852731e-02\n",
      "  -1.25103220e-02 -1.06744319e-02  2.50211507e-02 -1.28355753e-02\n",
      "  -2.37942897e-02  6.60387333e-03 -4.51861545e-02 -2.52997987e-02\n",
      "  -1.44446185e-02 -2.34871376e-02 -1.52201103e-02 -1.17628053e-02\n",
      "  -7.26489164e-03  3.18065844e-03  4.54726582e-03  9.84920282e-03\n",
      "  -1.98508240e-03 -2.17977948e-02  1.03809815e-02 -2.24148110e-02\n",
      "   1.72260264e-03  6.25554705e-03 -1.86556228e-03  1.57595687e-02\n",
      "   3.14417947e-03 -7.18052499e-03  9.73371789e-03  4.97715455e-03\n",
      "   6.84081228e-04  5.05960546e-03 -6.54119207e-03  2.20960025e-02\n",
      "  -1.62357986e-02  8.91664904e-03 -2.09552087e-02 -1.58351660e-02\n",
      "  -9.82075650e-03  1.13849258e-02 -1.66506544e-02 -1.41430199e-02\n",
      "   1.17683243e-02 -1.62844360e-03 -2.42238096e-03 -1.12224631e-02\n",
      "   3.63391684e-03 -1.27230957e-02  2.67035794e-03 -1.59988888e-02\n",
      "   1.13584762e-02 -1.56253837e-02  7.42130913e-03  3.49073373e-02\n",
      "   6.62877783e-03 -9.53839347e-03  1.83868054e-02 -2.62389425e-02\n",
      "   2.56571639e-02 -9.92638990e-03 -2.87270285e-02 -2.06519067e-02\n",
      "   2.10264921e-02 -1.02554206e-02  2.41132658e-02 -3.20784040e-02\n",
      "  -9.73635633e-03 -6.03062660e-03 -1.16851553e-02  1.99209023e-02\n",
      "  -2.18216293e-02  1.37928352e-02 -1.65251847e-02  3.63102108e-02\n",
      "   4.84154513e-03  2.16063764e-03  3.70288640e-02  8.93945864e-04\n",
      "  -2.67993961e-03 -1.24607449e-02  1.96913891e-02 -4.75240732e-03\n",
      "   1.22686587e-02 -7.43941590e-03  7.71822967e-03 -5.79440559e-04\n",
      "  -9.24979895e-03  2.08953172e-02  1.85083435e-03 -1.21936444e-02]\n",
      " [-8.32583383e-03 -1.23561770e-02 -6.23731036e-03 -1.38305910e-02\n",
      "  -9.87764727e-03  1.48653481e-02  2.19723489e-02  9.80291329e-03\n",
      "  -1.66341867e-02 -2.75616255e-02  2.37630121e-02 -2.46519111e-02\n",
      "   3.23570147e-02  4.31065187e-02  1.40168853e-02 -1.65416114e-02\n",
      "   2.54608924e-03  6.07933942e-03 -7.83149619e-03  9.14535299e-03\n",
      "  -1.94442980e-02  1.32369362e-02 -1.55770089e-02 -7.21313152e-03\n",
      "   2.35469081e-04  7.82562885e-03  9.92035121e-03  1.64007042e-02\n",
      "   1.76411532e-02  3.30495872e-02 -1.79780573e-02 -2.20923871e-03\n",
      "  -2.75067752e-04  1.99641157e-02  3.10081453e-03 -6.55612908e-03\n",
      "  -5.32921031e-03 -8.69134255e-03 -1.29841622e-02 -3.36116701e-02\n",
      "   6.72742492e-03 -1.41940417e-03 -3.57339568e-02 -3.12882243e-03\n",
      "  -8.28498323e-03  2.10498925e-02  1.05753802e-02 -1.00137135e-02\n",
      "   1.91020351e-02 -3.68227363e-02 -1.02309342e-02 -5.72777959e-03\n",
      "   9.76403803e-03  1.83702894e-02 -4.04311530e-03 -1.59305800e-02\n",
      "   6.38633873e-03 -1.85995037e-03  5.15430048e-02  3.19662094e-02\n",
      "   2.60634907e-02  1.04565155e-02 -2.03955770e-02  9.96664260e-03\n",
      "  -2.69373553e-03 -2.41925903e-02 -1.09911291e-02 -2.58241259e-02\n",
      "   1.65198017e-02  3.10332850e-02  4.45526186e-03  2.86956280e-02\n",
      "  -1.36708049e-03 -8.97501409e-03 -1.36114862e-02 -5.64709771e-03\n",
      "  -2.43705660e-02 -7.78378639e-03  6.27360772e-03  2.90497094e-02\n",
      "   5.86786494e-03  1.93520468e-02  1.81896407e-02  3.53438896e-03\n",
      "  -3.73141491e-04  7.74416234e-03  8.52061994e-03 -2.68667731e-02\n",
      "  -3.30567965e-03 -3.62508446e-02 -2.67097098e-03  7.25304615e-03\n",
      "   2.31587086e-02  1.93363545e-03 -3.96313891e-03 -1.84423998e-02\n",
      "  -6.98036281e-03  1.63643975e-02  2.66241049e-03 -1.83102749e-02\n",
      "   1.05435112e-02  1.10726682e-02  1.57758668e-02 -5.72053995e-03\n",
      "   1.39961950e-04 -2.00421847e-02 -8.50533880e-03  6.18015509e-03\n",
      "   1.22760534e-02  5.64316940e-03  3.69179249e-03  7.74053391e-03\n",
      "  -1.35393338e-02  1.40997469e-02 -8.32779333e-03  2.68636774e-02\n",
      "  -1.85897537e-02 -5.29728690e-03 -2.14100089e-02 -1.83767881e-02\n",
      "  -1.45614808e-02  3.26009933e-03 -1.77344140e-02  2.86730714e-02\n",
      "  -2.34046169e-02  1.83253102e-02  4.36243461e-03 -2.90890448e-02\n",
      "  -4.95260535e-03  4.77008596e-02  2.99357483e-03 -2.82403477e-03\n",
      "  -3.47106382e-02 -7.56356865e-03 -2.49880785e-03 -2.61322092e-02\n",
      "   1.48291383e-02  1.32986289e-02 -1.45693338e-02  2.97896266e-02\n",
      "  -1.21172015e-02 -4.63385461e-03 -1.68535905e-03  3.75981964e-02\n",
      "   2.82225781e-03  8.89418647e-03 -1.33448895e-02 -1.15160253e-02\n",
      "   3.27057987e-02 -1.42046530e-02  1.37463491e-02  1.78591646e-02\n",
      "  -5.25485072e-03  2.91020647e-02 -2.58631743e-02  1.79850385e-02\n",
      "  -2.83556432e-03 -4.50246036e-03 -1.67879416e-03 -3.33395461e-03\n",
      "   1.91216283e-02  3.98004875e-02 -7.13684363e-04 -9.52368602e-03\n",
      "  -8.25574435e-03  1.43895112e-03  6.37725275e-03  4.33616340e-03\n",
      "   2.29660589e-02  3.39219882e-03 -1.72225181e-02 -9.47669148e-03\n",
      "  -1.83780268e-02 -2.60679014e-02 -1.22761652e-02 -1.67804249e-02\n",
      "   3.45969275e-02  2.06508692e-02 -9.90262069e-03 -4.18633372e-02\n",
      "   1.42274201e-02 -3.60580999e-03 -1.09387550e-03  3.56900133e-03\n",
      "  -2.19186358e-02 -1.50556518e-02  2.11467855e-02 -2.16222778e-02\n",
      "   1.68333203e-02  1.51712941e-02 -3.49790119e-02  3.67036387e-02\n",
      "  -1.78820062e-02  9.79995169e-03 -8.61424371e-04  3.34528275e-02\n",
      "  -6.87644258e-02  3.89969908e-02  2.32625101e-02 -3.98146361e-03\n",
      "  -1.80686936e-02  3.22771445e-02  1.07594975e-03  1.07247652e-02\n",
      "  -1.97494142e-02 -7.71216769e-03  7.31046079e-03  1.26805119e-02\n",
      "   6.66190404e-04  1.86243188e-03  3.84185985e-02 -7.14949099e-03\n",
      "  -2.74789371e-02 -1.39957238e-02 -1.26229716e-03 -8.28762725e-03\n",
      "  -2.26532184e-02  8.01599585e-04 -2.39007398e-02 -4.06358838e-02\n",
      "  -1.23769846e-02 -3.84693518e-02 -1.58408396e-02 -1.84648926e-03\n",
      "  -9.38885473e-03  3.02674342e-03  2.94070393e-02  1.34680290e-02\n",
      "   2.42915889e-03 -7.17028789e-03  1.60329323e-02  5.21231350e-03\n",
      "  -1.01957656e-02 -1.63004603e-02 -1.97092537e-04  2.12277677e-02\n",
      "   1.19646592e-02 -1.16621349e-02  1.95152462e-02  1.33006852e-02\n",
      "   2.67575122e-02 -2.61869021e-02  4.75334330e-03 -4.29440150e-03\n",
      "  -6.65683020e-03  5.71342278e-03 -7.72947725e-03 -9.48377047e-03\n",
      "  -3.59016024e-02  1.13571612e-02 -4.76749893e-03 -3.81343556e-03\n",
      "   1.42287835e-02  2.31695524e-03 -8.75484198e-03  4.52176062e-03\n",
      "   9.35985614e-03 -1.83631908e-02 -1.17430631e-02 -2.20152307e-02\n",
      "  -1.08513876e-03 -4.17842809e-03  9.87029076e-03  3.97494100e-02\n",
      "   7.42903678e-03 -2.36824900e-02  9.16628167e-03 -2.30093207e-02\n",
      "   5.26432097e-02 -1.19137149e-02 -4.07605469e-02 -1.24093173e-02\n",
      "   1.20504294e-03  1.44931842e-02  1.91289932e-02 -3.62265110e-02\n",
      "  -1.68226520e-03  2.45732022e-04  5.77116152e-03  2.23395508e-02\n",
      "  -3.25207375e-02 -9.56720789e-04 -1.47071164e-02  9.82304290e-03\n",
      "   2.81085316e-02  5.77302556e-03  1.79443955e-02 -6.93957973e-03\n",
      "  -7.73878908e-03 -5.08179422e-04  5.19540673e-03 -1.62506029e-02\n",
      "   2.55048387e-02 -2.22917907e-02  1.35257700e-02  6.84876367e-03\n",
      "  -1.42153446e-03  1.60585847e-02  1.60550885e-02 -3.04329768e-03]]\n"
     ]
    }
   ],
   "source": [
    "vec1 = sess.run(vec, feed_dict={model.dropout_keep_prob:1.0})\n",
    "print(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = tf.constant(0.0, shape=[input_x.shape[0], 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins\n",
    "x_len = tf.constant(int(ins.shape[1]), shape =[int(ins.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_6:0\", shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_4:0' shape=(10,) dtype=float64>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
