{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 20:52:29.969840 139931423835968 deprecation_wrapper.py:119] From /home/hadoop/ERD/baslines/ERDProj/ERDModel.py:3: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load glove finished\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from collections import deque\n",
    "from ERDModel import RL_GRU2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.path.curdir), '../'))\n",
    "from dataUtils import *\n",
    "from logger import MyLogger\n",
    "os.chdir(\"/home/hadoop/ERD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "logger = MyLogger(\"ERDMain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_train(sess, summary_writer, mm, t_acc, t_steps, new_data_len=[]):\n",
    "    sum_loss = 0.0\n",
    "    sum_acc = 0.0\n",
    "    ret_acc = 0.0\n",
    "    init_states = np.zeros([FLAGS.batch_size, FLAGS.hidden_dim], dtype=np.float32)\n",
    "\n",
    "    for i in range(t_steps):\n",
    "        if len(new_data_len) > 0:\n",
    "            x, x_len, y = get_df_batch(i, new_data_len)\n",
    "        else:\n",
    "            x, x_len, y = get_df_batch(i)\n",
    "        feed_dic = {mm.input_x: x, mm.x_len: x_len, mm.input_y: y, mm.init_states: init_states, mm.dropout_keep_prob: 0.5}\n",
    "        _, step, loss, acc = sess.run([df_train_op, df_global_step, mm.loss, mm.accuracy], feed_dic)\n",
    "        summary = tf.Summary(value=[\n",
    "                    tf.Summary.Value(tag=\"df_train_loss\", simple_value=loss),\n",
    "                    tf.Summary.Value(tag=\"df_train_accuracy\", simple_value=acc),\n",
    "                ])\n",
    "        summary_writer.add_summary(summary, step)\n",
    "\n",
    "        sum_loss += loss\n",
    "        sum_acc += acc\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            sum_loss = sum_loss / 10\n",
    "            sum_acc = sum_acc / 10\n",
    "            ret_acc = sum_acc\n",
    "            print(get_curtime() + \" Step: \" + str(step) + \" Training loss: \" + str(sum_loss) + \" accuracy: \" + str(sum_acc))\n",
    "            logger.info(get_curtime() + \" Step: \" + str(step) + \" Training loss: \" + str(sum_loss) + \" accuracy: \" + str(sum_acc))\n",
    "\n",
    "            if sum_acc > t_acc:\n",
    "                break\n",
    "            sum_acc = 0.0\n",
    "            sum_loss = 0.0\n",
    "\n",
    "    print(get_curtime() + \" Train df Model End.\")\n",
    "    logger.info(get_curtime() + \" Train df Model End.\")\n",
    "    return ret_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rl_train(sess, mm, t_rw, t_steps):\n",
    "    ids = np.array(range(FLAGS.batch_size), dtype=np.int32)\n",
    "    seq_states = np.zeros([FLAGS.batch_size], dtype=np.int32)\n",
    "    isStop = np.zeros([FLAGS.batch_size], dtype=np.int32)\n",
    "    max_id = FLAGS.batch_size\n",
    "    init_states = np.zeros([FLAGS.batch_size, FLAGS.hidden_dim], dtype=np.float32)\n",
    "    feed_dic = {mm.init_states: init_states}\n",
    "    state = sess.run(mm.df_state, feed_dic)\n",
    "    D = deque()\n",
    "    ssq = []\n",
    "    print(\"in RL the begining\")\n",
    "    logger.info(\"in RL the begining\")\n",
    "    # get_new_len(sess, mm)\n",
    "    data_ID = get_data_ID()\n",
    "    if len(data_ID) % FLAGS.batch_size == 0: # the total number of events\n",
    "        flags = int(len(data_ID) / FLAGS.batch_size)\n",
    "    else:\n",
    "        flags = int(len(data_ID) / FLAGS.batch_size) + 1\n",
    "    for i in range(flags):\n",
    "        x, x_len, y = get_df_batch(i)\n",
    "        feed_dic = {mm.input_x: x, mm.x_len: x_len, mm.input_y: y, mm.init_states:init_states, mm.dropout_keep_prob: 1.0}\n",
    "        t_ssq = sess.run(mm.out_seq, feed_dic)# t_ssq = [batchsize, max_seq, scores]\n",
    "        if len(ssq) > 0:\n",
    "            ssq = np.append(ssq, t_ssq, axis=0)\n",
    "        else:\n",
    "            ssq = t_ssq\n",
    "\n",
    "    print(get_curtime() + \" Now Start RL training ...\")\n",
    "    logger.info(get_curtime() + \" Now Start RL training ...\")\n",
    "    counter = 0\n",
    "    sum_rw = 0.0 # sum of rewards\n",
    "\n",
    "    data_len = get_data_len()\n",
    "    while True:\n",
    "        if counter > FLAGS.OBSERVE:\n",
    "            sum_rw += np.mean(rw)\n",
    "            if counter % 200 == 0:\n",
    "                sum_rw = sum_rw / 2000\n",
    "                print(get_curtime() + \" Step: \" + str(step) + \" REWARD IS \" + str(sum_rw))\n",
    "                logger.info(get_curtime() + \" Step: \" + str(step) + \" REWARD IS \" + str(sum_rw))\n",
    "                if sum_rw > t_rw:\n",
    "                    print(\"Retch The Target Reward\")\n",
    "                    logger.info(\"Retch The Target Reward\")\n",
    "                    break\n",
    "                if counter > t_steps:\n",
    "                    print(\"Retch The Target Steps\")\n",
    "                    logger.info(\"Retch The Target Steps\")\n",
    "                    break\n",
    "                sum_rw = 0.0\n",
    "            s_state, s_x, s_isStop, s_rw = get_RL_Train_batch(D)\n",
    "            feed_dic = {mm.rl_state: s_state, mm.rl_input: s_x, mm.action: s_isStop, mm.reward:s_rw, mm.dropout_keep_prob: 0.5}\n",
    "            _, step = sess.run([rl_train_op, rl_global_step], feed_dic)\n",
    "\n",
    "        x, y, ids, seq_states, max_id = get_rl_batch(ids, seq_states, isStop, max_id, 0, 3150)\n",
    "        batch_dic = {mm.rl_state: state, mm.rl_input: x, mm.dropout_keep_prob: 1.0}\n",
    "        isStop, mss, mNewState = sess.run([mm.isStop, mm.stopScore, mm.rl_new_state], batch_dic)\n",
    "\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            if random.random() < FLAGS.random_rate:\n",
    "                isStop[j] = np.argmax(np.random.rand(2))\n",
    "            if seq_states[j] == data_len[ids[j]]:\n",
    "                isStop[j] = 1\n",
    "\n",
    "        # eval\n",
    "        rw = get_reward(isStop, mss, ssq, ids, seq_states)\n",
    "\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            D.append((state[j], x[j], isStop[j], rw[j]))\n",
    "            if len(D) > FLAGS.max_memory:\n",
    "                D.popleft()\n",
    "\n",
    "        state = mNewState\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            if isStop[j] == 1:\n",
    "                # init_states = np.zeros([FLAGS.batch_size, FLAGS.hidden_dim], dtype=np.float32)\n",
    "                # feed_dic = {mm.init_states: init_states}\n",
    "                # state[j] = sess.run(mm.df_state, feed_dic)\n",
    "                state[j] = np.zeros([FLAGS.hidden_dim], dtype=np.float32)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(sess, mm):\n",
    "#     start_ef = int(eval_flag / FLAGS.batch_size)\n",
    "#     end_ef = int(len(data_ID) / FLAGS.batch_size) + 1\n",
    "    data_ID = get_data_ID()\n",
    "    batchs = int( len(data_ID)/FLAGS.batch_size )\n",
    "    init_states = np.zeros([FLAGS.batch_size, FLAGS.hidden_dim], dtype=np.float32)\n",
    "\n",
    "    counter = 0\n",
    "    sum_acc = 0.0\n",
    "\n",
    "    for i in range(batchs):\n",
    "        x, x_len, y = get_df_batch(i)\n",
    "        feed_dic = {mm.input_x: x, mm.x_len: x_len, mm.input_y: y, mm.init_states: init_states, mm.dropout_keep_prob: 1.0}\n",
    "        loss, acc = sess.run([mm.loss, mm.accuracy], feed_dic)\n",
    "        counter += 1\n",
    "        sum_acc += acc\n",
    "\n",
    "    print(sum_acc / counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0924 20:52:39.392374 139931423835968 logger.py:24] 2019-09-24 20:52:39 Loading data ...\n",
      "I0924 20:52:39.447720 139931423835968 logger.py:24] 2019-09-24 20:52:39 Data loaded.\n",
      "I0924 20:52:39.448502 139931423835968 logger.py:24] (300, 200, 101, 156, 2, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-24 20:52:39 Loading data ...\n",
      "max_sent: 156 ,  max_seq_len: 101\n",
      "835 data loaded\n",
      "2019-09-24 20:52:39 Data loaded.\n",
      "300 200 101 156 2 2\n"
     ]
    }
   ],
   "source": [
    "print(get_curtime() + \" Loading data ...\")\n",
    "logger.info(get_curtime() + \" Loading data ...\")\n",
    "# load_data(FLAGS.data_file_path)\n",
    "load_data_fast()\n",
    "print(get_curtime() + \" Data loaded.\")\n",
    "logger.info(get_curtime() + \" Data loaded.\")\n",
    "gpu_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "# (self, input_dim, hidden_dim, max_seq_len, max_word_len, class_num, action_num):\n",
    "print(FLAGS.embedding_dim, FLAGS.hidden_dim, FLAGS.max_seq_len, FLAGS.max_sent_len, FLAGS.class_num, FLAGS.action_num)\n",
    "logger.info((FLAGS.embedding_dim, FLAGS.hidden_dim, FLAGS.max_seq_len, FLAGS.max_sent_len, FLAGS.class_num, FLAGS.action_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=gpu_config)\n",
    "with  sess.as_default():\n",
    "    with tf.device('/GPU:0'):\n",
    "        mm = RL_GRU2(FLAGS.embedding_dim, FLAGS.hidden_dim, FLAGS.max_seq_len,\n",
    "                     FLAGS.max_sent_len, FLAGS.class_num, FLAGS.action_num, FLAGS.sent_num)\n",
    "\n",
    "        # df model\n",
    "        df_global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        df_train_op = tf.train.AdagradOptimizer(0.05).minimize(mm.loss, df_global_step)\n",
    "\n",
    "        # rl model\n",
    "        rl_global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        rl_train_op = tf.train.AdamOptimizer(0.001).minimize(mm.rl_cost, rl_global_step)\n",
    "\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=4)\n",
    "        sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "2 root error(s) found.\n  (0) Failed precondition: Attempting to use uninitialized value Variable_1\n\t [[node Variable_1/read (defined at /home/hadoop/ERD/baslines/ERDProj/ERDModel.py:47) ]]\n\t [[accuracy/_27]]\n  (1) Failed precondition: Attempting to use uninitialized value Variable_1\n\t [[node Variable_1/read (defined at /home/hadoop/ERD/baslines/ERDProj/ERDModel.py:47) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'Variable_1/read':\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-203af24a5d20>\", line 3, in <module>\n    FLAGS.max_sent_len, FLAGS.class_num, FLAGS.action_num, FLAGS.sent_num)\n  File \"/home/hadoop/ERD/baslines/ERDProj/ERDModel.py\", line 47, in __init__\n    b_ps = tf.Variable(tf.constant(0.01, shape=[class_num])) #\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 259, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 220, in _variable_v1_call\n    shape=shape)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 198, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2511, in default_variable_creator\n    shape=shape)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 263, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1568, in __init__\n    shape=shape)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1755, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 86, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4253, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) Failed precondition: Attempting to use uninitialized value Variable_1\n\t [[{{node Variable_1/read}}]]\n\t [[accuracy/_27]]\n  (1) Failed precondition: Attempting to use uninitialized value Variable_1\n\t [[{{node Variable_1/read}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-91c5a3cc761a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-95516b7b6e15>\u001b[0m in \u001b[0;36meval\u001b[0;34m(sess, mm)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_df_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mfeed_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minit_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msum_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) Failed precondition: Attempting to use uninitialized value Variable_1\n\t [[node Variable_1/read (defined at /home/hadoop/ERD/baslines/ERDProj/ERDModel.py:47) ]]\n\t [[accuracy/_27]]\n  (1) Failed precondition: Attempting to use uninitialized value Variable_1\n\t [[node Variable_1/read (defined at /home/hadoop/ERD/baslines/ERDProj/ERDModel.py:47) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'Variable_1/read':\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-203af24a5d20>\", line 3, in <module>\n    FLAGS.max_sent_len, FLAGS.class_num, FLAGS.action_num, FLAGS.sent_num)\n  File \"/home/hadoop/ERD/baslines/ERDProj/ERDModel.py\", line 47, in __init__\n    b_ps = tf.Variable(tf.constant(0.01, shape=[class_num])) #\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 259, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 220, in _variable_v1_call\n    shape=shape)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 198, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2511, in default_variable_creator\n    shape=shape)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 263, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1568, in __init__\n    shape=shape)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1755, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 86, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4253, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    eval(sess, mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with  sess.as_default():\n",
    "    with tf.device('/GPU:0'):\n",
    "        mm = RL_GRU2(FLAGS.embedding_dim, FLAGS.hidden_dim, FLAGS.max_seq_len,\n",
    "                     FLAGS.max_sent_len, FLAGS.class_num, FLAGS.action_num, FLAGS.sent_num)\n",
    "\n",
    "        # df model\n",
    "        df_global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        df_train_op = tf.train.AdagradOptimizer(0.05).minimize(mm.loss, df_global_step)\n",
    "\n",
    "        # rl model\n",
    "        rl_global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        rl_train_op = tf.train.AdamOptimizer(0.001).minimize(mm.rl_cost, rl_global_step)\n",
    "\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=4)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(\"./reports/\", graph=sess.graph)\n",
    "df_train(sess, summary_writer, mm, 0.90, 20000)\n",
    "\n",
    "for i in range(20):\n",
    "    rl_train(sess, mm, 0.5, 50000)\n",
    "    saver.save(sess, \"rl_saved_erd/model\"+str(i))\n",
    "    print(\"rl_model \"+str(i)+\" saved\")\n",
    "    logger.info(\"rl_model \"+str(i)+\" saved\")\n",
    "    new_len = get_new_len(sess, mm)\n",
    "    acc = df_train(sess, summary_writer, mm, 0.9, 1000, new_len)\n",
    "    saver.save(sess, \"df_saved_erd/model\"+str(i))\n",
    "    print(\"df_model \"+str(i)+\" saved\")\n",
    "    logger.info(\"df_model \"+str(i)+\" saved\")\n",
    "    if acc > 0.9:\n",
    "        break\n",
    "\n",
    "print(\"The End of My Program\")\n",
    "logger.info(\"The End of My Program\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
