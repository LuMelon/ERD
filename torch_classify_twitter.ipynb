{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_transformers import *\n",
    "from torch import nn\n",
    "from SubjObjLoader import *\n",
    "import numpy as np\n",
    "import importlib\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, t, c = BertModel,       BertTokenizer,      'bert-base-uncased'\n",
    "tt = t.from_pretrained(\"bert-base-uncased\", cached_dir = \"/home/hadoop/transformer_pretrained_models/bert-base-uncased-pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = b.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_file = \"/home/hadoop/rotten_imdb/subj.data\"\n",
    "obj_file = \"/home/hadoop/rotten_imdb/obj.data\"\n",
    "tr, dev, te = load_data(subj_file, obj_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = SubjObjReader(tr, 20, tt)\n",
    "valid_reader = SubjObjReader(dev, 20, tt)\n",
    "test_reader =  SubjObjReader(te, 20, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y, l in train_reader.iter():\n",
    "#     break\n",
    "\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    \"\"\"\n",
    "        Input: the outputs of bert\n",
    "        Model: BiLSTM\n",
    "        Output: sentence embedding\n",
    "    \"\"\"\n",
    "    def __init__(   self,\n",
    "                    bert ,\n",
    "                    hidden_size,\n",
    "                    rnn_size, \n",
    "                    senti_num,\n",
    "                    drop_out\n",
    "                ):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.gru = nn.GRU(hidden_size, rnn_size, 1, batch_first=True)\n",
    "        self.classifier = nn.Linear(rnn_size, senti_num)\n",
    "        \n",
    "    def forward(self, word_ids):\n",
    "        outs = [self.bert( torch.tensor([input_]).cuda() )\n",
    "                for input_ in word_ids]\n",
    "#         cls_feature =torch.cat([item[0][0][0] + item[1][0] for item in outs], axis=0).reshape([-1, 768]).cuda()\n",
    "        states = [item[0][0] for item in outs]\n",
    "        pad = rnn_utils.pad_sequence(states, batch_first=True)\n",
    "        h_outs, h_final = self.gru(pad)\n",
    "        cls_feature = h_final[0] + h_outs.max(axis=1)[0]\n",
    "        pred_scores = self.classifier(cls_feature)\n",
    "        return pred_scores, cls_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_Accs(ylabel, pred_scores):\n",
    "    correct_preds = np.array([1 if y1==y2 else 0 for (y1, y2) in zip(ylabel, pred_scores.argmax(axis=1))])\n",
    "    y_idxs = [idx if yl >0 else idx - len(ylabel) for (idx, yl) in enumerate(ylabel)]\n",
    "    pos_idxs = list(filter(lambda x: x > 0, y_idxs))\n",
    "    neg_idxs = list(filter(lambda x: x < 0, y_idxs))\n",
    "    acc = sum(correct_preds) / (1.0 * len(ylabel))\n",
    "    pos_acc = sum(correct_preds[pos_idxs])/(1.0*len(pos_idxs))\n",
    "    neg_acc = sum(correct_preds[neg_idxs])/(1.0*len(neg_idxs))\n",
    "    return acc, pos_acc, neg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss_Fn(ylabel, pred_scores):\n",
    "    diff = (ylabel - pred_scores)*(ylabel - pred_scores)\n",
    "    return diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(bert, train_reader, valid_reader, test_reader, hidden_dim, logger, logdir):\n",
    "    max_epoch = 5\n",
    "    loss_fn = Loss_Fn\n",
    "    senti_model = SentimentModel(bert, hidden_dim, 300, 2, 0.8).cuda()\n",
    "    optim = torch.optim.Adagrad([\n",
    "#                                 {'params': senti_model.bert.parameters(), 'lr':1e-2},\n",
    "                                {'params': senti_model.classifier.parameters(), 'lr': 1e-1},\n",
    "                                {'params': senti_model.gru.parameters(), 'lr': 1e-1}\n",
    "                             ],\n",
    "                                weight_decay = 0.2\n",
    "            \n",
    "    )\n",
    "    writer = SummaryWriter(logdir)\n",
    "    batches = train_reader.label.shape[0]\n",
    "    step = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        sum_acc = 0.0\n",
    "        sum_loss = 0.0\n",
    "        for x, y, l in  valid_reader.iter():\n",
    "            pred_scores, _ = senti_model(x)\n",
    "            ylabel = y.argmax(axis=1)\n",
    "            acc, pos_acc, neg_acc = Count_Accs(ylabel, pred_scores)\n",
    "            print(\"step %d| pos_acc/neg_acc = %6.8f/%6.7f, pos_pred/all_pred = %2d/%2d\"%(step, \n",
    "                                                                                         pos_acc, neg_acc,\n",
    "                                                                                         sum(pred_scores.argmax(axis=1)),\n",
    "                                                                                         len(pred_scores)\n",
    "                                                                                        ))\n",
    "            loss = loss_fn(pred_scores, torch.tensor(y, dtype=torch.float32).cuda())\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            writer.add_scalar('Train Loss', loss, step)\n",
    "            writer.add_scalar('Train Accuracy', acc, step)\n",
    "            \n",
    "            sum_acc += acc\n",
    "            sum_loss += loss\n",
    "            step += 1\n",
    "            \n",
    "            if step % 20 == 0:\n",
    "                sum_loss = sum_loss / 10\n",
    "                sum_acc = sum_acc / 10\n",
    "                ret_acc = sum_acc\n",
    "                print('%6d: %d [%5d/%5d], train_loss/accuracy = %6.8f/%6.7f' % (step,\n",
    "                                                        epoch, step%batches,\n",
    "                                                        batches,\n",
    "                                                        sum_loss, sum_acc,\n",
    "                                                        ))\n",
    "                logger.info('%6d: %d [%5d/%5d], train_loss/accuracy = %6.8f/%6.7f' % (step,\n",
    "                                                            epoch, step%batches,\n",
    "                                                            batches,\n",
    "                                                            sum_loss, sum_acc,\n",
    "                                                        ))\n",
    "                sum_acc = 0.0\n",
    "                sum_loss = 0.0\n",
    "                \n",
    "        sum_loss = 0\n",
    "        sum_acc = 0\n",
    "        for x, y, l in  valid_reader.iter():\n",
    "            print(\"valid count:\", count)\n",
    "            pred_scores, _ = senti_model(x)\n",
    "            loss = loss_fn(pred_scores, torch.tensor(y, dtype=torch.float32).cuda())\n",
    "            loss.backward() # to release the GPU cache...... \n",
    "            sum_acc += acc\n",
    "            sum_loss += loss\n",
    "            count += 1\n",
    "        sum_acc = sum_acc/(1.0*valid_reader.label.shape[0])\n",
    "        sum_loss = sum_loss/(1.0*valid_reader.label.shape[0])\n",
    "        print('[%5d/%5d], valid_loss/accuracy = %6.8f/%6.7f' % (epoch, max_epoch,\n",
    "                                                    sum_loss, sum_acc,\n",
    "                                                    ))\n",
    "        logger.info('[%5d/%5d], valid_loss/accuracy = %6.8f/%6.7f' % (epoch, max_epoch,\n",
    "                                                                sum_loss, sum_acc,\n",
    "                                                                ))\n",
    "        writer.add_scalar('Valid Loss', sum_loss, epoch)\n",
    "        writer.add_scalar('Valid Accuracy', sum_acc, epoch)\n",
    "        save_as = '/home/hadoop/ERD/BERTTwitter/epoch%03d_%.4f.pkl' % (step%1000, sum_acc)\n",
    "        torch.save(senti_model.state_dict(), save_as)\n",
    "        sum_acc = 0.0\n",
    "        sum_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0| pos_acc/neg_acc = 0.75000000/0.5000000, pos_pred/all_pred = 13/20\n",
      "step 1| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 2| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 3| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 4| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 5| pos_acc/neg_acc = 0.00000000/1.0000000, pos_pred/all_pred =  0/20\n",
      "step 6| pos_acc/neg_acc = 0.90909091/0.3750000, pos_pred/all_pred = 16/20\n",
      "step 7| pos_acc/neg_acc = 0.11111111/0.7000000, pos_pred/all_pred =  4/20\n",
      "step 8| pos_acc/neg_acc = 0.90000000/0.0000000, pos_pred/all_pred = 19/20\n",
      "step 9| pos_acc/neg_acc = 0.00000000/1.0000000, pos_pred/all_pred =  0/20\n",
      "step 10| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 11| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 12| pos_acc/neg_acc = 0.08333333/1.0000000, pos_pred/all_pred =  1/20\n",
      "step 13| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 14| pos_acc/neg_acc = 0.00000000/1.0000000, pos_pred/all_pred =  0/20\n",
      "step 15| pos_acc/neg_acc = 1.00000000/0.1000000, pos_pred/all_pred = 19/20\n",
      "step 16| pos_acc/neg_acc = 0.16666667/0.7857143, pos_pred/all_pred =  4/20\n",
      "step 17| pos_acc/neg_acc = 0.00000000/1.0000000, pos_pred/all_pred =  0/20\n",
      "step 18| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 19| pos_acc/neg_acc = 0.00000000/1.0000000, pos_pred/all_pred =  0/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:BERTSubObj:    20: 0 [   20/  425], train_loss/accuracy = 139.34754944/1.0100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    20: 0 [   20/  425], train_loss/accuracy = 139.34754944/1.0100000\n",
      "valid count: 0\n",
      "valid count: 1\n",
      "valid count: 2\n",
      "valid count: 3\n",
      "valid count: 4\n",
      "valid count: 5\n",
      "valid count: 6\n",
      "valid count: 7\n",
      "valid count: 8\n",
      "valid count: 9\n",
      "valid count: 10\n",
      "valid count: 11\n",
      "valid count: 12\n",
      "valid count: 13\n",
      "valid count: 14\n",
      "valid count: 15\n",
      "valid count: 16\n",
      "valid count: 17\n",
      "valid count: 18\n",
      "valid count: 19\n",
      "valid count: 20\n",
      "valid count: 21\n",
      "valid count: 22\n",
      "valid count: 23\n",
      "valid count: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:BERTSubObj:[    0/    5], valid_loss/accuracy = 2.09525800/0.5500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0/    5], valid_loss/accuracy = 2.09525800/0.5500000\n",
      "step 20| pos_acc/neg_acc = 0.00000000/1.0000000, pos_pred/all_pred =  0/20\n",
      "step 21| pos_acc/neg_acc = 1.00000000/0.0000000, pos_pred/all_pred = 20/20\n",
      "step 22| pos_acc/neg_acc = 0.00000000/1.0000000, pos_pred/all_pred =  0/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7d047a98882c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMyLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BERTSubObj\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BERTSubjObj\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-9b3d856f81cd>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(bert, train_reader, valid_reader, test_reader, hidden_dim, logger, logdir)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mvalid_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mpred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msenti_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mylabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCount_Accs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-49575dc88c35>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_ids)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         outs = [self.bert( torch.tensor([input_]).cuda() )\n\u001b[0;32m---> 21\u001b[0;31m                 for input_ in word_ids]\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#         cls_feature =torch.cat([item[0][0][0] + item[1][0] for item in outs], axis=0).reshape([-1, 768]).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-49575dc88c35>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         outs = [self.bert( torch.tensor([input_]).cuda() )\n\u001b[0;32m---> 21\u001b[0;31m                 for input_ in word_ids]\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#         cls_feature =torch.cat([item[0][0][0] + item[1][0] for item in outs], axis=0).reshape([-1, 768]).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    713\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    714\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    716\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from logger import MyLogger\n",
    "logger = MyLogger(\"BERTSubObj\")\n",
    "Train(bb, train_reader, valid_reader, test_reader, 768, logger, \"BERTSubjObj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.\n",
    "# BERT_MODEL_CLASSES = [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
    "#                       BertForSequenceClassification, BertForMultipleChoice, BertForTokenClassification,\n",
    "#                       BertForQuestionAnswering]\n",
    "\n",
    "# # All the classes for an architecture can be initiated from pretrained weights for this architecture\n",
    "# # Note that additional weights added for fine-tuning are only initialized\n",
    "# # and need to be trained on the down-stream task\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# for model_class in BERT_MODEL_CLASSES:\n",
    "#     # Load pretrained model/tokenizer\n",
    "#     model = model_class.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Models can return full list of hidden-states & attentions weights at each layer\n",
    "# model = model_class.from_pretrained(pretrained_weights,\n",
    "#                                     output_hidden_states=True,\n",
    "#                                     output_attentions=True)\n",
    "# input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])\n",
    "# all_hidden_states, all_attentions = model(input_ids)[-2:]\n",
    "\n",
    "# # Models are compatible with Torchscript\n",
    "# model = model_class.from_pretrained(pretrained_weights, torchscript=True)\n",
    "# traced_model = torch.jit.trace(model, (input_ids,))\n",
    "\n",
    "# # Simple serialization for models and tokenizers\n",
    "# model.save_pretrained('./directory/to/save/')  # save\n",
    "# model = model_class.from_pretrained('./directory/to/save/')  # re-load\n",
    "# tokenizer.save_pretrained('./directory/to/save/')  # save\n",
    "# tokenizer = tokenizer_class.from_pretrained('./directory/to/save/')  # re-load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
