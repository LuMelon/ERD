{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hadoop/trainingandtestdata/training.1600000.processed.noemoticon.csv\n",
      "/home/hadoop/trainingandtestdata/testdata.manual.2009.06.14.csv\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 08:26:01.509800 140287778412352 utils_any2vec.py:354] duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in /home/hadoop/word2vec.model, ignoring all but first\n"
     ]
    }
   ],
   "source": [
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 08:17:17.197633 140287778412352 deprecation_wrapper.py:119] From /home/hadoop/ERD/SentCNN.py:8: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0804 08:17:17.198248 140287778412352 deprecation_wrapper.py:119] From /home/hadoop/ERD/SentCNN.py:11: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 08:17:17.199956 140287778412352 deprecation.py:323] From /home/hadoop/ERD/SentCNN.py:15: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "W0804 08:17:17.201435 140287778412352 deprecation.py:506] From /home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0804 08:17:17.266108 140287778412352 deprecation_wrapper.py:119] From /home/hadoop/ERD/SentCNN.py:18: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "W0804 08:17:17.428305 140287778412352 deprecation_wrapper.py:119] From /home/hadoop/ERD/SentCNN.py:21: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
      "\n",
      "W0804 08:17:17.428691 140287778412352 deprecation_wrapper.py:119] From /home/hadoop/ERD/SentCNN.py:27: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0804 08:17:17.447197 140287778412352 deprecation.py:323] From /home/hadoop/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from SentCNN import *\n",
    "def get_curtime():\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "sent_mm = SentCNN(300, 256, 41, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sent_global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "sent_train_op = tf.train.AdamOptimizer(0.01).minimize(sent_mm.loss, sent_global_step)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainlabel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7c849396251a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainlabel' is not defined"
     ]
    }
   ],
   "source": [
    "train_batch = 20\n",
    "test_batch = 20\n",
    "\n",
    "train_iter = int(len(dataloader.trainlabel)/train_batch) + 1\n",
    "test_iter = int(len(dataloader.testlabel)/test_batch) + 1\n",
    "\n",
    "sum_loss = 0.0\n",
    "sum_acc = 0.0\n",
    "ret_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=4)\n",
    "\n",
    "with sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for t_epoch in range(100): \n",
    "    for t_iter in range(train_iter):\n",
    "        data_X, data_Y = GetTrainingBatch(t_iter, train_batch, 300)\n",
    "        feed_dic = {sent_mm.input_x: data_X, sent_mm.input_y: data_Y}\n",
    "        _, step, loss, acc = sess.run([sent_train_op, sent_global_step, sent_mm.loss, sent_mm.accuracy], feed_dic)\n",
    "        sum_loss += loss\n",
    "        sum_acc += acc\n",
    "        if t_iter % 100 == 99:\n",
    "            sum_loss = sum_loss / 100\n",
    "            sum_acc = sum_acc / 100\n",
    "            ret_acc = sum_acc\n",
    "            print(get_curtime() + \" Step: \" + str(step) + \" Training loss: \" + str(sum_loss) + \" accuracy: \" + str(sum_acc))\n",
    "#             if sum_acc > 0.9:\n",
    "#                 break\n",
    "            sum_acc = 0.0\n",
    "            sum_loss = 0.0\n",
    "    # for validation\n",
    "    sum_acc = 0.0\n",
    "    sum_loss = 0.0\n",
    "    for t_iter in range(10):\n",
    "        data_X, data_Y = dataloader.GetTestData(t_iter, test_batch, 300)\n",
    "        feed_dic = {sent_mm.input_x: data_X, sent_mm.input_y: data_Y}\n",
    "        loss, acc = sess.run([sent_mm.loss, sent_mm.accuracy], feed_dic)\n",
    "        sum_loss += loss\n",
    "        sum_acc += acc    \n",
    "    sum_loss = sum_loss / 100\n",
    "    sum_acc = sum_acc / 100\n",
    "    ret_acc = sum_acc\n",
    "    print(get_curtime() + \" Step: \" + str(step) + \" Training loss: \" + str(sum_loss) + \" accuracy: \" + str(sum_acc))\n",
    "    sum_acc = 0.0\n",
    "    sum_loss = 0.0\n",
    "    \n",
    "    saver.save(sess, \"df_saved/sent_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
