{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import MyLogger\n",
    "import time\n",
    "import SubjObjLoader\n",
    "import json\n",
    "from torch import nn\n",
    "import torch\n",
    "from pytorch_transformers import *\n",
    "import importlib\n",
    "from collections import deque\n",
    "# import dataloader\n",
    "from BertRDMLoader import *\n",
    "import json\n",
    "from torch import nn\n",
    "import torch\n",
    "from pytorch_transformers import *\n",
    "import importlib\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import tsentiLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工具函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 画柱状图表达特征指标的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(heatmap, data_label, heat_max, heat_min):\n",
    "    #attention: [batch, seq_len]\n",
    "    #data_label: [batch]\n",
    "    batch = len(data_label)\n",
    "    height = 0.5\n",
    "    plt.figure(figsize=(50, batch*height))\n",
    "    plt.ylim(0, batch*height)\n",
    "    plt.xlim(0, 50)\n",
    "    plt.yticks(np.arange(0, batch*height, height), data_label)\n",
    "    plt.yticks(np.arange(0, 50, 5), ['']*10)\n",
    "    for idx, h in enumerate(heatmap):\n",
    "        color_list = [((b-heat_min)*1.0/(heat_max - heat_min), 0.0, 0.0) for b in h]\n",
    "        d = np.arange(0, 50, 49.99/len(h)).tolist()\n",
    "        d.reverse()\n",
    "        color_list.reverse()\n",
    "        for color, length in zip(color_list, d):\n",
    "            plt.barh([idx*0.5], length, 1.0, color=color) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 旧模型的评价\n",
    "\n",
    "bert没有分到多块GPU上去进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class pooling_layer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(pooling_layer, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        assert(inputs.ndim == 4 ) # [batchsize, max_seq_len, max_word_num, input_dim] \n",
    "        batch_size, max_seq_len, max_word_num, input_dim = inputs.shape\n",
    "        assert(input_dim == self.input_dim)\n",
    "        t_inputs = inputs.reshape([-1, self.input_dim])\n",
    "        return self.linear(t_inputs).reshape(\n",
    "            \n",
    "            [-1, max_word_num, self.output_dim]\n",
    "        \n",
    "        ).max(axis=1)[0].reshape(\n",
    "        \n",
    "            [-1, max_seq_len, self.output_dim]\n",
    "        \n",
    "        )\n",
    "\n",
    "class RDM_Model(nn.Module):\n",
    "    def __init__(self, word_embedding_dim, sent_embedding_dim, hidden_dim, dropout_prob):\n",
    "        super(RDM_Model, self).__init__()\n",
    "        self.embedding_dim = sent_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gru_model = nn.GRU(word_embedding_dim, \n",
    "                                self.hidden_dim, \n",
    "                                batch_first=True, \n",
    "                                dropout=dropout_prob\n",
    "                            )\n",
    "        self.DropLayer = nn.Dropout(dropout_prob)\n",
    "#         self.PoolLayer = pooling_layer(word_embedding_dim, sent_embedding_dim) \n",
    "        \n",
    "    def forward(self, x_emb, x_len, init_states): \n",
    "        \"\"\"\n",
    "        input_x: [batchsize, max_seq_len, sentence_embedding_dim] \n",
    "        x_emb: [batchsize, max_seq_len, 1, embedding_dim]\n",
    "        x_len: [batchsize]\n",
    "        init_states: [batchsize, hidden_dim]\n",
    "        \"\"\"\n",
    "        batchsize, max_seq_len, _ , emb_dim = x_emb.shape\n",
    "#         pool_feature = self.PoolLayer(x_emb)\n",
    "#         sent_feature = sentiModel( \n",
    "#                 x_emb.reshape(\n",
    "#                     [-1, max_sent_len, emb_dim]\n",
    "#                 ) \n",
    "#             ).reshape(\n",
    "#                 [batchsize, max_seq_len, -1]\n",
    "#             )\n",
    "#         pooled_input_x_dp = self.DropLayer(input_x)\n",
    "        pool_feature = x_emb.reshape(\n",
    "                [-1, max_seq_len, emb_dim]\n",
    "        )\n",
    "        df_outputs, df_last_state = self.gru_model(pool_feature, init_states)\n",
    "        hidden_outs = [df_outputs[i][:x_len[i]] for i in range(batchsize)]\n",
    "        final_outs = [df_outputs[i][x_len[i]-1] for i in range(batchsize)]\n",
    "        return hidden_outs, final_outs\n",
    "\n",
    "\n",
    "class CM_Model(nn.Module):\n",
    "    def __init__(self, sentence_embedding_dim, hidden_dim, action_num):\n",
    "        super(CM_Model, self).__init__()\n",
    "        self.sentence_embedding_dim = sentence_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.action_num = action_num\n",
    "#         self.PoolLayer = pooling_layer(self.embedding_dim, \n",
    "#                                             self.hidden_dim)\n",
    "        self.DenseLayer = nn.Linear(self.hidden_dim, 64)\n",
    "        self.Classifier = nn.Linear(64, self.action_num)\n",
    "        \n",
    "    def forward(self, rdm_model, s_model, rl_input, rl_state):\n",
    "        \"\"\"\n",
    "        rl_input: [batchsize, max_word_num, sentence_embedding_dim]\n",
    "        rl_state: [1, batchsize, hidden_dim]\n",
    "        \"\"\"\n",
    "        assert(rl_input.ndim==3)\n",
    "        batchsize, max_word_num, embedding_dim = rl_input.shape\n",
    "#         assert(embedding_dim==self.embedding_dim)\n",
    "        sentence = s_model(rl_input).reshape(batch_size, 1, self.sentence_embedding_dim)\n",
    "#         pooled_rl_input = self.PoolLayer(\n",
    "#             rl_input.reshape(\n",
    "#                 [-1, 1, max_word_num, self.embedding_dim]\n",
    "#             )\n",
    "#         ).reshape([-1, 1, self.hidden_dim])\n",
    "        \n",
    "#         print(\"sentence:\", sentence.shape)\n",
    "#         print(\"rl_state:\", rl_state.shape)\n",
    "        rl_output, rl_new_state = rdm_model.gru_model(\n",
    "                                            sentence, \n",
    "                                            rl_state\n",
    "                                        )\n",
    "        rl_h1 = nn.functional.relu(\n",
    "            self.DenseLayer(\n",
    "#                 rl_state.reshape([len(rl_input), self.hidden_dim]) #it is not sure to take rl_state , rather than rl_output, as the feature\n",
    "                rl_output.reshape(\n",
    "                    [len(rl_input), self.hidden_dim]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        stopScore = self.Classifier(rl_h1)\n",
    "        isStop = stopScore.argmax(axis=1)\n",
    "        return stopScore, isStop, rl_new_state\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def layer2seq(bert, layer, cuda=False):\n",
    "    if cuda:\n",
    "        outs = [bert( torch.tensor([input_]).cuda())\n",
    "                for input_ in layer]   \n",
    "    else: \n",
    "        outs = [bert( torch.tensor([input_]))\n",
    "                    for input_ in layer]\n",
    "    states = [item[1] for item in outs]\n",
    "    return rnn_utils.pad_sequence(states, batch_first=True)\n",
    "\n",
    "def Word_ids2SeqStates(word_ids, bert, ndim, cuda=False):\n",
    "    assert(ndim == 3)\n",
    "    if cuda:\n",
    "        embedding = [layer2seq(bert, layer, cuda) for layer in word_ids]\n",
    "    else:\n",
    "        embedding = [layer2seq(bert, layer) for layer in word_ids]\n",
    "    return padding_sequence(embedding)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def Count_Accs(ylabel, preds):\n",
    "    correct_preds = np.array(\n",
    "        [1 if y1==y2 else 0 \n",
    "        for (y1, y2) in zip(ylabel, preds)]\n",
    "    )\n",
    "    y_idxs = [idx if yl >0 else idx - len(ylabel) \n",
    "            for (idx, yl) in enumerate(ylabel)]\n",
    "    pos_idxs = list(filter(lambda x: x >= 0, y_idxs))\n",
    "    neg_idxs = list(filter(lambda x: x < 0, y_idxs))\n",
    "    acc = sum(correct_preds) / (1.0 * len(ylabel))\n",
    "    if len(pos_idxs) > 0:\n",
    "        pos_acc = sum(correct_preds[pos_idxs])/(1.0*len(pos_idxs))\n",
    "    else:\n",
    "        pos_acc = 0\n",
    "    if len(neg_idxs) > 0:\n",
    "        neg_acc = sum(correct_preds[neg_idxs])/(1.0*len(neg_idxs))\n",
    "    else:\n",
    "        neg_acc = 0\n",
    "    return acc, pos_acc, neg_acc, y_idxs, pos_idxs, neg_idxs, correct_preds\n",
    "\n",
    "def Loss_Fn(ylabel, pred_scores):\n",
    "    diff = ((ylabel - pred_scores)*(ylabel - pred_scores)).mean(axis=1)\n",
    "#     pos_neg = (1.0*sum(ylabel.argmax(axis=1)))/(1.0*(len(ylabel) - sum(ylabel.argmax(axis=1))))\n",
    "    pos_neg = 0\n",
    "    if pos_neg > 0:\n",
    "        print(\"unbalanced data\")\n",
    "        weight = torch.ones(len(ylabel)).cuda() + (ylabel.argmax(axis=1).to(torch.float32)/(1.0*pos_neg)) - ylabel.argmax(axis=1).to(torch.float32)\n",
    "        return (weight *diff).mean()\n",
    "    else:\n",
    "        print(\"totally unbalanced data\")\n",
    "        return diff.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eval(rdm_model, bert, rdm_classifier, \n",
    "                    tokenizer, new_data_len=[]):\n",
    "    batch_size = 20 \n",
    "    d_IDs = get_data_ID()\n",
    "    t_steps=int(len(d_IDs)/batch_size)\n",
    "    \n",
    "    max_gpu_batch = 2 #cannot load a larger batch into the limited memory, but we could  accumulates grads\n",
    "    splits = int(batch_size/max_gpu_batch)\n",
    "    assert(batch_size%max_gpu_batch == 0)\n",
    "    sum_loss = 0.0\n",
    "    sum_acc = 0.0\n",
    "    init_states = torch.zeros([1, max_gpu_batch, rdm_model.hidden_dim], dtype=torch.float32).cuda()\n",
    "    weight = torch.tensor([2.0, 1.0], dtype=torch.float32).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "    acc_l = np.zeros(splits)\n",
    "    loss_l = np.zeros(splits)\n",
    "    with torch.no_grad():\n",
    "        for step in range(t_steps):\n",
    "            try:\n",
    "                for j in range(splits):\n",
    "                    if len(new_data_len) > 0:\n",
    "                        x, x_len, y = get_df_batch(step*splits+j, max_gpu_batch, new_data_len, tokenizer=tokenizer)\n",
    "                    else:\n",
    "                        x, x_len, y = get_df_batch(step, max_gpu_batch, tokenizer=tokenizer)\n",
    "                    x_emb = Word_ids2SeqStates(x, bert, 3, cuda=True) \n",
    "                    batchsize, max_seq_len, max_sent_len,                                     emb_dim = x_emb.shape\n",
    "                    rdm_hiddens, rdm_outs = rdm_model(x_emb, x_len, init_states)\n",
    "                    rdm_scores = rdm_classifier(\n",
    "                        torch.cat(\n",
    "                            rdm_outs # a list of tensor, where the ndim of tensor is 1 and the shape of tensor is [hidden_size]\n",
    "                        ).reshape(\n",
    "                            [-1, rdm_model.hidden_dim]\n",
    "                        )\n",
    "                    )\n",
    "                    rdm_preds = rdm_scores.argmax(axis=1)\n",
    "                    y_label = y.argmax(axis=1)\n",
    "                    acc_l[j], _, _, _, _, _, _ = Count_Accs(y_label, rdm_preds)\n",
    "                    loss = loss_fn(rdm_scores, torch.tensor(y_label).cuda())\n",
    "                    loss_l[j] = float(loss)\n",
    "    #                 print(\"%d, %d | x_len:\"%(step, j), x_len)\n",
    "            except RuntimeError as exception:\n",
    "                if \"out of memory\" in str(exception):\n",
    "                    print(\"WARNING: out of memory\")\n",
    "                    print(\"%d, %d | x_len:\"%(step, j), x_len)\n",
    "                    if hasattr(torch.cuda, 'empty_cache'):\n",
    "                        torch.cuda.empty_cache()\n",
    "    #                     time.sleep(5)\n",
    "                    raise exception\n",
    "                else:   \n",
    "                    raise exception\n",
    "            sum_loss += loss_l.mean()\n",
    "            sum_acc += acc_l.mean()\n",
    "            print(\"loss:\", loss_l.mean(), \"acc:\", acc_l.mean())\n",
    "    mean_loss = sum_loss/(1.0*t_steps)\n",
    "    mean_acc = sum_acc/(1.0*t_steps)\n",
    "    print(\"mean_loss\", mean_loss, \" | mean_acc:\", mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 187 ,  max_seq_len: 101\n",
      "5802 data loaded\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", cached_dir = \"/home/hadoop/transformer_pretrained_models/bert-base-uncased-pytorch_model.bin\")\n",
    "\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\").cuda()\n",
    "\n",
    "with open(\"config.json\", \"r\") as cr:\n",
    "    dic = json.load(cr)\n",
    "\n",
    "class adict(dict):\n",
    "    ''' Attribute dictionary - a convenience data structure, similar to SimpleNamespace in python 3.3\n",
    "        One can use attributes to read/write dictionary content.\n",
    "    '''\n",
    "    def __init__(self, *av, **kav):\n",
    "        dict.__init__(self, *av, **kav)\n",
    "        self.__dict__ = self\n",
    "\n",
    "FLAGS = adict(dic)\n",
    "# In[10]:\n",
    "load_data_fast()\n",
    "\n",
    "data_ID = get_data_ID()\n",
    "\n",
    "len(data_ID)\n",
    "\n",
    "data = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 切分原数据集 | 3884: 200 :500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 187 ,  max_seq_len: 101\n",
      "5802 data loaded\n"
     ]
    }
   ],
   "source": [
    "load_data_fast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_马晶那个数据集跟这个数据集差异太大，无法迁移_\n",
    "\n",
    "``` python\n",
    "data_ID = get_data_ID()\n",
    "data_len = get_data_len()\n",
    "data_y = get_data_y()\n",
    "\n",
    "test_data_y = data_y[-500:]\n",
    "\n",
    "test_data_len = data_len[-500:]\n",
    "\n",
    "test_data_ID = data_ID[-500:]\n",
    "\n",
    "np.save(\"data/data_ID.npy\", np.array(data_ID)[:-500])\n",
    "np.save(\"data/data_len.npy\", np.array(data_len)[:-500])\n",
    "np.save(\"data/data_y.npy\", np.array(data_y)[:-500])\n",
    "\n",
    "np.save(\"data/test_data_ID.npy\", np.array(test_data_ID))\n",
    "np.save(\"data/test_data_len.npy\", np.array(test_data_len))\n",
    "np.save(\"data/test_data_y.npy\", np.array(test_data_y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "data_ID = get_data_ID()\n",
    "data_len = get_data_len()\n",
    "data_y = get_data_y()\n",
    "\n",
    "valid_data_y = data_y[-200:]\n",
    "\n",
    "valid_data_len = data_len[-200:]\n",
    "\n",
    "valid_data_ID = data_ID[-200:]\n",
    "\n",
    "np.save(\"data/data_ID.npy\", np.array(data_ID)[:-200])\n",
    "np.save(\"data/data_len.npy\", np.array(data_len)[:-200])\n",
    "np.save(\"data/data_y.npy\", np.array(data_y)[:-200])\n",
    "\n",
    "np.save(\"data/valid_data_ID.npy\", np.array(valid_data_ID))\n",
    "np.save(\"data/valid_data_len.npy\", np.array(valid_data_len))\n",
    "np.save(\"data/valid_data_y.npy\", np.array(valid_data_y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "del data               \n",
    "del data_ID              \n",
    "del data_len               \n",
    "del data_y             \n",
    "del valid_data_ID            \n",
    "del valid_data_len       \n",
    "del valid_data_y            \n",
    "\n",
    "from BertRDMLoader import data          \n",
    "from BertRDMLoader import data_ID       \n",
    "from BertRDMLoader import data_len      \n",
    "from BertRDMLoader import data_y        \n",
    "from BertRDMLoader import valid_data_ID \n",
    "from BertRDMLoader import valid_data_len\n",
    "from BertRDMLoader import valid_data_y  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 创建测试所用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rdm_model = RDM_Model(768, 300, 256, 0.2).cuda()\n",
    "cm_model = CM_Model(300, 256, 2).cuda()\n",
    "rdm_classifier = nn.Linear(256, 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "senti_save_as = '/home/hadoop/ERD/RDMBertTrain/rdmModel_epoch019.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(senti_save_as)\n",
    "bert.load_state_dict(checkpoint['bert'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "``` python\n",
    "torch.save(\n",
    "                    {\n",
    "                        \"bert\":bert.state_dict(),\n",
    "                        \"rmdModel\":rdm_model.state_dict(),\n",
    "                        \"rdm_classifier\": rdm_classifier.state_dict()\n",
    "                    },\n",
    "                    rdm_save_as\n",
    "                )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm_model.load_state_dict(checkpoint['rmdModel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm_classifier.load_state_dict(checkpoint['rdm_classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### test the bert embedding model on the trainning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.11101210117340088 acc: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-afd2bcba5c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m eval(rdm_model, bert, rdm_classifier, \n\u001b[0;32m----> 2\u001b[0;31m                     tokenizer)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-220f3a1020df>\u001b[0m in \u001b[0;36meval\u001b[0;34m(rdm_model, bert, rdm_classifier, tokenizer, new_data_len)\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_df_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_gpu_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mx_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord_ids2SeqStates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sent_len\u001b[0m\u001b[0;34m,\u001b[0m                                     \u001b[0memb_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mrdm_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdm_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-bae56a178560>\u001b[0m in \u001b[0;36mWord_ids2SeqStates\u001b[0;34m(word_ids, bert, ndim, cuda)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-bae56a178560>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-bae56a178560>\u001b[0m in \u001b[0;36mlayer2seq\u001b[0;34m(bert, layer, cuda)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         outs = [bert( torch.tensor([input_]).cuda())\n\u001b[0;32m--> 113\u001b[0;31m                 for input_ in layer]   \n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         outs = [bert( torch.tensor([input_]))\n",
      "\u001b[0;32m<ipython-input-37-bae56a178560>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         outs = [bert( torch.tensor([input_]).cuda())\n\u001b[0;32m--> 113\u001b[0;31m                 for input_ in layer]   \n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         outs = [bert( torch.tensor([input_]))\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    713\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    714\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    716\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m# initialize self.training separately from the rest of the internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# state, as it is managed differently by nn.Module and ScriptModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthnn_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval(rdm_model, bert, rdm_classifier, \n",
    "                    tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475982532751092"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(\"/home/hadoop/tmp_loss\").readlines()\n",
    "\n",
    "accs = [float(line.strip(\"\\n\").split(\"acc:\")[1]) for line in lines]\n",
    "\n",
    "mean_acc = np.array(accs).mean()\n",
    "\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = torch.randn([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9957, -0.4725,  0.5221,  0.0872]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### test the bert model on another data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 187 ,  max_seq_len: 101\n",
      "5802 data loaded\n"
     ]
    }
   ],
   "source": [
    "load_test_data_fast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_ID =  get_data_ID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([163., 337.]),\n",
       " [[0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0],\n",
       "  [1.0, 0.0],\n",
       "  [1.0, 0.0],\n",
       "  [0.0, 1.0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = np.array(get_data_y())\n",
    "test_labels.sum(axis=0), test_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.07612740993499756 acc: 1.0\n",
      "loss: 0.017561832442879677 acc: 1.0\n",
      "loss: 0.6489768028259277 acc: 0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-afd2bcba5c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m eval(rdm_model, bert, rdm_classifier, \n\u001b[0;32m----> 2\u001b[0;31m                     tokenizer)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-220f3a1020df>\u001b[0m in \u001b[0;36meval\u001b[0;34m(rdm_model, bert, rdm_classifier, tokenizer, new_data_len)\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_df_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_gpu_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mx_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord_ids2SeqStates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sent_len\u001b[0m\u001b[0;34m,\u001b[0m                                     \u001b[0memb_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mrdm_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdm_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bae56a178560>\u001b[0m in \u001b[0;36mWord_ids2SeqStates\u001b[0;34m(word_ids, bert, ndim, cuda)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bae56a178560>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bae56a178560>\u001b[0m in \u001b[0;36mlayer2seq\u001b[0;34m(bert, layer, cuda)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         outs = [bert( torch.tensor([input_]).cuda())\n\u001b[0;32m--> 113\u001b[0;31m                 for input_ in layer]   \n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         outs = [bert( torch.tensor([input_]))\n",
      "\u001b[0;32m<ipython-input-2-bae56a178560>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         outs = [bert( torch.tensor([input_]).cuda())\n\u001b[0;32m--> 113\u001b[0;31m                 for input_ in layer]   \n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         outs = [bert( torch.tensor([input_]))\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    713\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    714\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    716\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval(rdm_model, bert, rdm_classifier, \n",
    "                    tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新模型的评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 新模型的模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pooling_layer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(pooling_layer, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        assert(inputs.ndim == 4 ) # [batchsize, max_seq_len, max_word_num, input_dim] \n",
    "        batch_size, max_seq_len, max_word_num, input_dim = inputs.shape\n",
    "        assert(input_dim == self.input_dim)\n",
    "        t_inputs = inputs.reshape([-1, self.input_dim])\n",
    "        return self.linear(t_inputs).reshape(\n",
    "            \n",
    "            [-1, max_word_num, self.output_dim]\n",
    "        \n",
    "        ).max(axis=1)[0].reshape(\n",
    "        \n",
    "            [-1, max_seq_len, self.output_dim]\n",
    "        \n",
    "        )\n",
    "\n",
    "class RDM_Model(nn.Module):\n",
    "    def __init__(self, word_embedding_dim, sent_embedding_dim, hidden_dim, dropout_prob):\n",
    "        super(RDM_Model, self).__init__()\n",
    "        self.embedding_dim = sent_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gru_model = nn.GRU(word_embedding_dim, \n",
    "                                self.hidden_dim, \n",
    "                                batch_first=True, \n",
    "                                dropout=dropout_prob\n",
    "                            )\n",
    "        self.DropLayer = nn.Dropout(dropout_prob)\n",
    "#         self.PoolLayer = pooling_layer(word_embedding_dim, sent_embedding_dim) \n",
    "        \n",
    "    def forward(self, x_emb): \n",
    "        \"\"\"\n",
    "        input_x: [batchsize, max_seq_len, sentence_embedding_dim] \n",
    "        x_emb: [batchsize, max_seq_len, 1, embedding_dim]\n",
    "        x_len: [batchsize]\n",
    "        init_states: [batchsize, hidden_dim]\n",
    "        \"\"\"\n",
    "        batchsize, max_seq_len, _ , emb_dim = x_emb.shape\n",
    "        init_states = torch.zeros([1, batchsize, self.hidden_dim], dtype=torch.float32).cuda()\n",
    "        pool_feature = x_emb.reshape(\n",
    "                [-1, max_seq_len, emb_dim]\n",
    "        )\n",
    "        try:\n",
    "            df_outputs, df_last_state = self.gru_model(pool_feature, init_states)\n",
    "        except:\n",
    "            print(\"Error:\", pool_feature.shape, init_states.shape)\n",
    "            raise\n",
    "        # hidden_outs = [df_outputs[i][:x_len[i]] for i in range(batchsize)]\n",
    "        # final_outs = [df_outputs[i][x_len[i]-1] for i in range(batchsize)]\n",
    "        # return hidden_outs, final_outs\n",
    "        return df_outputs\n",
    "\n",
    "\n",
    "class CM_Model(nn.Module):\n",
    "    def __init__(self, sentence_embedding_dim, hidden_dim, action_num):\n",
    "        super(CM_Model, self).__init__()\n",
    "        self.sentence_embedding_dim = sentence_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.action_num = action_num\n",
    "#         self.PoolLayer = pooling_layer(self.embedding_dim, \n",
    "#                                             self.hidden_dim)\n",
    "        self.DenseLayer = nn.Linear(self.hidden_dim, 64)\n",
    "        self.Classifier = nn.Linear(64, self.action_num)\n",
    "        \n",
    "    def forward(self, rdm_model, rl_input, rl_state):\n",
    "        \"\"\"\n",
    "        rl_input: [batchsize, max_word_num, sentence_embedding_dim]\n",
    "        rl_state: [1, batchsize, hidden_dim]\n",
    "        \"\"\"\n",
    "        assert(rl_input.ndim==3)\n",
    "        batchsize, max_word_num, embedding_dim = rl_input.shape\n",
    "        rl_output, rl_new_state = rdm_model.gru_model(\n",
    "                                            rl_input, \n",
    "                                            rl_state\n",
    "                                        )\n",
    "        rl_h1 = nn.functional.relu(\n",
    "            self.DenseLayer(\n",
    "#                 rl_state.reshape([len(rl_input), self.hidden_dim]) #it is not sure to take rl_state , rather than rl_output, as the feature\n",
    "                rl_output.reshape(\n",
    "                    [len(rl_input), self.hidden_dim]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        stopScore = self.Classifier(rl_h1)\n",
    "        isStop = stopScore.argmax(axis=1)\n",
    "        return stopScore, isStop, rl_new_state\n",
    "\n",
    "def Loss_Fn(ylabel, pred_scores):\n",
    "    diff = ((ylabel - pred_scores)*(ylabel - pred_scores)).mean(axis=1)\n",
    "#     pos_neg = (1.0*sum(ylabel.argmax(axis=1)))/(1.0*(len(ylabel) - sum(ylabel.argmax(axis=1))))\n",
    "    pos_neg = 0\n",
    "    if pos_neg > 0:\n",
    "        print(\"unbalanced data\")\n",
    "        weight = torch.ones(len(ylabel)).cuda() + (ylabel.argmax(axis=1).to(torch.float32)/(1.0*pos_neg)) - ylabel.argmax(axis=1).to(torch.float32)\n",
    "        return (weight *diff).mean()\n",
    "    else:\n",
    "        print(\"totally unbalanced data\")\n",
    "        return diff.mean()\n",
    "    \n",
    "def WeightsForUmbalanced(data_label):\n",
    "    _, _, labels = data_label.shape\n",
    "    label_cnt = data_label.reshape([-1, labels]).sum(axis=0)\n",
    "    weights = 1.0/label_cnt\n",
    "    normalized_weights = weights/sum(weights)\n",
    "    return normalized_weights\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# x_new = [sent1, sent2, sent3, ...]　\n",
    "# x_new -> x_old_emb [batchsize, seq_len, sent_emb]：#使用seq_info 将sent组装回去\n",
    "# ---> [batchsize, max_seq_len, sent_emb] # padding 成一个可以计算的batch, 从而可以切分\n",
    "def rdm_data2bert_tensors(data_X, cuda):\n",
    "    def padding_sent_list(sent_list):\n",
    "        sent_len = [len(sent) for sent in sent_list]\n",
    "        max_sent_len = max(sent_len)\n",
    "        sent_padding = torch.zeros([len(sent_list), max_sent_len], dtype=torch.int64)\n",
    "        attn_mask = torch.ones_like(sent_padding)\n",
    "        for i, sent in enumerate(sent_list):\n",
    "            sent_padding[i][:len(sent)] = torch.tensor(sent, dtype=torch.int32)\n",
    "            attn_mask[i][len(sent):].fill_(0)\n",
    "        return sent_padding, attn_mask\n",
    "    sent_list = []\n",
    "    [sent_list.extend(seq) for seq in data_X]\n",
    "    seq_len = [len(seq) for seq in data_X]\n",
    "    sent_tensors, attn_mask = padding_sent_list(sent_list)\n",
    "    if cuda:\n",
    "        sent_tensors = sent_tensors.cuda()\n",
    "        attn_mask = attn_mask.cuda()\n",
    "    return sent_tensors, attn_mask, seq_len\n",
    "\n",
    "def subj_data2bert_tensors(sent_list, cuda):\n",
    "    sent_len = [len(sent) for sent in sent_list]\n",
    "    max_sent_len = max(sent_len)\n",
    "    sent_padding = torch.zeros([len(sent_list), max_sent_len], dtype=torch.int64)\n",
    "    attn_mask = torch.ones_like(sent_padding)\n",
    "    for i, sent in enumerate(sent_list):\n",
    "        sent_padding[i][:len(sent)] = torch.tensor(sent, dtype=torch.int32)\n",
    "        attn_mask[i][len(sent):].fill_(0)\n",
    "    if cuda:\n",
    "        sent_padding = sent_padding.cuda()\n",
    "        attn_mask = attn_mask.cuda()\n",
    "    return sent_padding, attn_mask\n",
    "\n",
    "def senti_data2bert_tensors(sent_list, cuda):\n",
    "    sent_len = [len(sent) for sent in sent_list]\n",
    "    max_sent_len = max(sent_len)\n",
    "    sent_padding = torch.zeros([len(sent_list), max_sent_len], dtype=torch.int64)\n",
    "    attn_mask = torch.ones_like(sent_padding)\n",
    "    for i, sent in enumerate(sent_list):\n",
    "        sent_padding[i][:len(sent)] = torch.tensor(sent, dtype=torch.int32)\n",
    "        attn_mask[i][len(sent):].fill_(0)\n",
    "    if cuda:\n",
    "        sent_padding = sent_padding.cuda()\n",
    "        attn_mask = attn_mask.cuda()\n",
    "    return sent_padding, attn_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 模型的评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 187 ,  max_seq_len: 101\n",
      "5802 data loaded\n"
     ]
    }
   ],
   "source": [
    "load_data_fast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eval_rdm(rdm_model, bert, rdm_classifier, \n",
    "                    tokenizer, new_data_len=[], cuda=True):\n",
    "    batch_size = 20 \n",
    "    d_IDs = get_data_ID()\n",
    "    t_steps=int(len(d_IDs)/batch_size)\n",
    "    assert(batch_size%max_gpu_batch == 0)\n",
    "    sum_loss = 0.0\n",
    "    sum_acc = 0.0\n",
    "    init_states = torch.zeros([1, max_gpu_batch, rdm_model.hidden_dim], dtype=torch.float32).cuda()\n",
    "    weight = torch.tensor([2.0, 1.0], dtype=torch.float32).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    labels = []\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for step in range(t_steps):\n",
    "            x, x_len, y = get_df_batch(step, batch_size, tokenizer=tokenizer)\n",
    "            sent_tensors, attn_mask, seq_len = rdm_data2bert_tensors(x, cuda)\n",
    "            bert_outs = bert(sent_tensors, attention_mask=attn_mask)\n",
    "            pooled_sents = [bert_outs[1][sum(seq_len[:idx]):sum(seq_len[:idx])+seq_len[idx]] for idx, s_len in enumerate(seq_len)]\n",
    "            data_tensors = rnn_utils.pad_sequence(pooled_sents, batch_first=True).unsqueeze(-2)\n",
    "            rdm_hiddens = rdm_model(data_tensors)\n",
    "            batchsize, _, _ = rdm_hiddens.shape\n",
    "            rdm_outs = torch.cat(\n",
    "                [ rdm_hiddens[i][x_len[i]-1] for i in range(batchsize)] \n",
    "                # a list of tensor, where the ndim of tensor is 1 and the shape of tensor is [hidden_size]\n",
    "            ).reshape(\n",
    "                [-1, rdm_model.hidden_dim]\n",
    "            )\n",
    "            rdm_scores = rdm_classifier(\n",
    "                rdm_outs\n",
    "            )\n",
    "            rdm_preds = rdm_scores.argmax(axis=1)\n",
    "            y_label = torch.tensor(y).argmax(axis=1).cuda() if cuda else torch.tensor(y).argmax(axis=1)\n",
    "\n",
    "            labels.append(y_label)\n",
    "            preds.append(rdm_preds)\n",
    "\n",
    "            loss = loss_fn(rdm_scores, y_label)\n",
    "            sum_loss += loss\n",
    "            torch.cuda.empty_cache()\n",
    "    mean_loss = sum_loss/(1.0*t_steps)\n",
    "\n",
    "    rdm_preds = torch.cat(preds, axis=0) if not cuda else torch.cat(preds, axis=0).cpu()\n",
    "    y_label = torch.cat(labels, axis=0) if not cuda else torch.cat(labels, axis=0).cpu()\n",
    "    macro_precision, micro_precision, precision = precision_score(y_label, rdm_preds, average=\"macro\"), precision_score(y_label, rdm_preds, average=\"micro\"), precision_score(y_label, rdm_preds, average=None)\n",
    "    macro_recall, micro_recall, recall = recall_score(y_label, rdm_preds, average=\"macro\"), recall_score(y_label, rdm_preds, average=\"micro\"), recall_score(y_label, rdm_preds, average=None)\n",
    "    acc = accuracy_score(y_label, rdm_preds)\n",
    "    macro_f1, micro_f1, f1 = f1_score(y_label, rdm_preds, average=\"macro\"), f1_score(y_label, rdm_preds, average=\"micro\"), f1_score(y_label, rdm_preds, average=None)\n",
    "    return mean_loss, (macro_precision, micro_precision, precision), (macro_recall, micro_recall, recall), acc, (macro_f1, micro_f1, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data_by_idxs(data_idxs, new_data_len=[], tokenizer=None):\n",
    "    batchsize = len(data_idxs)\n",
    "    m_data_y = np.zeros([batchsize, 2], dtype=np.int32)\n",
    "    m_data_len = np.zeros([batchsize], dtype=np.int32)\n",
    "    data_x = [] #[batchsize, seq_len, sent_len]\n",
    "    if len(new_data_len) > 0:\n",
    "        t_data_len = new_data_len\n",
    "    else:\n",
    "        t_data_len = data_len\n",
    "    \n",
    "    for i in range(batchsize):\n",
    "        idx = data_idxs[i]\n",
    "        m_data_y[i] = data_y[idx]\n",
    "        m_data_len[i] = t_data_len[idx]\n",
    "        seq_x = [\n",
    "            tokenizer.encode(\n",
    "                data[data_ID[idx]]['text'][j],\n",
    "                add_special_tokens=True\n",
    "            )\n",
    "            for j in range(t_data_len[idx])\n",
    "        ]\n",
    "        data_x.append(seq_x)\n",
    "    return data_x, m_data_len, m_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as cr:\n",
    "    dic = json.load(cr)\n",
    "\n",
    "class adict(dict):\n",
    "    ''' Attribute dictionary - a convenience data structure, similar to SimpleNamespace in python 3.3\n",
    "        One can use attributes to read/write dictionary content.\n",
    "    '''\n",
    "    def __init__(self, *av, **kav):\n",
    "        dict.__init__(self, *av, **kav)\n",
    "        self.__dict__ = self\n",
    "\n",
    "FLAGS = adict(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 创建模型并导入测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"./bertModel/\")\n",
    "bert = BertModel.from_pretrained(\"./bertModel/\").cuda()\n",
    "rdm_model = RDM_Model(768, 300, 256, 0.2).cuda()\n",
    "rdm_classifier = nn.Linear(256, 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_ids = [0]\n",
    "bert = nn.DataParallel(bert, device_ids=device_ids)\n",
    "device_name = \"cuda:%d\"%device_ids[0]\n",
    "device = torch.device(device_name)\n",
    "bert.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 测试RDM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_显然这个模型的挑选时机不好，过拟合了，应当挑选一个在开发集上最好的模型_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_file = \"./MTLRDM/rdmModel_epoch199.pkl\"\n",
    "checkpoint = torch.load(pretrained_file)\n",
    "bert.load_state_dict(checkpoint['bert'])\n",
    "rdm_model.load_state_dict(checkpoint[\"rmdModel\"])\n",
    "rdm_classifier.load_state_dict(checkpoint[\"rdm_classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 187 ,  max_seq_len: 101\n",
      "5802 data loaded\n",
      "loss: 0.0013149792794138193 acc: 1.0\n",
      "loss: 0.0008682012557983398 acc: 1.0\n",
      "loss: 0.0011640170123428106 acc: 1.0\n",
      "loss: 0.0019624531269073486 acc: 1.0\n",
      "loss: 0.0012935230042785406 acc: 1.0\n",
      "loss: 0.0010040828492492437 acc: 1.0\n",
      "loss: 0.0012245089747011662 acc: 1.0\n",
      "loss: 0.03089812584221363 acc: 1.0\n",
      "loss: 0.0006210895953699946 acc: 1.0\n",
      "loss: 0.0008620548178441823 acc: 1.0\n",
      "loss: 0.0008964042062871158 acc: 1.0\n",
      "loss: 0.0012937907595187426 acc: 1.0\n",
      "loss: 0.0007344117620959878 acc: 1.0\n",
      "loss: 0.0011110963532701135 acc: 1.0\n",
      "loss: 0.0009626635583117604 acc: 1.0\n",
      "loss: 0.0013735622633248568 acc: 1.0\n",
      "loss: 0.001495623611845076 acc: 1.0\n",
      "loss: 0.0015656640753149986 acc: 1.0\n",
      "loss: 0.001469327020458877 acc: 1.0\n",
      "loss: 0.001017270260490477 acc: 1.0\n",
      "loss: 0.0010514497989788651 acc: 1.0\n",
      "loss: 0.0009182266076095402 acc: 1.0\n",
      "loss: 0.0010460523189976811 acc: 1.0\n",
      "loss: 0.002764412434771657 acc: 1.0\n",
      "loss: 0.0009817044483497739 acc: 1.0\n",
      "loss: 0.0009120305185206234 acc: 1.0\n",
      "loss: 0.0009324635611847043 acc: 1.0\n",
      "loss: 0.0007556629134342074 acc: 1.0\n",
      "loss: 0.0010860516922548413 acc: 1.0\n",
      "loss: 0.001237954362295568 acc: 1.0\n",
      "loss: 0.00093841552734375 acc: 1.0\n",
      "loss: 0.0012408593902364373 acc: 1.0\n",
      "loss: 0.0010895913001149893 acc: 1.0\n",
      "loss: 0.0012248887214809656 acc: 1.0\n",
      "loss: 0.0011911392211914062 acc: 1.0\n",
      "loss: 0.000963398371823132 acc: 1.0\n",
      "loss: 0.0008591898949816823 acc: 1.0\n",
      "loss: 0.0012306059943512082 acc: 1.0\n",
      "loss: 0.0010384846245869994 acc: 1.0\n",
      "loss: 0.0017500590765848756 acc: 1.0\n",
      "loss: 0.0014520457480102777 acc: 1.0\n",
      "loss: 0.001205179374665022 acc: 1.0\n",
      "loss: 0.0007400676840916276 acc: 1.0\n",
      "loss: 0.0007810684619471431 acc: 1.0\n",
      "loss: 0.0010892009595409036 acc: 1.0\n",
      "loss: 0.0010371208190917969 acc: 1.0\n",
      "loss: 0.0009419459383934736 acc: 1.0\n",
      "loss: 0.001387719763442874 acc: 1.0\n",
      "loss: 0.0010444223880767822 acc: 1.0\n",
      "loss: 0.0009412318468093872 acc: 1.0\n",
      "loss: 0.001095356303267181 acc: 1.0\n",
      "loss: 0.0007423214265145361 acc: 1.0\n",
      "loss: 0.001696729683317244 acc: 1.0\n",
      "loss: 0.0011089423205703497 acc: 1.0\n",
      "loss: 0.0011621458688750863 acc: 1.0\n",
      "loss: 0.0011781002394855022 acc: 1.0\n",
      "loss: 0.0010005811927840114 acc: 1.0\n",
      "loss: 0.0006505684577859938 acc: 1.0\n",
      "loss: 0.0013092940207570791 acc: 1.0\n",
      "loss: 0.0008088074973784387 acc: 1.0\n",
      "loss: 0.002396596362814307 acc: 1.0\n",
      "loss: 0.0007900595664978027 acc: 1.0\n",
      "loss: 0.0016605942510068417 acc: 1.0\n",
      "loss: 0.0014764070510864258 acc: 1.0\n",
      "loss: 0.0017024462576955557 acc: 1.0\n",
      "loss: 0.0010665787849575281 acc: 1.0\n",
      "loss: 0.0008024236303754151 acc: 1.0\n",
      "loss: 0.0009129230747930706 acc: 1.0\n",
      "loss: 0.0012889078352600336 acc: 1.0\n",
      "loss: 0.0007127810968086123 acc: 1.0\n",
      "loss: 0.0013098539784550667 acc: 1.0\n",
      "loss: 0.0009724426199682057 acc: 1.0\n",
      "loss: 0.0015028970083221793 acc: 1.0\n",
      "loss: 0.0009602175559848547 acc: 1.0\n",
      "loss: 0.001069987309165299 acc: 1.0\n",
      "loss: 0.0007270145579241216 acc: 1.0\n",
      "loss: 0.001442308770492673 acc: 1.0\n",
      "loss: 0.0007454395527020097 acc: 1.0\n",
      "loss: 0.0009263072861358523 acc: 1.0\n",
      "loss: 0.0010785579215735197 acc: 1.0\n",
      "loss: 0.0016188091831281781 acc: 1.0\n",
      "loss: 0.0009730358724482358 acc: 1.0\n",
      "loss: 0.0008481884142383933 acc: 1.0\n",
      "loss: 0.0023365479428321123 acc: 1.0\n",
      "loss: 0.0010721731232479215 acc: 1.0\n",
      "loss: 0.0008632307290099561 acc: 1.0\n",
      "loss: 0.0012313586194068193 acc: 1.0\n",
      "loss: 0.001210664864629507 acc: 1.0\n",
      "loss: 0.0008304119110107422 acc: 1.0\n",
      "loss: 0.002780128503218293 acc: 1.0\n",
      "loss: 0.0006673622410744429 acc: 1.0\n",
      "loss: 0.001028159516863525 acc: 1.0\n",
      "loss: 0.0008328667609021068 acc: 1.0\n",
      "loss: 0.0011273111449554563 acc: 1.0\n",
      "loss: 0.0012942773755639791 acc: 1.0\n",
      "loss: 0.0009214419405907393 acc: 1.0\n",
      "loss: 0.001112929661758244 acc: 1.0\n",
      "loss: 0.0012114247074350715 acc: 1.0\n",
      "loss: 0.0014329084660857916 acc: 1.0\n",
      "loss: 0.0012953034602105618 acc: 1.0\n",
      "loss: 0.0008450666791759431 acc: 1.0\n",
      "loss: 0.0008107324247248471 acc: 1.0\n",
      "loss: 0.0011810516007244587 acc: 1.0\n",
      "loss: 0.0010390722891315818 acc: 1.0\n",
      "loss: 0.0010450744302943349 acc: 1.0\n",
      "loss: 0.005982222035527229 acc: 1.0\n",
      "loss: 0.0008703003986738622 acc: 1.0\n",
      "loss: 0.0009285944979637861 acc: 1.0\n",
      "loss: 0.0012923204340040684 acc: 1.0\n",
      "loss: 0.0023166032042354345 acc: 1.0\n",
      "loss: 0.0007601793040521443 acc: 1.0\n",
      "loss: 0.0015653830487281084 acc: 1.0\n",
      "loss: 0.0008654594421386719 acc: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f70387af2ec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mload_data_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m eval_rdm(rdm_model, bert, rdm_classifier, \n\u001b[0;32m----> 3\u001b[0;31m                     tokenizer, new_data_len=[])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-724d13c2cdd4>\u001b[0m in \u001b[0;36meval_rdm\u001b[0;34m(rdm_model, bert, rdm_classifier, tokenizer, new_data_len, cuda)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mpooled_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbert_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdata_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mrdm_hiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdm_hiddens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             rdm_outs = torch.cat(\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0cb5b7df4f7f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_emb)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[1;32m     43\u001b[0m         \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0minit_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         pool_feature = x_emb.reshape(\n\u001b[1;32m     46\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "load_data_fast()\n",
    "eval_rdm(rdm_model, bert, rdm_classifier, \n",
    "                    tokenizer, new_data_len=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 187 ,  max_seq_len: 101\n",
      "5802 data loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.4481, device='cuda:0'),\n",
       " (0.6215083798882681, 0.674, array([0.5       , 0.74301676])),\n",
       " (0.6124501647521436, 0.674, array([0.43558282, 0.78931751])),\n",
       " 0.674,\n",
       " (0.615520698195542, 0.674, array([0.46557377, 0.76546763])))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_test_data_fast()\n",
    "eval_rdm(rdm_model, bert, rdm_classifier, \n",
    "                    tokenizer, new_data_len=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试数据集中的情感变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdm_seq_data2scores_seq(rdm_data, bert, task_emb, classifier, label_num =2):\n",
    "    batch_size = 20\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(int(len(rdm_data)/batch_size)):\n",
    "            x = rdm_data[i*batch_size:min((i+1)*batch_size, len(rdm_data))]\n",
    "            sent_tensors, attn_mask, seq_len = rdm_data2bert_tensors(x, cuda)\n",
    "            xsj_embs, _ = bert(sent_tensors, attention_mask=attn_mask)\n",
    "            tensors = xsj_embs + task_emb\n",
    "            subj_feature = transformer(tensors, attention_mask = attn_mask)\n",
    "            cls_feature = subj_feature[0][:, 0]\n",
    "            subj_scores = subj_cls(cls_feature).softmax(axis=1)\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"subj_scores:\", subj_scores.shape)\n",
    "            seq_len.insert(0, 0)\n",
    "            print(\"seq_len:\", seq_len)\n",
    "            for j in range(len(seq_len)-1):\n",
    "                scores.append(subj_scores[sum(seq_len[:j]):sum(seq_len[:j])+seq_len[j+1], 1].tolist())\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(x_tuples, bins, xlabel, ylabel, legends):\n",
    "    colors = [(1, 0, 0), (1, 1, 0), (0, 1, 0,), (0, 0, 1)]\n",
    "    def normfun(x,mu,sigma):\n",
    "        pdf = np.exp(-((x - mu)**2)/(2*sigma**2)) / (sigma * np.sqrt(2*np.pi))\n",
    "        return pdf\n",
    "    \n",
    "    x_scales = np.arange(0, 1, 0.0001)\n",
    "    for i in range(len(x_tuples)):\n",
    "        plt.hist(x_tuples[i], bins=bins, normed=True)\n",
    "        mu = np.mean(x_tuples[i])\n",
    "        sigma = np.std(x_tuples[i])\n",
    "        y = normfun(x_scales, mu, sigma)\n",
    "        plt.plot(x_scales, y, color=colors[i])\n",
    "    plt.legend(legends, loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 旧模型，nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embedding = nn.Embedding(3, 768)\n",
    "\n",
    "encoder_layer = nn.TransformerEncoderLayer(768, 8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, 1)\n",
    "\n",
    "subj_cls = nn.Linear(768, 2)\n",
    "\n",
    "transformer = transformer_encoder.cuda()\n",
    "task_embedding = task_embedding.cuda()\n",
    "subj_cls = subj_cls.cuda()\n",
    "\n",
    "senti_cls = nn.Linear(768, 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_save_as = '/home/hadoop/ERD/MTLTrain/jointModel_epoch015.pkl'\n",
    "checkpoint = torch.load(joint_save_as)\n",
    "senti_cls.load_state_dict(checkpoint['senti_classifier'])\n",
    "bert.load_state_dict(checkpoint['bert'])\n",
    "transformer.load_state_dict(checkpoint['transformer'])\n",
    "task_embedding.load_state_dict(checkpoint['task_embedding'])\n",
    "subj_cls.load_state_dict(checkpoint['subj_classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 新模型, BertEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "tt = BertTokenizer.from_pretrained(\"./bertModel/\")\n",
    "bb = BertModel.from_pretrained(\"./bertModel/\")\n",
    "task_embedding = nn.Embedding(3, 768)\n",
    "\n",
    "trans_conf = adict({\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-12,\n",
    "  \"max_position_embeddings\": 512,\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 2,\n",
    "  \"num_labels\": 2,\n",
    "  \"output_attentions\": False,\n",
    "  \"output_hidden_states\": False,\n",
    "  \"torchscript\": False\n",
    "})\n",
    "BertEncoder = transformer_utils.BertEncoder\n",
    "transformer = BertEncoder(trans_conf)\n",
    "\n",
    "subj_cls = nn.Linear(768, 2)\n",
    "bert = bb.cuda()\n",
    "transformer = transformer.cuda()\n",
    "task_embedding = task_embedding.cuda()\n",
    "subj_cls = subj_cls.cuda()\n",
    "rdm_model = RDM_Model(768, 300, 256, 0.2).cuda()\n",
    "rdm_classifier = nn.Linear(256, 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_save_as = './SubjRDM/subj_best_Model.pkl'\n",
    "checkpoint = torch.load(joint_save_as)\n",
    "bert.load_state_dict(checkpoint['bert'])\n",
    "transformer.load_state_dict(checkpoint['transformer'])\n",
    "task_embedding.load_state_dict(checkpoint['task_embedding'])\n",
    "subj_cls.load_state_dict(checkpoint['subj_classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 187 ,  max_seq_len: 101\n",
      "5802 data loaded\n"
     ]
    }
   ],
   "source": [
    "load_test_data_fast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del data_ID\n",
    "del data_len\n",
    "del data_y\n",
    "\n",
    "from BertRDMLoader import data\n",
    "from BertRDMLoader import data_ID\n",
    "from BertRDMLoader import data_len\n",
    "from BertRDMLoader import data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_idxs = [idx for idx, d_y in enumerate(data_y) if d_y[1]==1]\n",
    "neg_idxs = [idx for idx, d_y in enumerate(data_y) if d_y[0]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_samples = random.sample(pos_idxs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = random.sample(pos_idxs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_x, pos_len, labels = get_data_by_idxs(pos_idxs, tokenizer=tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_x, neg_len, labels = get_data_by_idxs(neg_idxs, tokenizer=tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "subj_task_id = torch.tensor([1]).cuda() if cuda else torch.tensor([1])\n",
    "task_emb = task_embedding(subj_task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_scores: torch.Size([362, 2])\n",
      "seq_len: [0, 35, 18, 25, 19, 9, 10, 34, 19, 7, 11, 20, 29, 25, 12, 13, 8, 20, 20, 14, 14]\n",
      "subj_scores: torch.Size([500, 2])\n",
      "seq_len: [0, 41, 14, 49, 26, 17, 83, 22, 9, 7, 20, 26, 11, 16, 6, 20, 12, 23, 18, 23, 57]\n",
      "subj_scores: torch.Size([463, 2])\n",
      "seq_len: [0, 19, 8, 28, 20, 20, 16, 72, 8, 23, 10, 6, 31, 37, 27, 11, 39, 28, 46, 6, 8]\n",
      "subj_scores: torch.Size([555, 2])\n",
      "seq_len: [0, 30, 24, 30, 10, 20, 27, 28, 90, 29, 14, 34, 9, 24, 20, 20, 101, 8, 15, 11, 11]\n",
      "subj_scores: torch.Size([409, 2])\n",
      "seq_len: [0, 8, 20, 9, 11, 21, 19, 12, 9, 24, 23, 20, 18, 13, 9, 65, 23, 8, 8, 25, 64]\n",
      "subj_scores: torch.Size([518, 2])\n",
      "seq_len: [0, 96, 10, 40, 8, 9, 19, 14, 16, 13, 18, 11, 18, 9, 16, 16, 25, 56, 8, 48, 68]\n",
      "subj_scores: torch.Size([362, 2])\n",
      "seq_len: [0, 6, 10, 11, 11, 35, 10, 14, 22, 17, 41, 20, 35, 24, 9, 21, 16, 20, 8, 11, 21]\n",
      "subj_scores: torch.Size([428, 2])\n",
      "seq_len: [0, 21, 23, 15, 28, 101, 13, 25, 23, 18, 20, 21, 20, 31, 8, 7, 10, 19, 8, 9, 8]\n",
      "subj_scores: torch.Size([389, 2])\n",
      "seq_len: [0, 12, 16, 16, 28, 19, 15, 43, 7, 21, 18, 12, 21, 7, 8, 15, 27, 16, 29, 20, 39]\n",
      "subj_scores: torch.Size([511, 2])\n",
      "seq_len: [0, 40, 14, 37, 19, 34, 30, 7, 8, 10, 18, 21, 19, 53, 10, 92, 6, 33, 21, 15, 24]\n",
      "subj_scores: torch.Size([369, 2])\n",
      "seq_len: [0, 10, 12, 9, 8, 14, 11, 46, 38, 20, 19, 19, 26, 22, 8, 21, 18, 19, 11, 18, 20]\n",
      "subj_scores: torch.Size([333, 2])\n",
      "seq_len: [0, 11, 10, 20, 19, 17, 42, 20, 23, 18, 11, 13, 17, 7, 15, 16, 17, 19, 10, 16, 12]\n",
      "subj_scores: torch.Size([623, 2])\n",
      "seq_len: [0, 55, 10, 52, 13, 100, 7, 25, 19, 11, 6, 24, 24, 9, 101, 21, 30, 46, 19, 31, 20]\n",
      "subj_scores: torch.Size([503, 2])\n",
      "seq_len: [0, 9, 20, 46, 21, 23, 12, 32, 18, 42, 11, 7, 18, 21, 6, 33, 14, 19, 23, 101, 27]\n",
      "subj_scores: torch.Size([607, 2])\n",
      "seq_len: [0, 13, 72, 20, 12, 101, 25, 26, 26, 7, 16, 15, 17, 49, 101, 12, 16, 22, 19, 18, 20]\n",
      "subj_scores: torch.Size([512, 2])\n",
      "seq_len: [0, 28, 7, 101, 16, 33, 16, 34, 17, 19, 30, 25, 25, 23, 20, 12, 17, 31, 20, 18, 20]\n",
      "subj_scores: torch.Size([319, 2])\n",
      "seq_len: [0, 20, 20, 6, 8, 21, 30, 23, 12, 20, 8, 18, 20, 7, 25, 13, 7, 30, 16, 7, 8]\n",
      "subj_scores: torch.Size([310, 2])\n",
      "seq_len: [0, 9, 16, 19, 34, 17, 10, 19, 18, 12, 10, 6, 25, 7, 6, 9, 12, 28, 19, 19, 15]\n",
      "subj_scores: torch.Size([453, 2])\n",
      "seq_len: [0, 33, 20, 17, 21, 23, 7, 13, 33, 19, 55, 11, 10, 49, 17, 21, 21, 24, 30, 9, 20]\n",
      "subj_scores: torch.Size([325, 2])\n",
      "seq_len: [0, 19, 10, 21, 21, 13, 11, 11, 22, 18, 25, 8, 12, 53, 12, 19, 12, 11, 7, 7, 13]\n",
      "subj_scores: torch.Size([421, 2])\n",
      "seq_len: [0, 20, 37, 18, 13, 20, 24, 24, 31, 11, 56, 42, 17, 6, 20, 12, 21, 16, 8, 9, 16]\n",
      "subj_scores: torch.Size([494, 2])\n",
      "seq_len: [0, 19, 25, 24, 10, 13, 6, 20, 8, 16, 8, 9, 27, 20, 101, 15, 61, 75, 9, 15, 13]\n",
      "subj_scores: torch.Size([372, 2])\n",
      "seq_len: [0, 9, 20, 10, 6, 20, 13, 39, 19, 35, 11, 10, 101, 8, 13, 9, 10, 6, 11, 11, 11]\n",
      "subj_scores: torch.Size([492, 2])\n",
      "seq_len: [0, 101, 6, 20, 22, 20, 19, 26, 22, 35, 19, 23, 19, 9, 6, 40, 35, 17, 19, 15, 19]\n"
     ]
    }
   ],
   "source": [
    "pos_scores = rdm_seq_data2scores_seq(pos_x, bert, task_emb, subj_cls, label_num =2)\n",
    "neg_scores = rdm_seq_data2scores_seq(neg_x, bert, task_emb, subj_cls, label_num =2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_head = [h[0] for h in neg_scores]\n",
    "neg_tail = [h[-1] for h in neg_scores]\n",
    "\n",
    "pos_head = [h[0] for h in pos_scores]\n",
    "pos_tail = [h[-1] for h in pos_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist((neg_head, neg_tail), 20, \"objective score\", \"probability\", [\"first issue\", \"last issue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist((pos_head, pos_tail), 20, \"objective score\", \"probability\", [\"first issue\", \"last issue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXhT1dbA4d9q0jYts1IBZagoIMioZVBERhEBQcUBJ0ARxBmnK16v471ecRZxQFQUFQFFRRTUCwiCgEzKKKKggCAKlrlzkv39sSMfYrGFJjnJyXqfJ0/T5PScdZp2ZWefvdcWYwxKKaXiX5LTASillAoPTehKKeUSmtCVUsolNKErpZRLaEJXSimX8Dp14KpVq5rMzEynDq+UUnFp6dKlvxtjMop7zrGEnpmZyZIlS5w6vFJKxSUR2Xio57TLRSmlXEITulJKuYQmdKWUcgnH+tCLU1RUxObNm8nPz3c6lITh8/moWbMmycnJToeilCqjmEromzdvpkKFCmRmZiIiTofjesYYsrOz2bx5M8cff7zT4Silyiimulzy8/M5+uijNZlHiYhw9NFH6ycipVwiphI6oMk8yvT3rZR7xFxCV0opdWQ0oSullEvE1EXRROH3+/F6I/+rj9ZxlOKBSoex7e7IxZHgtIV+kA0bNtCwYUMGDRrEySefTNeuXcnLy2PZsmW0adOGpk2bcv7557Nz504AOnTowF133UWrVq2oX78+c+fOLXa/HTp0YOjQoWRlZTFixAgGDBjApEmT9j9fvnx5AGbPnk379u3p3bs3devWZdiwYYwbN45WrVrRpEkT1q9fvz/OTp060bRpUzp37symTZsAGDBgAEOGDKF169b84x//4IsvvqB58+Y0b96cFi1asHfv3kj++pRSDord5tvQobBsWXj32bw5PPNMiZv98MMPjB8/npdffpmLL76Y9957j8cee4yRI0fSvn177rvvPh588EGeCe3L7/ezaNEipk2bxoMPPsiMGTOK3W9hYeH++jUDBgw45PGXL1/OmjVrOOqoo6hbty7XXHMNixYtYsSIEYwcOZJnnnmGm266if79+9O/f3/GjBnDzTffzOTJkwE7/HP+/Pl4PB7OPfdcnn/+edq2bcu+ffvw+XyH+UtTSsULbaEX4/jjj6d58+YAnHrqqaxfv55du3bRvn17APr378+cOXP2b3/BBRfs33bDhg2H3O8ll1xSquO3bNmSGjVqkJqaygknnEDXrl0BaNKkyf79L1iwgMsuuwyAK6+8ki+//HL/z1900UV4PB4A2rZty2233cazzz7Lrl27tAtGKReL3f/uUrSkIyU1NXX/fY/Hw65du0q1vcfjwe/3A3DVVVfxzTffcOyxxzJt2jQAypUrt/9nvF4vwWAQgGAwSGFhYbHHT0pK2v99UlLS/v3/nQOPM2zYMHr06MG0adNo27Ytn332GSeddFKJ+1BKxR9toZdCpUqVqFKlyv7+8TfffHN/a/1QXnvtNZYtW7Y/mR8sMzOTpUuXAjBlyhSKiooOK6bTTz+dCRMmADBu3DjatWtX7Hbr16+nSZMm3HXXXbRs2ZLvvvvusI6jlIofsdtCjzFjx45lyJAh5ObmUrduXV577bUy7W/QoEH07t2bZs2a0a1btz+1qktj5MiRXHXVVTz++ONkZGQcMp5nnnmGWbNmkZSUxMknn8w555xTpriVUrFLjDGOHDgrK8scvMDFmjVraNiwoSPxJDL9vasy02GLUSMiS40xWcU9p10uSinlEprQlVLKJTShK6WUS2hCV0oplygxoYuIT0QWichyEVktIg8Ws02qiEwUkXUislBEMiMRrFJKqUMrTQu9AOhkjGkGNAe6iUibg7YZCOw0xpwIPA08Gt4wlVJKlaTEhG6sfaFvk0O3g8c69gbGhu5PAjqLrpyglFJRVao+dBHxiMgyYBsw3Riz8KBNjgN+BjDG+IHdwNHF7GewiCwRkSXbt28vW+RRYIzZPz0/kgKBQMSPoZRyv1IldGNMwBjTHKgJtBKRxkdyMGPMaGNMljEmKyMj40h2EXEbNmygQYMG9OvXj8aNG+8vcgUwadKk/VUSBwwYwHXXXUebNm2oW7cus2fP5uqrr6Zhw4Z/qqQ4fvx4mjRpQuPGjbnrrrv2P16+fHluv/12mjVrxoIFCxg2bBiNGjWiadOm3HHHHdE6XaWUixzW1H9jzC4RmQV0A1Yd8NQWoBawWUS8QCUgu2yhDQXCXD6X5kDpyueOHTuWNm3a7K9TXpydO3eyYMECpkyZQq9evZg3bx6vvPIKLVu2ZNmyZRxzzDHcddddLF26lCpVqtC1a1cmT57MeeedR05ODq1bt+bJJ58kOzubgQMH8t133yEiJRYDU0qp4pRmlEuGiFQO3U8DzgIOrvA0Begfun8h8LlxqqZAGNSpU4c2bQ6+7vtX5557LiJCkyZNqFatGk2aNNlfM2XDhg0sXryYDh06kJGRgdfr5fLLL99fdtfj8dCnTx/AFv/y+XwMHDiQ999/n/T09Iien1LKnUrTQq8BjBURD/YN4B1jzMci8hCwxBgzBXgVeFNE1gE7gL5lD8258rkHFso68Npufn7+n7Y7sKztwSVv/X4/ycnJhzyGz+fb353j9XpZtGgRM2fOZNKkSTz33HN8/vnnYTkXpVTiKDGhG2NWAC2Kefy+A+7nAxeFN7TYUK1aNdasWUODBg344IMPqFChQql/tlWrVtx88838/vvvVKlShfHjx3PTTTf9Zbt9+/aRm5tL9+7dadu2LXXr1g3nKSilEoSWzy3B8OHD6dmzJxkZGWRlZbFv376SfyikRo0aDB8+nI4dO2KMoUePHvTu3fsv2+3du5fevXuTn5+PMYannnoqnKeglEoQWj5X6e9dlV0slM+NhRiiQMvnKqVUAtCErpRSLhFzCT2ORzvGJf19K+UeMZXQfT4f2dnZmmSixBhDdnY2Pp/P6VCUUmEQU6NcatasyebNm4mHOi9u4fP5qFmzptNhKKXCIKYSenJyMscff7zTYSilVFyKqS4XpZRSR04TulJKuYQmdKWUcglN6Eop5RKa0JVSyiU0oSullEtoQldKKZfQhK6UUi6hCV0ppVxCE7pSSrmEJnSllHIJTehKKeUSmtCVUsolNKErpZRLxFT5XKVUBB3OIspud7i/izhZVLrEFrqI1BKRWSLyrYisFpFbitmmg4jsFpFlodt9kQlXKaXUoZSmhe4HbjfGfC0iFYClIjLdGPPtQdvNNcb0DH+ISimlSqPEFroxZqsx5uvQ/b3AGuC4SAemlFLq8BxWH7qIZAItgIXFPH2aiCwHfgHuMMasLubnBwODAWrXrn24sSqlIs5A9SDU9UPtAFQJQgUDSQYCAnsEspNgoxfWeWGnjquIJaVO6CJSHngPGGqM2XPQ018DdYwx+0SkOzAZqHfwPowxo4HRAFlZWeaIo1ZKhVeKgVML4ZQiyAjax7KTYHsSbBQICngNVDJQKwCN/XabTR5Ymgwrk+02ylGlSugikoxN5uOMMe8f/PyBCd4YM01EXhCRqsaY38MXqlIq7JIMtC6EdoWQbmyC/sgHa72w71CtbwNVDDQsghZFcH4+tC+Az32wygtoYndKiQldRAR4FVhjjHnqENtUB34zxhgRaYXtm88Oa6RKqfCq6Ydz86FaENZ5YHYqbC5NG09gp8D8VJifAg380KEALsyDFh74OE27YhxSmlevLXAlsFJEloUe+ydQG8AYMwq4ELhORPxAHtDXGKNdKkrFIjFwRiF0LIC9AuPTYG3yke7M/uz3Xsgqgs75MGQffJQGq450n+pIlZjQjTFfUsJnKGPMc8Bz4QpKKRUhqQYuzIV6AVjpta3pgjB0kRiBxSm2q+bCPHur7YdPfdq3HkU6U1SpRFExCJfnQtUgfOyDJcmEvb97TxK8ng6dC6BtIVQ2MCkNCjWpR4N2dCmVENbCwByoHIRx6bAkhYhdvAwKTPfZi6sn+qF/DqRpD2w0aEJXyvV+ADqCBxhTDn6M0gfzpSkwIc1edL0yB3ya1CNNE7pSrrYe6AgUwdh0+M0T3cN/nwwT0+CYIPTTpB5pmtCVcq1tQFfswLOZsD3KyfwPP4SSerUgXJILFDoTRwLQhK6UK+UBvYCtwDSgqbPh/JAMH/rg+AAwENCWeiRoQlfKdYLAFcAiYBzQ2tlw/rAiBWamAm8BWmE7EjShK+U6DwLvA08C5zscy0HmpmBb6P/BxqjCSRO6Uq4yDXgIGAAMdTaUYgnwPPZTQ3/gO2fDcRlN6Eq5xk/YrpZm2KQZq5N5UoFJQBr2E8ReZ8NxEU3oSrlCAbakUhBbGDXd2XBKVBN4BztG/jqHY3EPTehKucK92GUJXgdOcDaUUusA3I+9cDvO2VBcQmu5KBXPHqgEmX7on2sXmvi4v9MRHaa7gc+A64HTgeOdDSfOaUJXKg5lDpsKwIbKBs7Pgx1J8JnP4aiOhBc7jLEZtv//CzQtHTntclEqnnXPs2t+vpcGRbF6EbQkmcAoYD7whLOhxDlN6ErFqbNPng9N/XaloV8cmtYfNpcCfYAHgLXOhhLHNKErFYcq+vbxUO9R8GsSfJnidDhh8hx2dM7VQMDhWOKTJnSl4tCwc16navldMCXNRSsCVQdGYLtennc4lvikCV2puPMFl7X+lFfmnueCrpaDXQGcgx398pPDscQfvZys1JEwBnbsgG3b4PffIRCApCSoWBGqV4eMDPBEItnmAYPYmF2dp2dcxrWeGRE4hpMEeAloBNwEfETszniNPZrQlSqN3Fz44guYMQOWLoUVK2DnzkNvn5oKTZpAixbQoQN07QpVq4YhkOHAD/zzg/+QX+SzqxC5Ti1sgbHbgSlAb2fDiSOa0JU6lMJC+OQTeP11+7WgAHw+aN4cLr4YTjrJtsarVrWt8WAQdu+GX36Bn36CZcvg3Xfh5ZdBBE4/Hfr3tz9bqdIRBPQj8ChwGfPWNQ/vucacm4DXgFuAs4j9UgaxQRO6Cps/Jrscjg3De0QgkjLatQteeAFGjLBdKtWqwZAh0L07tGsHaWml31cgAF9/bd8QJk6EwYPhlltsYr/zTqhb9zACuxVIBh4Hvjm8c4o7ycALwJnAw6GbKkmJF0VFpJaIzBKRb0VktYjcUsw2IiLPisg6EVkhIqdEJlylImjvXrj3XqhdG+65B049FT7+GDZvhmeesd0mh5PMwbbcW7aE++6DVatg4UK47DIYMwbq14d+/WDTplLsaBq2++E+4NjDP7e41A7oh30D07HppVGaUS5+4HZjTCOgDXCDiDQ6aJtzgHqh22DgxbBGqVQkBQLwyitQrx785z+2Jb5sGUybBj16gDdMH2RFoFUre6wff4ShQ22XTIMG8K9/wb59h/jBAmzXQ4PQ10TyGLa75UZ02bqSlZjQjTFbjTFfh+7vBdYAxx20WW/gDWN9BVQWkRphj1apcFu7Fs48EwYNghNOgK++ggkToFmzyB73uOPgiSfs8S+4AB5+GBo3hunTi9n4KWAd8CzglklEpVUN+DcwA/jY4Vhi32GNQxeRTKAFsPCgp44Dfj7g+838NekjIoNFZImILNm+ffvhRapUOAUCNqE2bw5r1sDYsfDll9A6yutv1q4N48bZY/t8tltn0CDYsye0wWbscm0XAF2jG1vMGAKcBNwBFDocS2wrdUIXkfLYyvlDjTF7Stq+OMaY0caYLGNMVkZGxpHsQqmy27YNzjnHXpTs1g1Wr7Z92eLgeOe2bW03z1132f71rCxYvhz4F7bXM5GLViVjz/97tDf375UqoYtIMjaZjzPGFLey6xbs4NE/1Aw9plRsmTPHjg2fMwdGj4b334caMdI76PPB8OEwezbk5MDglmDeAHMzWie8O3b44oPADodjiV2lGeUiwKvAGmPMU4fYbArQLzTapQ2w2xizNYxxKlV2L74InTpBuXJ2tMmgQc62yg+lXTv45msYVQGyDdz2OxQVOR2VwwR7LWE3Nqmr4pSmhd4WuBLoJCLLQrfuIjJERIaEtpmGnfWwDngZu/yIUrEhEIBbb4Xrr7ddLEuWRP6iZ1kdsxRa7ID5XeCZ1+3Im127nI7KYY2xg+heAL5zOJbYVOJ4LGPMl5RQTMEYY4AbwhWUUmGTkwOXXgoffWQn9Dz5ZIRqrISTH7gTqAe9psKYcXDttXDaaXaCUmamw/E56SHgbezv5yOHY4k9Wm1RudeuXXbUyNSp8NxzdnJQzCdzsD2c32Kn+afAVVfZ4Yy//gpnnGFH5SSsDGwlxo+BLx2OJfZoQlfutH07dOwIixfDO+/ADfHyAXIvdjboGcB5//9w+/a2OJjfD2eeycm/rnMovlhwM3a27F3oZKM/01ouyn22bIEuXWDDBpgyxfabx43HgW0UWza2aVOYOxe6dGH8+H9y1UUPwInRj7DMHjiMwmQP7C7mwXTgfuBa7O+pV1jCcgNtoSt3+eUXW652yxb47LM4S+bbgaeBC4FWxW9Srx58+SXby1fh9Xfvh83+KMYXS64G6mO7X3S5uj9oC125x/bttmW+davtcz7ttKiHULaKk48BudgLf3+jVi0u6/swE9++mwpvbYV+5eDYeLg2EE5e4L/YN783gKucDSdGaAtducPOnfYC6E8/2YugDiTzstmKXUfzcqBhiVv/VqEql136MKQJvJkDvyZiK/UC7CeZ+4F8h2OJDZrQVfzbu9dO5f/2W5g82V5AjDuPYOuU3F/qn/il4jG2dZ4i8GYuZCdaUhfsCk4/o4tKW5rQVXwrLIQ+fexkoXfegbPPdjqiI7AJu47m1cAJh/ejVZKgX2g1n7dyYV8wzLHFuo5AN+Bh8OmIF03oKn4ZY6fvT59ua4z3jte1J/8T+vqvI/vxoz1wWTrkGBiXCwWJltgeAXbC6QVOB+I4vSiq4te//gVvvAH//jcMGOB0NEek9lFb8Qde5a2F3Xlgykpg5ZHt6DgPXJQG4/NgYi5cng6eGKxTExHNgUugzUT4KgVyE7edmrhnruLbqFHw3//aFvo99zgdzRG7pfN4/EEvz8+6uOw7q5cMvXzwUwA+zLOfYBLGA7Z52jax66VrQlfxZ+pUO/OzZ0+7mHMsVkwshRMyfua8FrMZO78n2/ceFZ6dNk+Bjqmw0g9zEym5nQQrkqFVIZRPtOsI/08Tuoovq1dD3752paEJE8K33qcDbu3yNnlFqbw0p094d9wuBZomw6wC+DaByu5+kWozWrtEeiP7s/j9b1CJJzsbevWC8uXhww9tXfM41bDGj/RsNpeRn1/Cjpw/T4Xf4LusbDsXgXN9sCMIH+RB5aT4nXh0OGUCSIJlyXBqIcxPgd2J117VhK7iQ1ERXHSRndI/ezbUrHlYP162GZzhd9tZ49iTV46X554fmQN4BS5Jg1dyYEIuXFMOKiZAgpuTCs2K4MwC+CjN6WiiLgFeYeUKQ4fCrFnw8svQpo3T0ZRJ05rfc1ajhYyeez578spH7kDlk+DSdDuMcUIuFCXARdLdSbA0GZoXQZXE60vXhK5i36hR9uLnnXfClVc6HU2Z3X7WW+zIqchrX0ahSmA1D1yQBluDMC0/MUa+zE2FINA+8cala0JXsW3+fLjpJju1/5FHnI6mzFpmrqJ9g68Z9UUfcgrTo3PQBslwZgosK4KlCXCRdF8SLEqBpkVQNbHKIWhCV7Hrt99sv3mdOvD223Gy2tDfMdzR9S22763MGwsi1z9frA6pcKIXPslPjJK781LsSn4dEquVrhdFVWzy++1aoDt2wFdfQeXKUQ/hSC6k/p22Jy6ndd1V3D/lWvKLfGHdd4lEbNfLy/vgnTwYXM72sbtVbpKdNXpmIcwNwG/x3hgoHRe/oiqu3XuvvQg6ahQ0a+Z0NGFguP2sN9myK4PxCx1adCNN4OJ0yDMwKQ8CLu9Pn59qq+p2TJxWuiZ0FXs+/BCGD4fBg6F/f6ejCYuODZZwSp21jJx5CYWBZOcCqe6Bc9NgYwBmuDzR5YtN6if54djE6EvXhK5iy7p1NolnZcGIEU5HExYiQW7v+hYbs6szaWkXp8Oxs0hbpcBXhfCdyy+SLkyBXEmYVnqJCV1ExojINhFZdYjnO4jIbhFZFrrdF/4wVULIzbW1zT0eePdd8EW5nzlCzj55AY2PW8+ImZfiD8bIZauzUuHYJFvEa5eLx2sXiL1AWs8Ptdx/Mbg0LfTXsRXk/85cY0zz0K2EBRGVOoSbb4aVK2HcOMjMdDqasEiSALedNY5122oy+ZsOTofz/7wCF6aDASblurs/fVEK7EuMVnqJCd0YMwfYEYVYVCIbPx5efRXuvhu6OXTRMAJ6Np1L/WqbeHr65QRNjI20qJIEvdNgS9Dd/elFAl+mQN0AZLq7lR6uPvTTRGS5iHwiIicfaiMRGSwiS0Rkyfbt28N0aBX31q2Da6+Ftm3hwQedjiZsPEkBbj1rHGu2ZjJtVVunwylewwTpT1+SAnsEOhVgP5a4UzgS+tdAHWNMM2AkMPlQGxpjRhtjsowxWRkZGWE4tIp7BQW2HK7XaycPxXE53INdcMpMjq+6laemX4ExMTz+4KxUqOHy/nS/2MJdtQNwgntHvJT5r8wYs8cYsy90fxqQLCJVyxyZSgx33w1Ll8KYMVC7ttPRhE2Kp4hbOo9n+c/1mP5ta6fD+XtegYsSoD/9m2TYJdApH7e20suc0EWkuohdMkZEWoX2mV3W/Sr367RuETz9tK3Vct55TocTVhe3/B81q2znyf9dAcTBikpVkqCXy/vTA2IXwTguCA3c2Zde4udbERkPdACqishm4H4gGcAYMwq4ELhORPxAHtDXmEQo6abKovqe33li2jN25aHHHnM6nLBK9RZwY8eJLPqpEXN+OMXpcEqvUTK09Nv+9Loeu0ap2yxPhjMK7YiX771g4uDN9jCUmNCNMZeW8PxzwHNhi0i5nicYYMTHT5DqL4SJE10z3vwPV7T5hOqVdjB04h3ERev8QF19dhbp5HwY4oEKMdz3fySCArNToU8eNPTDt+5603LZq6Xiwc3zJtD651Xcc/YNUL++0+GEVXpKHtd1eJcvf2jGVz82dTqcw+cVuDANCg1MznNn/fRVXtiWZFvp4q7zc8+QAhUXTtu4gpvmT2BS485MPrkjk8Nc0dBpA07/iKrld/PU9CucDuXIZXigmw8+zof5hdA21emIwsuEWukX50FjP6x0TytdW+gqao7K3c0zHz/BT0cdx31nDXE6nLCr6NvHte3fY+aalny9qaHT4ZTNKcnQ0AufF8AWFw7zW+OFX5NsvfQk97TSNaGr6DCGJ6Y+TeW8vdzY+x/kprhvAd9r2n1ApbSc+G6d/0HEVmUsL/Berl2X1E2MwKxUODpoF5V2CU3oKiquWjqFTj8u4eGOV7PmmLpOhxN2R5XbzdVnTGHqiras/uUEp8MJj7TQohi7jF2P1G3WemFLkl171OOONyxN6CriGv32I8Nmv8b0E1vzxik9nQ4nIoa0n0RacoE7WucHquOFM1NhRRGsKHQ6mjAT+NwHlQ20cEcrXRO6iqi0wnxGTnmMnWkV+cc5N9uP8i5zTIVs+p02lcnfdGD99lpOhxN+Z6ZAbQ9MzYcdLisNsN4DmzxwZgF447+VrgldRdR9M0dz/I4t3NrzdnamV3I6nIi4sdM7eJICPDPzMqdDiYykUNdLErY/3VWlAQQ+T4WKBk6N/08gmtBVxHT/7ksuXfE/XmxzIQvquGFd0L+qWeU3+rb8jImLu/LzjupOhxM5lZLsRdJfgnbki5ts8MKPHmhXCMnx/WalCV1FxHG7tzH805F8U6MBT59xudPhRMwtncdjjPDc55c4HUrkNUq2wxnnF8J6l9VCmZUK5Q20iu9Wuk4sSgCZRzB5Z8PwHkd8PE8wwIiPHkdMkJt73Ynf484/s7pVN3PBKZ/z2rxz+XVPghQY7eaDTQE7i3RIOSjnkjbhz174wQNtC2FxChTG57Uel7waKpbcPG8CWVvWcM/ZN/BzZfd2Q9x61jjyi1J4cfZFTocSPcmh0gB5xtZ7cVNpgFk+SDfQJn5b6ZrQVVi1+nkVNy6YyKTGnZnSqIPT4URMwxo/cm6zuYyZ15vsnMpOhxNd1Txwtg/W+WFB/Ca/v/jFA9954fQC8MXnG5UmdBU2lfL28sxHT7CpcjXu73Kt0+FE1O1d32RPXjlennu+06E4IysZTvLCzAL4xUWlAWalgg9oG58Xft3ZuamizxiGfzqSqjm7uODKJ8hJTXc6oohpmbmKLg0X8+gn/dmTV97pcJwhYhfEGLXPrnJ0bXlIjc9+5z/5zQMrkm23y6IU2Btq8z5wGENuH9gdmdhKQVvoKjxGj+ac7+fz+Jn9WFX9RKejiSDD3ee8xtbdRzNmXi+ng3FWmkCfUGmAqS4qtft5qi1j3yH+Wuma0FXZrV4NQ4cyJ7MFr7Ry11JyBzv75AWcUmctT0+/nAK/y8rKHonaXmifCiv9sNwd0+fZlWRHurQogoz46k7ShK7KJj8fLr0UKlTg9h63YcS9f1LeJD//6DaW73+rzXtfd3Y6nNjRLgUyPbaA1+/xlQAPaW4KFAKd46uV7t7/PhUdd94JK1fC2LFsL1/F6Wgi6uKs6ZyQsYXHPu1PIOhxOpzYkSRwfppd7WhSHvhd0PWSmwTzUuEkP9SKn0lUelFUFas0k5HO/n4+L33wHK9m9ebfX7isaNNB0pLzGdrlbRb91IgZa1o5HU7sqZgE5/lgfB5ML4BzXLBO7Fcp0LIQuhbAqx7iYX1YbaGrI1Jz9288Nm0Ey6vXY3iHAU6HE3HXtPuAYyruZPgnVxEP/9iOqJ8MrVNgUSGsdUF/elFoqbpaAdtSjwOa0NVhSw4U8dyHjyLGcGPvuyjyuGdNxuIcVW4317Z/n09XnRb/S8tFWpdUqJ4EH+bDHhd8aluWDNuTbF96HCxVpwldHbY7v3iD5lu/5x/db3H11P4/3Nx5PD5vAY9/1s/pUGKfN1QaIGDg/TwIxn4S/FtBgRmpkBGMi0UwSkzoIjJGRLaJyKpDPC8i8qyIrBORFSJySvjDVLGi07pFDF78AWNP6cGnDdo6HU7EnZDxM1e0nsaExWe7c/GKSDjaA0e+EEcAABdNSURBVN19sDEAc1xQGmCtFzZ6oGMBpMb2G1RpWuivA93+5vlzgHqh22DgxbKHpWJRjT3beXLq06yqdgL/7TjQ6XCi4l89XiG3yOe+peUirVkKNEuGOQWwIT76nw9N4DOfLa/bLraHMZaY0I0xc4Adf7NJb+ANY30FVBaRGuEKUMUGb8DPyCmP4Q36uaH3XRR4U5wOKeI61F9Cx5OW8uzMvuzIcedqSxHV3QdHJdmhjHvjvD/9F4/tT29TCFVi91zC0Yd+HPDzAd9vDj32FyIyWESWiMiS7du3h+HQKlpun/sWWVvWcHe3m9hY5Vinw4k4b5Kfe3q8yk+/12Ds/HOdDic+pQhcnAaFBt5zQX/6zFQIAmflOx3JIUX1oqgxZrQxJssYk5WRkRHNQ6sy6LB+CdctnMS45t34uOGZTocTFZe1/oR61X7m4anXUBRw9yieiDrGAz1C/enxvnTd3iSYmwqN/JAZm91I4UjoW4ADrxbVDD2mXKDm7t94+uMnWZORyUOdBjkdTlRUStvLrV3e5ssfmukkonBolgKnJsM8F4xPX5ACuwS65YPE3ieOcCT0KUC/0GiXNsBuY8zWMOxXOSzVX8gLkx/BY4Jce/49FCQnRjGqWzqPp2JaDv+Zeg06iShMuvmgRpJdum5n7PZBl8gvMN0H1YNwSuy9OZVm2OJ4YAHQQEQ2i8hAERkiIkNCm0wDfgTWAS8D10csWhVVD0wfRdNf13Frz9vYVCUxrnPXO2YjV542lYmLu/Ldr8c7HY57eAUuCtXIfzc3vuu9rA4NY+wUe8MYS6zlYoy5tITnDXBD2CJSMeGS5Z9x6Yr/MfK0S5h5Ymunw4kSw3/Oe5F9+ek8/tmVTgfjPlWS4Lw0mJAHn+ZDzzSnIzpCAp/6YHCOHZv+aezUrdGZouovGv+6joemj2JOZguePuMyp8OJmvOaz6Z13VU89ll/dubqMMWIaJAMbVNgaREsj+NJR1s9sCQZWhVC9dgpGawJXf1J5bw9jPrgv2wvV5lbzr2DYFJilImtkJrDPT1eZdnP9Zi4+Cynw3G3Tqm2fvpH+fG9HulMH+QJ9IidC6Sa0NV+ScEAIz56goycHVx/3t3sTE+cVuptXd/i6HK7uXfy9QRNYryJOSYpVO+lvMDEXNgXpxdJ8wX+F6rGGCN1XrQeutrvH3PeoP1PX3P32TeyokZ9p8MJiw2+UnQZVQ/AaTmwNJmVW+pFPigF5ZKgbzq8mgPv5kG/dPDE4Yii5ck2mXcpgO+8dmEMB2kLXQFw3upZDFn4Hm+26M745n9XusdlxNiPzHliP0Kr6Knugd5psCkAn8Tu7Mu/JzDVZ0e7dHF+4pQmdEWzX9by6CfPsqB2Ex7sPNjpcKIrq8h+ZJ6eaj9Cq+hqnAynhy6SLo3Ti6TbPXbC0SlFji9Xpwk9wR2zN5vRHzzMb+WP4vrew/B7EqgXrmIQuuTD+lDhJeWMzqlwQmiR6U2xOaW+RHNS7QzSXvmAc582NKEnsNSiAkZ/8B/KFeZxTZ97E+oiKBjomW8ngn6chs4IdVCSQJ90qJwE7+TBrji8SFoo8FGaXQiDfzsWhib0RGUMwz8dSfOtP3Brz9v5PiPT6Yiiq4kf6vvh81TYqf8GjksT6JtmZ5C+nQv5sTEM8LCs98I3ycCjwDeOhKB/yQnqlnnjOf/b2Tze7kqm12vjdDjRlR60xZU2J8FC99d1jxsZHrgkHbKDtjxAIA6T+mc+IAO4Goj+UEZN6Amoz8qZ3Drvbd5t3IXnT7vY6XCir1s++AxMSQOjXS0x5Xgv9PTBjwHbp27iLKnnC/ACsAx4POqH14SeYE7fsIzhnz7L3DrNubvbjSAJltAaFUFTP8xNgW06gSgmtUiBM1Lg6yJYEI8jX84HLgIeBL6N6pE1oSeQ+ts3MOqD/7Lu6Fpcf/7diTWiBaB80F4I3ZJkRyWo2NUpFRp5YXoBrImNWZiH5zmgInA5EL03JU3oCeKYvdm89u6D5Kb4uPrC+9mbWs7pkKLMQO98SDbwQRoEE+yTSbwRsZUZa3rs8nUb42044zHAK9iul/ujdtQEa6Ilpor5+xj77v1UKtjHxZc9ytaKCbj836lFUM8P03zwe3i6WkpVVkAduWSBS9PgtVwYnwsDytnZpXGjNzAIO+rlHCDyyzdqC93tcnIYM+lB6u7YzJDz/sm31eo6HVH0HRWEs0MTiBbrBKK4kp4EV6RDqsBbuXG42tFTwAnAlcDuiB9NE7qbFRbChRfS4pe13HzuP/jy+BZORxR9HgMX5kIA+FBHtcSlSqGkHgTezImz6ozlgbewyyxHfh0gTehuFQhAv37w6afcffaNfNbgdKcjckbXAjg2CJPTYI/+ucetDA9clgb7DIyLt4lHrYH7gHHA6xE9kv6Fu5ExcMMNMHEiPP447zTr6nREjjj75PnQutAWTlqrXS1xr6YXLk6HbUGb1AviKanfA3TALrm8OmJH0YTuNsbALbfASy/BsGFwxx1OR+SImlV+5fELR9ghijN0iKJrnOi1i2NsCdikXhgvSd0DvA1UAC4GciJyFE3obmIMDB0KI0fCrbfCf//rdESOSPUW8txlj9pv3k2HgPabu0rDZOiTBpsDtu5L3CT1GthulzXAsIgcQRO6Wxhjk/izz9qk/uSTiTcLFADDv897gea1fuCOd4fCLv0Td6WTk+GC0OIYE3KhKF6SehdgDHBXRPauf+1uYAzcdhuMGGG7W556KkGTOfQ//WMuzprBiBmX8r9vT3M6HBVJjZPhPB/8FLDj1OOmpT4AqBmRPZcqoYtINxFZKyLrROQvnxVEZICIbBeRZaHbNeEPVRUrGISbboJnnrHJ/OmnEzaZt6m7gnt7vMz0b1vzzMxLnQ5HRUPTFJvUNwTsOPW4Gv0SfiXOFBURD/A8cBawGVgsIlOMMQdXnZlojLkxAjGqQykqggED4O234c474dFHEzaZ16zyG89fNpwN2cdy68TbMUY/fCaMZil2Vul7eTA2x45ZL5eYr39ppv63AtYZY34EEJEJ2Dmt0S0jpv4sLw8uugimToVHHrEjWqLgcKa7Z+a/HZ0Y0gxcnQOeIEdPDLBKrgFd7zmxNEqGFIGJufB6LlyZDhUTL6mX5oyPA34+4PvNoccO1kdEVojIJBGpVdyORGSwiCwRkSXbt28/gnAVALt3Q7duMG0ajBoVtWQek7wG+uZClSBMSIfseKr1ocLqRK9tne8Jwpgc2B5wOqKoC9db2EdApjGmKTAdGFvcRsaY0caYLGNMVkZGAhaICodNm6BdO5g/33a1XHut0xE5Rwyclwd1AnYm6EatNZfw6nihfznwY5P6hnir0lg2pUnoW4ADW9w1Q4/tZ4zJNsYUhL59BTg1POGpP1m6FFq3ho0b4ZNPoG9fpyNykIGzCqCxH6anwiqdCapCjvXANeWgfJK9ULoyHuupH5nSJPTFQD0ROV5EUoC+wJQDNxCRGgd82ws7cl6F04cfwplnQmqqbZ136eJ0RM7qUACnF8LCZJin64Kqg1ROgqvL2Xrq7+fB3IL4W87uCJT4GdUY4xeRG4HPsPNXxxhjVovIQ8ASY8wU4GYR6YX9oLMDO9Ay4WQOmxr+nRrD4EXvM2z266yocSKDet7H4pNPDv9x4knbAuhQaFdY/9QHJObIHlWCNLF96lPy4PMC2BaAXml2RIxLlarT0RgzDZh20GP3HXD/buDu8Iam0gvzeGzaCHqu/ZKpDdpye49byU9O7OEb/U//yHa1rPTCFJ+Ww1V/zytwfhpkFNqk/nsOXJJuW/AupFeRYtTxO7bw0vsPc8KOzTzSYQAvteqTsGPM/zDwjA+4t+ersMZrl5HTZK5KQwTapUL1JNv9MjrHFviq67705863qTh39vfz+XDsrVTN3UW/ix/ipdYXJngyN9zS+W3u7fkqU1e0hUm6Jqg6AvWSYVB5KB9a/eiLAgi6q1/dfW9RccxXlM+9n7/C5cs+ZXn1elx/3t1sqXTMX7aLSF99zDL8s/sYBp/5Ae8u6cKw92+iR8qVTgel4tVRSTCwHEzLh9kF8JPfFvlyySQkTegx4qRtP/HslMepn72JUa0u4Mkzr6TIk9hD8VI8RQzv8ywXnDKL1+ady0MfD9Ip/arsUkP96nU9MDUfRuVAbx80iP//N03oDksKBrhqyRT+MecNdvvKc/kl/2FeZvOoHT+SK9eXad9pQegbmjQ0M5Wr5s7mqtQvwhfcIUTy96FiTLMUO6xxUh5MyIMWfujqA1/8dudpQndQve0beeyTZ2mxdS3TT2zNXefczI70Sk6H5byjAnB5HlQK2v5ynTSkIuVoj+2CmV0A8wthvR96+mx/exzShO4Ab8DPkIWTuGn+BHJS0rn53DuZ0vDMBL/wGdKgCM7Psxc9x6bDz/onqiLMK9DFZ1dC+jAP3s6D5n44KxXS46uLT/9bouy0jct5cPpL1M/exEcnteOBLteSXa6y02E5L8lApwI4o9CuA/puuq42pKLrOA8MLmdHv8wrhLV+6JwKpyQfVmMrc9hUNgzvEcFAD00TepQcu2cb93z+Kj3WzmNTpWpcc8G9zKjX2umwYkOloG2VZwZgcWj2p64DqpzgFejss6shTcuHj/Phm0LonmZrxMQ4TegRVr4gl0GLPmDwovcRDE+ecTmjW11AQbKuRA8GmhXBOfl29v77PlihdVlUDKjmgQHpsNIP0/Ph5RxomgwdU2N6lqkm9AhJ9RdyxddTueGrdzkqbw8fNziDRzpeXey48oRUPgg98qGhHzZ4bPlb7WJRsUTEJvEGXphTAIsKYXURZKVAu5SYXBVJE3qYpfiL6LNqJjfNn8Cxe39nTmYLHj+zHytr1HM6tNggBloWQad8+9f3v1RYkKLT+FXsShU4ywetU+xomEWFthumdYq9xVBi14QeLnv2MHjhewxc8iHV9u3gmxoNuL3HrSyo08zpyGJHTT90z4djg7DeA1N9sCP2+yWVAuxs0l5pcFoosc8thAWFcGoKnJ4SE7NNNaGX1caNdhm4F1/kn7t3M7dOc27tcRvz6zTTYYh/ODoAnQugkR/2CrybBqu9aNlbFZcyPHBROvwesKNhFoduTZKhZQoc7VxomtCPRDAIn30GL7xg1/UEuOACzk1vq10rB6ochDMK4JQiKAJmhbpXCjWRKxeo6oHeadA+1bbUlxXC8iIm17gVGv4Ol1wCvuiWuxbj0CoeWVlZZsmSJY4c+4itWwfjxsHYsfDTT1CtGlxzDQweDLVrx0zRLMenrx8TgLaF0KQIDLAkBeakQI7zH0mVipgCA8uLWLewKifu2AxVqthlIq+8Etq0CdsndhFZaozJKu45baGXZNs2eOcdeOstWLjQvigdOsAjj8D550OKDrMD7MSgen7IKrJfC4GvUuxtjyZylQBSBVql0KXJi2zomgavvgqvvw4vvggnnmgTe9++UL9+xELQhF6ctWthyhS7juf8+XYtwmbN4LHH4NJLoWZNpyOMHZWC0LwITimESsb2kc9KhUUpkKddKyoBiUDnzva2Zw+89x68+Sbcf7+9NW0Kd94JV1wR9kNrQgf7S58zB2bOhE8+sQkdoEULuO8+6NMHmjRxNsZYUiEIjYqgsR9qBWy3ynoPfJIC33t18Qml/lCxIlx1lb39/DO8/z5MmgS7d0fkcImZ0LOzYfFim8Q//xyWLIFAwF7AaNcObrwRevWC2rWdjjQ2iIEaQTjRb7tTagbsAJVfk2BGqq2GqJOClPp7tWrBLbfYW4SuXbo/oe/dC6tXw6JF9rZwob24CeDxQOvWcPfd0KkTnHZa1K9KxyQxcEwQageglh9OCEA5Y1vivyTB7FQ77PB3HUOu1BGJ0JBm9yT0PXtg/XpYswZWroRVq+xtw4b/36ZGDZvABw60X7OyoEIFx0KOCWLgqCBUC0L1ABwbsC3wP97X9ortTlnntbdcbYkrFaviL6Fv3AgzZsCPP9rb+vX2a3b2/2/j9cJJJ9mhQoMGwcknw6mnJvbFTF8ocR94qxq0Qwz/GKgTBLYn2S6UTR7Y5IVdgk4AUio+lCqhi0g3YATgAV4xxgw/6PlU4A3gVCAbuMQYsyG8oYYsXmzHfns8UKcOnHACXHih/Vq3rk3k9eolxHDCVG8BldL2UTl9L5XS9nFUuT1Uq5gNR+VDBWMLYFUwUDEIaQf98B6B7CT4OsX2hf/mscncr8lbqXhVYkIXEQ/wPHAWsBlYLCJTjDHfHrDZQGCnMeZEEekLPApcEomA6drVtspr17Yt8VIzJdxKs83fb1et4u94k4J4PX68SQF78/hJ9gTwJAVI/tPjgf3bJXv8pCUXkJZSgC+5YP/9tOTQ96H75VLzbAJPswk8Nbmo+FMNAPvEdpfsSIKNHtiZZO/vSLIXMIs0cSvlNqXJiK2AdcaYHwFEZALQGzgwofcGHgjdnwQ8JyJiIjENteIMqHgFpU/C0bPwn+HZjz+QRG6Rj/zCVPKKQrdCH7mFqazbVpPdeeXZnVeePXnl2ZVbYf/3O3Mr8uvuo1kavE6rFyqVgEqT0I8Dfj7g+83AwUvt7N/GGOMXkd3YEjW/H7iRiAwGBoe+3Scia48kaKDqwft2lyCQG7rtV+pzdlEqd/nrXCw957jXE3m0xI3Kcs51DvVEVC+KGmNGA6PLuh8RWXKoWgZupeecGPScE0Okzrk0Y9C2ALUO+L5m6LFitxERL1AJe3FUKaVUlJQmoS8G6onI8SKSAvQFphy0zRSgf+j+hcDnEek/V0opdUgldrmE+sRvBD7DDlscY4xZLSIPAUuMMVOAV4E3RWQdsAOb9COpzN02cUjPOTHoOSeGiJyzY/XQlVJKhZfO41ZKKZfQhK6UUi4R0wldRLqJyFoRWSciw4p5PlVEJoaeXygimdGPMrxKcc63ici3IrJCRGaKyCHHpMaLks75gO36iIgRkbgf4laacxaRi0Ov9WoReTvaMYZbKf62a4vILBH5JvT33d2JOMNFRMaIyDYRWXWI50VEng39PlaIyCllPqgxJiZv2Auw64G62PJRy4FGB21zPTAqdL8vMNHpuKNwzh2B9ND96xLhnEPbVQDmAF8BWU7HHYXXuR7wDVAl9P0xTscdhXMeDVwXut8I2OB03GU85zOBU4BVh3i+O/AJdi5gG2BhWY8Zyy30/SUHjDGFwB8lBw7UGxgbuj8J6CwSoULD0VHiORtjZhlj/phC+hV2XkA8K83rDPBvbI2g/GgGFyGlOedBwPPGmJ0AxphtUY4x3EpzzgaoGLpfCfglivGFnTFmDnbU36H0Bt4w1ldAZRGpUZZjxnJCL67kwHGH2sYY4wf+KDkQr0pzzgcaiH2Hj2clnnPoo2gtY8zUaAYWQaV5nesD9UVknoh8Fap4Gs9Kc84PAFeIyGZgGnBTdEJzzOH+v5co/uqhKwBE5AogC2jvdCyRJCJJwFPAAIdDiTYvttulA/ZT2BwRaWKM2eVoVJF1KfC6MeZJETkNO7elsTEm6HRg8SKWW+iJWHKgNOeMiHQB7gF6GWMKohRbpJR0zhWAxsBsEdmA7WucEucXRkvzOm8GphhjiowxPwHfYxN8vCrNOQ8E3gEwxizArptVNSrROaNU/++HI5YTeiKWHCjxnEWkBfASNpnHe78qlHDOxpjdxpiqxphMY0wm9rpBL2PMEmfCDYvS/G1PxrbOEZGq2C6YH6MZZJiV5pw3AZ0BRKQhNqFvj2qU0TUF6Bca7dIG2G2M2VqmPTp9JbiEq8TdsS2T9cA9occewv5Dg33B3wXWAYuAuk7HHIVzngH8BiwL3aY4HXOkz/mgbWcT56NcSvk6C7ar6VtgJdDX6ZijcM6NgHnYETDLgK5Ox1zG8x0PbAWKsJ+4BgJDgCEHvMbPh34fK8Pxd61T/5VSyiViuctFKaXUYdCErpRSLqEJXSmlXEITulJKuYQmdKWUcglN6Eop5RKa0JVSyiX+D1I8sYGGRCIaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist((pos_head, neg_head), 20, \"objective score\", \"probability\", [\"non-rumors\", \"rumors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 情感的变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_情感分类器本身并不合理，得到的结果并不是在０~1之间均匀分布，即将所有的情感都笼统地分类为正面情感了。这样显然是不合情理的，尽管它在验证集上的分数确实很高_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "tt = BertTokenizer.from_pretrained(\"./bertModel/\")\n",
    "bb = BertModel.from_pretrained(\"./bertModel/\")\n",
    "task_embedding = nn.Embedding(3, 768)\n",
    "trans_conf = adict({\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-12,\n",
    "  \"max_position_embeddings\": 512,\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 2,\n",
    "  \"num_labels\": 2,\n",
    "  \"output_attentions\": False,\n",
    "  \"output_hidden_states\": False,\n",
    "  \"torchscript\": False\n",
    "})\n",
    "BertEncoder = transformer_utils.BertEncoder\n",
    "transformer = BertEncoder(trans_conf)\n",
    "\n",
    "\n",
    "\n",
    "bert = bb.cuda()\n",
    "transformer = transformer.cuda()\n",
    "task_embedding = task_embedding.cuda()\n",
    "senti_cls = nn.Linear(768, 2).cuda()\n",
    "rdm_model = RDM_Model(768, 300, 256, 0.2).cuda()\n",
    "rdm_classifier = nn.Linear(256, 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_save_as = './SentiRDM/senti_best_Model.pkl'\n",
    "checkpoint = torch.load(joint_save_as)\n",
    "senti_cls.load_state_dict(checkpoint['senti_classifier'])\n",
    "bert.load_state_dict(checkpoint['bert'])\n",
    "transformer.load_state_dict(checkpoint['transformer'])\n",
    "task_embedding.load_state_dict(checkpoint['task_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "senti_task_id = torch.tensor([0]) if not cuda else torch.tensor([0]).cuda()\n",
    "task_emb = task_embedding(senti_task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_scores: torch.Size([362, 2])\n",
      "seq_len: [0, 35, 18, 25, 19, 9, 10, 34, 19, 7, 11, 20, 29, 25, 12, 13, 8, 20, 20, 14, 14]\n",
      "subj_scores: torch.Size([500, 2])\n",
      "seq_len: [0, 41, 14, 49, 26, 17, 83, 22, 9, 7, 20, 26, 11, 16, 6, 20, 12, 23, 18, 23, 57]\n",
      "subj_scores: torch.Size([463, 2])\n",
      "seq_len: [0, 19, 8, 28, 20, 20, 16, 72, 8, 23, 10, 6, 31, 37, 27, 11, 39, 28, 46, 6, 8]\n",
      "subj_scores: torch.Size([555, 2])\n",
      "seq_len: [0, 30, 24, 30, 10, 20, 27, 28, 90, 29, 14, 34, 9, 24, 20, 20, 101, 8, 15, 11, 11]\n",
      "subj_scores: torch.Size([409, 2])\n",
      "seq_len: [0, 8, 20, 9, 11, 21, 19, 12, 9, 24, 23, 20, 18, 13, 9, 65, 23, 8, 8, 25, 64]\n",
      "subj_scores: torch.Size([518, 2])\n",
      "seq_len: [0, 96, 10, 40, 8, 9, 19, 14, 16, 13, 18, 11, 18, 9, 16, 16, 25, 56, 8, 48, 68]\n",
      "subj_scores: torch.Size([362, 2])\n",
      "seq_len: [0, 6, 10, 11, 11, 35, 10, 14, 22, 17, 41, 20, 35, 24, 9, 21, 16, 20, 8, 11, 21]\n",
      "subj_scores: torch.Size([428, 2])\n",
      "seq_len: [0, 21, 23, 15, 28, 101, 13, 25, 23, 18, 20, 21, 20, 31, 8, 7, 10, 19, 8, 9, 8]\n",
      "subj_scores: torch.Size([389, 2])\n",
      "seq_len: [0, 12, 16, 16, 28, 19, 15, 43, 7, 21, 18, 12, 21, 7, 8, 15, 27, 16, 29, 20, 39]\n",
      "subj_scores: torch.Size([511, 2])\n",
      "seq_len: [0, 40, 14, 37, 19, 34, 30, 7, 8, 10, 18, 21, 19, 53, 10, 92, 6, 33, 21, 15, 24]\n",
      "subj_scores: torch.Size([369, 2])\n",
      "seq_len: [0, 10, 12, 9, 8, 14, 11, 46, 38, 20, 19, 19, 26, 22, 8, 21, 18, 19, 11, 18, 20]\n",
      "subj_scores: torch.Size([333, 2])\n",
      "seq_len: [0, 11, 10, 20, 19, 17, 42, 20, 23, 18, 11, 13, 17, 7, 15, 16, 17, 19, 10, 16, 12]\n",
      "subj_scores: torch.Size([623, 2])\n",
      "seq_len: [0, 55, 10, 52, 13, 100, 7, 25, 19, 11, 6, 24, 24, 9, 101, 21, 30, 46, 19, 31, 20]\n",
      "subj_scores: torch.Size([503, 2])\n",
      "seq_len: [0, 9, 20, 46, 21, 23, 12, 32, 18, 42, 11, 7, 18, 21, 6, 33, 14, 19, 23, 101, 27]\n",
      "subj_scores: torch.Size([607, 2])\n",
      "seq_len: [0, 13, 72, 20, 12, 101, 25, 26, 26, 7, 16, 15, 17, 49, 101, 12, 16, 22, 19, 18, 20]\n",
      "subj_scores: torch.Size([512, 2])\n",
      "seq_len: [0, 28, 7, 101, 16, 33, 16, 34, 17, 19, 30, 25, 25, 23, 20, 12, 17, 31, 20, 18, 20]\n",
      "subj_scores: torch.Size([319, 2])\n",
      "seq_len: [0, 20, 20, 6, 8, 21, 30, 23, 12, 20, 8, 18, 20, 7, 25, 13, 7, 30, 16, 7, 8]\n",
      "subj_scores: torch.Size([310, 2])\n",
      "seq_len: [0, 9, 16, 19, 34, 17, 10, 19, 18, 12, 10, 6, 25, 7, 6, 9, 12, 28, 19, 19, 15]\n",
      "subj_scores: torch.Size([453, 2])\n",
      "seq_len: [0, 33, 20, 17, 21, 23, 7, 13, 33, 19, 55, 11, 10, 49, 17, 21, 21, 24, 30, 9, 20]\n",
      "subj_scores: torch.Size([325, 2])\n",
      "seq_len: [0, 19, 10, 21, 21, 13, 11, 11, 22, 18, 25, 8, 12, 53, 12, 19, 12, 11, 7, 7, 13]\n",
      "subj_scores: torch.Size([421, 2])\n",
      "seq_len: [0, 20, 37, 18, 13, 20, 24, 24, 31, 11, 56, 42, 17, 6, 20, 12, 21, 16, 8, 9, 16]\n",
      "subj_scores: torch.Size([494, 2])\n",
      "seq_len: [0, 19, 25, 24, 10, 13, 6, 20, 8, 16, 8, 9, 27, 20, 101, 15, 61, 75, 9, 15, 13]\n",
      "subj_scores: torch.Size([372, 2])\n",
      "seq_len: [0, 9, 20, 10, 6, 20, 13, 39, 19, 35, 11, 10, 101, 8, 13, 9, 10, 6, 11, 11, 11]\n",
      "subj_scores: torch.Size([492, 2])\n",
      "seq_len: [0, 101, 6, 20, 22, 20, 19, 26, 22, 35, 19, 23, 19, 9, 6, 40, 35, 17, 19, 15, 19]\n"
     ]
    }
   ],
   "source": [
    "pos_senti = rdm_seq_data2scores_seq(pos_x, bert, task_emb, senti_cls, label_num =2)\n",
    "neg_senti = rdm_seq_data2scores_seq(neg_x, bert, task_emb, senti_cls, label_num =2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_st_head = [h[0] for h in neg_senti]\n",
    "neg_st_tail = [h[-1] for h in neg_senti]\n",
    "\n",
    "pos_st_head = [h[0] for h in pos_senti]\n",
    "pos_st_tail = [h[-1] for h in pos_senti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9182321429252625, 0.9144377112388611)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(pos_senti).max(), np.concatenate(neg_senti).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5743967890739441, 0.5650441646575928)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(pos_senti).min(), np.concatenate(neg_senti).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist((pos_st_head, neg_st_head), 20, \"objective score\", \"probability\", [\"non-rumors\", \"rumors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist((pos_st_head, pos_st_tail), 20, \"objective score\", \"probability\", [\"first issue\", \"last issue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/torch_B/lib/python3.6/site-packages/ipykernel_launcher.py:9: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist((neg_st_head, neg_st_tail), 20, \"objective score\", \"probability\", [\"first issue\", \"last issue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
