{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import MyLogger\n",
    "import SubjObjLoader\n",
    "import json\n",
    "from torch import nn\n",
    "import torch\n",
    "from pytorch_transformers import *\n",
    "import importlib\n",
    "from collections import deque\n",
    "# import dataloader\n",
    "from BertRDMLoader import *\n",
    "import json\n",
    "from torch import nn\n",
    "import torch\n",
    "from pytorch_transformers import *\n",
    "import importlib\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import tsentiLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emotionLoader\n",
    "from SubjObjLoader import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BERT RDM CM 模型代码\n",
    "> 需要改动的地方\n",
    "> - 损失函数要从训练函数中拆分出来，方便后面的联合训练\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class pooling_layer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(pooling_layer, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        assert(inputs.ndim == 4 ) # [batchsize, max_seq_len, max_word_num, input_dim] \n",
    "        batch_size, max_seq_len, max_word_num, input_dim = inputs.shape\n",
    "        assert(input_dim == self.input_dim)\n",
    "        t_inputs = inputs.reshape([-1, self.input_dim])\n",
    "        return self.linear(t_inputs).reshape(\n",
    "            \n",
    "            [-1, max_word_num, self.output_dim]\n",
    "        \n",
    "        ).max(axis=1)[0].reshape(\n",
    "        \n",
    "            [-1, max_seq_len, self.output_dim]\n",
    "        \n",
    "        )\n",
    "\n",
    "class RDM_Model(nn.Module):\n",
    "    def __init__(self, word_embedding_dim, sent_embedding_dim, hidden_dim, dropout_prob):\n",
    "        super(RDM_Model, self).__init__()\n",
    "        self.embedding_dim = sent_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gru_model = nn.GRU(word_embedding_dim, \n",
    "                                self.hidden_dim, \n",
    "                                batch_first=True, \n",
    "                                dropout=dropout_prob\n",
    "                            )\n",
    "        self.DropLayer = nn.Dropout(dropout_prob)\n",
    "#         self.PoolLayer = pooling_layer(word_embedding_dim, sent_embedding_dim) \n",
    "        \n",
    "    def forward(self, x_emb, x_len, init_states): \n",
    "        \"\"\"\n",
    "        input_x: [batchsize, max_seq_len, sentence_embedding_dim] \n",
    "        x_emb: [batchsize, max_seq_len, 1, embedding_dim]\n",
    "        x_len: [batchsize]\n",
    "        init_states: [batchsize, hidden_dim]\n",
    "        \"\"\"\n",
    "        batchsize, max_seq_len, _ , emb_dim = x_emb.shape\n",
    "#         pool_feature = self.PoolLayer(x_emb)\n",
    "#         sent_feature = sentiModel( \n",
    "#                 x_emb.reshape(\n",
    "#                     [-1, max_sent_len, emb_dim]\n",
    "#                 ) \n",
    "#             ).reshape(\n",
    "#                 [batchsize, max_seq_len, -1]\n",
    "#             )\n",
    "#         pooled_input_x_dp = self.DropLayer(input_x)\n",
    "        pool_feature = x_emb.reshape(\n",
    "                [-1, max_seq_len, emb_dim]\n",
    "        )\n",
    "        df_outputs, df_last_state = self.gru_model(pool_feature, init_states)\n",
    "        hidden_outs = [df_outputs[i][:x_len[i]] for i in range(batchsize)]\n",
    "        final_outs = [df_outputs[i][x_len[i]-1] for i in range(batchsize)]\n",
    "        return hidden_outs, final_outs\n",
    "\n",
    "\n",
    "class CM_Model(nn.Module):\n",
    "    def __init__(self, sentence_embedding_dim, hidden_dim, action_num):\n",
    "        super(CM_Model, self).__init__()\n",
    "        self.sentence_embedding_dim = sentence_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.action_num = action_num\n",
    "#         self.PoolLayer = pooling_layer(self.embedding_dim, \n",
    "#                                             self.hidden_dim)\n",
    "        self.DenseLayer = nn.Linear(self.hidden_dim, 64)\n",
    "        self.Classifier = nn.Linear(64, self.action_num)\n",
    "        \n",
    "    def forward(self, rdm_model, s_model, rl_input, rl_state):\n",
    "        \"\"\"\n",
    "        rl_input: [batchsize, max_word_num, sentence_embedding_dim]\n",
    "        rl_state: [1, batchsize, hidden_dim]\n",
    "        \"\"\"\n",
    "        assert(rl_input.ndim==3)\n",
    "        batchsize, max_word_num, embedding_dim = rl_input.shape\n",
    "#         assert(embedding_dim==self.embedding_dim)\n",
    "        sentence = s_model(rl_input).reshape(batch_size, 1, self.sentence_embedding_dim)\n",
    "#         pooled_rl_input = self.PoolLayer(\n",
    "#             rl_input.reshape(\n",
    "#                 [-1, 1, max_word_num, self.embedding_dim]\n",
    "#             )\n",
    "#         ).reshape([-1, 1, self.hidden_dim])\n",
    "        \n",
    "#         print(\"sentence:\", sentence.shape)\n",
    "#         print(\"rl_state:\", rl_state.shape)\n",
    "        rl_output, rl_new_state = rdm_model.gru_model(\n",
    "                                            sentence, \n",
    "                                            rl_state\n",
    "                                        )\n",
    "        rl_h1 = nn.functional.relu(\n",
    "            self.DenseLayer(\n",
    "#                 rl_state.reshape([len(rl_input), self.hidden_dim]) #it is not sure to take rl_state , rather than rl_output, as the feature\n",
    "                rl_output.reshape(\n",
    "                    [len(rl_input), self.hidden_dim]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        stopScore = self.Classifier(rl_h1)\n",
    "        isStop = stopScore.argmax(axis=1)\n",
    "        return stopScore, isStop, rl_new_state\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def layer2seq(bert, layer, cuda=False):\n",
    "    if cuda:\n",
    "        outs = [bert( torch.tensor([input_]).cuda())\n",
    "                for input_ in layer]   \n",
    "    else: \n",
    "        outs = [bert( torch.tensor([input_]))\n",
    "                    for input_ in layer]\n",
    "    states = [item[1] for item in outs]\n",
    "    return rnn_utils.pad_sequence(states, batch_first=True)\n",
    "\n",
    "def Word_ids2SeqStates(word_ids, bert, ndim, cuda=False):\n",
    "    assert(ndim == 3)\n",
    "    if cuda:\n",
    "        embedding = [layer2seq(bert, layer, cuda) for layer in word_ids]\n",
    "    else:\n",
    "        embedding = [layer2seq(bert, layer) for layer in word_ids]\n",
    "    return padding_sequence(embedding)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def Count_Accs(ylabel, preds):\n",
    "    correct_preds = np.array(\n",
    "        [1 if y1==y2 else 0 \n",
    "        for (y1, y2) in zip(ylabel, preds)]\n",
    "    )\n",
    "    y_idxs = [idx if yl >0 else idx - len(ylabel) \n",
    "            for (idx, yl) in enumerate(ylabel)]\n",
    "    pos_idxs = list(filter(lambda x: x >= 0, y_idxs))\n",
    "    neg_idxs = list(filter(lambda x: x < 0, y_idxs))\n",
    "    acc = sum(correct_preds) / (1.0 * len(ylabel))\n",
    "    if len(pos_idxs) > 0:\n",
    "        pos_acc = sum(correct_preds[pos_idxs])/(1.0*len(pos_idxs))\n",
    "    else:\n",
    "        pos_acc = 0\n",
    "    if len(neg_idxs) > 0:\n",
    "        neg_acc = sum(correct_preds[neg_idxs])/(1.0*len(neg_idxs))\n",
    "    else:\n",
    "        neg_acc = 0\n",
    "    return acc, pos_acc, neg_acc, y_idxs, pos_idxs, neg_idxs, correct_preds\n",
    "\n",
    "def Loss_Fn(ylabel, pred_scores):\n",
    "    diff = ((ylabel - pred_scores)*(ylabel - pred_scores)).mean(axis=1)\n",
    "#     pos_neg = (1.0*sum(ylabel.argmax(axis=1)))/(1.0*(len(ylabel) - sum(ylabel.argmax(axis=1))))\n",
    "    pos_neg = 0\n",
    "    if pos_neg > 0:\n",
    "        print(\"unbalanced data\")\n",
    "        weight = torch.ones(len(ylabel)).cuda() + (ylabel.argmax(axis=1).to(torch.float32)/(1.0*pos_neg)) - ylabel.argmax(axis=1).to(torch.float32)\n",
    "        return (weight *diff).mean()\n",
    "    else:\n",
    "        print(\"totally unbalanced data\")\n",
    "        return diff.mean()\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "def rdm_loss(x, y, x_len, bert, rdm_model, rdm_classifier, loss_fn):\n",
    "    x_emb = Word_ids2SeqStates(x, bert, 3, cuda=True) \n",
    "    batchsize, max_seq_len, max_sent_len, emb_dim = x_emb.shape\n",
    "    init_states = torch.zeros([1, batchsize, rdm_model.hidden_dim]).cuda()\n",
    "    rdm_hiddens, rdm_outs = rdm_model(x_emb, x_len, init_states)\n",
    "    rdm_scores = rdm_classifier(\n",
    "        torch.cat(\n",
    "            rdm_outs # a list of tensor, where the ndim of tensor is 1 and the shape of tensor is [hidden_size]\n",
    "        ).reshape(\n",
    "            [-1, rdm_model.hidden_dim]\n",
    "        )\n",
    "    )\n",
    "    rdm_preds = rdm_scores.argmax(axis=1)\n",
    "    y_label = y.argmax(axis=1)\n",
    "    acc, _, _, _, _, _, _ = Count_Accs(y_label, rdm_preds)\n",
    "    loss = loss_fn(rdm_scores, torch.tensor(y_label).cuda())\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def TrainRDMModel(rdm_model, bert, rdm_classifier, \n",
    "                    tokenizer, t_steps, new_data_len=[], logger=None, \n",
    "                        log_dir=\"RDMBertTrain\"):\n",
    "    batch_size = 20 \n",
    "    max_gpu_batch = 5 #cannot load a larger batch into the limited memory, but we could  accumulates grads\n",
    "    assert(batch_size%max_gpu_batch == 0)\n",
    "    sum_loss = 0.0\n",
    "    sum_acc = 0.0\n",
    "    t_acc = 0.9\n",
    "    ret_acc = 0.0\n",
    "    init_states = torch.zeros([1, 5, rdm_model.hidden_dim], dtype=torch.float32).cuda()\n",
    "    weight = torch.tensor([2.0, 1.0], dtype=torch.float32).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':5e-5},\n",
    "                                {'params': rdm_classifier.parameters(), 'lr': 5e-5},\n",
    "                                {'params': rdm_model.parameters(), 'lr': 5e-5}\n",
    "                             ]\n",
    "    )\n",
    "    \n",
    "    writer = SummaryWriter(log_dir)\n",
    "    acc_l = np.zeros(int(batch_size/max_gpu_batch))\n",
    "    loss_l = np.zeros(int(batch_size/max_gpu_batch))\n",
    "    for step in range(t_steps):\n",
    "        optim.zero_grad()\n",
    "        for j in range(int(batch_size/max_gpu_batch)):\n",
    "            if len(new_data_len) > 0:\n",
    "                x, x_len, y = get_df_batch(step, max_gpu_batch, new_data_len, tokenizer=tokenizer)\n",
    "            else:\n",
    "                x, x_len, y = get_df_batch(step, max_gpu_batch, tokenizer=tokenizer)\n",
    "                \n",
    "            loss, acc = rdm_loss(x, y, bert, rdm_model, rdm_classifier, loss_fn)\n",
    "            loss.backward()\n",
    "            loss_l[j] = loss\n",
    "            acc_l[j] = acc\n",
    "            \n",
    "        optim.step()        \n",
    "        writer.add_scalar('Train Loss', loss_l.mean(), step)\n",
    "        writer.add_scalar('Train Accuracy', acc_l.mean(), step)\n",
    "\n",
    "        sum_loss += loss_l.mean()\n",
    "        sum_acc += acc_l.mean()\n",
    "        \n",
    "\n",
    "        if step % 10 == 9:\n",
    "            sum_loss = sum_loss / 10\n",
    "            sum_acc = sum_acc / 10\n",
    "            print('%3d | %d , train_loss/accuracy = %6.8f/%6.7f'             % (step, t_steps, \n",
    "                sum_loss, sum_acc,\n",
    "                ))\n",
    "            logger.info('%3d | %d , train_loss/accuracy = %6.8f/%6.7f'             % (step, t_steps, \n",
    "                sum_loss, sum_acc,\n",
    "                ))\n",
    "            if step%500 == 499:\n",
    "                rdm_save_as = '/home/hadoop/ERD/%s/rdmModel_epoch%03d.pkl'                                    % (log_dir, step/500, sum_acc)\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"bert\":bert.state_dict(),\n",
    "                        \"sentiModel\":sentiModel.state_dict(),\n",
    "                        \"rmdModel\":rdm_model.state_dict(),\n",
    "                        \"rdm_classifier\": rdm_classifierdm.state_dict()\n",
    "                    },\n",
    "                    rdm_save_as\n",
    "                )\n",
    "#                 rdm_model, bert, sentiModel, rdm_classifier\n",
    "            if sum_acc > t_acc:\n",
    "                break\n",
    "            sum_acc = 0.0\n",
    "            sum_loss = 0.0\n",
    "\n",
    "    print(get_curtime() + \" Train df Model End.\")\n",
    "    logger.info(get_curtime() + \" Train df Model End.\")\n",
    "    return ret_acc\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def TrainCMModel(bert, rdm_model, rdm_classifier, cm_model, tokenizer, log_dir, logger, FLAGS):\n",
    "    batch_size = 20\n",
    "    t_acc = 0.9\n",
    "    ids = np.array(range(batch_size), dtype=np.int32)\n",
    "    seq_states = np.zeros([batch_size], dtype=np.int32)\n",
    "    isStop = np.zeros([batch_size], dtype=np.int32)\n",
    "    max_id = batch_size\n",
    "    df_init_states = torch.zeros([1, batch_size, FLAGS.hidden_dim], dtype=torch.float32).cuda()\n",
    "    state = df_init_states\n",
    "    D = deque()\n",
    "    ssq = []\n",
    "    print(\"in RL the begining\")\n",
    "    rdm_optim = torch.optim.Adagrad([\n",
    "                            {'params': bert.parameters(), 'lr':1e-3},\n",
    "    #                                 {'params': rdm_classifier.parameters(), 'lr': 5e-2},\n",
    "                            {'params': rdm_model.parameters(), 'lr': 5e-2},\n",
    "                            {'params': sentiModel.parameters(), 'lr': 1e-2}\n",
    "                         ],\n",
    "                            weight_decay = 0.2\n",
    "    )\n",
    "    rl_optim = torch.optim.Adam([{'params':cm_model.parameters(), 'lr':1e-3}])\n",
    "    # get_new_len(sess, mm)\n",
    "    data_ID = get_data_ID()\n",
    "\n",
    "    if len(data_ID) % batch_size == 0: # the total number of events\n",
    "        flags = int(len(data_ID) / FLAGS.batch_size)\n",
    "    else:\n",
    "        flags = int(len(data_ID) / FLAGS.batch_size) + 1\n",
    "    for i in range(flags):\n",
    "        with torch.no_grad():\n",
    "            x, x_len, y = get_df_batch(i, batch_size, tokenizer=tokenizer)\n",
    "            x_emb = Word_ids2SeqStates(x, bert, 3, cuda=True) \n",
    "            batchsize, max_seq_len, max_sent_len,                                     emb_dim = x_emb.shape\n",
    "            sent_feature = sentiModel( \n",
    "                x_emb.reshape(\n",
    "                    [-1, max_sent_len, emb_dim]\n",
    "                ) \n",
    "            ).reshape(\n",
    "                [batchsize, max_seq_len, -1]\n",
    "            )\n",
    "            rdm_hiddens, rdm_outs = rdm_model(sent_feature, x_len, df_init_states)\n",
    "        #         t_ssq = sess.run(rdm_train.out_seq, feed_dic)# t_ssq = [batchsize, max_seq, scores]\n",
    "            print(\"batch %d\"%i)\n",
    "            if len(ssq) > 0:\n",
    "                ssq.extend([rdm_classifier(h) for h in rdm_hiddens])\n",
    "            else:\n",
    "                ssq = [rdm_classifier(h) for h in rdm_hiddens]\n",
    "\n",
    "    print(get_curtime() + \" Now Start RL training ...\")\n",
    "    counter = 0\n",
    "    sum_rw = 0.0 # sum of rewards\n",
    "\n",
    "    data_len = get_data_len()\n",
    "\n",
    "    while True:\n",
    "        if counter > FLAGS.OBSERVE:\n",
    "            sum_rw += np.mean(rw)\n",
    "            if counter % 200 == 0:\n",
    "                sum_rw = sum_rw / 2000\n",
    "                print( get_curtime() + \" Step: \" + str(step) \n",
    "                       + \" REWARD IS \" + str(sum_rw) \n",
    "                     )\n",
    "                logger.info( get_curtime() + \n",
    "                             \" Step: \" + str(step) + \n",
    "                            \" REWARD IS \" + str(sum_rw)\n",
    "                           )\n",
    "                if sum_rw > t_rw:\n",
    "                    print(\"Retch The Target Reward\")\n",
    "                    logger.info(\"Retch The Target Reward\")\n",
    "                    break\n",
    "                if counter > t_steps:\n",
    "                    print(\"Retch The Target Steps\")\n",
    "                    logger.info(\"Retch The Target Steps\")\n",
    "                    break\n",
    "                sum_rw = 0.0\n",
    "            s_state, s_x, s_isStop, s_rw = get_RL_Train_batch(D, FLAGS)\n",
    "            stopScore, isStop, rl_new_state = cm_model(rdm_model, sentiModel, s_x, s_state)\n",
    "            out_action = (stopScore*s_isStop).sum(axis=1)\n",
    "            rl_cost = torch.mean((s_rw - out_action)*(s_rw - out_action))\n",
    "            rl_cost.backward()\n",
    "            rl_optim.step()\n",
    "\n",
    "        input_x, input_y, ids, seq_states, max_id = get_rl_batch(ids, seq_states, isStop, max_id, 0, FLAGS, tokenizer=tokenizer)\n",
    "        with torch.no_grad():\n",
    "            x_emb = layer2seq(bert, input_x, cuda=True)\n",
    "            batchsize, max_sent_len, emb_dim = x_emb.shape\n",
    "            mss, isStop, mNewState = cm_model(rdm_model, sentiModel, x_emb, state)\n",
    "\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            if random.random() < FLAGS.random_rate:\n",
    "    #             isStop[j] = np.argmax(np.random.rand(2))\n",
    "                isStop[j] = int(torch.rand(2).argmax())\n",
    "            if seq_states[j] == data_len[ids[j]]:\n",
    "                isStop[j] = 1\n",
    "\n",
    "        # eval\n",
    "        rw = get_reward(isStop, mss, ssq, ids, seq_states)\n",
    "\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            D.append((state[0][j], input_x[j], isStop[j], rw[j]))\n",
    "            if len(D) > FLAGS.max_memory:\n",
    "                D.popleft()\n",
    "\n",
    "        state = mNewState\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            if isStop[j] == 1:\n",
    "                # init_states = np.zeros([FLAGS.batch_size, FLAGS.hidden_dim], dtype=np.float32)\n",
    "                # feed_dic = {rl_model.init_states: init_states}\n",
    "                # state[j] = sess.run(rl_model.df_state, feed_dic)\n",
    "    #             state[j] = np.zeros([FLAGS.hidden_dim], dtype=np.float32)\n",
    "                state[0][j].fill_(0)\n",
    "        counter += 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 联合学习部分\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2tensor(bert, layer, cuda=False):\n",
    "    if cuda:\n",
    "        outs = [bert( torch.tensor([input_]).cuda())\n",
    "                for input_ in layer]   \n",
    "    else: \n",
    "        outs = [bert( torch.tensor([input_]))\n",
    "                    for input_ in layer]\n",
    "    states = [item[0][0] for item in outs]\n",
    "    return rnn_utils.pad_sequence(states, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> normalized the data for unbalanced learning:\n",
    "```python\n",
    "weights = WeightsForUmbalanced(emoReader.label)\n",
    "weights\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdm_data2bert_tensors(data_X, cuda):\n",
    "    def padding_sent_list(sent_list):\n",
    "        sent_len = [len(sent) for sent in sent_list]\n",
    "        max_sent_len = max(sent_len)\n",
    "        sent_padding = torch.zeros([len(sent_list), max_sent_len], dtype=torch.int64)\n",
    "        attn_mask = torch.ones_like(sent_padding)\n",
    "        for i, sent in enumerate(sent_list):\n",
    "            sent_padding[i][:len(sent)] = torch.tensor(sent, dtype=torch.int32)\n",
    "            attn_mask[i][len(sent):].fill_(0)\n",
    "        return sent_padding, attn_mask\n",
    "    sent_list = []\n",
    "    [sent_list.extend(seq) for seq in data_X]\n",
    "    seq_len = [len(seq) for seq in data_X]\n",
    "    sent_tensors, attn_mask = padding_sent_list(sent_list)\n",
    "    if cuda:\n",
    "        sent_tensors = sent_tensors.cuda()\n",
    "        attn_mask = attn_mask.cuda()\n",
    "    return sent_tensors, attn_mask, seq_len\n",
    "\n",
    "def senti_data2bert_tensors(sent_list, cuda):\n",
    "    sent_len = [len(sent) for sent in sent_list]\n",
    "    max_sent_len = max(sent_len)\n",
    "    sent_padding = torch.zeros([len(sent_list), max_sent_len], dtype=torch.int64)\n",
    "    attn_mask = torch.ones_like(sent_padding)\n",
    "    input_mask = torch.zeros\n",
    "    for i, sent in enumerate(sent_list):\n",
    "        sent_padding[i][:len(sent)] = torch.tensor(sent, dtype=torch.int32)\n",
    "        attn_mask[i][len(sent):].fill_(0)\n",
    "    if cuda:\n",
    "        sent_padding = sent_padding.cuda()\n",
    "        attn_mask = attn_mask.cuda()\n",
    "    return sent_padding, attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightsForUmbalanced(data_label):\n",
    "    _, _, labels = data_label.shape\n",
    "    label_cnt = data_label.reshape([-1, labels]).sum(axis=0)\n",
    "    weights = 1.0/label_cnt\n",
    "    normalized_weights = weights/sum(weights)\n",
    "    return normalized_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练各个任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用单个分类器进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_cls_train(emotion_reader, val_reader, bert, transformer, \n",
    "                  task_embedding, emotion_classifier,\n",
    "                  train_epochs, \n",
    "                  log_dir,\n",
    "                  cuda=False\n",
    "                 ):\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':1e-6},\n",
    "                                {'params': task_embedding.parameters(), 'lr':1e-6},\n",
    "                                {'params': transformer.parameters(), 'lr': 1e-6},\n",
    "                                {'params': emotion_classifier.parameters(), 'lr': 1e-6}\n",
    "                             ]\n",
    "    )\n",
    "    losses = np.zeros([10]) \n",
    "    accs = np.zeros([10])\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    e_weight = WeightsForUmbalanced(emotion_reader.label) \n",
    "    e_weight = torch.tensor(e_weight, dtype= torch.float32) if not cuda else torch.tensor(e_weight, dtype=torch.float32).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=e_weight)\n",
    "    emo_task_id = torch.tensor([2]).cuda() if cuda else torch.tensor([2])\n",
    "    optim.zero_grad()\n",
    "    for epoch in range(train_epochs):\n",
    "        step = 0\n",
    "        for xem, yem, lem in emotion_reader.iter():\n",
    "            bs, l_cnt = yem.shape\n",
    "            emo_tensors, emo_mask = senti_data2bert_tensors(xem, cuda)\n",
    "            xem_embs, _ = bert(emo_tensors, attention_mask = emo_mask)\n",
    "\n",
    "            tensors = xem_embs + task_embedding(emo_task_id)\n",
    "            emo_feature = transformer(tensors.transpose(0, 1)).transpose(0, 1)\n",
    "            cls_feature = emo_feature.max(axis=1)[0]\n",
    "            emo_scores = emotion_classifier(cls_feature)\n",
    "            emo_label = torch.tensor(yem).argmax(axis=1) if not cuda else torch.tensor(yem).argmax(axis=1).cuda()\n",
    "            emo_loss = loss_fn(emo_scores, emo_label)\n",
    "            emo_loss.backward()\n",
    "            optim.step()\n",
    "            torch.cuda.empty_cache()\n",
    "            losses[int(step%10)] = emo_loss.cpu()\n",
    "            emo_acc = accuracy_score(yem.argmax(axis=1), emo_scores.argmax(axis=1).cpu())\n",
    "            accs[int(step%10)] = emo_acc\n",
    "            writer.add_scalar('Train Loss', emo_loss.cpu(), step)\n",
    "            writer.add_scalar('Train Accuracy', emo_acc, step)\n",
    "            print(\"step:%d | loss/acc = %.3f/%.3f\"%(step, emo_loss, emo_acc))\n",
    "            if step %10 == 9:\n",
    "                print('emotion task: %6d: [%5d/%5d], senti_loss/senti_acc = %6.8f/%6.7f ' % ( step,\n",
    "                                                                                epoch, train_epochs,\n",
    "                                                                                losses.mean(), accs.mean(),\n",
    "                                                                            )\n",
    "                         )       \n",
    "            step += 1 \n",
    "        with torch.no_grad():\n",
    "            batchs, bs, l_cnt = val_reader.label.shape\n",
    "            losses = np.zeros(batchs)\n",
    "            acces = np.zeros(batchs)\n",
    "            it = 0\n",
    "            for xem, yem, lem in val_reader.iter():\n",
    "                emo_tensors, emo_mask = senti_data2bert_tensors(xem, cuda)\n",
    "                xem_embs, _ = bert(emo_tensors, attention_mask = emo_mask)\n",
    "                tensors = xem_embs + task_embedding(emo_task_id)\n",
    "                emo_feature = transformer(tensors.transpose(0, 1)).transpose(0, 1)\n",
    "                cls_feature = emo_feature.max(axis=1)[0]\n",
    "                emo_scores = emotion_classifier(cls_feature)\n",
    "                emo_label = torch.tensor(yem).argmax(axis=1) if not cuda else torch.tensor(yem).argmax(axis=1).cuda()\n",
    "                emo_loss = loss_fn(emo_scores, emo_label)\n",
    "                torch.cuda.empty_cache()\n",
    "                emo_acc = accuracy_score(yem.argmax(axis=1), emo_scores.argmax(axis=1).cpu()) \n",
    "                losses[it] = emo_loss\n",
    "                acces[it] = emo_acc\n",
    "                it += 1\n",
    "            writer.add_scalar('valid Loss', losses.mean(), epoch)\n",
    "            writer.add_scalar('valid Accuracy', acces.mean(), epoch)\n",
    "        cls_save_as = './%s/EmoModel_epoch%03d.pkl'% (log_dir, epoch)\n",
    "        torch.save(\n",
    "                            {\n",
    "                                \"bert\":bert.state_dict(),\n",
    "                                \"transformer\":transformer.state_dict(),\n",
    "                                \"task_embedding\":task_embedding.state_dict(),\n",
    "                                \"emotion_classifier\": emotion_classifier.state_dict()\n",
    "                            },\n",
    "                            cls_save_as\n",
    "                        )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 使用多个分类器进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def emo_cls_train(emotion_reader, bert, transformer, \n",
    "                  task_embedding, emotion_classifiers,\n",
    "                  train_epochs, \n",
    "                  cuda=False\n",
    "                 ):\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':1e-6},\n",
    "                                {'params': task_embedding.parameters(), 'lr':1e-6},\n",
    "                                {'params': transformer.parameters(), 'lr': 1e-6},\n",
    "                                {'params': emotion_classifiers.parameters(), 'lr': 1e-6}\n",
    "                             ]\n",
    "    )\n",
    "    losses = np.zeros([10]) \n",
    "    accs = np.zeros([10])\n",
    "    label_cnt = emoReader.label.reshape([-1, 6]).sum(axis=0)\n",
    "    sum_cnt = sum(label_cnt)\n",
    "    emo_weights_bi = [torch.tensor([(label_cnt[i]*1.0)/sum_cnt, (sum_cnt - label_cnt[i])*1.0/sum_cnt]) for i in range(emo_weights.shape[-1])]\n",
    "    loss_list = nn.ModuleList([nn.CrossEntropyLoss(weight=e_weight.cuda()) for e_weight in emo_weights_bi])\n",
    "    emo_task_id = torch.tensor([2]).cuda() if cuda else torch.tensor([2])\n",
    "    optim.zero_grad()\n",
    "    for epoch in range(train_epochs):\n",
    "        step = 0\n",
    "        for xem, yem, lem in emotion_reader.iter():\n",
    "            bs, l_cnt = yem.shape\n",
    "            emo_tensors, emo_mask = senti_data2bert_tensors(xem, cuda)\n",
    "            xem_embs, _ = bert(emo_tensors, attention_mask = emo_mask)\n",
    "\n",
    "            tensors = xem_embs + task_embedding(emo_task_id)\n",
    "            emo_feature = transformer(tensors.transpose(0, 1)).transpose(0, 1)\n",
    "            cls_feature = emo_feature.max(axis=1)[0]\n",
    "            emo_scores = [emotion_classifier(cls_feature) for emotion_classifier in emotion_classifiers]\n",
    "\n",
    "            labels = torch.zeros([bs, l_cnt, 2])\n",
    "            y = yem.astype(np.int32)\n",
    "            [[labels[idx][jdx][y_i].fill_(1.0) for jdx, y_i in enumerate(ylabel) ] for idx, ylabel in enumerate(y)]\n",
    "            labels = labels.transpose(0, 1).cuda() if cuda else labels.transpose(0, 1)\n",
    "            emo_loss = sum([loss_list[i](emo_scores[i], labels[i].argmax(axis=1)) for i in range(l_cnt)])\n",
    "            emo_loss.backward()\n",
    "            optim.step()\n",
    "            torch.cuda.empty_cache()\n",
    "            losses[int(step%10)] = emo_loss.cpu()\n",
    "            preds = torch.cat([tensor[:, 1] for tensor in emo_scores]).reshape(l_cnt, bs).max(axis=0)[1]\n",
    "            emo_acc = accuracy_score(y.argmax(axis=1), preds.cpu())\n",
    "\n",
    "            accs[int(step%10)] = emo_acc\n",
    "            print(\"step:%d | loss/acc = %.3f/%.3f\"%(step, emo_loss, emo_acc))\n",
    "            if step %10 == 9:\n",
    "                print('emotion task: %6d: [%5d/%5d], senti_loss/senti_acc = %6.8f/%6.7f ' % ( step,\n",
    "                                                                                epoch, train_epochs,\n",
    "                                                                                losses.mean(), accs.mean(),\n",
    "                                                                            )\n",
    "                         )       \n",
    "            step += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "os.path.exists(\"./RDMBertTrain/cached_ssq.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 训练subjective classification　任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def subj_cls_train(subj_reader, bert, transformer, task_embedding,\n",
    "                   subj_classifier, train_epochs, subj_loss_fn,\n",
    "                   cuda=False\n",
    "                  ):\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':1e-6},\n",
    "                                {'params': task_embedding.parameters(), 'lr':5e-5},\n",
    "                                {'params': transformer.parameters(), 'lr': 5e-5},\n",
    "                                {'params': subj_classifier.parameters(), 'lr': 5e-5}\n",
    "                             ]\n",
    "    )\n",
    "    losses = np.zeros([10]) \n",
    "    accs = np.zeros([10])\n",
    "    task_emb = task_embedding(torch.tensor([1]).cuda()) if cuda else task_embedding(torch.tensor([1]))\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    for epoch in range(train_epochs):\n",
    "        step = 0\n",
    "        for x, y, l in subj_reader.iter():\n",
    "            sj_loss, sj_acc = subj_loss(x, y, l,\n",
    "                                    bert, transformer, task_emb,\n",
    "                                    subj_classifier, subj_loss_fn, \n",
    "                                    cuda\n",
    "                                   )\n",
    "            sj_loss.backward(retain_graph=True)\n",
    "            optim.step()\n",
    "            losses[int(step%10)] = sj_loss.cpu()\n",
    "            accs[int(step%10)] = sj_acc\n",
    "            print(\"step:%d | loss/acc = %.3f/%.3f\"%(step, sj_loss, sj_acc))\n",
    "            if step %10 == 9:\n",
    "                print('subjective task: %6d: [%5d/%5d], senti_loss/senti_acc = %6.8f/%6.7f ' % ( step,\n",
    "                                                                                epoch, train_epochs,\n",
    "                                                                                losses.mean(), accs.mean(),\n",
    "                                                                            )\n",
    "                         )       \n",
    "            step += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练sentiment analysis任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_cls_train(senti_reader, bert, transformer,\n",
    "                    task_embedding, senti_classifier,\n",
    "                    train_epochs, senti_loss_fn,\n",
    "                    cuda=False\n",
    "                   ):\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':1e-6},\n",
    "                                {'params': task_embedding.parameters(), 'lr':1e-5},\n",
    "                                {'params': transformer.parameters(), 'lr': 1e-5},\n",
    "                                {'params': senti_classifier.parameters(), 'lr': 1e-5}\n",
    "                             ]\n",
    "    )\n",
    "    losses = np.zeros([10]) \n",
    "    accs = np.zeros([10])\n",
    "    \n",
    "    task_emb = task_embedding(torch.tensor([0]).cuda()) if cuda else task_embedding(torch.tensor([0]))\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    for epoch in range(train_epochs):\n",
    "        step = 0\n",
    "        for xst, yst, lst in senti_reader.iter():\n",
    "            xsj_embs, _ = bert(sent_tensors, attention_mask = sent_mask)\n",
    "            tensors = xsj_embs + task_embedding(subj_task_id)\n",
    "            subj_feature = transformer(tensors.transpose(0, 1)).transpose(0, 1)\n",
    "            cls_feature = subj_feature.max(axis=1)[0]\n",
    "            senti_scores = senti_cls(cls_feature)\n",
    "            y_label = torch.tensor(yst.argmax(axis=1)).cuda() if cuda else torch.tensor(yst.argmax(axis=1))\n",
    "            st_loss = senti_loss_fn(senti_scores, y_label)\n",
    "            st_acc, _, _, _, _, _, _ = Count_Accs(y_label, senti_scores.argmax(axis=1))\n",
    "            st_loss.backward()\n",
    "            torch.cuda.empty_cache()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "            losses[int(step%10)] = st_loss.cpu()\n",
    "            accs[int(step%10)] = st_acc\n",
    "            print(\"step:%d | loss/acc = %.3f/%.3f\"%(step, st_loss, st_acc))\n",
    "            if step %10 == 9:\n",
    "                print('sentiment task: %6d: [%5d/%5d], senti_loss/senti_acc = %6.8f/%6.7f ' % ( step,\n",
    "                                                                                epoch, train_epochs,\n",
    "                                                                                losses.mean(), accs.mean(),\n",
    "                                                                            )\n",
    "                         )    \n",
    "            step += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 联合训练函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 三人舞\n",
    "情感任务，主观客观性任务，　情绪分析任务，　三个共同训练的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def JointLearning(senti_reader, subj_reader, emotion_reader, \n",
    "                  bert, transformer, task_embedding, \n",
    "                  senti_classifier, subj_classifier, emotion_classifier,\n",
    "                  cuda=False\n",
    "                 ):\n",
    "    \n",
    "    #stage 3: deploy the trainning on the emotion classification task\n",
    "#     emo_weights = torch.tensor(\n",
    "#             WeightsForUmbalanced(\n",
    "#                 emotion_reader.label\n",
    "#             ),\n",
    "#             dtype = torch.float32\n",
    "#     )\n",
    "#     emo_loss_fn = nn.CrossEntropyLoss(weight=emo_weights) if not cuda else nn.CrossEntropyLoss(weight=emo_weights.cuda())\n",
    "#     emo_cls_train(\n",
    "#         emotion_reader, \n",
    "#         bert, \n",
    "#         transformer, \n",
    "#         task_embedding, \n",
    "#         emotion_classifier, \n",
    "#         2, \n",
    "#         emo_loss_fn,\n",
    "#         cuda\n",
    "#     )\n",
    "#     emotion_reader.reset_batchsize(5)    \n",
    "    \n",
    "    # stage 1: deploy the trainning on the senti classification task\n",
    "    senti_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                senti_reader.label\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "    )\n",
    "    senti_loss_fn = nn.CrossEntropyLoss(weight=senti_weights.cuda()) if cuda else nn.CrossEntropyLoss(weight=senti_weights)\n",
    "    senti_cls_train(\n",
    "                    senti_reader, \n",
    "                    bert, \n",
    "                    transformer, \n",
    "                    task_embedding, \n",
    "                    senti_classifier, \n",
    "                    2, \n",
    "                    senti_loss_fn,\n",
    "                    cuda\n",
    "                   )\n",
    "    #stage 2: deploy the trainning on the subj classification task\n",
    "    subj_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                subj_reader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    )\n",
    "    subj_loss_fn = nn.CrossEntropyLoss(weight=subj_weights) if not cuda else nn.CrossEntropyLoss(weight=subj_weights.cuda())\n",
    "    subj_cls_train(\n",
    "                   subj_reader, \n",
    "                   bert, \n",
    "                   transformer, \n",
    "                   task_embedding, \n",
    "                   subj_classifier, \n",
    "                   2, \n",
    "                   subj_loss_fn,\n",
    "                   cuda\n",
    "                  )\n",
    "    \n",
    "    joint_model_save_as = '/home/hadoop/ERD/MTLTrain/PreTrModel_epoch.pkl'\n",
    "    torch.save(\n",
    "        {\n",
    "            \"bert\":bert.state_dict(),\n",
    "            \"transformer\":transformer.state_dict(),\n",
    "            \"task_embedding\":task_embedding.state_dict(),\n",
    "            \"senti_classifier\": senti_classifier.state_dict(),\n",
    "            \"subj_classifier\": subj_classifier.state_dict(),\n",
    "#             \"emotion_classifier\": emotion_classifier.state_dict()\n",
    "        },\n",
    "        joint_model_save_as\n",
    "    )\n",
    "    print(\"saved pretrained model!\")\n",
    "\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':5e-7},\n",
    "                                {'params': task_embedding.parameters(), 'lr':1e-6},\n",
    "                                {'params': transformer.parameters(), 'lr': 1e-6},\n",
    "                                {'params': senti_classifier.parameters(), 'lr': 1e-6},\n",
    "                                {'params': subj_classifier.parameters(), 'lr':1e-6},\n",
    "                                {'params': emotion_classifier.parameters(), 'lr':1e-6}\n",
    "                             ]\n",
    "    )\n",
    "    \n",
    "    max_epoch = 100\n",
    "    \n",
    "    losses = np.zeros([3, 10]) \n",
    "    accs = np.zeros([3, 10])\n",
    "    # [[senti_loss_1, ..., senti_loss_10], [subj_loss_1, ..., subj_loss_10], [emo_loss_1, ..., emo_loss_10]] \n",
    "    senti_task_id = torch.tensor([0]) if not cuda else torch.tensor([0]).cuda()\n",
    "    subj_task_id = torch.tensor([1]) if not cuda else torch.tensor([1]).cuda()\n",
    "#     emo_task_id = torch.tensor([2]) if not cuda else torch.tensor([2]).cuda()\n",
    "    \n",
    "    loss_weight = torch.tensor([0.333, 0.333, 0.333]) if not cuda else torch.tensor([0.333, 0.333, 0.333]).cuda()\n",
    "    \n",
    "    batchs = min(senti_reader.label.shape[0], subj_reader.label.shape[0], emotion_reader.label.shape[0])\n",
    "    optim.zero_grad()\n",
    "    for epoch in range(max_epoch):\n",
    "        step = 0\n",
    "        for ((xst, yst, lst), (xsj, ysj, lsj), (xem, yem, lem)) in zip(senti_reader.iter(), subj_reader.iter(), emotion_reader.iter()):\n",
    "            st_loss, st_acc = senti_loss(xst, yst, lst, \n",
    "                                    bert, transformer, task_embedding(senti_task_id),\n",
    "                                    senti_classifier, senti_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "#             st_loss.backward()\n",
    "            MTL_Loss = st_loss*loss_weight[0]\n",
    "    \n",
    "            losses[0][step%10] = st_loss.tolist()\n",
    "            accs[0][step%10] = st_acc\n",
    "             \n",
    "            sj_loss, sj_acc = subj_loss(xsj, ysj, lsj,\n",
    "                                    bert, transformer, task_embedding(subj_task_id),\n",
    "                                    subj_classifier, subj_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "#             sj_loss.backward()\n",
    "            MTL_Loss += sj_loss*loss_weight[1]\n",
    "\n",
    "            losses[1][step%10] = sj_loss.tolist()\n",
    "            accs[1][step%10] = sj_acc\n",
    "            \n",
    "            emo_loss, emo_acc = emotion_loss(xem, yem, lem,\n",
    "                                    bert, transformer, task_embedding(emo_task_id),\n",
    "                                    emotion_classifier, emo_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "#             emo_loss.backward()\n",
    "            MTL_Loss += emo_loss*loss_weight[2]\n",
    "    \n",
    "            losses[2][step%10] = emo_loss.tolist()\n",
    "            accs[2][step%10] = emo_acc\n",
    "            \n",
    "            MTL_Loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            print(\"%6d|MTL_Loss:%6.8f, senti_loss/senti_acc = %6.8f/%6.7f | subj_loss/subj_acc = %6.8f/%6.7f | emo_loss/emo_acc = %6.8f/%6.7f\" % (\n",
    "                                                                                                step, MTL_Loss,        \n",
    "                                                                                                losses[0].mean(), accs[0].mean(),\n",
    "                                                                                                losses[1].mean(), accs[1].mean(),\n",
    "                                                                                                losses[2].mean(), accs[2].mean()\n",
    "            )\n",
    "            )\n",
    "            if step % 10 == 9:\n",
    "                print('%6d: [%5d/%5d], MTL_Loss|%6.8f, senti_loss/senti_acc = %6.8f/%6.7f | subj_loss/subj_acc = %6.8f/%6.7f | emo_loss/emo_acc = %6.8f/%6.7f' % (\n",
    "                                                                                                step,\n",
    "                                                                                                epoch,max_epoch, MTL_Loss,\n",
    "                                                                                                losses[0].mean(), accs[0].mean(),\n",
    "                                                                                                losses[1].mean(), accs[1].mean(),\n",
    "                                                                                                losses[2].mean(), accs[2].mean()\n",
    "                                                                                            )\n",
    "                     )\n",
    "                loss_weight = torch.tensor(\n",
    "                                            (1.0/accs.mean(axis=1))/sum(1.0/accs.mean(axis=1)),\n",
    "                                            dtype=torch.float32\n",
    "                                )\n",
    "                print(\"\\n\\n loss_weight:\", loss_weight)\n",
    "            step += 1\n",
    "        joint_model_save_as = '/home/hadoop/ERD/MTLTrain/jointModel_epoch%03d.pkl'% (epoch)\n",
    "        torch.save(\n",
    "            {\n",
    "                \"bert\":bert.state_dict(),\n",
    "                \"transformer\":transformer.state_dict(),\n",
    "                \"task_embedding\":task_embedding.state_dict(),\n",
    "                \"senti_classifier\": senti_classifier.state_dict(),\n",
    "                \"subj_classifier\": subj_classifier.state_dict(),\n",
    "                \"emotion_classifier\": emotion_classifier.state_dict()\n",
    "            },\n",
    "            joint_model_save_as\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 双人舞\n",
    "情感分析和主观客观性任务联合训练的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentiSubjLearning(senti_reader, subj_reader, \n",
    "                  bert, transformer, task_embedding, \n",
    "                  senti_classifier, subj_classifier,\n",
    "                  cuda=False\n",
    "                 ):  \n",
    "    \n",
    "    # stage 1: deploy the trainning on the senti classification task\n",
    "    senti_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                senti_reader.label\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "    )\n",
    "    senti_loss_fn = nn.CrossEntropyLoss(weight=senti_weights.cuda()) if cuda else nn.CrossEntropyLoss(weight=senti_weights)\n",
    "    #stage 2: deploy the trainning on the subj classification task\n",
    "    subj_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                subj_reader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    )\n",
    "    subj_loss_fn = nn.CrossEntropyLoss(weight=subj_weights) if not cuda else nn.CrossEntropyLoss(weight=subj_weights.cuda())\n",
    "\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':5e-7},\n",
    "                                {'params': task_embedding.parameters(), 'lr':1e-6},\n",
    "                                {'params': transformer.parameters(), 'lr': 1e-6},\n",
    "                                {'params': senti_classifier.parameters(), 'lr': 1e-6},\n",
    "                                {'params': subj_classifier.parameters(), 'lr':1e-6}\n",
    "                             ]\n",
    "    )\n",
    "    \n",
    "    max_epoch = 10\n",
    "    \n",
    "    losses = np.zeros([3, 10]) \n",
    "    accs = np.zeros([3, 10])\n",
    "    # [[senti_loss_1, ..., senti_loss_10], [subj_loss_1, ..., subj_loss_10], [emo_loss_1, ..., emo_loss_10]] \n",
    "    senti_task_id = torch.tensor([0]) if not cuda else torch.tensor([0]).cuda()\n",
    "    subj_task_id = torch.tensor([1]) if not cuda else torch.tensor([1]).cuda()\n",
    "    \n",
    "    loss_weight = torch.tensor([0.5, 0.5]) if not cuda else torch.tensor([0.5, 0.5]).cuda()\n",
    "    \n",
    "    batchs = min(senti_reader.label.shape[0], subj_reader.label.shape[0])\n",
    "    optim.zero_grad()\n",
    "    for epoch in range(10, max_epoch+10):\n",
    "        step = 0\n",
    "        for ((xst, yst, lst), (xsj, ysj, lsj)) in zip(senti_reader.iter(), subj_reader.iter() ):\n",
    "            st_loss, st_acc = senti_loss(xst, yst, lst, \n",
    "                                    bert, transformer, task_embedding(senti_task_id),\n",
    "                                    senti_classifier, senti_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "            MTL_Loss = st_loss*loss_weight[0]\n",
    "            losses[0][step%10] = st_loss.tolist()\n",
    "            accs[0][step%10] = st_acc\n",
    "             \n",
    "            sj_loss, sj_acc = subj_loss(xsj, ysj, lsj,\n",
    "                                    bert, transformer, task_embedding(subj_task_id),\n",
    "                                    subj_classifier, subj_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "            MTL_Loss += sj_loss*loss_weight[1]\n",
    "            losses[1][step%10] = sj_loss.tolist()\n",
    "            accs[1][step%10] = sj_acc\n",
    "            \n",
    "            MTL_Loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            print(\"%6d %6d|MTL_Loss:%6.8f, senti_loss/senti_acc = %6.8f/%6.7f | subj_loss/subj_acc = %6.8f/%6.7f \" % (\n",
    "                                                                                                step, batchs, MTL_Loss,        \n",
    "                                                                                                losses[0].mean(), accs[0].mean(),\n",
    "                                                                                                losses[1].mean(), accs[1].mean()\n",
    "            )\n",
    "            )\n",
    "            if step % 10 == 9:\n",
    "                print('%6d %6d: [%5d/%5d], MTL_Loss|%6.8f, senti_loss/senti_acc = %6.8f/%6.7f | subj_loss/subj_acc = %6.8f/%6.7f' % (\n",
    "                                                                                                step, batchs, \n",
    "                                                                                                epoch,max_epoch, MTL_Loss,\n",
    "                                                                                                losses[0].mean(), accs[0].mean(),\n",
    "                                                                                                losses[1].mean(), accs[1].mean()\n",
    "                                                                                            )\n",
    "                     )\n",
    "                loss_weight = torch.tensor(\n",
    "                                            (1.0/( accs.mean(axis=1)[:2] ) )/sum( 1.0/accs.mean(axis=1)[:2] ),\n",
    "                                            dtype=torch.float32\n",
    "                                )\n",
    "                print(\"\\n\\n loss_weight:\", loss_weight)\n",
    "            step += 1\n",
    "        joint_model_save_as = '/home/hadoop/ERD/MTLTrain/jointModel_epoch%03d.pkl'% (epoch)\n",
    "        torch.save(\n",
    "            {\n",
    "                \"bert\":bert.state_dict(),\n",
    "                \"transformer\":transformer.state_dict(),\n",
    "                \"task_embedding\":task_embedding.state_dict(),\n",
    "                \"senti_classifier\": senti_classifier.state_dict(),\n",
    "                \"subj_classifier\": subj_classifier.state_dict()\n",
    "            },\n",
    "            joint_model_save_as\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 双任务增强\n",
    "subj任务和sentiment任务来增强谣言检测模块\n",
    "\n",
    "> 此时应当要能从Reader中随机地挑出一个batch出来训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MTLTrainRDMModel(rdm_model, bert, rdm_classifier,\n",
    "                     transformer, task_embedding, senti_classifier, subj_classifier, \n",
    "                     sentiReader, subjReader, \n",
    "                    tokenizer, t_steps, new_data_len=[], logger=None, cuda=False, \n",
    "                        log_dir=\"RDMBertTrain\"):\n",
    "    batch_size = 10 \n",
    "    max_gpu_batch = 2 #cannot load a larger batch into the limited memory, but we could  accumulates grads\n",
    "    sentiReader.reset_batchsize(max_gpu_batch)\n",
    "    subjReader.reset_batchsize(max_gpu_batch)\n",
    "    \n",
    "    assert(batch_size%max_gpu_batch == 0)\n",
    "    \n",
    "    sum_loss = np.zeros(4)\n",
    "    sum_acc = np.zeros(3)\n",
    "    \n",
    "    t_acc = 0.9\n",
    "    ret_acc = 0.0\n",
    "    init_states = torch.zeros([1, 5, rdm_model.hidden_dim], dtype=torch.float32).cuda()\n",
    "    \n",
    "    senti_task_id = torch.tensor([0]) if not cuda else torch.tensor([0]).cuda()\n",
    "    subj_task_id = torch.tensor([1]) if not cuda else torch.tensor([1]).cuda()\n",
    "    \n",
    "    weight = torch.tensor([2.0, 1.0], dtype=torch.float32).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "    \n",
    "    senti_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                sentiReader.label\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "    )\n",
    "    senti_loss_fn = nn.CrossEntropyLoss(weight=senti_weights.cuda()) if cuda else nn.CrossEntropyLoss(weight=senti_weights)\n",
    "    \n",
    "    subj_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                subjReader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    )\n",
    "    subj_loss_fn = nn.CrossEntropyLoss(weight=subj_weights) if not cuda else nn.CrossEntropyLoss(weight=subj_weights.cuda())\n",
    "\n",
    "    loss_weight = torch.tensor([0.8, 0.1, 0.1]) if not cuda else torch.tensor([0.8, 0.1, 0.1]).cuda()   \n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':5e-7},\n",
    "                                {'params': rdm_classifier.parameters(), 'lr': 5e-5},\n",
    "                                {'params': rdm_model.parameters(), 'lr': 5e-5},\n",
    "                                {'params': task_embedding.parameters(), 'lr':1e-6},\n",
    "                                {'params': transformer.parameters(), 'lr': 1e-6},\n",
    "                                {'params': senti_classifier.parameters(), 'lr': 1e-6},\n",
    "                                {'params': subj_classifier.parameters(), 'lr':1e-6}\n",
    "                             ]\n",
    "    )\n",
    "    \n",
    "    writer = SummaryWriter(log_dir)\n",
    "    \n",
    "    acc_tmp = np.zeros([3, int(batch_size/max_gpu_batch)])\n",
    "    loss_tmp = np.zeros([4, int(batch_size/max_gpu_batch)])\n",
    "    \n",
    "    for step in range(t_steps):\n",
    "        optim.zero_grad()\n",
    "        for j in range(int(batch_size/max_gpu_batch)):\n",
    "            if len(new_data_len) > 0:\n",
    "                x, x_len, y = get_df_batch(step, max_gpu_batch, new_data_len, tokenizer=tokenizer)\n",
    "            else:\n",
    "                x, x_len, y = get_df_batch(step, max_gpu_batch, tokenizer=tokenizer) \n",
    "            loss, acc = rdm_loss(x, y, x_len, bert, rdm_model, rdm_classifier, loss_fn)\n",
    "            MTL_Loss = loss*loss_weight[0]\n",
    "            \n",
    "            xst, yst, lst = sentiReader.sample()\n",
    "            st_loss, st_acc = senti_loss(xst, yst, lst, \n",
    "                                    bert, transformer, task_embedding(senti_task_id),\n",
    "                                    senti_classifier, senti_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "            MTL_Loss += st_loss*loss_weight[1]\n",
    "            \n",
    "            xsj, ysj, lsj = subjReader.sample()\n",
    "            sj_loss, sj_acc = subj_loss(xsj, ysj, lsj,\n",
    "                                    bert, transformer, task_embedding(subj_task_id),\n",
    "                                    subj_classifier, subj_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "            MTL_Loss += sj_loss*loss_weight[2]\n",
    "            \n",
    "            MTL_Loss.backward()\n",
    "            \n",
    "            loss_tmp[:, j] = np.array([MTL_Loss, loss, st_loss, sj_loss])\n",
    "            acc_tmp[:, j] = np.array([acc, st_acc, sj_acc])\n",
    "            \n",
    "        optim.step()        \n",
    "        writer.add_scalar('Train Loss', loss_tmp[0].mean(), step)\n",
    "        writer.add_scalar('Train Accuracy', acc_tmp[0].mean(), step)\n",
    "        \n",
    "        sum_acc += acc_tmp.mean(axis=1)\n",
    "        sum_loss += loss_tmp.mean(axis=1)\n",
    "        \n",
    "        print(\"%6d %6d|MTL_Loss:%6.8f, rdm_loss/rdm_acc = %6.8f/%6.7f | senti_loss/senti_acc = %6.8f/%6.7f | subj_loss/subj_acc = %6.8f/%6.7f \" % (\n",
    "                                                                                                step, t_steps, loss_tmp[0].mean(),        \n",
    "                                                                                            loss_tmp[1].mean(), acc_tmp[0].mean(),\n",
    "                                                                                            loss_tmp[2].mean(), acc_tmp[1].mean(),\n",
    "                                                                                            loss_tmp[3].mean(), acc_tmp[2].mean()\n",
    "            )\n",
    "            )\n",
    "        \n",
    "        if step % 10 == 9:\n",
    "            sum_loss = sum_loss / 10\n",
    "            sum_acc = sum_acc / 10\n",
    "            print(\"MTL_Loss:%6.8f, rdm_loss/rdm_acc = %6.8f/%6.7f | senti_loss/senti_acc = %6.8f/%6.7f | subj_loss/subj_acc = %6.8f/%6.7f \" % (\n",
    "                                                                                            sum_loss[0],        \n",
    "                                                                                            sum_loss[1], sum_acc[0],\n",
    "                                                                                            sum_loss[2], sum_acc[1],\n",
    "                                                                                            sum_loss[3], sum_acc[2]\n",
    "            )\n",
    "            )\n",
    "            if step%100 == 99:\n",
    "                rdm_save_as = '/home/hadoop/ERD/%s/rdmModel_epoch%03d.pkl'% (log_dir, step/100, sum_acc)\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"bert\":bert.state_dict(),\n",
    "                        \"transformer\":transformer.state_dict(),\n",
    "                        \"task_embedding\":task_embedding.state_dict(),\n",
    "                        \"senti_classifier\": senti_classifier.state_dict(),\n",
    "                        \"subj_classifier\": subj_classifier.state_dict(),\n",
    "                        \"rmdModel\":rdm_model.state_dict(),\n",
    "                        \"rdm_classifier\": rdm_classifierdm.state_dict()\n",
    "                    },\n",
    "                    rdm_save_as\n",
    "                )\n",
    "#                 rdm_model, bert, sentiModel, rdm_classifier\n",
    "            sum_acc = 0.0\n",
    "            sum_loss = 0.0\n",
    "\n",
    "    print(get_curtime() + \" Train df Model End.\")\n",
    "    logger.info(get_curtime() + \" Train df Model End.\")\n",
    "    return ret_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主函数部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = BertTokenizer.from_pretrained(\"./bertModel/\")\n",
    "bb = BertModel.from_pretrained(\"./bertModel/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "bb.save_pretrained('./bertModel/')  # save\n",
    "tt.save_pretrained('./bertModel/')  # save\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embedding = nn.Embedding(3, 768)\n",
    "\n",
    "encoder_layer = nn.TransformerEncoderLayer(768, 8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, 1)\n",
    "\n",
    "subj_cls = nn.Linear(768, 2)\n",
    "\n",
    "bert = bb.cuda()\n",
    "transformer = transformer_encoder.cuda()\n",
    "task_embedding = task_embedding.cuda()\n",
    "subj_cls = subj_cls.cuda()\n",
    "\n",
    "senti_cls = nn.Linear(768, 2).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 各个任务的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_file = \"./rotten_imdb/subj.data\"\n",
    "obj_file = \"./rotten_imdb/obj.data\"\n",
    "tr, dev, te = load_data(subj_file, obj_file)\n",
    "\n",
    "subj_train_reader = SubjObjReader(tr, 20, tt)\n",
    "subj_valid_reader = SubjObjReader(dev, 20, tt)\n",
    "subj_test_reader =  SubjObjReader(te, 20, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trainingandtestdata/training.1600000.processed.noemoticon.csv\n",
      "./trainingandtestdata/testdata.manual.2009.06.14.csv\n"
     ]
    }
   ],
   "source": [
    "train_file = \"./trainingandtestdata/training.1600000.processed.noemoticon.csv\"\n",
    "test_file = \"./trainingandtestdata/testdata.manual.2009.06.14.csv\"\n",
    "train_set, test_set = tsentiLoader.load_data(train_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_train_reader = tsentiLoader.tSentiReader(train_set[:10000], 20, tt)\n",
    "senti_train_reader.label = np.delete(senti_train_reader.label, 1, axis=2)\n",
    "# senti_valid_reader = tsentiLoader.tSentiReader(train_set[10000:10100], 20, tt)\n",
    "# senti_test_reader =  tsentiLoader.tSentiReader(test_set, 20, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 187 ,  max_seq_len: 101\n",
      "5802 data loaded\n"
     ]
    }
   ],
   "source": [
    "load_data_fast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调试各个任务的部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 调试subjective的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subj_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                subj_train_reader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    ).cuda()\n",
    "subj_loss_fn = nn.CrossEntropyLoss(weight=subj_weights)\n",
    "subj_cls_train(subj_train_reader, bert, transformer, task_embedding, subj_cls, 1, subj_loss_fn, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "joint_model_save_as = './MTLTrain/SubjAfterSentiModel_epoch.pkl'\n",
    "torch.save(\n",
    "    {\n",
    "        \"bert\":bert.state_dict(),\n",
    "        \"transformer\":transformer.state_dict(),\n",
    "        \"task_embedding\":task_embedding.state_dict(),\n",
    "#         \"senti_classifier\": senti_cls.state_dict(),\n",
    "        \"subj_classifier\": subj_cls.state_dict(),\n",
    "#         \"emotion_classifier\": emotion_classifier.state_dict()\n",
    "    },\n",
    "    joint_model_save_as\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> __test code__\n",
    "``` python\n",
    "for xsj, ysj, lsj in subj_train_reader.iter():\n",
    "    loss = subj_loss(  xsj, ysj, lsj,\n",
    "                bb, transformer_encoder, task_embedding(torch.tensor([1])),\n",
    "                subj_cls, subj_loss_fn\n",
    "               )\n",
    "    break\n",
    "```\n",
    "> __train stage__\n",
    "```python\n",
    "subj_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                subj_train_reader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    ).cuda()\n",
    "subj_loss_fn = nn.CrossEntropyLoss(weight=subj_weights)\n",
    "subj_cls_train(subj_train_reader, bert, transformer, task_embedding, subj_cls, 1, subj_loss_fn, cuda=True)\n",
    "```\n",
    "_subj task 的训练，在当前的参数配置下，一个ｅｐｏｃｈ可以调到很好的状态_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 调试sentiment 的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-145662b7e566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mtask_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msenti_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msenti_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                    )\n",
      "\u001b[0;32m<ipython-input-25-eabcd629ddfe>\u001b[0m in \u001b[0;36msenti_cls_train\u001b[0;34m(senti_reader, bert, transformer, task_embedding, senti_classifier, train_epochs, senti_loss_fn, cuda)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mst_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msenti_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msenti_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mst_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCount_Accs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msenti_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mst_loss_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mst_loss_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_weight' is not defined"
     ]
    }
   ],
   "source": [
    "senti_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                senti_train_reader.label\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "    )\n",
    "senti_loss_fn = nn.CrossEntropyLoss(weight=senti_weights.cuda())\n",
    "senti_cls_train(senti_train_reader, bert, transformer,\n",
    "                    task_embedding, senti_cls,\n",
    "                    1, senti_loss_fn,\n",
    "                    cuda=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> __测试sentiment analysis的task__\n",
    "``` python\n",
    "senti_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                senti_train_reader.label\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "    )\n",
    "senti_loss_fn = nn.CrossEntropyLoss(weight=senti_weights.cuda())\n",
    "senti_cls_train(senti_train_reader, bert, transformer,\n",
    "                    task_embedding, senti_cls,\n",
    "                    2, senti_loss_fn,\n",
    "                    cuda=True\n",
    "                   )\n",
    "``` \n",
    "_这个任务至少需要５个ｅｐｏｃｈ才能训练出来个大概的样子_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "senti_cls_train(senti_train_reader, bert, transformer,\n",
    "                    task_embedding, senti_cls,\n",
    "                    1, senti_loss_fn,\n",
    "                    cuda=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "joint_model_save_as = '/home/hadoop/ERD/MTLTrain/SentiPretrainModel_epoch.pkl'\n",
    "torch.save(\n",
    "    {\n",
    "        \"bert\":bert.state_dict(),\n",
    "        \"transformer\":transformer.state_dict(),\n",
    "        \"task_embedding\":task_embedding.state_dict(),\n",
    "        \"senti_classifier\": senti_cls.state_dict(),\n",
    "#         \"subj_classifier\": subj_classifier.state_dict(),\n",
    "#         \"emotion_classifier\": emotion_classifier.state_dict()\n",
    "    },\n",
    "    joint_model_save_as\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调试emotion classification　任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = \"/home/hadoop/EmoNet-PyTorch/twitter30.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels, emotion_set = emotionLoader.load_data_from_file(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoReader = emotionLoader.EmotionReader(sentences[:-400], labels[:-400], 20, tt)\n",
    "valReader = emotionLoader.EmotionReader(sentences[-400:], labels[-400:], 20, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_cls = nn.ModuleList([nn.Linear(768, 2).cuda()  for i in range(emoReader.label.shape[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1011, 20, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoReader.label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_cls = nn.Linear(768, 6).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0 | loss/acc = 2.104/0.350\n",
      "step:1 | loss/acc = 2.084/0.200\n",
      "step:2 | loss/acc = 2.035/0.150\n",
      "step:3 | loss/acc = 2.027/0.300\n",
      "step:4 | loss/acc = 2.378/0.050\n",
      "step:5 | loss/acc = 2.063/0.250\n",
      "step:6 | loss/acc = 2.118/0.150\n",
      "step:7 | loss/acc = 2.004/0.150\n",
      "step:8 | loss/acc = 2.146/0.150\n",
      "step:9 | loss/acc = 2.211/0.250\n",
      "emotion task:      9: [    0/    2], senti_loss/senti_acc = 2.11709208/0.2000000 \n",
      "step:10 | loss/acc = 2.030/0.200\n",
      "step:11 | loss/acc = 2.224/0.100\n",
      "step:12 | loss/acc = 1.720/0.350\n",
      "step:13 | loss/acc = 1.918/0.100\n",
      "step:14 | loss/acc = 1.997/0.300\n",
      "step:15 | loss/acc = 2.144/0.200\n",
      "step:16 | loss/acc = 1.992/0.150\n",
      "step:17 | loss/acc = 1.735/0.200\n",
      "step:18 | loss/acc = 1.984/0.300\n",
      "step:19 | loss/acc = 2.112/0.150\n",
      "emotion task:     19: [    0/    2], senti_loss/senti_acc = 1.98568085/0.2050000 \n",
      "step:20 | loss/acc = 1.902/0.150\n",
      "step:21 | loss/acc = 2.107/0.150\n",
      "step:22 | loss/acc = 1.770/0.150\n",
      "step:23 | loss/acc = 1.948/0.250\n",
      "step:24 | loss/acc = 1.794/0.200\n",
      "step:25 | loss/acc = 1.830/0.250\n",
      "step:26 | loss/acc = 2.035/0.300\n",
      "step:27 | loss/acc = 1.659/0.300\n",
      "step:28 | loss/acc = 2.054/0.150\n",
      "step:29 | loss/acc = 1.989/0.200\n",
      "emotion task:     29: [    0/    2], senti_loss/senti_acc = 1.90878242/0.2100000 \n",
      "step:30 | loss/acc = 1.931/0.100\n",
      "step:31 | loss/acc = 1.779/0.150\n",
      "step:32 | loss/acc = 2.015/0.050\n",
      "step:33 | loss/acc = 1.907/0.200\n",
      "step:34 | loss/acc = 1.982/0.100\n",
      "step:35 | loss/acc = 2.143/0.150\n",
      "step:36 | loss/acc = 1.902/0.250\n",
      "step:37 | loss/acc = 1.690/0.300\n",
      "step:38 | loss/acc = 1.934/0.250\n",
      "step:39 | loss/acc = 1.987/0.200\n",
      "emotion task:     39: [    0/    2], senti_loss/senti_acc = 1.92712060/0.1750000 \n",
      "step:40 | loss/acc = 2.074/0.050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-69a25904ab1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0memo_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-23-184ddd218f1a>\u001b[0m in \u001b[0;36memo_cls_train\u001b[0;34m(emotion_reader, bert, transformer, task_embedding, emotion_classifier, train_epochs, cuda)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0memo_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memo_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msenti_data2bert_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mxem_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memo_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memo_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxem_embs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtask_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memo_task_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    713\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    714\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    716\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emo_cls_train(\n",
    "        emoReader,\n",
    "        valReader,\n",
    "        bert, \n",
    "        transformer, \n",
    "        task_embedding, \n",
    "        emo_cls, \n",
    "        2, \n",
    "        log_dir=\"EmoRDM\"\n",
    "        cuda=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 联合训练部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 导入预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_save_as = '/home/hadoop/ERD/MTLTrain/SentiPretrainModel_epoch.pkl'\n",
    "\n",
    "checkpoint = torch.load(senti_save_as)\n",
    "\n",
    "senti_cls.load_state_dict(checkpoint['senti_classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentiSubj_saved_as =  '/home/hadoop/ERD/MTLTrain/SubjAfterSentiModel_epoch.pkl'\n",
    "checkpoint = torch.load(SentiSubj_saved_as)\n",
    "bert.load_state_dict(checkpoint['bert'])\n",
    "transformer.load_state_dict(checkpoint['transformer'])\n",
    "task_embedding.load_state_dict(checkpoint['task_embedding'])\n",
    "subj_cls.load_state_dict(checkpoint['subj_classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_save_as = '/home/hadoop/ERD/MTLTrain/jointModel_epoch015.pkl'\n",
    "checkpoint = torch.load(joint_save_as)\n",
    "senti_cls.load_state_dict(checkpoint['senti_classifier'])\n",
    "bert.load_state_dict(checkpoint['bert'])\n",
    "transformer.load_state_dict(checkpoint['transformer'])\n",
    "task_embedding.load_state_dict(checkpoint['task_embedding'])\n",
    "subj_cls.load_state_dict(checkpoint['subj_classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 联合训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    425|MTL_Loss:0.29332089, senti_loss/senti_acc = 0.05127532/0.0750000 | subj_loss/subj_acc = 0.00738885/0.1000000 \n",
      "     1    425|MTL_Loss:0.19184102, senti_loss/senti_acc = 0.08910429/0.1500000 | subj_loss/subj_acc = 0.00792809/0.2000000 \n",
      "     2    425|MTL_Loss:0.41711080, senti_loss/senti_acc = 0.15514933/0.2150000 | subj_loss/subj_acc = 0.02530521/0.2850000 \n",
      "     3    425|MTL_Loss:0.18992978, senti_loss/senti_acc = 0.18254753/0.3150000 | subj_loss/subj_acc = 0.03589297/0.3800000 \n",
      "     4    425|MTL_Loss:0.26974079, senti_loss/senti_acc = 0.22672767/0.4000000 | subj_loss/subj_acc = 0.04566098/0.4800000 \n",
      "     5    425|MTL_Loss:0.22977003, senti_loss/senti_acc = 0.26549595/0.4800000 | subj_loss/subj_acc = 0.05284671/0.5750000 \n",
      "     6    425|MTL_Loss:0.36548451, senti_loss/senti_acc = 0.32818922/0.5450000 | subj_loss/subj_acc = 0.06325034/0.6700000 \n",
      "     7    425|MTL_Loss:0.31482914, senti_loss/senti_acc = 0.38309467/0.6200000 | subj_loss/subj_acc = 0.07131071/0.7650000 \n",
      "     8    425|MTL_Loss:0.44549656, senti_loss/senti_acc = 0.44721097/0.6900000 | subj_loss/subj_acc = 0.09629373/0.8500000 \n",
      "     9    425|MTL_Loss:0.41118744, senti_loss/senti_acc = 0.50849429/0.7700000 | subj_loss/subj_acc = 0.11724790/0.9400000 \n",
      "     9    425: [   10/   10], MTL_Loss|0.41118744, senti_loss/senti_acc = 0.50849429/0.7700000 | subj_loss/subj_acc = 0.11724790/0.9400000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.5497, 0.4503])\n",
      "    10    425|MTL_Loss:0.35562450, senti_loss/senti_acc = 0.49600718/0.7750000 | subj_loss/subj_acc = 0.14148355/0.9300000 \n",
      "    11    425|MTL_Loss:0.18287030, senti_loss/senti_acc = 0.48587354/0.7900000 | subj_loss/subj_acc = 0.14774589/0.9300000 \n",
      "    12    425|MTL_Loss:0.23819391, senti_loss/senti_acc = 0.46149455/0.8000000 | subj_loss/subj_acc = 0.13240132/0.9450000 \n",
      "    13    425|MTL_Loss:0.18142822, senti_loss/senti_acc = 0.46481916/0.7900000 | subj_loss/subj_acc = 0.12459900/0.9500000 \n",
      "    14    425|MTL_Loss:0.22860153, senti_loss/senti_acc = 0.45942976/0.7900000 | subj_loss/subj_acc = 0.11824341/0.9500000 \n",
      "    15    425|MTL_Loss:0.53267473, senti_loss/senti_acc = 0.50940974/0.7600000 | subj_loss/subj_acc = 0.12101096/0.9500000 \n",
      "    16    425|MTL_Loss:0.19913864, senti_loss/senti_acc = 0.47467377/0.7900000 | subj_loss/subj_acc = 0.12070194/0.9500000 \n",
      "    17    425|MTL_Loss:0.26943874, senti_loss/senti_acc = 0.45890998/0.8050000 | subj_loss/subj_acc = 0.12469463/0.9500000 \n",
      "    18    425|MTL_Loss:0.27028030, senti_loss/senti_acc = 0.44121280/0.8100000 | subj_loss/subj_acc = 0.10306742/0.9650000 \n",
      "    19    425|MTL_Loss:0.25000343, senti_loss/senti_acc = 0.41247987/0.8150000 | subj_loss/subj_acc = 0.09789664/0.9700000 \n",
      "    19    425: [   10/   10], MTL_Loss|0.25000343, senti_loss/senti_acc = 0.41247987/0.8150000 | subj_loss/subj_acc = 0.09789664/0.9700000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.5434, 0.4566])\n",
      "    20    425|MTL_Loss:0.23430155, senti_loss/senti_acc = 0.41219096/0.8200000 | subj_loss/subj_acc = 0.07176723/0.9750000 \n",
      "    21    425|MTL_Loss:0.25959307, senti_loss/senti_acc = 0.41881520/0.8150000 | subj_loss/subj_acc = 0.08097471/0.9700000 \n",
      "    22    425|MTL_Loss:0.20007096, senti_loss/senti_acc = 0.40946593/0.8250000 | subj_loss/subj_acc = 0.08429845/0.9650000 \n",
      "    23    425|MTL_Loss:0.33145151, senti_loss/senti_acc = 0.42937333/0.8100000 | subj_loss/subj_acc = 0.09384773/0.9600000 \n",
      "    24    425|MTL_Loss:0.34290275, senti_loss/senti_acc = 0.43229983/0.7950000 | subj_loss/subj_acc = 0.11588611/0.9550000 \n",
      "    25    425|MTL_Loss:0.19526073, senti_loss/senti_acc = 0.37688231/0.8250000 | subj_loss/subj_acc = 0.10902882/0.9600000 \n",
      "    26    425|MTL_Loss:0.37790570, senti_loss/senti_acc = 0.40587832/0.8100000 | subj_loss/subj_acc = 0.11391759/0.9600000 \n",
      "    27    425|MTL_Loss:0.46717098, senti_loss/senti_acc = 0.43066982/0.7850000 | subj_loss/subj_acc = 0.12809134/0.9550000 \n",
      "    28    425|MTL_Loss:0.15816286, senti_loss/senti_acc = 0.41143264/0.7950000 | subj_loss/subj_acc = 0.12702460/0.9550000 \n",
      "    29    425|MTL_Loss:0.28883454, senti_loss/senti_acc = 0.42939648/0.7750000 | subj_loss/subj_acc = 0.11438005/0.9600000 \n",
      "    29    425: [   10/   10], MTL_Loss|0.28883454, senti_loss/senti_acc = 0.42939648/0.7750000 | subj_loss/subj_acc = 0.11438005/0.9600000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.5533, 0.4467])\n",
      "    30    425|MTL_Loss:0.36552021, senti_loss/senti_acc = 0.45611764/0.7750000 | subj_loss/subj_acc = 0.10992509/0.9650000 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f8fa2d193282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                   \u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0msenti_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                   \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                  )\n",
      "\u001b[0;32m<ipython-input-13-3b7086f56f7c>\u001b[0m in \u001b[0;36mSentiSubjLearning\u001b[0;34m(senti_reader, subj_reader, bert, transformer, task_embedding, senti_classifier, subj_classifier, cuda)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0maccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msj_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mMTL_Loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SentiSubjLearning(senti_train_reader, subj_train_reader, \n",
    "                  bert, transformer, task_embedding, \n",
    "                  senti_cls, subj_cls,\n",
    "                  cuda=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0 | loss/acc = 0.702/0.500\n",
      "step:1 | loss/acc = 0.696/0.450\n",
      "step:2 | loss/acc = 0.697/0.500\n",
      "step:3 | loss/acc = 0.690/0.500\n",
      "step:4 | loss/acc = 0.687/0.450\n",
      "step:5 | loss/acc = 0.668/0.600\n",
      "step:6 | loss/acc = 0.692/0.500\n",
      "step:7 | loss/acc = 0.743/0.350\n",
      "step:8 | loss/acc = 0.651/0.650\n",
      "step:9 | loss/acc = 0.648/0.750\n",
      "sentiment task:      9: [    0/    2], senti_loss/senti_acc = 0.68745612/0.5250000 \n",
      "step:10 | loss/acc = 0.708/0.450\n",
      "step:11 | loss/acc = 0.664/0.700\n",
      "step:12 | loss/acc = 0.658/0.750\n",
      "step:13 | loss/acc = 0.681/0.400\n",
      "step:14 | loss/acc = 0.672/0.600\n",
      "step:15 | loss/acc = 0.706/0.450\n",
      "step:16 | loss/acc = 0.737/0.450\n",
      "step:17 | loss/acc = 0.781/0.400\n",
      "step:18 | loss/acc = 0.742/0.450\n",
      "step:19 | loss/acc = 0.703/0.500\n",
      "sentiment task:     19: [    0/    2], senti_loss/senti_acc = 0.70535051/0.5150000 \n",
      "step:20 | loss/acc = 0.784/0.400\n",
      "step:21 | loss/acc = 0.757/0.450\n",
      "step:22 | loss/acc = 0.689/0.450\n",
      "step:23 | loss/acc = 0.720/0.400\n",
      "step:24 | loss/acc = 0.664/0.650\n",
      "step:25 | loss/acc = 0.691/0.550\n",
      "step:26 | loss/acc = 0.691/0.400\n",
      "step:27 | loss/acc = 0.675/0.650\n",
      "step:28 | loss/acc = 0.690/0.550\n",
      "step:29 | loss/acc = 0.696/0.450\n",
      "sentiment task:     29: [    0/    2], senti_loss/senti_acc = 0.70567194/0.4950000 \n",
      "step:30 | loss/acc = 0.617/0.850\n",
      "step:31 | loss/acc = 0.661/0.650\n",
      "step:32 | loss/acc = 0.588/0.750\n",
      "step:33 | loss/acc = 0.611/0.650\n",
      "step:34 | loss/acc = 0.832/0.150\n",
      "step:35 | loss/acc = 0.739/0.450\n",
      "step:36 | loss/acc = 0.679/0.550\n",
      "step:37 | loss/acc = 0.604/0.650\n",
      "step:38 | loss/acc = 0.651/0.600\n",
      "step:39 | loss/acc = 0.841/0.300\n",
      "sentiment task:     39: [    0/    2], senti_loss/senti_acc = 0.68237178/0.5600000 \n",
      "step:40 | loss/acc = 0.634/0.600\n",
      "step:41 | loss/acc = 0.754/0.500\n",
      "step:42 | loss/acc = 0.685/0.600\n",
      "step:43 | loss/acc = 0.784/0.300\n",
      "step:44 | loss/acc = 0.660/0.550\n",
      "step:45 | loss/acc = 0.660/0.650\n",
      "step:46 | loss/acc = 0.683/0.550\n",
      "step:47 | loss/acc = 0.613/0.650\n",
      "step:48 | loss/acc = 0.672/0.500\n",
      "step:49 | loss/acc = 0.770/0.400\n",
      "sentiment task:     49: [    0/    2], senti_loss/senti_acc = 0.69155188/0.5300000 \n",
      "step:50 | loss/acc = 0.684/0.550\n",
      "step:51 | loss/acc = 0.669/0.550\n",
      "step:52 | loss/acc = 0.618/0.750\n",
      "step:53 | loss/acc = 0.714/0.500\n",
      "step:54 | loss/acc = 0.679/0.650\n",
      "step:55 | loss/acc = 0.689/0.550\n",
      "step:56 | loss/acc = 0.659/0.750\n",
      "step:57 | loss/acc = 0.699/0.500\n",
      "step:58 | loss/acc = 0.708/0.500\n",
      "step:59 | loss/acc = 0.653/0.650\n",
      "sentiment task:     59: [    0/    2], senti_loss/senti_acc = 0.67720622/0.5950000 \n",
      "step:60 | loss/acc = 0.654/0.700\n",
      "step:61 | loss/acc = 0.692/0.500\n",
      "step:62 | loss/acc = 0.701/0.550\n",
      "step:63 | loss/acc = 0.642/0.650\n",
      "step:64 | loss/acc = 0.701/0.500\n",
      "step:65 | loss/acc = 0.636/0.600\n",
      "step:66 | loss/acc = 0.684/0.500\n",
      "step:67 | loss/acc = 0.720/0.500\n",
      "step:68 | loss/acc = 0.716/0.450\n",
      "step:69 | loss/acc = 0.744/0.400\n",
      "sentiment task:     69: [    0/    2], senti_loss/senti_acc = 0.68896019/0.5350000 \n",
      "step:70 | loss/acc = 0.606/0.750\n",
      "step:71 | loss/acc = 0.665/0.550\n",
      "step:72 | loss/acc = 0.735/0.350\n",
      "step:73 | loss/acc = 0.702/0.500\n",
      "step:74 | loss/acc = 0.751/0.400\n",
      "step:75 | loss/acc = 0.589/0.700\n",
      "step:76 | loss/acc = 0.676/0.450\n",
      "step:77 | loss/acc = 0.596/0.700\n",
      "step:78 | loss/acc = 0.682/0.450\n",
      "step:79 | loss/acc = 0.674/0.500\n",
      "sentiment task:     79: [    0/    2], senti_loss/senti_acc = 0.66758999/0.5350000 \n",
      "step:80 | loss/acc = 0.644/0.650\n",
      "step:81 | loss/acc = 0.740/0.400\n",
      "step:82 | loss/acc = 0.616/0.700\n",
      "step:83 | loss/acc = 0.700/0.600\n",
      "step:84 | loss/acc = 0.612/0.850\n",
      "step:85 | loss/acc = 0.660/0.700\n",
      "step:86 | loss/acc = 0.645/0.700\n",
      "step:87 | loss/acc = 0.677/0.500\n",
      "step:88 | loss/acc = 0.604/0.800\n",
      "step:89 | loss/acc = 0.617/0.750\n",
      "sentiment task:     89: [    0/    2], senti_loss/senti_acc = 0.65142357/0.6650000 \n",
      "step:90 | loss/acc = 0.622/0.700\n",
      "step:91 | loss/acc = 0.652/0.750\n",
      "step:92 | loss/acc = 0.643/0.800\n",
      "step:93 | loss/acc = 0.686/0.600\n",
      "step:94 | loss/acc = 0.671/0.550\n",
      "step:95 | loss/acc = 0.556/0.950\n",
      "step:96 | loss/acc = 0.713/0.500\n",
      "step:97 | loss/acc = 0.630/0.700\n",
      "step:98 | loss/acc = 0.754/0.450\n",
      "step:99 | loss/acc = 0.701/0.500\n",
      "sentiment task:     99: [    0/    2], senti_loss/senti_acc = 0.66272725/0.6500000 \n",
      "step:100 | loss/acc = 0.711/0.450\n",
      "step:101 | loss/acc = 0.698/0.500\n",
      "step:102 | loss/acc = 0.632/0.700\n",
      "step:103 | loss/acc = 0.723/0.500\n",
      "step:104 | loss/acc = 0.680/0.450\n",
      "step:105 | loss/acc = 0.657/0.650\n",
      "step:106 | loss/acc = 0.706/0.600\n",
      "step:107 | loss/acc = 0.664/0.600\n",
      "step:108 | loss/acc = 0.714/0.600\n",
      "step:109 | loss/acc = 0.688/0.500\n",
      "sentiment task:    109: [    0/    2], senti_loss/senti_acc = 0.68733670/0.5550000 \n",
      "step:110 | loss/acc = 0.661/0.600\n",
      "step:111 | loss/acc = 0.638/0.650\n",
      "step:112 | loss/acc = 0.676/0.700\n",
      "step:113 | loss/acc = 0.703/0.500\n",
      "step:114 | loss/acc = 0.696/0.550\n",
      "step:115 | loss/acc = 0.661/0.600\n",
      "step:116 | loss/acc = 0.625/0.750\n",
      "step:117 | loss/acc = 0.684/0.600\n",
      "step:118 | loss/acc = 0.685/0.550\n",
      "step:119 | loss/acc = 0.642/0.800\n",
      "sentiment task:    119: [    0/    2], senti_loss/senti_acc = 0.66698242/0.6300000 \n",
      "step:120 | loss/acc = 0.661/0.650\n",
      "step:121 | loss/acc = 0.660/0.650\n",
      "step:122 | loss/acc = 0.636/0.700\n",
      "step:123 | loss/acc = 0.660/0.800\n",
      "step:124 | loss/acc = 0.689/0.550\n",
      "step:125 | loss/acc = 0.698/0.500\n",
      "step:126 | loss/acc = 0.647/0.650\n",
      "step:127 | loss/acc = 0.704/0.450\n",
      "step:128 | loss/acc = 0.611/0.750\n",
      "step:129 | loss/acc = 0.622/0.700\n",
      "sentiment task:    129: [    0/    2], senti_loss/senti_acc = 0.65894927/0.6400000 \n",
      "step:130 | loss/acc = 0.614/0.900\n",
      "step:131 | loss/acc = 0.704/0.500\n",
      "step:132 | loss/acc = 0.631/0.750\n",
      "step:133 | loss/acc = 0.659/0.650\n",
      "step:134 | loss/acc = 0.635/0.750\n",
      "step:135 | loss/acc = 0.673/0.550\n",
      "step:136 | loss/acc = 0.650/0.650\n",
      "step:137 | loss/acc = 0.667/0.600\n",
      "step:138 | loss/acc = 0.651/0.500\n",
      "step:139 | loss/acc = 0.681/0.550\n",
      "sentiment task:    139: [    0/    2], senti_loss/senti_acc = 0.65632160/0.6400000 \n",
      "step:140 | loss/acc = 0.665/0.500\n",
      "step:141 | loss/acc = 0.633/0.650\n",
      "step:142 | loss/acc = 0.644/0.650\n",
      "step:143 | loss/acc = 0.669/0.600\n",
      "step:144 | loss/acc = 0.691/0.450\n",
      "step:145 | loss/acc = 0.660/0.550\n",
      "step:146 | loss/acc = 0.623/0.750\n",
      "step:147 | loss/acc = 0.626/0.750\n",
      "step:148 | loss/acc = 0.621/0.650\n",
      "step:149 | loss/acc = 0.671/0.600\n",
      "sentiment task:    149: [    0/    2], senti_loss/senti_acc = 0.65055208/0.6150000 \n",
      "step:150 | loss/acc = 0.661/0.600\n",
      "step:151 | loss/acc = 0.660/0.600\n",
      "step:152 | loss/acc = 0.680/0.600\n",
      "step:153 | loss/acc = 0.581/0.850\n",
      "step:154 | loss/acc = 0.643/0.650\n",
      "step:155 | loss/acc = 0.649/0.650\n",
      "step:156 | loss/acc = 0.681/0.550\n",
      "step:157 | loss/acc = 0.718/0.500\n",
      "step:158 | loss/acc = 0.612/0.650\n",
      "step:159 | loss/acc = 0.615/0.800\n",
      "sentiment task:    159: [    0/    2], senti_loss/senti_acc = 0.65001236/0.6450000 \n",
      "step:160 | loss/acc = 0.652/0.600\n",
      "step:161 | loss/acc = 0.645/0.650\n",
      "step:162 | loss/acc = 0.638/0.700\n",
      "step:163 | loss/acc = 0.626/0.650\n",
      "step:164 | loss/acc = 0.639/0.650\n",
      "step:165 | loss/acc = 0.645/0.650\n",
      "step:166 | loss/acc = 0.645/0.600\n",
      "step:167 | loss/acc = 0.659/0.700\n",
      "step:168 | loss/acc = 0.643/0.550\n",
      "step:169 | loss/acc = 0.591/0.800\n",
      "sentiment task:    169: [    0/    2], senti_loss/senti_acc = 0.63827297/0.6550000 \n",
      "step:170 | loss/acc = 0.719/0.600\n",
      "step:171 | loss/acc = 0.632/0.650\n",
      "step:172 | loss/acc = 0.648/0.700\n",
      "step:173 | loss/acc = 0.613/0.700\n",
      "step:174 | loss/acc = 0.718/0.500\n",
      "step:175 | loss/acc = 0.651/0.650\n",
      "step:176 | loss/acc = 0.576/0.900\n",
      "step:177 | loss/acc = 0.639/0.650\n",
      "step:178 | loss/acc = 0.595/0.700\n",
      "step:179 | loss/acc = 0.656/0.500\n",
      "sentiment task:    179: [    0/    2], senti_loss/senti_acc = 0.64461319/0.6550000 \n",
      "step:180 | loss/acc = 0.661/0.700\n",
      "step:181 | loss/acc = 0.679/0.600\n",
      "step:182 | loss/acc = 0.677/0.550\n",
      "step:183 | loss/acc = 0.627/0.700\n",
      "step:184 | loss/acc = 0.589/0.750\n",
      "step:185 | loss/acc = 0.608/0.650\n",
      "step:186 | loss/acc = 0.633/0.700\n",
      "step:187 | loss/acc = 0.625/0.650\n",
      "step:188 | loss/acc = 0.614/0.750\n",
      "step:189 | loss/acc = 0.609/0.700\n",
      "sentiment task:    189: [    0/    2], senti_loss/senti_acc = 0.63222559/0.6750000 \n",
      "step:190 | loss/acc = 0.692/0.500\n",
      "step:191 | loss/acc = 0.655/0.650\n",
      "step:192 | loss/acc = 0.608/0.850\n",
      "step:193 | loss/acc = 0.564/0.900\n",
      "step:194 | loss/acc = 0.642/0.700\n",
      "step:195 | loss/acc = 0.717/0.450\n",
      "step:196 | loss/acc = 0.592/0.700\n",
      "step:197 | loss/acc = 0.609/0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:198 | loss/acc = 0.631/0.800\n",
      "step:199 | loss/acc = 0.658/0.550\n",
      "sentiment task:    199: [    0/    2], senti_loss/senti_acc = 0.63688825/0.6850000 \n",
      "step:200 | loss/acc = 0.669/0.600\n",
      "step:201 | loss/acc = 0.604/0.750\n",
      "step:202 | loss/acc = 0.628/0.750\n",
      "step:203 | loss/acc = 0.574/0.700\n",
      "step:204 | loss/acc = 0.590/0.700\n",
      "step:205 | loss/acc = 0.649/0.600\n",
      "step:206 | loss/acc = 0.694/0.450\n",
      "step:207 | loss/acc = 0.741/0.350\n",
      "step:208 | loss/acc = 0.583/0.750\n",
      "step:209 | loss/acc = 0.693/0.500\n",
      "sentiment task:    209: [    0/    2], senti_loss/senti_acc = 0.64253100/0.6150000 \n",
      "step:210 | loss/acc = 0.694/0.500\n",
      "step:211 | loss/acc = 0.580/0.750\n",
      "step:212 | loss/acc = 0.652/0.650\n",
      "step:213 | loss/acc = 0.713/0.500\n",
      "step:214 | loss/acc = 0.623/0.700\n",
      "step:215 | loss/acc = 0.646/0.650\n",
      "step:216 | loss/acc = 0.656/0.550\n",
      "step:217 | loss/acc = 0.611/0.800\n",
      "step:218 | loss/acc = 0.587/0.750\n",
      "step:219 | loss/acc = 0.642/0.750\n",
      "sentiment task:    219: [    0/    2], senti_loss/senti_acc = 0.64036837/0.6600000 \n",
      "step:220 | loss/acc = 0.582/0.750\n",
      "step:221 | loss/acc = 0.649/0.600\n",
      "step:222 | loss/acc = 0.569/0.900\n",
      "step:223 | loss/acc = 0.700/0.550\n",
      "step:224 | loss/acc = 0.598/0.800\n",
      "step:225 | loss/acc = 0.597/0.700\n",
      "step:226 | loss/acc = 0.668/0.550\n",
      "step:227 | loss/acc = 0.662/0.650\n",
      "step:228 | loss/acc = 0.624/0.700\n",
      "step:229 | loss/acc = 0.604/0.650\n",
      "sentiment task:    229: [    0/    2], senti_loss/senti_acc = 0.62530499/0.6850000 \n",
      "step:230 | loss/acc = 0.663/0.600\n",
      "step:231 | loss/acc = 0.571/0.800\n",
      "step:232 | loss/acc = 0.611/0.700\n",
      "step:233 | loss/acc = 0.644/0.550\n",
      "step:234 | loss/acc = 0.653/0.700\n",
      "step:235 | loss/acc = 0.598/0.700\n",
      "step:236 | loss/acc = 0.585/0.700\n",
      "step:237 | loss/acc = 0.619/0.600\n",
      "step:238 | loss/acc = 0.642/0.600\n",
      "step:239 | loss/acc = 0.631/0.650\n",
      "sentiment task:    239: [    0/    2], senti_loss/senti_acc = 0.62162771/0.6600000 \n",
      "step:240 | loss/acc = 0.579/0.700\n",
      "step:241 | loss/acc = 0.663/0.650\n",
      "step:242 | loss/acc = 0.660/0.600\n",
      "step:243 | loss/acc = 0.698/0.550\n",
      "step:244 | loss/acc = 0.604/0.750\n",
      "step:245 | loss/acc = 0.558/0.900\n",
      "step:246 | loss/acc = 0.651/0.700\n",
      "step:247 | loss/acc = 0.541/0.950\n",
      "step:248 | loss/acc = 0.618/0.800\n",
      "step:249 | loss/acc = 0.623/0.650\n",
      "sentiment task:    249: [    0/    2], senti_loss/senti_acc = 0.61942162/0.7250000 \n",
      "step:250 | loss/acc = 0.588/0.900\n",
      "step:251 | loss/acc = 0.590/0.750\n",
      "step:252 | loss/acc = 0.586/0.750\n",
      "step:253 | loss/acc = 0.620/0.650\n",
      "step:254 | loss/acc = 0.565/0.750\n",
      "step:255 | loss/acc = 0.616/0.750\n",
      "step:256 | loss/acc = 0.554/0.800\n",
      "step:257 | loss/acc = 0.589/0.750\n",
      "step:258 | loss/acc = 0.667/0.700\n",
      "step:259 | loss/acc = 0.618/0.700\n",
      "sentiment task:    259: [    0/    2], senti_loss/senti_acc = 0.59935344/0.7500000 \n",
      "step:260 | loss/acc = 0.639/0.650\n",
      "step:261 | loss/acc = 0.663/0.600\n",
      "step:262 | loss/acc = 0.634/0.600\n",
      "step:263 | loss/acc = 0.596/0.700\n",
      "step:264 | loss/acc = 0.653/0.550\n",
      "step:265 | loss/acc = 0.599/0.550\n",
      "step:266 | loss/acc = 0.630/0.650\n",
      "step:267 | loss/acc = 0.579/0.700\n",
      "step:268 | loss/acc = 0.597/0.650\n",
      "step:269 | loss/acc = 0.605/0.700\n",
      "sentiment task:    269: [    0/    2], senti_loss/senti_acc = 0.61960433/0.6350000 \n",
      "step:270 | loss/acc = 0.612/0.800\n",
      "step:271 | loss/acc = 0.588/0.750\n",
      "step:272 | loss/acc = 0.711/0.650\n",
      "step:273 | loss/acc = 0.704/0.650\n",
      "step:274 | loss/acc = 0.619/0.600\n",
      "step:275 | loss/acc = 0.638/0.600\n",
      "step:276 | loss/acc = 0.622/0.650\n",
      "step:277 | loss/acc = 0.572/0.750\n",
      "step:278 | loss/acc = 0.664/0.700\n",
      "step:279 | loss/acc = 0.569/0.800\n",
      "sentiment task:    279: [    0/    2], senti_loss/senti_acc = 0.62992389/0.6950000 \n",
      "step:280 | loss/acc = 0.578/0.750\n",
      "step:281 | loss/acc = 0.600/0.700\n",
      "step:282 | loss/acc = 0.644/0.650\n",
      "step:283 | loss/acc = 0.676/0.600\n",
      "step:284 | loss/acc = 0.626/0.700\n",
      "step:285 | loss/acc = 0.605/0.750\n",
      "step:286 | loss/acc = 0.562/0.800\n",
      "step:287 | loss/acc = 0.637/0.700\n",
      "step:288 | loss/acc = 0.698/0.500\n",
      "step:289 | loss/acc = 0.597/0.800\n",
      "sentiment task:    289: [    0/    2], senti_loss/senti_acc = 0.62239937/0.6950000 \n",
      "step:290 | loss/acc = 0.569/0.800\n",
      "step:291 | loss/acc = 0.640/0.650\n",
      "step:292 | loss/acc = 0.602/0.800\n",
      "step:293 | loss/acc = 0.672/0.450\n",
      "step:294 | loss/acc = 0.574/0.800\n",
      "step:295 | loss/acc = 0.624/0.600\n",
      "step:296 | loss/acc = 0.647/0.550\n",
      "step:297 | loss/acc = 0.485/0.850\n",
      "step:298 | loss/acc = 0.634/0.550\n",
      "step:299 | loss/acc = 0.628/0.700\n",
      "sentiment task:    299: [    0/    2], senti_loss/senti_acc = 0.60758414/0.6750000 \n",
      "step:300 | loss/acc = 0.604/0.750\n",
      "step:301 | loss/acc = 0.610/0.700\n",
      "step:302 | loss/acc = 0.582/0.750\n",
      "step:303 | loss/acc = 0.569/0.650\n",
      "step:304 | loss/acc = 0.530/0.800\n",
      "step:305 | loss/acc = 0.581/0.700\n",
      "step:306 | loss/acc = 0.539/0.800\n",
      "step:307 | loss/acc = 0.561/0.650\n",
      "step:308 | loss/acc = 0.646/0.500\n",
      "step:309 | loss/acc = 0.624/0.700\n",
      "sentiment task:    309: [    0/    2], senti_loss/senti_acc = 0.58453255/0.7000000 \n",
      "step:310 | loss/acc = 0.608/0.700\n",
      "step:311 | loss/acc = 0.590/0.700\n",
      "step:312 | loss/acc = 0.513/0.750\n",
      "step:313 | loss/acc = 0.654/0.650\n",
      "step:314 | loss/acc = 0.606/0.700\n",
      "step:315 | loss/acc = 0.689/0.500\n",
      "step:316 | loss/acc = 0.592/0.750\n",
      "step:317 | loss/acc = 0.639/0.600\n",
      "step:318 | loss/acc = 0.522/0.750\n",
      "step:319 | loss/acc = 0.590/0.700\n",
      "sentiment task:    319: [    0/    2], senti_loss/senti_acc = 0.60020403/0.6800000 \n",
      "step:320 | loss/acc = 0.522/0.750\n",
      "step:321 | loss/acc = 0.684/0.500\n",
      "step:322 | loss/acc = 0.635/0.750\n",
      "step:323 | loss/acc = 0.539/0.750\n",
      "step:324 | loss/acc = 0.526/0.750\n",
      "step:325 | loss/acc = 0.672/0.550\n",
      "step:326 | loss/acc = 0.467/0.850\n",
      "step:327 | loss/acc = 0.655/0.600\n",
      "step:328 | loss/acc = 0.726/0.450\n",
      "step:329 | loss/acc = 0.613/0.700\n",
      "sentiment task:    329: [    0/    2], senti_loss/senti_acc = 0.60393503/0.6650000 \n",
      "step:330 | loss/acc = 0.652/0.650\n",
      "step:331 | loss/acc = 0.772/0.300\n",
      "step:332 | loss/acc = 0.634/0.600\n",
      "step:333 | loss/acc = 0.683/0.650\n",
      "step:334 | loss/acc = 0.578/0.650\n",
      "step:335 | loss/acc = 0.565/0.800\n",
      "step:336 | loss/acc = 0.561/0.800\n",
      "step:337 | loss/acc = 0.698/0.550\n",
      "step:338 | loss/acc = 0.498/0.850\n",
      "step:339 | loss/acc = 0.622/0.700\n",
      "sentiment task:    339: [    0/    2], senti_loss/senti_acc = 0.62613977/0.6550000 \n",
      "step:340 | loss/acc = 0.630/0.650\n",
      "step:341 | loss/acc = 0.594/0.650\n",
      "step:342 | loss/acc = 0.618/0.650\n",
      "step:343 | loss/acc = 0.502/0.900\n",
      "step:344 | loss/acc = 0.659/0.600\n",
      "step:345 | loss/acc = 0.666/0.550\n",
      "step:346 | loss/acc = 0.661/0.500\n",
      "step:347 | loss/acc = 0.540/0.900\n",
      "step:348 | loss/acc = 0.619/0.650\n",
      "step:349 | loss/acc = 0.581/0.800\n",
      "sentiment task:    349: [    0/    2], senti_loss/senti_acc = 0.60689710/0.6850000 \n",
      "step:350 | loss/acc = 0.542/0.750\n",
      "step:351 | loss/acc = 0.520/0.800\n",
      "step:352 | loss/acc = 0.603/0.750\n",
      "step:353 | loss/acc = 0.575/0.700\n",
      "step:354 | loss/acc = 0.614/0.750\n",
      "step:355 | loss/acc = 0.581/0.700\n",
      "step:356 | loss/acc = 0.565/0.700\n",
      "step:357 | loss/acc = 0.677/0.600\n",
      "step:358 | loss/acc = 0.581/0.750\n",
      "step:359 | loss/acc = 0.567/0.750\n",
      "sentiment task:    359: [    0/    2], senti_loss/senti_acc = 0.58260485/0.7250000 \n",
      "step:360 | loss/acc = 0.596/0.700\n",
      "step:361 | loss/acc = 0.569/0.750\n",
      "step:362 | loss/acc = 0.614/0.650\n",
      "step:363 | loss/acc = 0.582/0.750\n",
      "step:364 | loss/acc = 0.648/0.600\n",
      "step:365 | loss/acc = 0.572/0.700\n",
      "step:366 | loss/acc = 0.444/1.000\n",
      "step:367 | loss/acc = 0.643/0.550\n",
      "step:368 | loss/acc = 0.585/0.750\n",
      "step:369 | loss/acc = 0.523/0.800\n",
      "sentiment task:    369: [    0/    2], senti_loss/senti_acc = 0.57759149/0.7250000 \n",
      "step:370 | loss/acc = 0.617/0.700\n",
      "step:371 | loss/acc = 0.666/0.650\n",
      "step:372 | loss/acc = 0.590/0.650\n",
      "step:373 | loss/acc = 0.583/0.550\n",
      "step:374 | loss/acc = 0.594/0.750\n",
      "step:375 | loss/acc = 0.651/0.650\n",
      "step:376 | loss/acc = 0.635/0.650\n",
      "step:377 | loss/acc = 0.582/0.750\n",
      "step:378 | loss/acc = 0.503/0.850\n",
      "step:379 | loss/acc = 0.680/0.550\n",
      "sentiment task:    379: [    0/    2], senti_loss/senti_acc = 0.61008813/0.6750000 \n",
      "step:380 | loss/acc = 0.592/0.750\n",
      "step:381 | loss/acc = 0.567/0.700\n",
      "step:382 | loss/acc = 0.582/0.700\n",
      "step:383 | loss/acc = 0.512/0.800\n",
      "step:384 | loss/acc = 0.536/0.850\n",
      "step:385 | loss/acc = 0.596/0.700\n",
      "step:386 | loss/acc = 0.650/0.650\n",
      "step:387 | loss/acc = 0.584/0.650\n",
      "step:388 | loss/acc = 0.512/0.800\n",
      "step:389 | loss/acc = 0.583/0.700\n",
      "sentiment task:    389: [    0/    2], senti_loss/senti_acc = 0.57155668/0.7300000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:390 | loss/acc = 0.598/0.750\n",
      "step:391 | loss/acc = 0.631/0.600\n",
      "step:392 | loss/acc = 0.542/0.800\n",
      "step:393 | loss/acc = 0.530/0.850\n",
      "step:394 | loss/acc = 0.581/0.650\n",
      "step:395 | loss/acc = 0.700/0.550\n",
      "step:396 | loss/acc = 0.587/0.650\n",
      "step:397 | loss/acc = 0.513/0.700\n",
      "step:398 | loss/acc = 0.500/0.950\n",
      "step:399 | loss/acc = 0.460/0.850\n",
      "sentiment task:    399: [    0/    2], senti_loss/senti_acc = 0.56433112/0.7350000 \n",
      "step:400 | loss/acc = 0.535/0.800\n",
      "step:401 | loss/acc = 0.685/0.650\n",
      "step:402 | loss/acc = 0.519/0.850\n",
      "step:403 | loss/acc = 0.617/0.600\n",
      "step:404 | loss/acc = 0.568/0.750\n",
      "step:405 | loss/acc = 0.519/0.800\n",
      "step:406 | loss/acc = 0.526/0.800\n",
      "step:407 | loss/acc = 0.635/0.700\n",
      "step:408 | loss/acc = 0.602/0.750\n",
      "step:409 | loss/acc = 0.560/0.750\n",
      "sentiment task:    409: [    0/    2], senti_loss/senti_acc = 0.57669491/0.7450000 \n",
      "step:410 | loss/acc = 0.550/0.800\n",
      "step:411 | loss/acc = 0.567/0.750\n",
      "step:412 | loss/acc = 0.425/0.950\n",
      "step:413 | loss/acc = 0.654/0.550\n",
      "step:414 | loss/acc = 0.630/0.700\n",
      "step:415 | loss/acc = 0.632/0.650\n",
      "step:416 | loss/acc = 0.655/0.550\n",
      "step:417 | loss/acc = 0.557/0.700\n",
      "step:418 | loss/acc = 0.662/0.700\n",
      "step:419 | loss/acc = 0.475/0.900\n",
      "sentiment task:    419: [    0/    2], senti_loss/senti_acc = 0.58076472/0.7250000 \n",
      "step:420 | loss/acc = 0.539/0.800\n",
      "step:421 | loss/acc = 0.680/0.600\n",
      "step:422 | loss/acc = 0.640/0.700\n",
      "step:423 | loss/acc = 0.646/0.750\n",
      "step:424 | loss/acc = 0.571/0.700\n",
      "step:425 | loss/acc = 0.551/0.850\n",
      "step:426 | loss/acc = 0.655/0.750\n",
      "step:427 | loss/acc = 0.505/0.850\n",
      "step:428 | loss/acc = 0.516/0.700\n",
      "step:429 | loss/acc = 0.495/0.950\n",
      "sentiment task:    429: [    0/    2], senti_loss/senti_acc = 0.57988136/0.7650000 \n",
      "step:430 | loss/acc = 0.518/0.800\n",
      "step:431 | loss/acc = 0.552/0.800\n",
      "step:432 | loss/acc = 0.569/0.800\n",
      "step:433 | loss/acc = 0.554/0.750\n",
      "step:434 | loss/acc = 0.517/0.750\n",
      "step:435 | loss/acc = 0.526/0.850\n",
      "step:436 | loss/acc = 0.536/0.800\n",
      "step:437 | loss/acc = 0.608/0.700\n",
      "step:438 | loss/acc = 0.610/0.650\n",
      "step:439 | loss/acc = 0.558/0.800\n",
      "sentiment task:    439: [    0/    2], senti_loss/senti_acc = 0.55475162/0.7700000 \n",
      "step:440 | loss/acc = 0.544/0.800\n",
      "step:441 | loss/acc = 0.539/0.750\n",
      "step:442 | loss/acc = 0.510/0.850\n",
      "step:443 | loss/acc = 0.537/0.650\n",
      "step:444 | loss/acc = 0.639/0.700\n",
      "step:445 | loss/acc = 0.564/0.700\n",
      "step:446 | loss/acc = 0.594/0.600\n",
      "step:447 | loss/acc = 0.481/0.850\n",
      "step:448 | loss/acc = 0.584/0.750\n",
      "step:449 | loss/acc = 0.583/0.600\n",
      "sentiment task:    449: [    0/    2], senti_loss/senti_acc = 0.55742238/0.7250000 \n",
      "step:450 | loss/acc = 0.588/0.800\n",
      "step:451 | loss/acc = 0.603/0.700\n",
      "step:452 | loss/acc = 0.518/0.850\n",
      "step:453 | loss/acc = 0.594/0.800\n",
      "step:454 | loss/acc = 0.609/0.550\n",
      "step:455 | loss/acc = 0.424/0.950\n",
      "step:456 | loss/acc = 0.544/0.750\n",
      "step:457 | loss/acc = 0.568/0.650\n",
      "step:458 | loss/acc = 0.616/0.700\n",
      "step:459 | loss/acc = 0.564/0.700\n",
      "sentiment task:    459: [    0/    2], senti_loss/senti_acc = 0.56277716/0.7450000 \n",
      "step:460 | loss/acc = 0.540/0.700\n",
      "step:461 | loss/acc = 0.672/0.550\n",
      "step:462 | loss/acc = 0.677/0.650\n",
      "step:463 | loss/acc = 0.554/0.650\n",
      "step:464 | loss/acc = 0.544/0.800\n",
      "step:465 | loss/acc = 0.659/0.600\n",
      "step:466 | loss/acc = 0.555/0.750\n",
      "step:467 | loss/acc = 0.656/0.550\n",
      "step:468 | loss/acc = 0.756/0.400\n",
      "step:469 | loss/acc = 0.516/0.800\n",
      "sentiment task:    469: [    0/    2], senti_loss/senti_acc = 0.61279161/0.6450000 \n",
      "step:470 | loss/acc = 0.528/0.850\n",
      "step:471 | loss/acc = 0.581/0.650\n",
      "step:472 | loss/acc = 0.501/0.850\n",
      "step:473 | loss/acc = 0.588/0.700\n",
      "step:474 | loss/acc = 0.476/0.850\n",
      "step:475 | loss/acc = 0.519/0.850\n",
      "step:476 | loss/acc = 0.555/0.750\n",
      "step:477 | loss/acc = 0.557/0.750\n",
      "step:478 | loss/acc = 0.542/0.800\n",
      "step:479 | loss/acc = 0.519/0.850\n",
      "sentiment task:    479: [    0/    2], senti_loss/senti_acc = 0.53662301/0.7900000 \n",
      "step:480 | loss/acc = 0.501/0.800\n",
      "step:481 | loss/acc = 0.607/0.650\n",
      "step:482 | loss/acc = 0.635/0.600\n",
      "step:483 | loss/acc = 0.590/0.750\n",
      "step:484 | loss/acc = 0.646/0.600\n",
      "step:485 | loss/acc = 0.543/0.700\n",
      "step:486 | loss/acc = 0.582/0.650\n",
      "step:487 | loss/acc = 0.581/0.700\n",
      "step:488 | loss/acc = 0.664/0.600\n",
      "step:489 | loss/acc = 0.531/0.700\n",
      "sentiment task:    489: [    0/    2], senti_loss/senti_acc = 0.58816370/0.6750000 \n",
      "step:490 | loss/acc = 0.477/0.750\n",
      "step:491 | loss/acc = 0.667/0.600\n",
      "step:492 | loss/acc = 0.575/0.700\n",
      "step:493 | loss/acc = 0.657/0.550\n",
      "step:494 | loss/acc = 0.531/0.750\n",
      "step:495 | loss/acc = 0.515/0.700\n",
      "step:496 | loss/acc = 0.639/0.650\n",
      "step:497 | loss/acc = 0.640/0.600\n",
      "step:498 | loss/acc = 0.653/0.550\n",
      "step:499 | loss/acc = 0.451/0.900\n",
      "sentiment task:    499: [    0/    2], senti_loss/senti_acc = 0.58035262/0.6750000 \n",
      "step:0 | loss/acc = 0.395/0.950\n",
      "step:1 | loss/acc = 0.547/0.800\n",
      "step:2 | loss/acc = 0.505/0.700\n",
      "step:3 | loss/acc = 0.548/0.700\n",
      "step:4 | loss/acc = 0.504/0.800\n",
      "step:5 | loss/acc = 0.565/0.700\n",
      "step:6 | loss/acc = 0.508/0.700\n",
      "step:7 | loss/acc = 0.501/0.800\n",
      "step:8 | loss/acc = 0.511/0.750\n",
      "step:9 | loss/acc = 0.476/1.000\n",
      "sentiment task:      9: [    1/    2], senti_loss/senti_acc = 0.50611392/0.7900000 \n",
      "step:10 | loss/acc = 0.522/0.650\n",
      "step:11 | loss/acc = 0.556/0.750\n",
      "step:12 | loss/acc = 0.554/0.750\n",
      "step:13 | loss/acc = 0.484/0.800\n",
      "step:14 | loss/acc = 0.518/0.800\n",
      "step:15 | loss/acc = 0.556/0.600\n",
      "step:16 | loss/acc = 0.566/0.800\n",
      "step:17 | loss/acc = 0.484/0.800\n",
      "step:18 | loss/acc = 0.537/0.750\n",
      "step:19 | loss/acc = 0.480/0.900\n",
      "sentiment task:     19: [    1/    2], senti_loss/senti_acc = 0.52584083/0.7600000 \n",
      "step:20 | loss/acc = 0.532/0.650\n",
      "step:21 | loss/acc = 0.677/0.500\n",
      "step:22 | loss/acc = 0.540/0.800\n",
      "step:23 | loss/acc = 0.543/0.750\n",
      "step:24 | loss/acc = 0.497/0.700\n",
      "step:25 | loss/acc = 0.504/0.800\n",
      "step:26 | loss/acc = 0.424/0.900\n",
      "step:27 | loss/acc = 0.529/0.750\n",
      "step:28 | loss/acc = 0.594/0.750\n",
      "step:29 | loss/acc = 0.564/0.650\n",
      "sentiment task:     29: [    1/    2], senti_loss/senti_acc = 0.54027544/0.7250000 \n",
      "step:30 | loss/acc = 0.429/0.800\n",
      "step:31 | loss/acc = 0.478/0.700\n",
      "step:32 | loss/acc = 0.449/0.800\n",
      "step:33 | loss/acc = 0.421/0.850\n",
      "step:34 | loss/acc = 0.533/0.700\n",
      "step:35 | loss/acc = 0.575/0.750\n",
      "step:36 | loss/acc = 0.404/0.900\n",
      "step:37 | loss/acc = 0.486/0.850\n",
      "step:38 | loss/acc = 0.428/0.800\n",
      "step:39 | loss/acc = 0.655/0.600\n",
      "sentiment task:     39: [    1/    2], senti_loss/senti_acc = 0.48559452/0.7750000 \n",
      "step:40 | loss/acc = 0.448/0.850\n",
      "step:41 | loss/acc = 0.587/0.700\n",
      "step:42 | loss/acc = 0.484/0.750\n",
      "step:43 | loss/acc = 0.441/0.850\n",
      "step:44 | loss/acc = 0.565/0.700\n",
      "step:45 | loss/acc = 0.485/0.900\n",
      "step:46 | loss/acc = 0.548/0.750\n",
      "step:47 | loss/acc = 0.394/0.850\n",
      "step:48 | loss/acc = 0.533/0.700\n",
      "step:49 | loss/acc = 0.603/0.650\n",
      "sentiment task:     49: [    1/    2], senti_loss/senti_acc = 0.50874760/0.7700000 \n",
      "step:50 | loss/acc = 0.572/0.750\n",
      "step:51 | loss/acc = 0.385/0.950\n",
      "step:52 | loss/acc = 0.426/0.950\n",
      "step:53 | loss/acc = 0.576/0.700\n",
      "step:54 | loss/acc = 0.518/0.800\n",
      "step:55 | loss/acc = 0.593/0.750\n",
      "step:56 | loss/acc = 0.516/0.750\n",
      "step:57 | loss/acc = 0.553/0.700\n",
      "step:58 | loss/acc = 0.563/0.650\n",
      "step:59 | loss/acc = 0.742/0.650\n",
      "sentiment task:     59: [    1/    2], senti_loss/senti_acc = 0.54435040/0.7650000 \n",
      "step:60 | loss/acc = 0.434/0.900\n",
      "step:61 | loss/acc = 0.544/0.750\n",
      "step:62 | loss/acc = 0.490/0.800\n",
      "step:63 | loss/acc = 0.532/0.650\n",
      "step:64 | loss/acc = 0.510/0.700\n",
      "step:65 | loss/acc = 0.507/0.800\n",
      "step:66 | loss/acc = 0.411/0.900\n",
      "step:67 | loss/acc = 0.514/0.800\n",
      "step:68 | loss/acc = 0.455/0.850\n",
      "step:69 | loss/acc = 0.598/0.650\n",
      "sentiment task:     69: [    1/    2], senti_loss/senti_acc = 0.49958685/0.7800000 \n",
      "step:70 | loss/acc = 0.463/0.750\n",
      "step:71 | loss/acc = 0.416/0.850\n",
      "step:72 | loss/acc = 0.528/0.750\n",
      "step:73 | loss/acc = 0.621/0.700\n",
      "step:74 | loss/acc = 0.490/0.850\n",
      "step:75 | loss/acc = 0.439/0.850\n",
      "step:76 | loss/acc = 0.456/0.850\n",
      "step:77 | loss/acc = 0.378/0.900\n",
      "step:78 | loss/acc = 0.567/0.650\n",
      "step:79 | loss/acc = 0.660/0.550\n",
      "sentiment task:     79: [    1/    2], senti_loss/senti_acc = 0.50181257/0.7700000 \n",
      "step:80 | loss/acc = 0.573/0.850\n",
      "step:81 | loss/acc = 0.509/0.800\n",
      "step:82 | loss/acc = 0.453/0.850\n",
      "step:83 | loss/acc = 0.645/0.550\n",
      "step:84 | loss/acc = 0.414/0.750\n",
      "step:85 | loss/acc = 0.524/0.750\n",
      "step:86 | loss/acc = 0.395/0.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:87 | loss/acc = 0.577/0.800\n",
      "step:88 | loss/acc = 0.486/0.800\n",
      "step:89 | loss/acc = 0.461/0.750\n",
      "sentiment task:     89: [    1/    2], senti_loss/senti_acc = 0.50369355/0.7850000 \n",
      "step:90 | loss/acc = 0.435/0.900\n",
      "step:91 | loss/acc = 0.541/0.750\n",
      "step:92 | loss/acc = 0.382/0.950\n",
      "step:93 | loss/acc = 0.541/0.800\n",
      "step:94 | loss/acc = 0.497/0.850\n",
      "step:95 | loss/acc = 0.339/0.900\n",
      "step:96 | loss/acc = 0.543/0.850\n",
      "step:97 | loss/acc = 0.487/0.750\n",
      "step:98 | loss/acc = 0.602/0.650\n",
      "step:99 | loss/acc = 0.579/0.700\n",
      "sentiment task:     99: [    1/    2], senti_loss/senti_acc = 0.49462225/0.8100000 \n",
      "step:100 | loss/acc = 0.532/0.650\n",
      "step:101 | loss/acc = 0.578/0.700\n",
      "step:102 | loss/acc = 0.443/0.800\n",
      "step:103 | loss/acc = 0.563/0.750\n",
      "step:104 | loss/acc = 0.427/0.800\n",
      "step:105 | loss/acc = 0.509/0.750\n",
      "step:106 | loss/acc = 0.638/0.650\n",
      "step:107 | loss/acc = 0.469/0.750\n",
      "step:108 | loss/acc = 0.514/0.700\n",
      "step:109 | loss/acc = 0.451/0.900\n",
      "sentiment task:    109: [    1/    2], senti_loss/senti_acc = 0.51252159/0.7450000 \n",
      "step:110 | loss/acc = 0.484/0.900\n",
      "step:111 | loss/acc = 0.526/0.750\n",
      "step:112 | loss/acc = 0.592/0.650\n",
      "step:113 | loss/acc = 0.580/0.600\n",
      "step:114 | loss/acc = 0.561/0.650\n",
      "step:115 | loss/acc = 0.462/0.850\n",
      "step:116 | loss/acc = 0.495/0.750\n",
      "step:117 | loss/acc = 0.652/0.600\n",
      "step:118 | loss/acc = 0.588/0.750\n",
      "step:119 | loss/acc = 0.378/0.950\n",
      "sentiment task:    119: [    1/    2], senti_loss/senti_acc = 0.53177448/0.7450000 \n",
      "step:120 | loss/acc = 0.584/0.750\n",
      "step:121 | loss/acc = 0.600/0.650\n",
      "step:122 | loss/acc = 0.581/0.600\n",
      "step:123 | loss/acc = 0.475/0.800\n",
      "step:124 | loss/acc = 0.549/0.600\n",
      "step:125 | loss/acc = 0.537/0.750\n",
      "step:126 | loss/acc = 0.517/0.800\n",
      "step:127 | loss/acc = 0.693/0.450\n",
      "step:128 | loss/acc = 0.504/0.800\n",
      "step:129 | loss/acc = 0.456/0.900\n",
      "sentiment task:    129: [    1/    2], senti_loss/senti_acc = 0.54944409/0.7100000 \n",
      "step:130 | loss/acc = 0.402/0.900\n",
      "step:131 | loss/acc = 0.697/0.650\n",
      "step:132 | loss/acc = 0.418/0.800\n",
      "step:133 | loss/acc = 0.567/0.700\n",
      "step:134 | loss/acc = 0.391/0.900\n",
      "step:135 | loss/acc = 0.610/0.600\n",
      "step:136 | loss/acc = 0.436/0.800\n",
      "step:137 | loss/acc = 0.565/0.700\n",
      "step:138 | loss/acc = 0.486/0.750\n",
      "step:139 | loss/acc = 0.627/0.500\n",
      "sentiment task:    139: [    1/    2], senti_loss/senti_acc = 0.52002162/0.7300000 \n",
      "step:140 | loss/acc = 0.457/0.800\n",
      "step:141 | loss/acc = 0.452/0.800\n",
      "step:142 | loss/acc = 0.475/0.800\n",
      "step:143 | loss/acc = 0.525/0.700\n",
      "step:144 | loss/acc = 0.571/0.650\n",
      "step:145 | loss/acc = 0.599/0.700\n",
      "step:146 | loss/acc = 0.386/0.900\n",
      "step:147 | loss/acc = 0.455/0.800\n",
      "step:148 | loss/acc = 0.447/0.800\n",
      "step:149 | loss/acc = 0.513/0.750\n",
      "sentiment task:    149: [    1/    2], senti_loss/senti_acc = 0.48805252/0.7700000 \n",
      "step:150 | loss/acc = 0.595/0.750\n",
      "step:151 | loss/acc = 0.571/0.600\n",
      "step:152 | loss/acc = 0.609/0.750\n",
      "step:153 | loss/acc = 0.320/1.000\n",
      "step:154 | loss/acc = 0.544/0.800\n",
      "step:155 | loss/acc = 0.559/0.700\n",
      "step:156 | loss/acc = 0.556/0.650\n",
      "step:157 | loss/acc = 0.702/0.450\n",
      "step:158 | loss/acc = 0.394/0.900\n",
      "step:159 | loss/acc = 0.403/0.850\n",
      "sentiment task:    159: [    1/    2], senti_loss/senti_acc = 0.52544697/0.7450000 \n",
      "step:160 | loss/acc = 0.508/0.700\n",
      "step:161 | loss/acc = 0.413/0.850\n",
      "step:162 | loss/acc = 0.392/0.850\n",
      "step:163 | loss/acc = 0.619/0.700\n",
      "step:164 | loss/acc = 0.488/0.850\n",
      "step:165 | loss/acc = 0.451/0.800\n",
      "step:166 | loss/acc = 0.595/0.650\n",
      "step:167 | loss/acc = 0.585/0.700\n",
      "step:168 | loss/acc = 0.458/0.900\n",
      "step:169 | loss/acc = 0.428/0.850\n",
      "sentiment task:    169: [    1/    2], senti_loss/senti_acc = 0.49363675/0.7850000 \n",
      "step:170 | loss/acc = 0.642/0.650\n",
      "step:171 | loss/acc = 0.485/0.750\n",
      "step:172 | loss/acc = 0.590/0.750\n",
      "step:173 | loss/acc = 0.430/0.800\n",
      "step:174 | loss/acc = 0.731/0.600\n",
      "step:175 | loss/acc = 0.631/0.650\n",
      "step:176 | loss/acc = 0.352/0.900\n",
      "step:177 | loss/acc = 0.556/0.650\n",
      "step:178 | loss/acc = 0.436/0.800\n",
      "step:179 | loss/acc = 0.553/0.650\n",
      "sentiment task:    179: [    1/    2], senti_loss/senti_acc = 0.54065861/0.7200000 \n",
      "step:180 | loss/acc = 0.649/0.650\n",
      "step:181 | loss/acc = 0.517/0.800\n",
      "step:182 | loss/acc = 0.625/0.700\n",
      "step:183 | loss/acc = 0.408/0.800\n",
      "step:184 | loss/acc = 0.388/0.800\n",
      "step:185 | loss/acc = 0.443/0.850\n",
      "step:186 | loss/acc = 0.522/0.750\n",
      "step:187 | loss/acc = 0.382/0.950\n",
      "step:188 | loss/acc = 0.449/0.800\n",
      "step:189 | loss/acc = 0.456/0.750\n",
      "sentiment task:    189: [    1/    2], senti_loss/senti_acc = 0.48376382/0.7850000 \n",
      "step:190 | loss/acc = 0.637/0.600\n",
      "step:191 | loss/acc = 0.494/0.750\n",
      "step:192 | loss/acc = 0.451/0.800\n",
      "step:193 | loss/acc = 0.371/0.850\n",
      "step:194 | loss/acc = 0.545/0.800\n",
      "step:195 | loss/acc = 0.666/0.650\n",
      "step:196 | loss/acc = 0.422/0.800\n",
      "step:197 | loss/acc = 0.472/0.800\n",
      "step:198 | loss/acc = 0.411/0.900\n",
      "step:199 | loss/acc = 0.617/0.650\n",
      "sentiment task:    199: [    1/    2], senti_loss/senti_acc = 0.50858013/0.7600000 \n",
      "step:200 | loss/acc = 0.629/0.650\n",
      "step:201 | loss/acc = 0.449/0.900\n",
      "step:202 | loss/acc = 0.526/0.650\n",
      "step:203 | loss/acc = 0.361/0.950\n",
      "step:204 | loss/acc = 0.427/0.800\n",
      "step:205 | loss/acc = 0.541/0.700\n",
      "step:206 | loss/acc = 0.551/0.650\n",
      "step:207 | loss/acc = 0.735/0.700\n",
      "step:208 | loss/acc = 0.393/0.900\n",
      "step:209 | loss/acc = 0.622/0.550\n",
      "sentiment task:    209: [    1/    2], senti_loss/senti_acc = 0.52336217/0.7450000 \n",
      "step:210 | loss/acc = 0.663/0.600\n",
      "step:211 | loss/acc = 0.415/0.750\n",
      "step:212 | loss/acc = 0.454/0.750\n",
      "step:213 | loss/acc = 0.706/0.500\n",
      "step:214 | loss/acc = 0.603/0.750\n",
      "step:215 | loss/acc = 0.504/0.650\n",
      "step:216 | loss/acc = 0.543/0.700\n",
      "step:217 | loss/acc = 0.404/0.900\n",
      "step:218 | loss/acc = 0.481/0.700\n",
      "step:219 | loss/acc = 0.642/0.650\n",
      "sentiment task:    219: [    1/    2], senti_loss/senti_acc = 0.54156584/0.6950000 \n",
      "step:220 | loss/acc = 0.445/0.800\n",
      "step:221 | loss/acc = 0.447/0.750\n",
      "step:222 | loss/acc = 0.347/0.850\n",
      "step:223 | loss/acc = 0.683/0.650\n",
      "step:224 | loss/acc = 0.377/0.950\n",
      "step:225 | loss/acc = 0.434/0.750\n",
      "step:226 | loss/acc = 0.553/0.550\n",
      "step:227 | loss/acc = 0.639/0.600\n",
      "step:228 | loss/acc = 0.576/0.750\n",
      "step:229 | loss/acc = 0.403/0.700\n",
      "sentiment task:    229: [    1/    2], senti_loss/senti_acc = 0.49027191/0.7350000 \n",
      "step:230 | loss/acc = 0.547/0.750\n",
      "step:231 | loss/acc = 0.389/0.900\n",
      "step:232 | loss/acc = 0.413/0.850\n",
      "step:233 | loss/acc = 0.399/0.850\n",
      "step:234 | loss/acc = 0.470/0.800\n",
      "step:235 | loss/acc = 0.377/1.000\n",
      "step:236 | loss/acc = 0.460/0.700\n",
      "step:237 | loss/acc = 0.515/0.750\n",
      "step:238 | loss/acc = 0.556/0.700\n",
      "step:239 | loss/acc = 0.560/0.700\n",
      "sentiment task:    239: [    1/    2], senti_loss/senti_acc = 0.46867401/0.8000000 \n",
      "step:240 | loss/acc = 0.385/0.850\n",
      "step:241 | loss/acc = 0.468/0.700\n",
      "step:242 | loss/acc = 0.548/0.650\n",
      "step:243 | loss/acc = 0.665/0.650\n",
      "step:244 | loss/acc = 0.458/0.750\n",
      "step:245 | loss/acc = 0.330/0.900\n",
      "step:246 | loss/acc = 0.528/0.750\n",
      "step:247 | loss/acc = 0.240/1.000\n",
      "step:248 | loss/acc = 0.473/0.750\n",
      "step:249 | loss/acc = 0.469/0.750\n",
      "sentiment task:    249: [    1/    2], senti_loss/senti_acc = 0.45619712/0.7750000 \n",
      "step:250 | loss/acc = 0.491/0.800\n",
      "step:251 | loss/acc = 0.457/0.750\n",
      "step:252 | loss/acc = 0.321/0.900\n",
      "step:253 | loss/acc = 0.484/0.800\n",
      "step:254 | loss/acc = 0.356/0.850\n",
      "step:255 | loss/acc = 0.464/0.800\n",
      "step:256 | loss/acc = 0.469/0.750\n",
      "step:257 | loss/acc = 0.423/0.900\n",
      "step:258 | loss/acc = 0.444/0.850\n",
      "step:259 | loss/acc = 0.369/0.900\n",
      "sentiment task:    259: [    1/    2], senti_loss/senti_acc = 0.42771809/0.8300000 \n",
      "step:260 | loss/acc = 0.464/0.750\n",
      "step:261 | loss/acc = 0.429/0.800\n",
      "step:262 | loss/acc = 0.425/0.800\n",
      "step:263 | loss/acc = 0.356/0.900\n",
      "step:264 | loss/acc = 0.475/0.800\n",
      "step:265 | loss/acc = 0.527/0.650\n",
      "step:266 | loss/acc = 0.564/0.800\n",
      "step:267 | loss/acc = 0.437/0.800\n",
      "step:268 | loss/acc = 0.498/0.700\n",
      "step:269 | loss/acc = 0.387/0.900\n",
      "sentiment task:    269: [    1/    2], senti_loss/senti_acc = 0.45610586/0.7900000 \n",
      "step:270 | loss/acc = 0.488/0.750\n",
      "step:271 | loss/acc = 0.468/0.800\n",
      "step:272 | loss/acc = 0.662/0.750\n",
      "step:273 | loss/acc = 0.661/0.650\n",
      "step:274 | loss/acc = 0.624/0.650\n",
      "step:275 | loss/acc = 0.470/0.750\n",
      "step:276 | loss/acc = 0.588/0.700\n",
      "step:277 | loss/acc = 0.485/0.850\n",
      "step:278 | loss/acc = 0.537/0.800\n",
      "step:279 | loss/acc = 0.350/0.850\n",
      "sentiment task:    279: [    1/    2], senti_loss/senti_acc = 0.53338426/0.7550000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:280 | loss/acc = 0.385/0.850\n",
      "step:281 | loss/acc = 0.461/0.750\n",
      "step:282 | loss/acc = 0.591/0.600\n",
      "step:283 | loss/acc = 0.672/0.650\n",
      "step:284 | loss/acc = 0.457/0.850\n",
      "step:285 | loss/acc = 0.438/0.700\n",
      "step:286 | loss/acc = 0.277/0.950\n",
      "step:287 | loss/acc = 0.541/0.750\n",
      "step:288 | loss/acc = 0.629/0.650\n",
      "step:289 | loss/acc = 0.381/0.900\n",
      "sentiment task:    289: [    1/    2], senti_loss/senti_acc = 0.48315102/0.7650000 \n",
      "step:290 | loss/acc = 0.478/0.800\n",
      "step:291 | loss/acc = 0.533/0.800\n",
      "step:292 | loss/acc = 0.385/0.850\n",
      "step:293 | loss/acc = 0.513/0.750\n",
      "step:294 | loss/acc = 0.352/0.850\n",
      "step:295 | loss/acc = 0.633/0.650\n",
      "step:296 | loss/acc = 0.531/0.800\n",
      "step:297 | loss/acc = 0.239/0.900\n",
      "step:298 | loss/acc = 0.531/0.700\n",
      "step:299 | loss/acc = 0.526/0.750\n",
      "sentiment task:    299: [    1/    2], senti_loss/senti_acc = 0.47205535/0.7850000 \n",
      "step:300 | loss/acc = 0.450/0.750\n",
      "step:301 | loss/acc = 0.520/0.700\n",
      "step:302 | loss/acc = 0.368/0.900\n",
      "step:303 | loss/acc = 0.356/0.900\n",
      "step:304 | loss/acc = 0.382/0.850\n",
      "step:305 | loss/acc = 0.538/0.750\n",
      "step:306 | loss/acc = 0.410/0.850\n",
      "step:307 | loss/acc = 0.452/0.750\n",
      "step:308 | loss/acc = 0.373/0.900\n",
      "step:309 | loss/acc = 0.492/0.700\n",
      "sentiment task:    309: [    1/    2], senti_loss/senti_acc = 0.43421607/0.8050000 \n",
      "step:310 | loss/acc = 0.434/0.700\n",
      "step:311 | loss/acc = 0.489/0.700\n",
      "step:312 | loss/acc = 0.272/0.950\n",
      "step:313 | loss/acc = 0.513/0.700\n",
      "step:314 | loss/acc = 0.536/0.750\n",
      "step:315 | loss/acc = 0.405/0.700\n",
      "step:316 | loss/acc = 0.526/0.750\n",
      "step:317 | loss/acc = 0.537/0.750\n",
      "step:318 | loss/acc = 0.331/0.900\n",
      "step:319 | loss/acc = 0.489/0.750\n",
      "sentiment task:    319: [    1/    2], senti_loss/senti_acc = 0.45318824/0.7650000 \n",
      "step:320 | loss/acc = 0.400/0.800\n",
      "step:321 | loss/acc = 0.389/0.850\n",
      "step:322 | loss/acc = 0.495/0.800\n",
      "step:323 | loss/acc = 0.329/0.900\n",
      "step:324 | loss/acc = 0.358/0.900\n",
      "step:325 | loss/acc = 0.528/0.750\n",
      "step:326 | loss/acc = 0.392/0.800\n",
      "step:327 | loss/acc = 0.556/0.700\n",
      "step:328 | loss/acc = 0.494/0.850\n",
      "step:329 | loss/acc = 0.469/0.750\n",
      "sentiment task:    329: [    1/    2], senti_loss/senti_acc = 0.44109525/0.8100000 \n",
      "step:330 | loss/acc = 0.471/0.800\n",
      "step:331 | loss/acc = 0.662/0.700\n",
      "step:332 | loss/acc = 0.551/0.700\n",
      "step:333 | loss/acc = 0.713/0.750\n",
      "step:334 | loss/acc = 0.361/0.750\n",
      "step:335 | loss/acc = 0.344/0.900\n",
      "step:336 | loss/acc = 0.369/0.850\n",
      "step:337 | loss/acc = 0.616/0.600\n",
      "step:338 | loss/acc = 0.354/0.950\n",
      "step:339 | loss/acc = 0.420/0.800\n",
      "sentiment task:    339: [    1/    2], senti_loss/senti_acc = 0.48617635/0.7800000 \n",
      "step:340 | loss/acc = 0.651/0.700\n",
      "step:341 | loss/acc = 0.384/0.900\n",
      "step:342 | loss/acc = 0.453/0.750\n",
      "step:343 | loss/acc = 0.325/0.850\n",
      "step:344 | loss/acc = 0.627/0.700\n",
      "step:345 | loss/acc = 0.692/0.550\n",
      "step:346 | loss/acc = 0.613/0.650\n",
      "step:347 | loss/acc = 0.336/0.950\n",
      "step:348 | loss/acc = 0.512/0.700\n",
      "step:349 | loss/acc = 0.475/0.750\n",
      "sentiment task:    349: [    1/    2], senti_loss/senti_acc = 0.50678683/0.7500000 \n",
      "step:350 | loss/acc = 0.445/0.700\n",
      "step:351 | loss/acc = 0.257/0.900\n",
      "step:352 | loss/acc = 0.442/0.800\n",
      "step:353 | loss/acc = 0.541/0.600\n",
      "step:354 | loss/acc = 0.358/0.900\n",
      "step:355 | loss/acc = 0.344/0.900\n",
      "step:356 | loss/acc = 0.436/0.800\n",
      "step:357 | loss/acc = 0.702/0.600\n",
      "step:358 | loss/acc = 0.418/0.850\n",
      "step:359 | loss/acc = 0.439/0.750\n",
      "sentiment task:    359: [    1/    2], senti_loss/senti_acc = 0.43830234/0.7800000 \n",
      "step:360 | loss/acc = 0.495/0.750\n",
      "step:361 | loss/acc = 0.413/0.750\n",
      "step:362 | loss/acc = 0.535/0.750\n",
      "step:363 | loss/acc = 0.429/0.800\n",
      "step:364 | loss/acc = 0.455/0.850\n",
      "step:365 | loss/acc = 0.485/0.850\n",
      "step:366 | loss/acc = 0.198/0.950\n",
      "step:367 | loss/acc = 0.529/0.750\n",
      "step:368 | loss/acc = 0.358/0.800\n",
      "step:369 | loss/acc = 0.448/0.750\n",
      "sentiment task:    369: [    1/    2], senti_loss/senti_acc = 0.43449035/0.8000000 \n",
      "step:370 | loss/acc = 0.473/0.750\n",
      "step:371 | loss/acc = 0.598/0.650\n",
      "step:372 | loss/acc = 0.539/0.700\n",
      "step:373 | loss/acc = 0.481/0.750\n",
      "step:374 | loss/acc = 0.435/0.850\n",
      "step:375 | loss/acc = 0.599/0.750\n",
      "step:376 | loss/acc = 0.520/0.700\n",
      "step:377 | loss/acc = 0.568/0.650\n",
      "step:378 | loss/acc = 0.344/0.800\n",
      "step:379 | loss/acc = 0.632/0.700\n",
      "sentiment task:    379: [    1/    2], senti_loss/senti_acc = 0.51899180/0.7300000 \n",
      "step:380 | loss/acc = 0.572/0.650\n",
      "step:381 | loss/acc = 0.370/0.900\n",
      "step:382 | loss/acc = 0.479/0.700\n",
      "step:383 | loss/acc = 0.356/0.800\n",
      "step:384 | loss/acc = 0.331/0.950\n",
      "step:385 | loss/acc = 0.466/0.800\n",
      "step:386 | loss/acc = 0.512/0.800\n",
      "step:387 | loss/acc = 0.541/0.700\n",
      "step:388 | loss/acc = 0.345/0.800\n",
      "step:389 | loss/acc = 0.458/0.850\n",
      "sentiment task:    389: [    1/    2], senti_loss/senti_acc = 0.44311834/0.7950000 \n",
      "step:390 | loss/acc = 0.619/0.700\n",
      "step:391 | loss/acc = 0.570/0.750\n",
      "step:392 | loss/acc = 0.440/0.750\n",
      "step:393 | loss/acc = 0.505/0.750\n",
      "step:394 | loss/acc = 0.444/0.750\n",
      "step:395 | loss/acc = 0.703/0.700\n",
      "step:396 | loss/acc = 0.382/0.850\n",
      "step:397 | loss/acc = 0.347/0.850\n",
      "step:398 | loss/acc = 0.256/0.950\n",
      "step:399 | loss/acc = 0.228/0.950\n",
      "sentiment task:    399: [    1/    2], senti_loss/senti_acc = 0.44937689/0.8000000 \n",
      "step:400 | loss/acc = 0.491/0.800\n",
      "step:401 | loss/acc = 0.619/0.700\n",
      "step:402 | loss/acc = 0.321/0.900\n",
      "step:403 | loss/acc = 0.477/0.900\n",
      "step:404 | loss/acc = 0.436/0.750\n",
      "step:405 | loss/acc = 0.259/0.850\n",
      "step:406 | loss/acc = 0.338/0.850\n",
      "step:407 | loss/acc = 0.689/0.750\n",
      "step:408 | loss/acc = 0.490/0.800\n",
      "step:409 | loss/acc = 0.460/0.850\n",
      "sentiment task:    409: [    1/    2], senti_loss/senti_acc = 0.45802950/0.8150000 \n",
      "step:410 | loss/acc = 0.529/0.650\n",
      "step:411 | loss/acc = 0.476/0.700\n",
      "step:412 | loss/acc = 0.220/0.950\n",
      "step:413 | loss/acc = 0.556/0.750\n",
      "step:414 | loss/acc = 0.546/0.800\n",
      "step:415 | loss/acc = 0.576/0.700\n",
      "step:416 | loss/acc = 0.541/0.650\n",
      "step:417 | loss/acc = 0.396/0.850\n",
      "step:418 | loss/acc = 0.696/0.700\n",
      "step:419 | loss/acc = 0.325/0.900\n",
      "sentiment task:    419: [    1/    2], senti_loss/senti_acc = 0.48602299/0.7650000 \n",
      "step:420 | loss/acc = 0.434/0.850\n",
      "step:421 | loss/acc = 0.719/0.650\n",
      "step:422 | loss/acc = 0.579/0.750\n",
      "step:423 | loss/acc = 0.558/0.700\n",
      "step:424 | loss/acc = 0.489/0.750\n",
      "step:425 | loss/acc = 0.381/0.900\n",
      "step:426 | loss/acc = 0.514/0.800\n",
      "step:427 | loss/acc = 0.381/0.800\n",
      "step:428 | loss/acc = 0.378/0.850\n",
      "step:429 | loss/acc = 0.401/0.800\n",
      "sentiment task:    429: [    1/    2], senti_loss/senti_acc = 0.48358262/0.7850000 \n",
      "step:430 | loss/acc = 0.345/0.900\n",
      "step:431 | loss/acc = 0.418/0.850\n",
      "step:432 | loss/acc = 0.444/0.800\n",
      "step:433 | loss/acc = 0.458/0.800\n",
      "step:434 | loss/acc = 0.315/0.850\n",
      "step:435 | loss/acc = 0.471/0.800\n",
      "step:436 | loss/acc = 0.371/0.900\n",
      "step:437 | loss/acc = 0.548/0.750\n",
      "step:438 | loss/acc = 0.581/0.600\n",
      "step:439 | loss/acc = 0.415/0.800\n",
      "sentiment task:    439: [    1/    2], senti_loss/senti_acc = 0.43676372/0.8050000 \n",
      "step:440 | loss/acc = 0.422/0.800\n",
      "step:441 | loss/acc = 0.395/0.850\n",
      "step:442 | loss/acc = 0.392/0.850\n",
      "step:443 | loss/acc = 0.385/0.850\n",
      "step:444 | loss/acc = 0.655/0.750\n",
      "step:445 | loss/acc = 0.518/0.750\n",
      "step:446 | loss/acc = 0.641/0.550\n",
      "step:447 | loss/acc = 0.238/0.850\n",
      "step:448 | loss/acc = 0.482/0.850\n",
      "step:449 | loss/acc = 0.425/0.800\n",
      "sentiment task:    449: [    1/    2], senti_loss/senti_acc = 0.45521602/0.7900000 \n",
      "step:450 | loss/acc = 0.576/0.700\n",
      "step:451 | loss/acc = 0.497/0.800\n",
      "step:452 | loss/acc = 0.407/0.850\n",
      "step:453 | loss/acc = 0.565/0.800\n",
      "step:454 | loss/acc = 0.636/0.600\n",
      "step:455 | loss/acc = 0.255/0.950\n",
      "step:456 | loss/acc = 0.467/0.750\n",
      "step:457 | loss/acc = 0.566/0.750\n",
      "step:458 | loss/acc = 0.561/0.750\n",
      "step:459 | loss/acc = 0.299/0.850\n",
      "sentiment task:    459: [    1/    2], senti_loss/senti_acc = 0.48288649/0.7800000 \n",
      "step:460 | loss/acc = 0.422/0.750\n",
      "step:461 | loss/acc = 0.671/0.550\n",
      "step:462 | loss/acc = 0.824/0.600\n",
      "step:463 | loss/acc = 0.499/0.700\n",
      "step:464 | loss/acc = 0.431/0.800\n",
      "step:465 | loss/acc = 0.523/0.700\n",
      "step:466 | loss/acc = 0.479/0.850\n",
      "step:467 | loss/acc = 0.653/0.600\n",
      "step:468 | loss/acc = 0.835/0.450\n",
      "step:469 | loss/acc = 0.328/0.800\n",
      "sentiment task:    469: [    1/    2], senti_loss/senti_acc = 0.56645821/0.6800000 \n",
      "step:470 | loss/acc = 0.389/0.850\n",
      "step:471 | loss/acc = 0.424/0.800\n",
      "step:472 | loss/acc = 0.342/0.850\n",
      "step:473 | loss/acc = 0.507/0.800\n",
      "step:474 | loss/acc = 0.261/0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:475 | loss/acc = 0.368/0.850\n",
      "step:476 | loss/acc = 0.499/0.750\n",
      "step:477 | loss/acc = 0.442/0.750\n",
      "step:478 | loss/acc = 0.394/0.850\n",
      "step:479 | loss/acc = 0.356/0.900\n",
      "sentiment task:    479: [    1/    2], senti_loss/senti_acc = 0.39819183/0.8300000 \n",
      "step:480 | loss/acc = 0.408/0.800\n",
      "step:481 | loss/acc = 0.575/0.650\n",
      "step:482 | loss/acc = 0.510/0.750\n",
      "step:483 | loss/acc = 0.613/0.750\n",
      "step:484 | loss/acc = 0.486/0.700\n",
      "step:485 | loss/acc = 0.380/0.700\n",
      "step:486 | loss/acc = 0.399/0.800\n",
      "step:487 | loss/acc = 0.575/0.700\n",
      "step:488 | loss/acc = 0.563/0.700\n",
      "step:489 | loss/acc = 0.494/0.800\n",
      "sentiment task:    489: [    1/    2], senti_loss/senti_acc = 0.50039234/0.7350000 \n",
      "step:490 | loss/acc = 0.359/0.850\n",
      "step:491 | loss/acc = 0.769/0.650\n",
      "step:492 | loss/acc = 0.460/0.750\n",
      "step:493 | loss/acc = 0.503/0.650\n",
      "step:494 | loss/acc = 0.401/0.850\n",
      "step:495 | loss/acc = 0.386/0.750\n",
      "step:496 | loss/acc = 0.687/0.700\n",
      "step:497 | loss/acc = 0.674/0.700\n",
      "step:498 | loss/acc = 0.626/0.650\n",
      "step:499 | loss/acc = 0.242/0.900\n",
      "sentiment task:    499: [    1/    2], senti_loss/senti_acc = 0.51075475/0.7450000 \n",
      "step:0 | loss/acc = 0.784/0.600\n",
      "step:1 | loss/acc = 0.668/0.600\n",
      "step:2 | loss/acc = 0.762/0.400\n",
      "step:3 | loss/acc = 0.729/0.450\n",
      "step:4 | loss/acc = 0.729/0.450\n",
      "step:5 | loss/acc = 0.703/0.450\n",
      "step:6 | loss/acc = 0.608/0.750\n",
      "step:7 | loss/acc = 0.661/0.550\n",
      "step:8 | loss/acc = 0.658/0.600\n",
      "step:9 | loss/acc = 0.626/0.700\n",
      "subjective task:      9: [    0/    2], senti_loss/senti_acc = 0.69276426/0.5550000 \n",
      "step:10 | loss/acc = 0.602/0.850\n",
      "step:11 | loss/acc = 0.630/0.800\n",
      "step:12 | loss/acc = 0.585/0.900\n",
      "step:13 | loss/acc = 0.581/0.800\n",
      "step:14 | loss/acc = 0.575/0.800\n",
      "step:15 | loss/acc = 0.556/0.850\n",
      "step:16 | loss/acc = 0.575/0.800\n",
      "step:17 | loss/acc = 0.564/0.850\n",
      "step:18 | loss/acc = 0.512/0.900\n",
      "step:19 | loss/acc = 0.523/0.800\n",
      "subjective task:     19: [    0/    2], senti_loss/senti_acc = 0.57043629/0.8350000 \n",
      "step:20 | loss/acc = 0.546/0.650\n",
      "step:21 | loss/acc = 0.509/0.650\n",
      "step:22 | loss/acc = 0.660/0.550\n",
      "step:23 | loss/acc = 0.470/0.950\n",
      "step:24 | loss/acc = 0.428/1.000\n",
      "step:25 | loss/acc = 0.477/0.800\n",
      "step:26 | loss/acc = 0.606/0.600\n",
      "step:27 | loss/acc = 0.490/0.750\n",
      "step:28 | loss/acc = 0.497/0.800\n",
      "step:29 | loss/acc = 0.453/0.900\n",
      "subjective task:     29: [    0/    2], senti_loss/senti_acc = 0.51345625/0.7650000 \n",
      "step:30 | loss/acc = 0.446/0.800\n",
      "step:31 | loss/acc = 0.424/0.950\n",
      "step:32 | loss/acc = 0.385/1.000\n",
      "step:33 | loss/acc = 0.420/0.900\n",
      "step:34 | loss/acc = 0.378/0.950\n",
      "step:35 | loss/acc = 0.487/0.900\n",
      "step:36 | loss/acc = 0.380/0.900\n",
      "step:37 | loss/acc = 0.463/0.850\n",
      "step:38 | loss/acc = 0.418/0.950\n",
      "step:39 | loss/acc = 0.415/0.900\n",
      "subjective task:     39: [    0/    2], senti_loss/senti_acc = 0.42150997/0.9100000 \n",
      "step:40 | loss/acc = 0.317/0.950\n",
      "step:41 | loss/acc = 0.443/0.850\n",
      "step:42 | loss/acc = 0.352/0.950\n",
      "step:43 | loss/acc = 0.411/0.900\n",
      "step:44 | loss/acc = 0.548/0.700\n",
      "step:45 | loss/acc = 0.239/1.000\n",
      "step:46 | loss/acc = 0.445/0.850\n",
      "step:47 | loss/acc = 0.311/0.950\n",
      "step:48 | loss/acc = 0.271/1.000\n",
      "step:49 | loss/acc = 0.242/1.000\n",
      "subjective task:     49: [    0/    2], senti_loss/senti_acc = 0.35793331/0.9150000 \n",
      "step:50 | loss/acc = 0.351/0.900\n",
      "step:51 | loss/acc = 0.388/0.850\n",
      "step:52 | loss/acc = 0.373/0.900\n",
      "step:53 | loss/acc = 0.295/0.950\n",
      "step:54 | loss/acc = 0.295/0.950\n",
      "step:55 | loss/acc = 0.418/0.850\n",
      "step:56 | loss/acc = 0.295/0.850\n",
      "step:57 | loss/acc = 0.326/0.850\n",
      "step:58 | loss/acc = 0.208/0.950\n",
      "step:59 | loss/acc = 0.238/0.900\n",
      "subjective task:     59: [    0/    2], senti_loss/senti_acc = 0.31865245/0.8950000 \n",
      "step:60 | loss/acc = 0.212/0.950\n",
      "step:61 | loss/acc = 0.294/0.850\n",
      "step:62 | loss/acc = 0.192/0.950\n",
      "step:63 | loss/acc = 0.272/0.900\n",
      "step:64 | loss/acc = 0.154/0.950\n",
      "step:65 | loss/acc = 0.170/1.000\n",
      "step:66 | loss/acc = 0.265/0.950\n",
      "step:67 | loss/acc = 0.408/0.800\n",
      "step:68 | loss/acc = 0.276/0.950\n",
      "step:69 | loss/acc = 0.408/0.900\n",
      "subjective task:     69: [    0/    2], senti_loss/senti_acc = 0.26513407/0.9200000 \n",
      "step:70 | loss/acc = 0.229/0.950\n",
      "step:71 | loss/acc = 0.196/1.000\n",
      "step:72 | loss/acc = 0.140/0.950\n",
      "step:73 | loss/acc = 0.334/0.850\n",
      "step:74 | loss/acc = 0.274/0.850\n",
      "step:75 | loss/acc = 0.294/0.800\n",
      "step:76 | loss/acc = 0.278/0.900\n",
      "step:77 | loss/acc = 0.142/1.000\n",
      "step:78 | loss/acc = 0.214/0.900\n",
      "step:79 | loss/acc = 0.159/0.950\n",
      "subjective task:     79: [    0/    2], senti_loss/senti_acc = 0.22600412/0.9150000 \n",
      "step:80 | loss/acc = 0.367/0.750\n",
      "step:81 | loss/acc = 0.120/1.000\n",
      "step:82 | loss/acc = 0.150/0.950\n",
      "step:83 | loss/acc = 0.119/1.000\n",
      "step:84 | loss/acc = 0.195/0.900\n",
      "step:85 | loss/acc = 0.303/0.800\n",
      "step:86 | loss/acc = 0.104/1.000\n",
      "step:87 | loss/acc = 0.158/0.900\n",
      "step:88 | loss/acc = 0.052/1.000\n",
      "step:89 | loss/acc = 0.123/1.000\n",
      "subjective task:     89: [    0/    2], senti_loss/senti_acc = 0.16914426/0.9300000 \n",
      "step:90 | loss/acc = 0.135/0.950\n",
      "step:91 | loss/acc = 0.386/0.800\n",
      "step:92 | loss/acc = 0.138/0.950\n",
      "step:93 | loss/acc = 0.213/0.900\n",
      "step:94 | loss/acc = 0.331/0.900\n",
      "step:95 | loss/acc = 0.088/1.000\n",
      "step:96 | loss/acc = 0.139/0.950\n",
      "step:97 | loss/acc = 0.267/0.900\n",
      "step:98 | loss/acc = 0.134/0.950\n",
      "step:99 | loss/acc = 0.389/0.850\n",
      "subjective task:     99: [    0/    2], senti_loss/senti_acc = 0.22194921/0.9150000 \n",
      "step:100 | loss/acc = 0.105/0.950\n",
      "step:101 | loss/acc = 0.232/0.900\n",
      "step:102 | loss/acc = 0.183/0.900\n",
      "step:103 | loss/acc = 0.243/0.900\n",
      "step:104 | loss/acc = 0.131/0.900\n",
      "step:105 | loss/acc = 0.412/0.850\n",
      "step:106 | loss/acc = 0.068/0.950\n",
      "step:107 | loss/acc = 0.054/1.000\n",
      "step:108 | loss/acc = 0.283/0.850\n",
      "step:109 | loss/acc = 0.146/1.000\n",
      "subjective task:    109: [    0/    2], senti_loss/senti_acc = 0.18559965/0.9200000 \n",
      "step:110 | loss/acc = 0.161/0.900\n",
      "step:111 | loss/acc = 0.135/0.900\n",
      "step:112 | loss/acc = 0.198/0.850\n",
      "step:113 | loss/acc = 0.183/0.950\n",
      "step:114 | loss/acc = 0.085/0.950\n",
      "step:115 | loss/acc = 0.202/0.950\n",
      "step:116 | loss/acc = 0.239/0.850\n",
      "step:117 | loss/acc = 0.115/0.950\n",
      "step:118 | loss/acc = 0.141/1.000\n",
      "step:119 | loss/acc = 0.110/0.900\n",
      "subjective task:    119: [    0/    2], senti_loss/senti_acc = 0.15699163/0.9200000 \n",
      "step:120 | loss/acc = 0.162/0.950\n",
      "step:121 | loss/acc = 0.115/0.950\n",
      "step:122 | loss/acc = 0.319/0.800\n",
      "step:123 | loss/acc = 0.098/0.950\n",
      "step:124 | loss/acc = 0.116/0.950\n",
      "step:125 | loss/acc = 0.135/0.950\n",
      "step:126 | loss/acc = 0.087/0.950\n",
      "step:127 | loss/acc = 0.350/0.950\n",
      "step:128 | loss/acc = 0.044/1.000\n",
      "step:129 | loss/acc = 0.143/0.950\n",
      "subjective task:    129: [    0/    2], senti_loss/senti_acc = 0.15691362/0.9400000 \n",
      "step:130 | loss/acc = 0.159/0.900\n",
      "step:131 | loss/acc = 0.144/0.900\n",
      "step:132 | loss/acc = 0.054/1.000\n",
      "step:133 | loss/acc = 0.123/0.950\n",
      "step:134 | loss/acc = 0.112/0.950\n",
      "step:135 | loss/acc = 0.142/0.950\n",
      "step:136 | loss/acc = 0.228/0.950\n",
      "step:137 | loss/acc = 0.047/1.000\n",
      "step:138 | loss/acc = 0.036/1.000\n",
      "step:139 | loss/acc = 0.058/1.000\n",
      "subjective task:    139: [    0/    2], senti_loss/senti_acc = 0.11039898/0.9600000 \n",
      "step:140 | loss/acc = 0.164/0.950\n",
      "step:141 | loss/acc = 0.057/1.000\n",
      "step:142 | loss/acc = 0.448/0.750\n",
      "step:143 | loss/acc = 0.020/1.000\n",
      "step:144 | loss/acc = 0.216/0.900\n",
      "step:145 | loss/acc = 0.197/0.900\n",
      "step:146 | loss/acc = 0.095/0.950\n",
      "step:147 | loss/acc = 0.169/0.950\n",
      "step:148 | loss/acc = 0.493/0.900\n",
      "step:149 | loss/acc = 0.148/0.900\n",
      "subjective task:    149: [    0/    2], senti_loss/senti_acc = 0.20089328/0.9200000 \n",
      "step:150 | loss/acc = 0.144/0.900\n",
      "step:151 | loss/acc = 0.178/0.900\n",
      "step:152 | loss/acc = 0.024/1.000\n",
      "step:153 | loss/acc = 0.143/0.950\n",
      "step:154 | loss/acc = 0.046/1.000\n",
      "step:155 | loss/acc = 0.046/1.000\n",
      "step:156 | loss/acc = 0.091/0.950\n",
      "step:157 | loss/acc = 0.020/1.000\n",
      "step:158 | loss/acc = 0.121/0.950\n",
      "step:159 | loss/acc = 0.135/0.850\n",
      "subjective task:    159: [    0/    2], senti_loss/senti_acc = 0.09479679/0.9500000 \n",
      "step:160 | loss/acc = 0.221/0.900\n",
      "step:161 | loss/acc = 0.150/0.900\n",
      "step:162 | loss/acc = 0.035/1.000\n",
      "step:163 | loss/acc = 0.256/0.900\n",
      "step:164 | loss/acc = 0.195/0.900\n",
      "step:165 | loss/acc = 0.148/0.950\n",
      "step:166 | loss/acc = 0.437/0.850\n",
      "step:167 | loss/acc = 0.549/0.850\n",
      "step:168 | loss/acc = 0.284/0.900\n",
      "step:169 | loss/acc = 0.197/0.950\n",
      "subjective task:    169: [    0/    2], senti_loss/senti_acc = 0.24720432/0.9100000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:170 | loss/acc = 0.472/0.850\n",
      "step:171 | loss/acc = 0.090/1.000\n",
      "step:172 | loss/acc = 0.135/0.950\n",
      "step:173 | loss/acc = 0.114/0.950\n",
      "step:174 | loss/acc = 0.190/0.900\n",
      "step:175 | loss/acc = 0.065/1.000\n",
      "step:176 | loss/acc = 0.274/0.850\n",
      "step:177 | loss/acc = 0.114/0.950\n",
      "step:178 | loss/acc = 0.060/0.950\n",
      "step:179 | loss/acc = 0.187/0.950\n",
      "subjective task:    179: [    0/    2], senti_loss/senti_acc = 0.17018927/0.9350000 \n",
      "step:180 | loss/acc = 0.445/0.900\n",
      "step:181 | loss/acc = 0.049/1.000\n",
      "step:182 | loss/acc = 0.084/0.950\n",
      "step:183 | loss/acc = 0.491/0.800\n",
      "step:184 | loss/acc = 0.171/0.900\n",
      "step:185 | loss/acc = 0.259/0.900\n",
      "step:186 | loss/acc = 0.242/0.950\n",
      "step:187 | loss/acc = 0.072/0.950\n",
      "step:188 | loss/acc = 0.072/0.950\n",
      "step:189 | loss/acc = 0.163/0.950\n",
      "subjective task:    189: [    0/    2], senti_loss/senti_acc = 0.20488959/0.9250000 \n",
      "step:190 | loss/acc = 0.200/0.800\n",
      "step:191 | loss/acc = 0.118/0.950\n",
      "step:192 | loss/acc = 0.034/1.000\n",
      "step:193 | loss/acc = 0.463/0.900\n",
      "step:194 | loss/acc = 0.026/1.000\n",
      "step:195 | loss/acc = 0.156/0.900\n",
      "step:196 | loss/acc = 0.302/0.850\n",
      "step:197 | loss/acc = 0.032/1.000\n",
      "step:198 | loss/acc = 0.075/0.950\n",
      "step:199 | loss/acc = 0.014/1.000\n",
      "subjective task:    199: [    0/    2], senti_loss/senti_acc = 0.14190775/0.9350000 \n",
      "step:200 | loss/acc = 0.034/1.000\n",
      "step:201 | loss/acc = 0.016/1.000\n",
      "step:202 | loss/acc = 0.298/0.900\n",
      "step:203 | loss/acc = 0.423/0.900\n",
      "step:204 | loss/acc = 0.231/0.900\n",
      "step:205 | loss/acc = 0.117/0.950\n",
      "step:206 | loss/acc = 0.038/1.000\n",
      "step:207 | loss/acc = 0.036/1.000\n",
      "step:208 | loss/acc = 0.014/1.000\n",
      "step:209 | loss/acc = 0.002/1.000\n",
      "subjective task:    209: [    0/    2], senti_loss/senti_acc = 0.12083372/0.9650000 \n",
      "step:210 | loss/acc = 0.177/0.950\n",
      "step:211 | loss/acc = 0.369/0.900\n",
      "step:212 | loss/acc = 0.215/0.900\n",
      "step:213 | loss/acc = 0.008/1.000\n",
      "step:214 | loss/acc = 0.179/0.950\n",
      "step:215 | loss/acc = 0.656/0.850\n",
      "step:216 | loss/acc = 0.132/0.950\n",
      "step:217 | loss/acc = 0.375/0.900\n",
      "step:218 | loss/acc = 0.259/0.900\n",
      "step:219 | loss/acc = 0.219/0.950\n",
      "subjective task:    219: [    0/    2], senti_loss/senti_acc = 0.25884845/0.9250000 \n",
      "step:220 | loss/acc = 0.111/0.900\n",
      "step:221 | loss/acc = 0.145/0.900\n",
      "step:222 | loss/acc = 0.286/0.900\n",
      "step:223 | loss/acc = 0.124/0.950\n",
      "step:224 | loss/acc = 0.036/1.000\n",
      "step:225 | loss/acc = 0.135/0.950\n",
      "step:226 | loss/acc = 0.168/0.950\n",
      "step:227 | loss/acc = 0.144/0.900\n",
      "step:228 | loss/acc = 0.558/0.750\n",
      "step:229 | loss/acc = 0.055/0.950\n",
      "subjective task:    229: [    0/    2], senti_loss/senti_acc = 0.17623641/0.9150000 \n",
      "step:230 | loss/acc = 0.213/0.950\n",
      "step:231 | loss/acc = 0.134/0.950\n",
      "step:232 | loss/acc = 0.025/1.000\n",
      "step:233 | loss/acc = 0.055/1.000\n",
      "step:234 | loss/acc = 0.291/0.900\n",
      "step:235 | loss/acc = 0.087/0.950\n",
      "step:236 | loss/acc = 0.276/0.950\n",
      "step:237 | loss/acc = 0.183/0.950\n",
      "step:238 | loss/acc = 0.201/0.950\n",
      "step:239 | loss/acc = 0.225/0.850\n",
      "subjective task:    239: [    0/    2], senti_loss/senti_acc = 0.16908858/0.9450000 \n",
      "step:240 | loss/acc = 0.513/0.900\n",
      "step:241 | loss/acc = 0.110/0.950\n",
      "step:242 | loss/acc = 0.113/0.950\n",
      "step:243 | loss/acc = 0.037/1.000\n",
      "step:244 | loss/acc = 0.030/1.000\n",
      "step:245 | loss/acc = 0.171/0.950\n",
      "step:246 | loss/acc = 0.312/0.900\n",
      "step:247 | loss/acc = 0.196/0.950\n",
      "step:248 | loss/acc = 0.015/1.000\n",
      "step:249 | loss/acc = 0.055/1.000\n",
      "subjective task:    249: [    0/    2], senti_loss/senti_acc = 0.15527161/0.9600000 \n",
      "step:250 | loss/acc = 0.155/0.950\n",
      "step:251 | loss/acc = 0.283/0.950\n",
      "step:252 | loss/acc = 0.451/0.900\n",
      "step:253 | loss/acc = 0.005/1.000\n",
      "step:254 | loss/acc = 0.059/1.000\n",
      "step:255 | loss/acc = 0.413/0.900\n",
      "step:256 | loss/acc = 0.079/0.950\n",
      "step:257 | loss/acc = 0.044/1.000\n",
      "step:258 | loss/acc = 0.003/1.000\n",
      "step:259 | loss/acc = 0.012/1.000\n",
      "subjective task:    259: [    0/    2], senti_loss/senti_acc = 0.15049077/0.9650000 \n",
      "step:260 | loss/acc = 0.068/0.950\n",
      "step:261 | loss/acc = 0.451/0.850\n",
      "step:262 | loss/acc = 0.077/0.950\n",
      "step:263 | loss/acc = 0.318/0.850\n",
      "step:264 | loss/acc = 0.362/0.950\n",
      "step:265 | loss/acc = 0.259/0.900\n",
      "step:266 | loss/acc = 0.366/0.850\n",
      "step:267 | loss/acc = 0.003/1.000\n",
      "step:268 | loss/acc = 0.032/1.000\n",
      "step:269 | loss/acc = 0.234/0.900\n",
      "subjective task:    269: [    0/    2], senti_loss/senti_acc = 0.21711180/0.9200000 \n",
      "step:270 | loss/acc = 0.426/0.850\n",
      "step:271 | loss/acc = 0.023/1.000\n",
      "step:272 | loss/acc = 0.043/1.000\n",
      "step:273 | loss/acc = 0.237/0.900\n",
      "step:274 | loss/acc = 0.042/0.950\n",
      "step:275 | loss/acc = 0.123/0.900\n",
      "step:276 | loss/acc = 0.371/0.900\n",
      "step:277 | loss/acc = 0.291/0.850\n",
      "step:278 | loss/acc = 0.111/0.950\n",
      "step:279 | loss/acc = 0.224/0.950\n",
      "subjective task:    279: [    0/    2], senti_loss/senti_acc = 0.18909009/0.9250000 \n",
      "step:280 | loss/acc = 0.502/0.850\n",
      "step:281 | loss/acc = 0.117/0.950\n",
      "step:282 | loss/acc = 0.008/1.000\n",
      "step:283 | loss/acc = 0.006/1.000\n",
      "step:284 | loss/acc = 0.423/0.900\n",
      "step:285 | loss/acc = 0.155/0.900\n",
      "step:286 | loss/acc = 0.131/0.950\n",
      "step:287 | loss/acc = 0.158/0.950\n",
      "step:288 | loss/acc = 0.171/0.950\n",
      "step:289 | loss/acc = 0.430/0.800\n",
      "subjective task:    289: [    0/    2], senti_loss/senti_acc = 0.21014456/0.9250000 \n",
      "step:290 | loss/acc = 0.004/1.000\n",
      "step:291 | loss/acc = 0.237/0.800\n",
      "step:292 | loss/acc = 0.201/0.950\n",
      "step:293 | loss/acc = 0.212/0.900\n",
      "step:294 | loss/acc = 0.021/1.000\n",
      "step:295 | loss/acc = 0.016/1.000\n",
      "step:296 | loss/acc = 0.317/0.850\n",
      "step:297 | loss/acc = 0.158/0.950\n",
      "step:298 | loss/acc = 0.290/0.900\n",
      "step:299 | loss/acc = 0.624/0.750\n",
      "subjective task:    299: [    0/    2], senti_loss/senti_acc = 0.20796022/0.9100000 \n",
      "step:300 | loss/acc = 0.063/1.000\n",
      "step:301 | loss/acc = 0.188/0.900\n",
      "step:302 | loss/acc = 0.177/0.950\n",
      "step:303 | loss/acc = 0.062/1.000\n",
      "step:304 | loss/acc = 0.140/0.950\n",
      "step:305 | loss/acc = 0.450/0.900\n",
      "step:306 | loss/acc = 0.543/0.800\n",
      "step:307 | loss/acc = 0.121/0.950\n",
      "step:308 | loss/acc = 0.089/0.950\n",
      "step:309 | loss/acc = 0.234/0.900\n",
      "subjective task:    309: [    0/    2], senti_loss/senti_acc = 0.20659089/0.9300000 \n",
      "step:310 | loss/acc = 0.084/0.950\n",
      "step:311 | loss/acc = 0.091/0.950\n",
      "step:312 | loss/acc = 0.062/0.950\n",
      "step:313 | loss/acc = 0.468/0.900\n",
      "step:314 | loss/acc = 0.219/0.900\n",
      "step:315 | loss/acc = 0.311/0.950\n",
      "step:316 | loss/acc = 0.254/0.900\n",
      "step:317 | loss/acc = 0.053/1.000\n",
      "step:318 | loss/acc = 0.218/0.950\n",
      "step:319 | loss/acc = 0.199/0.900\n",
      "subjective task:    319: [    0/    2], senti_loss/senti_acc = 0.19567473/0.9350000 \n",
      "step:320 | loss/acc = 0.205/0.950\n",
      "step:321 | loss/acc = 0.032/1.000\n",
      "step:322 | loss/acc = 0.148/0.950\n",
      "step:323 | loss/acc = 0.177/0.950\n",
      "step:324 | loss/acc = 0.195/0.900\n",
      "step:325 | loss/acc = 0.064/0.950\n",
      "step:326 | loss/acc = 0.017/1.000\n",
      "step:327 | loss/acc = 0.100/0.950\n",
      "step:328 | loss/acc = 0.320/0.900\n",
      "step:329 | loss/acc = 0.117/0.900\n",
      "subjective task:    329: [    0/    2], senti_loss/senti_acc = 0.13754721/0.9450000 \n",
      "step:330 | loss/acc = 0.062/0.950\n",
      "step:331 | loss/acc = 0.570/0.850\n",
      "step:332 | loss/acc = 0.140/0.950\n",
      "step:333 | loss/acc = 0.149/0.900\n",
      "step:334 | loss/acc = 0.056/0.950\n",
      "step:335 | loss/acc = 0.104/0.950\n",
      "step:336 | loss/acc = 0.040/1.000\n",
      "step:337 | loss/acc = 0.015/1.000\n",
      "step:338 | loss/acc = 0.022/1.000\n",
      "step:339 | loss/acc = 0.095/0.950\n",
      "subjective task:    339: [    0/    2], senti_loss/senti_acc = 0.12526705/0.9500000 \n",
      "step:340 | loss/acc = 0.347/0.900\n",
      "step:341 | loss/acc = 0.106/0.950\n",
      "step:342 | loss/acc = 0.046/1.000\n",
      "step:343 | loss/acc = 0.028/1.000\n",
      "step:344 | loss/acc = 0.141/0.950\n",
      "step:345 | loss/acc = 0.040/1.000\n",
      "step:346 | loss/acc = 0.080/0.950\n",
      "step:347 | loss/acc = 0.145/0.950\n",
      "step:348 | loss/acc = 0.315/0.900\n",
      "step:349 | loss/acc = 0.122/0.950\n",
      "subjective task:    349: [    0/    2], senti_loss/senti_acc = 0.13696303/0.9550000 \n",
      "step:350 | loss/acc = 0.116/0.950\n",
      "step:351 | loss/acc = 0.233/0.950\n",
      "step:352 | loss/acc = 0.178/0.900\n",
      "step:353 | loss/acc = 0.151/0.950\n",
      "step:354 | loss/acc = 0.069/1.000\n",
      "step:355 | loss/acc = 0.121/0.900\n",
      "step:356 | loss/acc = 0.111/0.950\n",
      "step:357 | loss/acc = 0.216/0.900\n",
      "step:358 | loss/acc = 0.266/0.900\n",
      "step:359 | loss/acc = 0.110/0.900\n",
      "subjective task:    359: [    0/    2], senti_loss/senti_acc = 0.15717023/0.9300000 \n",
      "step:360 | loss/acc = 0.420/0.900\n",
      "step:361 | loss/acc = 0.114/1.000\n",
      "step:362 | loss/acc = 0.234/0.850\n",
      "step:363 | loss/acc = 0.324/0.850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:364 | loss/acc = 0.251/0.900\n",
      "step:365 | loss/acc = 0.177/0.900\n",
      "step:366 | loss/acc = 0.098/0.950\n",
      "step:367 | loss/acc = 0.115/1.000\n",
      "step:368 | loss/acc = 0.178/0.900\n",
      "step:369 | loss/acc = 0.160/0.950\n",
      "subjective task:    369: [    0/    2], senti_loss/senti_acc = 0.20711721/0.9200000 \n",
      "step:370 | loss/acc = 0.040/1.000\n",
      "step:371 | loss/acc = 0.091/0.950\n",
      "step:372 | loss/acc = 0.072/1.000\n",
      "step:373 | loss/acc = 0.496/0.850\n",
      "step:374 | loss/acc = 0.025/1.000\n",
      "step:375 | loss/acc = 0.072/1.000\n",
      "step:376 | loss/acc = 0.280/0.900\n",
      "step:377 | loss/acc = 0.064/1.000\n",
      "step:378 | loss/acc = 0.122/0.950\n",
      "step:379 | loss/acc = 0.092/1.000\n",
      "subjective task:    379: [    0/    2], senti_loss/senti_acc = 0.13545308/0.9650000 \n",
      "step:380 | loss/acc = 0.021/1.000\n",
      "step:381 | loss/acc = 0.105/0.950\n",
      "step:382 | loss/acc = 0.056/1.000\n",
      "step:383 | loss/acc = 0.041/1.000\n",
      "step:384 | loss/acc = 0.099/0.900\n",
      "step:385 | loss/acc = 0.234/0.900\n",
      "step:386 | loss/acc = 0.012/1.000\n",
      "step:387 | loss/acc = 0.097/0.950\n",
      "step:388 | loss/acc = 0.099/0.950\n",
      "step:389 | loss/acc = 0.030/1.000\n",
      "subjective task:    389: [    0/    2], senti_loss/senti_acc = 0.07927933/0.9650000 \n",
      "step:390 | loss/acc = 0.100/0.950\n",
      "step:391 | loss/acc = 0.070/0.950\n",
      "step:392 | loss/acc = 0.115/0.950\n",
      "step:393 | loss/acc = 0.247/0.900\n",
      "step:394 | loss/acc = 0.038/1.000\n",
      "step:395 | loss/acc = 0.051/1.000\n",
      "step:396 | loss/acc = 0.044/1.000\n",
      "step:397 | loss/acc = 0.068/0.950\n",
      "step:398 | loss/acc = 0.034/1.000\n",
      "step:399 | loss/acc = 0.271/0.950\n",
      "subjective task:    399: [    0/    2], senti_loss/senti_acc = 0.10370668/0.9650000 \n",
      "step:400 | loss/acc = 0.294/0.850\n",
      "step:401 | loss/acc = 0.050/1.000\n",
      "step:402 | loss/acc = 0.066/1.000\n",
      "step:403 | loss/acc = 0.046/1.000\n",
      "step:404 | loss/acc = 0.153/0.950\n",
      "step:405 | loss/acc = 0.016/1.000\n",
      "step:406 | loss/acc = 0.174/0.900\n",
      "step:407 | loss/acc = 0.378/0.800\n",
      "step:408 | loss/acc = 0.259/0.950\n",
      "step:409 | loss/acc = 0.094/0.950\n",
      "subjective task:    409: [    0/    2], senti_loss/senti_acc = 0.15308630/0.9400000 \n",
      "step:410 | loss/acc = 0.030/1.000\n",
      "step:411 | loss/acc = 0.091/0.950\n",
      "step:412 | loss/acc = 0.090/1.000\n",
      "step:413 | loss/acc = 0.050/1.000\n",
      "step:414 | loss/acc = 0.124/0.900\n",
      "step:415 | loss/acc = 0.114/0.950\n",
      "step:416 | loss/acc = 0.099/0.950\n",
      "step:417 | loss/acc = 0.050/1.000\n",
      "step:418 | loss/acc = 0.222/0.850\n",
      "step:419 | loss/acc = 0.050/1.000\n",
      "subjective task:    419: [    0/    2], senti_loss/senti_acc = 0.09201384/0.9600000 \n",
      "step:420 | loss/acc = 0.021/1.000\n",
      "step:421 | loss/acc = 0.029/1.000\n",
      "step:422 | loss/acc = 0.032/1.000\n",
      "step:423 | loss/acc = 0.113/0.950\n",
      "step:424 | loss/acc = 0.123/0.900\n",
      "step:0 | loss/acc = 0.174/0.950\n",
      "step:1 | loss/acc = 0.191/0.950\n",
      "step:2 | loss/acc = 0.144/0.950\n",
      "step:3 | loss/acc = 0.265/0.900\n",
      "step:4 | loss/acc = 0.038/1.000\n",
      "step:5 | loss/acc = 0.088/1.000\n",
      "step:6 | loss/acc = 0.224/0.900\n",
      "step:7 | loss/acc = 0.096/1.000\n",
      "step:8 | loss/acc = 0.285/0.850\n",
      "step:9 | loss/acc = 0.013/1.000\n",
      "subjective task:      9: [    1/    2], senti_loss/senti_acc = 0.15174172/0.9500000 \n",
      "step:10 | loss/acc = 0.052/1.000\n",
      "step:11 | loss/acc = 0.036/1.000\n",
      "step:12 | loss/acc = 0.104/1.000\n",
      "step:13 | loss/acc = 0.120/0.900\n",
      "step:14 | loss/acc = 0.022/1.000\n",
      "step:15 | loss/acc = 0.185/0.950\n",
      "step:16 | loss/acc = 0.333/0.850\n",
      "step:17 | loss/acc = 0.115/0.950\n",
      "step:18 | loss/acc = 0.161/0.950\n",
      "step:19 | loss/acc = 0.070/0.950\n",
      "subjective task:     19: [    1/    2], senti_loss/senti_acc = 0.11979381/0.9550000 \n",
      "step:20 | loss/acc = 0.131/0.950\n",
      "step:21 | loss/acc = 0.045/1.000\n",
      "step:22 | loss/acc = 0.305/0.850\n",
      "step:23 | loss/acc = 0.097/0.950\n",
      "step:24 | loss/acc = 0.119/0.950\n",
      "step:25 | loss/acc = 0.038/1.000\n",
      "step:26 | loss/acc = 0.130/0.950\n",
      "step:27 | loss/acc = 0.126/0.950\n",
      "step:28 | loss/acc = 0.087/1.000\n",
      "step:29 | loss/acc = 0.111/0.950\n",
      "subjective task:     29: [    1/    2], senti_loss/senti_acc = 0.11894179/0.9550000 \n",
      "step:30 | loss/acc = 0.144/0.950\n",
      "step:31 | loss/acc = 0.090/1.000\n",
      "step:32 | loss/acc = 0.130/0.950\n",
      "step:33 | loss/acc = 0.063/1.000\n",
      "step:34 | loss/acc = 0.028/1.000\n",
      "step:35 | loss/acc = 0.250/0.950\n",
      "step:36 | loss/acc = 0.037/1.000\n",
      "step:37 | loss/acc = 0.259/0.750\n",
      "step:38 | loss/acc = 0.030/1.000\n",
      "step:39 | loss/acc = 0.212/0.900\n",
      "subjective task:     39: [    1/    2], senti_loss/senti_acc = 0.12432423/0.9500000 \n",
      "step:40 | loss/acc = 0.025/1.000\n",
      "step:41 | loss/acc = 0.201/0.950\n",
      "step:42 | loss/acc = 0.062/1.000\n",
      "step:43 | loss/acc = 0.089/0.950\n",
      "step:44 | loss/acc = 0.163/0.950\n",
      "step:45 | loss/acc = 0.017/1.000\n",
      "step:46 | loss/acc = 0.148/0.950\n",
      "step:47 | loss/acc = 0.035/1.000\n",
      "step:48 | loss/acc = 0.005/1.000\n",
      "step:49 | loss/acc = 0.030/1.000\n",
      "subjective task:     49: [    1/    2], senti_loss/senti_acc = 0.07748546/0.9800000 \n",
      "step:50 | loss/acc = 0.057/1.000\n",
      "step:51 | loss/acc = 0.168/0.900\n",
      "step:52 | loss/acc = 0.169/0.950\n",
      "step:53 | loss/acc = 0.055/1.000\n",
      "step:54 | loss/acc = 0.142/0.950\n",
      "step:55 | loss/acc = 0.180/0.950\n",
      "step:56 | loss/acc = 0.174/0.900\n",
      "step:57 | loss/acc = 0.047/1.000\n",
      "step:58 | loss/acc = 0.024/1.000\n",
      "step:59 | loss/acc = 0.063/1.000\n",
      "subjective task:     59: [    1/    2], senti_loss/senti_acc = 0.10777112/0.9650000 \n",
      "step:60 | loss/acc = 0.037/1.000\n",
      "step:61 | loss/acc = 0.214/0.850\n",
      "step:62 | loss/acc = 0.082/0.950\n",
      "step:63 | loss/acc = 0.231/0.950\n",
      "step:64 | loss/acc = 0.017/1.000\n",
      "step:65 | loss/acc = 0.050/1.000\n",
      "step:66 | loss/acc = 0.087/1.000\n",
      "step:67 | loss/acc = 0.184/0.900\n",
      "step:68 | loss/acc = 0.094/0.950\n",
      "step:69 | loss/acc = 0.272/0.900\n",
      "subjective task:     69: [    1/    2], senti_loss/senti_acc = 0.12668295/0.9500000 \n",
      "step:70 | loss/acc = 0.054/1.000\n",
      "step:71 | loss/acc = 0.053/1.000\n",
      "step:72 | loss/acc = 0.063/0.950\n",
      "step:73 | loss/acc = 0.196/0.950\n",
      "step:74 | loss/acc = 0.083/1.000\n",
      "step:75 | loss/acc = 0.111/0.950\n",
      "step:76 | loss/acc = 0.038/1.000\n",
      "step:77 | loss/acc = 0.084/0.950\n",
      "step:78 | loss/acc = 0.136/0.900\n",
      "step:79 | loss/acc = 0.024/1.000\n",
      "subjective task:     79: [    1/    2], senti_loss/senti_acc = 0.08408174/0.9700000 \n",
      "step:80 | loss/acc = 0.096/0.950\n",
      "step:81 | loss/acc = 0.024/1.000\n",
      "step:82 | loss/acc = 0.034/1.000\n",
      "step:83 | loss/acc = 0.054/1.000\n",
      "step:84 | loss/acc = 0.080/1.000\n",
      "step:85 | loss/acc = 0.191/0.900\n",
      "step:86 | loss/acc = 0.093/1.000\n",
      "step:87 | loss/acc = 0.133/0.950\n",
      "step:88 | loss/acc = 0.104/0.950\n",
      "step:89 | loss/acc = 0.057/0.950\n",
      "subjective task:     89: [    1/    2], senti_loss/senti_acc = 0.08646298/0.9700000 \n",
      "step:90 | loss/acc = 0.019/1.000\n",
      "step:91 | loss/acc = 0.156/0.950\n",
      "step:92 | loss/acc = 0.023/1.000\n",
      "step:93 | loss/acc = 0.205/0.950\n",
      "step:94 | loss/acc = 0.183/0.950\n",
      "step:95 | loss/acc = 0.046/1.000\n",
      "step:96 | loss/acc = 0.065/1.000\n",
      "step:97 | loss/acc = 0.110/0.950\n",
      "step:98 | loss/acc = 0.115/0.950\n",
      "step:99 | loss/acc = 0.251/0.950\n",
      "subjective task:     99: [    1/    2], senti_loss/senti_acc = 0.11738369/0.9700000 \n"
     ]
    }
   ],
   "source": [
    "JointLearning(senti_train_reader, subj_train_reader, emoReader, \n",
    "                  bert, transformer, task_embedding, \n",
    "                  senti_cls, subj_cls, emo_cls,\n",
    "                  cuda=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "rdm_model = RDM_Model(768, 300, 256, 0.2).cuda()\n",
    "cm_model = CM_Model(300, 256, 2).cuda()\n",
    "rdm_classifier = nn.Linear(256, 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  20000|MTL_Loss:0.69997206, rdm_loss/rdm_acc = 0.72082072/0.0000000 | senti_loss/senti_acc = 0.56915508/0.7000000 | subj_loss/subj_acc = 0.66399979/0.7000000 \n",
      "     1  20000|MTL_Loss:0.76249111, rdm_loss/rdm_acc = 0.77836663/0.5000000 | senti_loss/senti_acc = 0.64321386/0.7000000 | subj_loss/subj_acc = 0.75476415/0.6000000 \n",
      "     2  20000|MTL_Loss:0.68839521, rdm_loss/rdm_acc = 0.65440810/1.0000000 | senti_loss/senti_acc = 0.78327168/0.4000000 | subj_loss/subj_acc = 0.86541580/0.4000000 \n",
      "     3  20000|MTL_Loss:0.63432469, rdm_loss/rdm_acc = 0.60354131/1.0000000 | senti_loss/senti_acc = 0.78165638/0.5000000 | subj_loss/subj_acc = 0.73325985/0.6000000 \n",
      "     4  20000|MTL_Loss:0.77588555, rdm_loss/rdm_acc = 0.80867416/0.5000000 | senti_loss/senti_acc = 0.58763288/0.7000000 | subj_loss/subj_acc = 0.70182917/0.6000000 \n",
      "     5  20000|MTL_Loss:0.77552871, rdm_loss/rdm_acc = 0.74261606/0.0000000 | senti_loss/senti_acc = 0.76038471/0.5000000 | subj_loss/subj_acc = 1.05397377/0.3000000 \n",
      "     6  20000|MTL_Loss:0.63857844, rdm_loss/rdm_acc = 0.60057181/1.0000000 | senti_loss/senti_acc = 0.68634045/0.6000000 | subj_loss/subj_acc = 0.89486938/0.4000000 \n",
      "     7  20000|MTL_Loss:0.80089411, rdm_loss/rdm_acc = 0.81035757/0.0000000 | senti_loss/senti_acc = 0.75310332/0.5000000 | subj_loss/subj_acc = 0.77297728/0.6000000 \n",
      "     8  20000|MTL_Loss:0.73944832, rdm_loss/rdm_acc = 0.73426324/0.5000000 | senti_loss/senti_acc = 0.78008971/0.5000000 | subj_loss/subj_acc = 0.74028726/0.6000000 \n",
      "     9  20000|MTL_Loss:0.73400935, rdm_loss/rdm_acc = 0.71050352/0.5000000 | senti_loss/senti_acc = 0.83446850/0.3000000 | subj_loss/subj_acc = 0.82159665/0.5000000 \n",
      "MTL_Loss:0.72495275, rdm_loss/rdm_acc = 0.71641231/0.5000000 | senti_loss/senti_acc = 0.71793166/0.5400000 | subj_loss/subj_acc = 0.80029731/0.5300000 \n",
      "    10  20000|MTL_Loss:0.72367420, rdm_loss/rdm_acc = 0.71359485/0.5000000 | senti_loss/senti_acc = 0.73749657/0.5000000 | subj_loss/subj_acc = 0.79048660/0.5000000 \n",
      "    11  20000|MTL_Loss:0.69845359, rdm_loss/rdm_acc = 0.69050735/0.5000000 | senti_loss/senti_acc = 0.73873118/0.6000000 | subj_loss/subj_acc = 0.72174577/0.7000000 \n",
      "    12  20000|MTL_Loss:0.66793118, rdm_loss/rdm_acc = 0.68196225/1.0000000 | senti_loss/senti_acc = 0.76090409/0.4000000 | subj_loss/subj_acc = 0.46270939/0.9000000 \n",
      "    13  20000|MTL_Loss:0.66269525, rdm_loss/rdm_acc = 0.63153446/1.0000000 | senti_loss/senti_acc = 0.71054145/0.5000000 | subj_loss/subj_acc = 0.86413549/0.5000000 \n",
      "    14  20000|MTL_Loss:0.77255206, rdm_loss/rdm_acc = 0.78044426/0.0000000 | senti_loss/senti_acc = 0.64666699/0.7000000 | subj_loss/subj_acc = 0.83529940/0.5000000 \n",
      "    15  20000|MTL_Loss:0.73912073, rdm_loss/rdm_acc = 0.74488181/0.0000000 | senti_loss/senti_acc = 0.64040604/0.7000000 | subj_loss/subj_acc = 0.79174654/0.5000000 \n",
      "    16  20000|MTL_Loss:0.68254323, rdm_loss/rdm_acc = 0.64451873/1.0000000 | senti_loss/senti_acc = 0.81738054/0.2000000 | subj_loss/subj_acc = 0.85190185/0.5000000 \n",
      "    17  20000|MTL_Loss:0.73283180, rdm_loss/rdm_acc = 0.71371180/0.5000000 | senti_loss/senti_acc = 0.71063194/0.5000000 | subj_loss/subj_acc = 0.90799171/0.4000000 \n",
      "    18  20000|MTL_Loss:0.68888658, rdm_loss/rdm_acc = 0.67697757/1.0000000 | senti_loss/senti_acc = 0.71261656/0.4000000 | subj_loss/subj_acc = 0.76042871/0.6000000 \n",
      "    19  20000|MTL_Loss:0.73758266, rdm_loss/rdm_acc = 0.72411436/0.0000000 | senti_loss/senti_acc = 0.59353443/0.8000000 | subj_loss/subj_acc = 0.98937690/0.4000000 \n",
      "MTL_Loss:0.71062713, rdm_loss/rdm_acc = 0.70022475/0.5500000 | senti_loss/senti_acc = 0.70689098/0.5300000 | subj_loss/subj_acc = 0.79758224/0.5500000 \n",
      "    20  20000|MTL_Loss:0.72729105, rdm_loss/rdm_acc = 0.71264249/0.0000000 | senti_loss/senti_acc = 0.81740638/0.3000000 | subj_loss/subj_acc = 0.75436388/0.6000000 \n",
      "    21  20000|MTL_Loss:0.72014757, rdm_loss/rdm_acc = 0.66945124/1.0000000 | senti_loss/senti_acc = 0.72332926/0.4000000 | subj_loss/subj_acc = 1.12253623/0.2000000 \n",
      "    22  20000|MTL_Loss:0.75386617, rdm_loss/rdm_acc = 0.73320884/0.0000000 | senti_loss/senti_acc = 0.73131270/0.5000000 | subj_loss/subj_acc = 0.94167815/0.4000000 \n",
      "    23  20000|MTL_Loss:0.70307910, rdm_loss/rdm_acc = 0.70999521/0.0000000 | senti_loss/senti_acc = 0.66146100/0.7000000 | subj_loss/subj_acc = 0.68936799/0.6000000 \n",
      "    24  20000|MTL_Loss:0.72809663, rdm_loss/rdm_acc = 0.72557837/0.0000000 | senti_loss/senti_acc = 0.67266300/0.6000000 | subj_loss/subj_acc = 0.80367630/0.5000000 \n",
      "    25  20000|MTL_Loss:0.70549861, rdm_loss/rdm_acc = 0.68772435/1.0000000 | senti_loss/senti_acc = 0.73321490/0.6000000 | subj_loss/subj_acc = 0.81997634/0.5000000 \n",
      "    26  20000|MTL_Loss:0.67867330, rdm_loss/rdm_acc = 0.64455390/1.0000000 | senti_loss/senti_acc = 0.76843286/0.4000000 | subj_loss/subj_acc = 0.86186898/0.4000000 \n",
      "    27  20000|MTL_Loss:0.63240165, rdm_loss/rdm_acc = 0.61258924/1.0000000 | senti_loss/senti_acc = 0.73620048/0.4000000 | subj_loss/subj_acc = 0.68710211/0.7000000 \n",
      "    28  20000|MTL_Loss:0.75572720, rdm_loss/rdm_acc = 0.75127774/0.5000000 | senti_loss/senti_acc = 0.67822152/0.4000000 | subj_loss/subj_acc = 0.86882859/0.5000000 \n",
      "    29  20000|MTL_Loss:0.73850583, rdm_loss/rdm_acc = 0.73633021/0.5000000 | senti_loss/senti_acc = 0.71046113/0.6000000 | subj_loss/subj_acc = 0.78395540/0.6000000 \n",
      "MTL_Loss:0.71432871, rdm_loss/rdm_acc = 0.69833516/0.5000000 | senti_loss/senti_acc = 0.72327032/0.4900000 | subj_loss/subj_acc = 0.83333540/0.5000000 \n",
      "    30  20000|MTL_Loss:0.65468252, rdm_loss/rdm_acc = 0.63589549/1.0000000 | senti_loss/senti_acc = 0.67899604/0.5000000 | subj_loss/subj_acc = 0.78066511/0.6000000 \n",
      "    31  20000|MTL_Loss:0.71281128, rdm_loss/rdm_acc = 0.71635437/0.5000000 | senti_loss/senti_acc = 0.68843691/0.6000000 | subj_loss/subj_acc = 0.70884066/0.6000000 \n",
      "    32  20000|MTL_Loss:0.74456620, rdm_loss/rdm_acc = 0.73687750/0.5000000 | senti_loss/senti_acc = 0.57997524/0.8000000 | subj_loss/subj_acc = 0.97066658/0.4000000 \n",
      "    33  20000|MTL_Loss:0.73118021, rdm_loss/rdm_acc = 0.72318298/0.5000000 | senti_loss/senti_acc = 0.80449235/0.4000000 | subj_loss/subj_acc = 0.72184591/0.6000000 \n"
     ]
    }
   ],
   "source": [
    "MTLTrainRDMModel(rdm_model, bert, rdm_classifier,\n",
    "                     transformer, task_embedding, senti_cls, subj_cls, \n",
    "                     senti_train_reader, subj_train_reader, \n",
    "                    tt, 20000, new_data_len=[], logger=None, cuda=True, \n",
    "                        log_dir=\"RDMBertTrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
