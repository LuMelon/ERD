{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import MyLogger\n",
    "import SubjObjLoader\n",
    "import json\n",
    "from torch import nn\n",
    "import torch\n",
    "from pytorch_transformers import *\n",
    "import importlib\n",
    "from collections import deque\n",
    "# import dataloader\n",
    "from BertRDMLoader import *\n",
    "import json\n",
    "from torch import nn\n",
    "import torch\n",
    "from pytorch_transformers import *\n",
    "import importlib\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import tsentiLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emotionLoader import *\n",
    "from SubjObjLoader import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT RDM CM 模型代码\n",
    "> 需要改动的地方\n",
    "> - 损失函数要从训练函数中拆分出来，方便后面的联合训练\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pooling_layer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(pooling_layer, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        assert(inputs.ndim == 4 ) # [batchsize, max_seq_len, max_word_num, input_dim] \n",
    "        batch_size, max_seq_len, max_word_num, input_dim = inputs.shape\n",
    "        assert(input_dim == self.input_dim)\n",
    "        t_inputs = inputs.reshape([-1, self.input_dim])\n",
    "        return self.linear(t_inputs).reshape(\n",
    "            \n",
    "            [-1, max_word_num, self.output_dim]\n",
    "        \n",
    "        ).max(axis=1)[0].reshape(\n",
    "        \n",
    "            [-1, max_seq_len, self.output_dim]\n",
    "        \n",
    "        )\n",
    "\n",
    "class RDM_Model(nn.Module):\n",
    "    def __init__(self, word_embedding_dim, sent_embedding_dim, hidden_dim, dropout_prob):\n",
    "        super(RDM_Model, self).__init__()\n",
    "        self.embedding_dim = sent_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gru_model = nn.GRU(word_embedding_dim, \n",
    "                                self.hidden_dim, \n",
    "                                batch_first=True, \n",
    "                                dropout=dropout_prob\n",
    "                            )\n",
    "        self.DropLayer = nn.Dropout(dropout_prob)\n",
    "#         self.PoolLayer = pooling_layer(word_embedding_dim, sent_embedding_dim) \n",
    "        \n",
    "    def forward(self, x_emb, x_len, init_states): \n",
    "        \"\"\"\n",
    "        input_x: [batchsize, max_seq_len, sentence_embedding_dim] \n",
    "        x_emb: [batchsize, max_seq_len, 1, embedding_dim]\n",
    "        x_len: [batchsize]\n",
    "        init_states: [batchsize, hidden_dim]\n",
    "        \"\"\"\n",
    "        batchsize, max_seq_len, _ , emb_dim = x_emb.shape\n",
    "#         pool_feature = self.PoolLayer(x_emb)\n",
    "#         sent_feature = sentiModel( \n",
    "#                 x_emb.reshape(\n",
    "#                     [-1, max_sent_len, emb_dim]\n",
    "#                 ) \n",
    "#             ).reshape(\n",
    "#                 [batchsize, max_seq_len, -1]\n",
    "#             )\n",
    "#         pooled_input_x_dp = self.DropLayer(input_x)\n",
    "        pool_feature = x_emb.reshape(\n",
    "                [-1, max_seq_len, emb_dim]\n",
    "        )\n",
    "        df_outputs, df_last_state = self.gru_model(pool_feature, init_states)\n",
    "        hidden_outs = [df_outputs[i][:x_len[i]] for i in range(batchsize)]\n",
    "        final_outs = [df_outputs[i][x_len[i]-1] for i in range(batchsize)]\n",
    "        return hidden_outs, final_outs\n",
    "\n",
    "\n",
    "class CM_Model(nn.Module):\n",
    "    def __init__(self, sentence_embedding_dim, hidden_dim, action_num):\n",
    "        super(CM_Model, self).__init__()\n",
    "        self.sentence_embedding_dim = sentence_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.action_num = action_num\n",
    "#         self.PoolLayer = pooling_layer(self.embedding_dim, \n",
    "#                                             self.hidden_dim)\n",
    "        self.DenseLayer = nn.Linear(self.hidden_dim, 64)\n",
    "        self.Classifier = nn.Linear(64, self.action_num)\n",
    "        \n",
    "    def forward(self, rdm_model, s_model, rl_input, rl_state):\n",
    "        \"\"\"\n",
    "        rl_input: [batchsize, max_word_num, sentence_embedding_dim]\n",
    "        rl_state: [1, batchsize, hidden_dim]\n",
    "        \"\"\"\n",
    "        assert(rl_input.ndim==3)\n",
    "        batchsize, max_word_num, embedding_dim = rl_input.shape\n",
    "#         assert(embedding_dim==self.embedding_dim)\n",
    "        sentence = s_model(rl_input).reshape(batch_size, 1, self.sentence_embedding_dim)\n",
    "#         pooled_rl_input = self.PoolLayer(\n",
    "#             rl_input.reshape(\n",
    "#                 [-1, 1, max_word_num, self.embedding_dim]\n",
    "#             )\n",
    "#         ).reshape([-1, 1, self.hidden_dim])\n",
    "        \n",
    "#         print(\"sentence:\", sentence.shape)\n",
    "#         print(\"rl_state:\", rl_state.shape)\n",
    "        rl_output, rl_new_state = rdm_model.gru_model(\n",
    "                                            sentence, \n",
    "                                            rl_state\n",
    "                                        )\n",
    "        rl_h1 = nn.functional.relu(\n",
    "            self.DenseLayer(\n",
    "#                 rl_state.reshape([len(rl_input), self.hidden_dim]) #it is not sure to take rl_state , rather than rl_output, as the feature\n",
    "                rl_output.reshape(\n",
    "                    [len(rl_input), self.hidden_dim]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        stopScore = self.Classifier(rl_h1)\n",
    "        isStop = stopScore.argmax(axis=1)\n",
    "        return stopScore, isStop, rl_new_state\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def layer2seq(bert, layer, cuda=False):\n",
    "    if cuda:\n",
    "        outs = [bert( torch.tensor([input_]).cuda())\n",
    "                for input_ in layer]   \n",
    "    else: \n",
    "        outs = [bert( torch.tensor([input_]))\n",
    "                    for input_ in layer]\n",
    "    states = [item[1] for item in outs]\n",
    "    return rnn_utils.pad_sequence(states, batch_first=True)\n",
    "\n",
    "def Word_ids2SeqStates(word_ids, bert, ndim, cuda=False):\n",
    "    assert(ndim == 3)\n",
    "    if cuda:\n",
    "        embedding = [layer2seq(bert, layer, cuda) for layer in word_ids]\n",
    "    else:\n",
    "        embedding = [layer2seq(bert, layer) for layer in word_ids]\n",
    "    return padding_sequence(embedding)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def Count_Accs(ylabel, preds):\n",
    "    correct_preds = np.array(\n",
    "        [1 if y1==y2 else 0 \n",
    "        for (y1, y2) in zip(ylabel, preds)]\n",
    "    )\n",
    "    y_idxs = [idx if yl >0 else idx - len(ylabel) \n",
    "            for (idx, yl) in enumerate(ylabel)]\n",
    "    pos_idxs = list(filter(lambda x: x >= 0, y_idxs))\n",
    "    neg_idxs = list(filter(lambda x: x < 0, y_idxs))\n",
    "    acc = sum(correct_preds) / (1.0 * len(ylabel))\n",
    "    if len(pos_idxs) > 0:\n",
    "        pos_acc = sum(correct_preds[pos_idxs])/(1.0*len(pos_idxs))\n",
    "    else:\n",
    "        pos_acc = 0\n",
    "    if len(neg_idxs) > 0:\n",
    "        neg_acc = sum(correct_preds[neg_idxs])/(1.0*len(neg_idxs))\n",
    "    else:\n",
    "        neg_acc = 0\n",
    "    return acc, pos_acc, neg_acc, y_idxs, pos_idxs, neg_idxs, correct_preds\n",
    "\n",
    "def Loss_Fn(ylabel, pred_scores):\n",
    "    diff = ((ylabel - pred_scores)*(ylabel - pred_scores)).mean(axis=1)\n",
    "#     pos_neg = (1.0*sum(ylabel.argmax(axis=1)))/(1.0*(len(ylabel) - sum(ylabel.argmax(axis=1))))\n",
    "    pos_neg = 0\n",
    "    if pos_neg > 0:\n",
    "        print(\"unbalanced data\")\n",
    "        weight = torch.ones(len(ylabel)).cuda() + (ylabel.argmax(axis=1).to(torch.float32)/(1.0*pos_neg)) - ylabel.argmax(axis=1).to(torch.float32)\n",
    "        return (weight *diff).mean()\n",
    "    else:\n",
    "        print(\"totally unbalanced data\")\n",
    "        return diff.mean()\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "def rdm_loss(x, y, bert, rdm_model, rdm_classifier, loss_fn):\n",
    "    x_emb = Word_ids2SeqStates(x, bert, 3, cuda=True) \n",
    "    batchsize, max_seq_len, max_sent_len, emb_dim = x_emb.shape\n",
    "    rdm_hiddens, rdm_outs = rdm_model(x_emb, x_len, init_states)\n",
    "    rdm_scores = rdm_classifier(\n",
    "        torch.cat(\n",
    "            rdm_outs # a list of tensor, where the ndim of tensor is 1 and the shape of tensor is [hidden_size]\n",
    "        ).reshape(\n",
    "            [-1, rdm_model.hidden_dim]\n",
    "        )\n",
    "    )\n",
    "    rdm_preds = rdm_scores.argmax(axis=1)\n",
    "    y_label = y.argmax(axis=1)\n",
    "    acc, _, _, _, _, _, _ = Count_Accs(y_label, rdm_preds)\n",
    "    loss = loss_fn(rdm_scores, torch.tensor(y_label).cuda())\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def TrainRDMModel(rdm_model, bert, rdm_classifier, \n",
    "                    tokenizer, t_steps, new_data_len=[], logger=None, \n",
    "                        log_dir=\"RDMBertTrain\"):\n",
    "    batch_size = 20 \n",
    "    max_gpu_batch = 5 #cannot load a larger batch into the limited memory, but we could  accumulates grads\n",
    "    assert(batch_size%max_gpu_batch == 0)\n",
    "    sum_loss = 0.0\n",
    "    sum_acc = 0.0\n",
    "    t_acc = 0.9\n",
    "    ret_acc = 0.0\n",
    "    init_states = torch.zeros([1, 5, rdm_model.hidden_dim], dtype=torch.float32).cuda()\n",
    "    weight = torch.tensor([2.0, 1.0], dtype=torch.float32).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':5e-5},\n",
    "                                {'params': rdm_classifier.parameters(), 'lr': 5e-5},\n",
    "                                {'params': rdm_model.parameters(), 'lr': 5e-5}\n",
    "                             ]\n",
    "    )\n",
    "    \n",
    "    writer = SummaryWriter(log_dir)\n",
    "    acc_l = np.zeros(int(batch_size/max_gpu_batch))\n",
    "    loss_l = np.zeros(int(batch_size/max_gpu_batch))\n",
    "    for step in range(t_steps):\n",
    "        optim.zero_grad()\n",
    "        for j in range(int(batch_size/max_gpu_batch)):\n",
    "            if len(new_data_len) > 0:\n",
    "                x, x_len, y = get_df_batch(step, max_gpu_batch, new_data_len, tokenizer=tokenizer)\n",
    "            else:\n",
    "                x, x_len, y = get_df_batch(step, max_gpu_batch, tokenizer=tokenizer)\n",
    "                \n",
    "            loss, acc = rdm_loss(x, y, bert, rdm_model, rdm_classifier, loss_fn)\n",
    "            loss.backward()\n",
    "            loss_l[j] = loss\n",
    "            acc_l[j] = acc\n",
    "            \n",
    "        optim.step()        \n",
    "        writer.add_scalar('Train Loss', loss_l.mean(), step)\n",
    "        writer.add_scalar('Train Accuracy', acc_l.mean(), step)\n",
    "\n",
    "        sum_loss += loss_l.mean()\n",
    "        sum_acc += acc_l.mean()\n",
    "        \n",
    "\n",
    "        if step % 10 == 9:\n",
    "            sum_loss = sum_loss / 10\n",
    "            sum_acc = sum_acc / 10\n",
    "            print('%3d | %d , train_loss/accuracy = %6.8f/%6.7f'             % (step, t_steps, \n",
    "                sum_loss, sum_acc,\n",
    "                ))\n",
    "            logger.info('%3d | %d , train_loss/accuracy = %6.8f/%6.7f'             % (step, t_steps, \n",
    "                sum_loss, sum_acc,\n",
    "                ))\n",
    "            if step%500 == 499:\n",
    "                rdm_save_as = '/home/hadoop/ERD/%s/rdmModel_epoch%03d.pkl'                                    % (log_dir, step/500, sum_acc)\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"bert\":bert.state_dict(),\n",
    "                        \"sentiModel\":sentiModel.state_dict(),\n",
    "                        \"rmdModel\":rdm_model.state_dict(),\n",
    "                        \"rdm_classifier\": rdm_classifierdm.state_dict()\n",
    "                    },\n",
    "                    rdm_save_as\n",
    "                )\n",
    "#                 rdm_model, bert, sentiModel, rdm_classifier\n",
    "            if sum_acc > t_acc:\n",
    "                break\n",
    "            sum_acc = 0.0\n",
    "            sum_loss = 0.0\n",
    "\n",
    "    print(get_curtime() + \" Train df Model End.\")\n",
    "    logger.info(get_curtime() + \" Train df Model End.\")\n",
    "    return ret_acc\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def TrainCMModel(bert, rdm_model, rdm_classifier, cm_model, tokenizer, log_dir, logger, FLAGS):\n",
    "    batch_size = 20\n",
    "    t_acc = 0.9\n",
    "    ids = np.array(range(batch_size), dtype=np.int32)\n",
    "    seq_states = np.zeros([batch_size], dtype=np.int32)\n",
    "    isStop = np.zeros([batch_size], dtype=np.int32)\n",
    "    max_id = batch_size\n",
    "    df_init_states = torch.zeros([1, batch_size, FLAGS.hidden_dim], dtype=torch.float32).cuda()\n",
    "    state = df_init_states\n",
    "    D = deque()\n",
    "    ssq = []\n",
    "    print(\"in RL the begining\")\n",
    "    rdm_optim = torch.optim.Adagrad([\n",
    "                            {'params': bert.parameters(), 'lr':1e-3},\n",
    "    #                                 {'params': rdm_classifier.parameters(), 'lr': 5e-2},\n",
    "                            {'params': rdm_model.parameters(), 'lr': 5e-2},\n",
    "                            {'params': sentiModel.parameters(), 'lr': 1e-2}\n",
    "                         ],\n",
    "                            weight_decay = 0.2\n",
    "    )\n",
    "    rl_optim = torch.optim.Adam([{'params':cm_model.parameters(), 'lr':1e-3}])\n",
    "    # get_new_len(sess, mm)\n",
    "    data_ID = get_data_ID()\n",
    "\n",
    "    if len(data_ID) % batch_size == 0: # the total number of events\n",
    "        flags = int(len(data_ID) / FLAGS.batch_size)\n",
    "    else:\n",
    "        flags = int(len(data_ID) / FLAGS.batch_size) + 1\n",
    "    for i in range(flags):\n",
    "        with torch.no_grad():\n",
    "            x, x_len, y = get_df_batch(i, batch_size, tokenizer=tokenizer)\n",
    "            x_emb = Word_ids2SeqStates(x, bert, 3, cuda=True) \n",
    "            batchsize, max_seq_len, max_sent_len,                                     emb_dim = x_emb.shape\n",
    "            sent_feature = sentiModel( \n",
    "                x_emb.reshape(\n",
    "                    [-1, max_sent_len, emb_dim]\n",
    "                ) \n",
    "            ).reshape(\n",
    "                [batchsize, max_seq_len, -1]\n",
    "            )\n",
    "            rdm_hiddens, rdm_outs = rdm_model(sent_feature, x_len, df_init_states)\n",
    "        #         t_ssq = sess.run(rdm_train.out_seq, feed_dic)# t_ssq = [batchsize, max_seq, scores]\n",
    "            print(\"batch %d\"%i)\n",
    "            if len(ssq) > 0:\n",
    "                ssq.extend([rdm_classifier(h) for h in rdm_hiddens])\n",
    "            else:\n",
    "                ssq = [rdm_classifier(h) for h in rdm_hiddens]\n",
    "\n",
    "    print(get_curtime() + \" Now Start RL training ...\")\n",
    "    counter = 0\n",
    "    sum_rw = 0.0 # sum of rewards\n",
    "\n",
    "    data_len = get_data_len()\n",
    "\n",
    "    while True:\n",
    "        if counter > FLAGS.OBSERVE:\n",
    "            sum_rw += np.mean(rw)\n",
    "            if counter % 200 == 0:\n",
    "                sum_rw = sum_rw / 2000\n",
    "                print( get_curtime() + \" Step: \" + str(step) \n",
    "                       + \" REWARD IS \" + str(sum_rw) \n",
    "                     )\n",
    "                logger.info( get_curtime() + \n",
    "                             \" Step: \" + str(step) + \n",
    "                            \" REWARD IS \" + str(sum_rw)\n",
    "                           )\n",
    "                if sum_rw > t_rw:\n",
    "                    print(\"Retch The Target Reward\")\n",
    "                    logger.info(\"Retch The Target Reward\")\n",
    "                    break\n",
    "                if counter > t_steps:\n",
    "                    print(\"Retch The Target Steps\")\n",
    "                    logger.info(\"Retch The Target Steps\")\n",
    "                    break\n",
    "                sum_rw = 0.0\n",
    "            s_state, s_x, s_isStop, s_rw = get_RL_Train_batch(D, FLAGS)\n",
    "            stopScore, isStop, rl_new_state = cm_model(rdm_model, sentiModel, s_x, s_state)\n",
    "            out_action = (stopScore*s_isStop).sum(axis=1)\n",
    "            rl_cost = torch.mean((s_rw - out_action)*(s_rw - out_action))\n",
    "            rl_cost.backward()\n",
    "            rl_optim.step()\n",
    "\n",
    "        input_x, input_y, ids, seq_states, max_id = get_rl_batch(ids, seq_states, isStop, max_id, 0, FLAGS, tokenizer=tokenizer)\n",
    "        with torch.no_grad():\n",
    "            x_emb = layer2seq(bert, input_x, cuda=True)\n",
    "            batchsize, max_sent_len, emb_dim = x_emb.shape\n",
    "            mss, isStop, mNewState = cm_model(rdm_model, sentiModel, x_emb, state)\n",
    "\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            if random.random() < FLAGS.random_rate:\n",
    "    #             isStop[j] = np.argmax(np.random.rand(2))\n",
    "                isStop[j] = int(torch.rand(2).argmax())\n",
    "            if seq_states[j] == data_len[ids[j]]:\n",
    "                isStop[j] = 1\n",
    "\n",
    "        # eval\n",
    "        rw = get_reward(isStop, mss, ssq, ids, seq_states)\n",
    "\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            D.append((state[0][j], input_x[j], isStop[j], rw[j]))\n",
    "            if len(D) > FLAGS.max_memory:\n",
    "                D.popleft()\n",
    "\n",
    "        state = mNewState\n",
    "        for j in range(FLAGS.batch_size):\n",
    "            if isStop[j] == 1:\n",
    "                # init_states = np.zeros([FLAGS.batch_size, FLAGS.hidden_dim], dtype=np.float32)\n",
    "                # feed_dic = {rl_model.init_states: init_states}\n",
    "                # state[j] = sess.run(rl_model.df_state, feed_dic)\n",
    "    #             state[j] = np.zeros([FLAGS.hidden_dim], dtype=np.float32)\n",
    "                state[0][j].fill_(0)\n",
    "        counter += 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 联合学习部分\n",
    "\n",
    "### 读数据\n",
    " zip 三个数据集，一次性全部读出来\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2tensor(bert, layer, cuda=False):\n",
    "    if cuda:\n",
    "        outs = [bert( torch.tensor([input_]).cuda())\n",
    "                for input_ in layer]   \n",
    "    else: \n",
    "        outs = [bert( torch.tensor([input_]))\n",
    "                    for input_ in layer]\n",
    "    states = [item[0][0] for item in outs]\n",
    "    return rnn_utils.pad_sequence(states, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> normalized the data for unbalanced learning:\n",
    "```python\n",
    "weights = WeightsForUmbalanced(emoReader.label)\n",
    "weights\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightsForUmbalanced(data_label):\n",
    "    _, _, labels = data_label.shape\n",
    "    label_cnt = data_label.reshape([-1, labels]).sum(axis=0)\n",
    "    weights = 1.0/label_cnt\n",
    "    normalized_weights = weights/sum(weights)\n",
    "    return normalized_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求各个任务的损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_loss( xst, yst, lst, \n",
    "                bert, transformer, task_emb,\n",
    "                senti_classifier, senti_loss_fn,\n",
    "                cuda=False\n",
    "               ):\n",
    "    tensors = words2tensor(bert, xst, cuda) + task_emb\n",
    "    y_label = torch.tensor(yst.argmax(axis=1)).cuda() if cuda else torch.tensor(yst.argmax(axis=1))\n",
    "    senti_feature = transformer(tensors.transpose(0, 1)).transpose(0, 1)\n",
    "    cls_feature = senti_feature.max(axis=1)[0]\n",
    "    senti_scores = senti_classifier(cls_feature)\n",
    "    loss = senti_loss_fn(senti_scores, y_label)\n",
    "    acc, _, _, _, _, _, _ = Count_Accs(y_label, senti_scores.argmax(axis=1))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subj_loss(  xsj, ysj, lsj,\n",
    "                bert, transformer, task_emb,\n",
    "                subj_classifier, subj_loss_fn,\n",
    "                cuda=False\n",
    "               ):\n",
    "    tensors = words2tensor(bert, xsj, cuda) + task_emb\n",
    "    y_label = torch.tensor(ysj.argmax(axis=1)) if not cuda else torch.tensor(ysj.argmax(axis=1)).cuda()\n",
    "    subj_feature = transformer(tensors.transpose(0, 1)).transpose(0, 1)\n",
    "    cls_feature = subj_feature.max(axis=1)[0]\n",
    "    subj_scores = subj_classifier(cls_feature)\n",
    "    loss = subj_loss_fn(subj_scores, y_label)\n",
    "    acc, _, _, _, _, _, _ = Count_Accs(y_label, subj_scores.argmax(axis=1))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_loss(   xem, yem, lem,\n",
    "                    bert, transformer, task_emb,\n",
    "                    emotion_classifier, emo_loss_fn, \n",
    "                    cuda\n",
    "                ):\n",
    "    tensors = words2tensor(bert, xem, cuda) + task_emb\n",
    "    y_label = torch.tensor(yem.argmax(axis=1)) if not cuda else torch.tensor(yem.argmax(axis=1)).cuda()\n",
    "    emo_feature = transformer(tensors.transpose(0, 1)).transpose(0, 1)\n",
    "    cls_feature = emo_feature.max(axis=1)[0]\n",
    "    emo_scores = emotion_classifier(cls_feature)\n",
    "    loss = emo_loss_fn(emo_scores, y_label)\n",
    "    acc, _, _, _, _, _, _ = Count_Accs(y_label, emo_scores.argmax(axis=1))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练各个任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_cls_train(emotion_reader, bert, transformer, \n",
    "                  task_embedding, emotion_classifier,\n",
    "                  train_epochs, emo_loss_fn,\n",
    "                  cuda=False\n",
    "                 ):\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':1e-6},\n",
    "                                {'params': task_embedding.parameters(), 'lr':5e-5},\n",
    "                                {'params': transformer.parameters(), 'lr': 5e-5},\n",
    "                                {'params': emotion_classifier.parameters(), 'lr': 5e-5}\n",
    "                             ]\n",
    "    )\n",
    "    losses = np.zeros([10]) \n",
    "    accs = np.zeros([10])\n",
    "    \n",
    "    task_emb = task_embedding(torch.tensor([2]).cuda()) if cuda else task_embedding(torch.tensor([2]))\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    for epoch in range(train_epochs):\n",
    "        step = 0\n",
    "        for x, y, l in emotion_reader.iter():\n",
    "            emo_loss, emo_acc = emotion_loss(\n",
    "                                            x, y, l,\n",
    "                                            bert, transformer, task_emb,\n",
    "                                            emotion_classifier, emo_loss_fn, \n",
    "                                            cuda\n",
    "                                   )\n",
    "            emo_loss.backward(retain_graph=True)\n",
    "            optim.step()\n",
    "            losses[int(step%10)] = emo_loss.cpu()\n",
    "            accs[int(step%10)] = emo_acc\n",
    "            print(\"step:%d | loss/acc = %.3f/%.3f\"%(step, emo_loss, emo_acc))\n",
    "            if step %10 == 9:\n",
    "                print('emotion task: %6d: [%5d/%5d], senti_loss/senti_acc = %6.8f/%6.7f ' % ( step,\n",
    "                                                                                epoch, train_epochs,\n",
    "                                                                                losses.mean(), accs.mean(),\n",
    "                                                                            )\n",
    "                         )       \n",
    "            step += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subj_cls_train(subj_reader, bert, transformer, task_embedding,\n",
    "                   subj_classifier, train_epochs, subj_loss_fn,\n",
    "                   cuda=False\n",
    "                  ):\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':1e-6},\n",
    "                                {'params': task_embedding.parameters(), 'lr':5e-5},\n",
    "                                {'params': transformer.parameters(), 'lr': 5e-5},\n",
    "                                {'params': subj_classifier.parameters(), 'lr': 5e-5}\n",
    "                             ]\n",
    "    )\n",
    "    losses = np.zeros([10]) \n",
    "    accs = np.zeros([10])\n",
    "    task_emb = task_embedding(torch.tensor([1]).cuda()) if cuda else task_embedding(torch.tensor([1]))\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    for epoch in range(train_epochs):\n",
    "        step = 0\n",
    "        for x, y, l in subj_reader.iter():\n",
    "            sj_loss, sj_acc = subj_loss(x, y, l,\n",
    "                                    bert, transformer, task_emb,\n",
    "                                    subj_classifier, subj_loss_fn, \n",
    "                                    cuda\n",
    "                                   )\n",
    "            sj_loss.backward(retain_graph=True)\n",
    "            optim.step()\n",
    "            losses[int(step%10)] = sj_loss.cpu()\n",
    "            accs[int(step%10)] = sj_acc\n",
    "            print(\"step:%d | loss/acc = %.3f/%.3f\"%(step, sj_loss, sj_acc))\n",
    "            if step %10 == 9:\n",
    "                print('subjective task: %6d: [%5d/%5d], senti_loss/senti_acc = %6.8f/%6.7f ' % ( step,\n",
    "                                                                                epoch, train_epochs,\n",
    "                                                                                losses.mean(), accs.mean(),\n",
    "                                                                            )\n",
    "                         )       \n",
    "            step += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_cls_train(senti_reader, bert, transformer,\n",
    "                    task_embedding, senti_classifier,\n",
    "                    train_epochs, senti_loss_fn,\n",
    "                    cuda=False\n",
    "                   ):\n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':1e-6},\n",
    "                                {'params': task_embedding.parameters(), 'lr':1e-5},\n",
    "                                {'params': transformer.parameters(), 'lr': 1e-5},\n",
    "                                {'params': senti_classifier.parameters(), 'lr': 1e-5}\n",
    "                             ]\n",
    "    )\n",
    "    losses = np.zeros([10]) \n",
    "    accs = np.zeros([10])\n",
    "    \n",
    "    task_emb = task_embedding(torch.tensor([0]).cuda()) if cuda else task_embedding(torch.tensor([0]))\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    for epoch in range(train_epochs):\n",
    "        step = 0\n",
    "        for x, y, l in senti_reader.iter():\n",
    "            st_loss, st_acc = senti_loss(x, y, l, \n",
    "                                    bert, transformer, task_emb,\n",
    "                                    senti_classifier, senti_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "            st_loss.backward(retain_graph=True)\n",
    "            optim.step()\n",
    "            losses[int(step%10)] = st_loss.cpu()\n",
    "            accs[int(step%10)] = st_acc\n",
    "            print(\"step:%d | loss/acc = %.3f/%.3f\"%(step, st_loss, st_acc))\n",
    "            if step %10 == 9:\n",
    "                print('sentiment task: %6d: [%5d/%5d], senti_loss/senti_acc = %6.8f/%6.7f ' % ( step,\n",
    "                                                                                epoch, train_epochs,\n",
    "                                                                                losses.mean(), accs.mean(),\n",
    "                                                                            )\n",
    "                         )       \n",
    "            step += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 联合训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.random.rand(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48045042, 0.54320519, 0.42130933])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JointLearning(senti_reader, subj_reader, emotion_reader, \n",
    "                  bert, transformer, task_embedding, \n",
    "                  senti_classifier, subj_classifier, emotion_classifier,\n",
    "                  cuda=False\n",
    "                 ):\n",
    "    # stage 1: deploy the trainning on the senti classification task\n",
    "    senti_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                senti_reader.label\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "    )\n",
    "    senti_loss_fn = nn.CrossEntropyLoss(weight=senti_weights.cuda()) if cuda else nn.CrossEntropyLoss(weight=senti_weights)\n",
    "#     senti_cls_train(\n",
    "#                     senti_reader, \n",
    "#                     bert, \n",
    "#                     transformer, \n",
    "#                     task_embedding, \n",
    "#                     senti_classifier, \n",
    "#                     2, \n",
    "#                     senti_loss_fn\n",
    "#                    )\n",
    "#     senti_reader.reset_batchsize(5)\n",
    "    #stage 2: deploy the trainning on the subj classification task\n",
    "    subj_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                subj_reader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    )\n",
    "    subj_loss_fn = nn.CrossEntropyLoss(weight=subj_weights) if not cuda else nn.CrossEntropyLoss(weight=subj_weights.cuda())\n",
    "#     subj_cls_train(\n",
    "#                    subj_reader, \n",
    "#                    bert, \n",
    "#                    transformer, \n",
    "#                    task_embedding, \n",
    "#                    subj_classifier, \n",
    "#                    2, \n",
    "#                    subj_loss_fn\n",
    "#                   )\n",
    "#     subj_reader.reset_batchsize(5)\n",
    "    #stage 3: deploy the trainning on the emotion classification task\n",
    "    emo_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                emotion_reader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    )\n",
    "    emo_loss_fn = nn.CrossEntropyLoss(weight=emo_weights) if not cuda else nn.CrossEntropyLoss(weight=emo_weights.cuda())\n",
    "#     emo_cls_train(\n",
    "#         emotion_reader, \n",
    "#         bert, \n",
    "#         transformer, \n",
    "#         task_embedding, \n",
    "#         emotion_classifier, \n",
    "#         2, \n",
    "#         emo_loss_fn\n",
    "#     )\n",
    "#     emotion_reader.reset_batchsize(5)    \n",
    "    \n",
    "    optim = torch.optim.Adagrad([\n",
    "                                {'params': bert.parameters(), 'lr':1e-6},\n",
    "                                {'params': task_embedding.parameters(), 'lr':1e-5},\n",
    "                                {'params': transformer.parameters(), 'lr': 1e-5},\n",
    "                                {'params': senti_classifier.parameters(), 'lr': 1e-5},\n",
    "                                {'params': subj_classifier.parameters(), 'lr':1e-5},\n",
    "                                {'params': emotion_classifier.parameters(), 'lr':1e-5}\n",
    "                             ]\n",
    "    )\n",
    "    \n",
    "#     writer = SummaryWriter(log_dir)\n",
    "    max_epoch = 100\n",
    "    \n",
    "    losses = np.zeros([3, 10]) \n",
    "    accs = np.zeros([3, 10])\n",
    "    # [[senti_loss_1, ..., senti_loss_10], [subj_loss_1, ..., subj_loss_10], [emo_loss_1, ..., emo_loss_10]] \n",
    "    senti_task_id = torch.tensor([0]) if not cuda else torch.tensor([0]).cuda()\n",
    "    subj_task_id = torch.tensor([1]) if not cuda else torch.tensor([1]).cuda()\n",
    "    emo_task_id = torch.tensor([2]) if not cuda else torch.tensor([2]).cuda()\n",
    "    \n",
    "    loss_weight = torch.tensor([0.333, 0.333, 0.333]) if not cuda else torch.tensor([0.333, 0.333, 0.333]).cuda()\n",
    "    \n",
    "    batchs = min(senti_reader.label.shape[0], subj_reader.label.shape[0], emotion_reader.label.shape[0])\n",
    "    optim.zero_grad()\n",
    "    for epoch in range(max_epoch):\n",
    "        step = 0\n",
    "        for ((xst, yst, lst), (xsj, ysj, lsj), (xem, yem, lem)) in zip(senti_reader.iter(), subj_reader.iter(), emotion_reader.iter()):\n",
    "            st_loss, st_acc = senti_loss(xst, yst, lst, \n",
    "                                    bert, transformer, task_embedding(senti_task_id),\n",
    "                                    senti_classifier, senti_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "#             st_loss.backward()\n",
    "            MTL_Loss = st_loss*loss_weight[0]\n",
    "    \n",
    "            losses[0][step%10] = st_loss.tolist()\n",
    "            accs[0][step%10] = st_acc\n",
    "             \n",
    "            sj_loss, sj_acc = subj_loss(xsj, ysj, lsj,\n",
    "                                    bert, transformer, task_embedding(subj_task_id),\n",
    "                                    subj_classifier, subj_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "#             sj_loss.backward()\n",
    "            MTL_Loss += sj_loss*loss_weight[1]\n",
    "\n",
    "            losses[1][step%10] = sj_loss.tolist()\n",
    "            accs[1][step%10] = sj_acc\n",
    "            \n",
    "            emo_loss, emo_acc = emotion_loss(xem, yem, lem,\n",
    "                                    bert, transformer, task_embedding(emo_task_id),\n",
    "                                    emotion_classifier, emo_loss_fn,\n",
    "                                    cuda\n",
    "                                   )\n",
    "#             emo_loss.backward()\n",
    "            MTL_Loss += emo_loss*loss_weight[2]\n",
    "    \n",
    "            losses[2][step%10] = emo_loss.tolist()\n",
    "            accs[2][step%10] = emo_acc\n",
    "            \n",
    "            MTL_Loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            print(\"%6d|MTL_Loss:%6.8f, senti_loss/senti_acc = %6.8f/%6.7f | subj_loss/subj_acc = %6.8f/%6.7f | emo_loss/emo_acc = %6.8f/%6.7f\" % (\n",
    "                                                                                                step, MTL_Loss,        \n",
    "                                                                                                losses[0].mean(), accs[0].mean(),\n",
    "                                                                                                losses[1].mean(), accs[1].mean(),\n",
    "                                                                                                losses[2].mean(), accs[2].mean()\n",
    "            )\n",
    "            )\n",
    "            if step % 10 == 9:\n",
    "                print('%6d: [%5d/%5d], MTL_Loss|%6.8f, senti_loss/senti_acc = %6.8f/%6.7f | subj_loss/subj_acc = %6.8f/%6.7f | emo_loss/emo_acc = %6.8f/%6.7f' % (\n",
    "                                                                                                step,\n",
    "                                                                                                epoch,max_epoch, MTL_Loss,\n",
    "                                                                                                losses[0].mean(), accs[0].mean(),\n",
    "                                                                                                losses[1].mean(), accs[1].mean(),\n",
    "                                                                                                losses[2].mean(), accs[2].mean()\n",
    "                                                                                            )\n",
    "                     )\n",
    "                loss_weight = torch.tensor(\n",
    "                                            (1.0/accs.mean(axis=1))/sum(1.0/accs.mean(axis=1)),\n",
    "                                            dtype=torch.float32\n",
    "                                )\n",
    "                print(\"\\n\\n loss_weight:\", loss_weight)\n",
    "            step += 1\n",
    "        joint_model_save_as = '/home/hadoop/ERD/MTLTrain/jointModel_epoch%03d.pkl'% (epoch)\n",
    "        torch.save(\n",
    "            {\n",
    "                \"bert\":bert.state_dict(),\n",
    "                \"transformer\":transformer.state_dict(),\n",
    "                \"task_embedding\":task_embedding.state_dict(),\n",
    "                \"senti_classifier\": senti_classifier.state_dict(),\n",
    "                \"subj_classifier\": subj_classifier.state_dict(),\n",
    "                \"emotion_classifier\": emotion_classifier.state_dict()\n",
    "            },\n",
    "            rdm_save_as\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主函数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = BertTokenizer.from_pretrained(\"bert-base-uncased\", cached_dir = \"/home/hadoop/transformer_pretrained_models/bert-base-uncased-pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embedding = nn.Embedding(3, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(768, 8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_file = \"/home/hadoop/rotten_imdb/subj.data\"\n",
    "obj_file = \"/home/hadoop/rotten_imdb/obj.data\"\n",
    "tr, dev, te = load_data(subj_file, obj_file)\n",
    "\n",
    "subj_train_reader = SubjObjReader(tr, 20, tt)\n",
    "subj_valid_reader = SubjObjReader(dev, 20, tt)\n",
    "subj_test_reader =  SubjObjReader(te, 20, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_cls = nn.Linear(768, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = bb.cuda()\n",
    "transformer = transformer_encoder.cuda()\n",
    "task_embedding = task_embedding.cuda()\n",
    "subj_cls = subj_cls.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调试各个任务的部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 调试subjective的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subj_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                subj_train_reader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    ).cuda()\n",
    "subj_loss_fn = nn.CrossEntropyLoss(weight=subj_weights)\n",
    "subj_cls_train(subj_train_reader, bert, transformer, task_embedding, subj_cls, 1, subj_loss_fn, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> __test code__\n",
    "``` python\n",
    "for xsj, ysj, lsj in subj_train_reader.iter():\n",
    "    loss = subj_loss(  xsj, ysj, lsj,\n",
    "                bb, transformer_encoder, task_embedding(torch.tensor([1])),\n",
    "                subj_cls, subj_loss_fn\n",
    "               )\n",
    "    break\n",
    "```\n",
    "> __train stage__\n",
    "```python\n",
    "subj_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                subj_train_reader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    ).cuda()\n",
    "subj_loss_fn = nn.CrossEntropyLoss(weight=subj_weights)\n",
    "subj_cls_train(subj_train_reader, bert, transformer, task_embedding, subj_cls, 1, subj_loss_fn, cuda=True)\n",
    "```\n",
    "_subj task 的训练，在当前的参数配置下，一个ｅｐｏｃｈ可以调到很好的状态_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调试sentiment 的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hadoop/trainingandtestdata/training.1600000.processed.noemoticon.csv\n",
      "/home/hadoop/trainingandtestdata/testdata.manual.2009.06.14.csv\n"
     ]
    }
   ],
   "source": [
    "train_file = \"/home/hadoop/trainingandtestdata/training.1600000.processed.noemoticon.csv\"\n",
    "test_file = \"/home/hadoop/trainingandtestdata/testdata.manual.2009.06.14.csv\"\n",
    "train_set, test_set = tsentiLoader.load_data(train_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_train_reader = tsentiLoader.tSentiReader(train_set[:10000], 20, tt)\n",
    "senti_train_reader.label = np.delete(senti_train_reader.label, 1, axis=2)\n",
    "# senti_valid_reader = tsentiLoader.tSentiReader(train_set[10000:10100], 20, tt)\n",
    "# senti_test_reader =  tsentiLoader.tSentiReader(test_set, 20, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_cls = nn.Linear(768, 2).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __测试sentiment analysis的task__\n",
    "``` python\n",
    "senti_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                senti_train_reader.label\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "    )\n",
    "senti_loss_fn = nn.CrossEntropyLoss(weight=senti_weights.cuda())\n",
    "senti_cls_train(senti_train_reader, bert, transformer,\n",
    "                    task_embedding, senti_cls,\n",
    "                    2, senti_loss_fn,\n",
    "                    cuda=True\n",
    "                   )\n",
    "``` \n",
    "_这个任务至少需要５个ｅｐｏｃｈ才能训练出来个大概的样子_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### 测试结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "```\n",
    "step:0 | loss/acc = 0.722/0.500\n",
    "step:1 | loss/acc = 0.721/0.550\n",
    "step:2 | loss/acc = 0.735/0.350\n",
    "step:3 | loss/acc = 0.721/0.350\n",
    "step:4 | loss/acc = 0.715/0.400\n",
    "step:5 | loss/acc = 0.748/0.250\n",
    "step:6 | loss/acc = 0.737/0.400\n",
    "step:7 | loss/acc = 0.700/0.550\n",
    "step:8 | loss/acc = 0.734/0.350\n",
    "step:9 | loss/acc = 0.749/0.450\n",
    "sentiment task:      9: [    0/    2], senti_loss/senti_acc = 0.72812036/0.4150000 \n",
    "step:10 | loss/acc = 0.700/0.500\n",
    "step:11 | loss/acc = 0.690/0.500\n",
    "step:12 | loss/acc = 0.700/0.500\n",
    "step:13 | loss/acc = 0.666/0.650\n",
    "step:14 | loss/acc = 0.663/0.600\n",
    "step:15 | loss/acc = 0.705/0.400\n",
    "step:16 | loss/acc = 0.678/0.600\n",
    "step:17 | loss/acc = 0.673/0.600\n",
    "step:18 | loss/acc = 0.678/0.550\n",
    "step:19 | loss/acc = 0.729/0.400\n",
    "sentiment task:     19: [    0/    2], senti_loss/senti_acc = 0.68820736/0.5300000 \n",
    "step:20 | loss/acc = 0.693/0.450\n",
    "step:21 | loss/acc = 0.710/0.300\n",
    "step:22 | loss/acc = 0.697/0.500\n",
    "step:23 | loss/acc = 0.659/0.800\n",
    "step:24 | loss/acc = 0.680/0.550\n",
    "step:25 | loss/acc = 0.706/0.500\n",
    "step:26 | loss/acc = 0.714/0.350\n",
    "step:27 | loss/acc = 0.704/0.600\n",
    "step:28 | loss/acc = 0.677/0.600\n",
    "step:29 | loss/acc = 0.667/0.550\n",
    "sentiment task:     29: [    0/    2], senti_loss/senti_acc = 0.69077948/0.5200000 \n",
    "step:30 | loss/acc = 0.691/0.550\n",
    "step:31 | loss/acc = 0.720/0.500\n",
    "step:32 | loss/acc = 0.683/0.600\n",
    "step:33 | loss/acc = 0.717/0.500\n",
    "step:34 | loss/acc = 0.729/0.450\n",
    "step:35 | loss/acc = 0.651/0.650\n",
    "step:36 | loss/acc = 0.770/0.400\n",
    "step:37 | loss/acc = 0.780/0.400\n",
    "step:38 | loss/acc = 0.614/0.650\n",
    "step:39 | loss/acc = 0.699/0.500\n",
    "sentiment task:     39: [    0/    2], senti_loss/senti_acc = 0.70538692/0.5200000 \n",
    "step:40 | loss/acc = 0.778/0.450\n",
    "step:41 | loss/acc = 0.767/0.350\n",
    "step:42 | loss/acc = 0.719/0.550\n",
    "step:43 | loss/acc = 0.750/0.400\n",
    "step:44 | loss/acc = 0.670/0.550\n",
    "step:45 | loss/acc = 0.665/0.500\n",
    "step:46 | loss/acc = 0.665/0.750\n",
    "step:47 | loss/acc = 0.682/0.600\n",
    "step:48 | loss/acc = 0.660/0.550\n",
    "step:49 | loss/acc = 0.653/0.600\n",
    "sentiment task:     49: [    0/    2], senti_loss/senti_acc = 0.70080397/0.5300000 \n",
    "step:50 | loss/acc = 0.698/0.500\n",
    "step:51 | loss/acc = 0.661/0.700\n",
    "step:52 | loss/acc = 0.731/0.350\n",
    "step:53 | loss/acc = 0.697/0.500\n",
    "step:54 | loss/acc = 0.712/0.450\n",
    "step:55 | loss/acc = 0.691/0.600\n",
    "step:56 | loss/acc = 0.686/0.600\n",
    "step:57 | loss/acc = 0.675/0.600\n",
    "step:58 | loss/acc = 0.630/0.650\n",
    "step:59 | loss/acc = 0.710/0.450\n",
    "sentiment task:     59: [    0/    2], senti_loss/senti_acc = 0.68888318/0.5400000 \n",
    "step:60 | loss/acc = 0.773/0.350\n",
    "step:61 | loss/acc = 0.698/0.500\n",
    "step:62 | loss/acc = 0.612/0.750\n",
    "step:63 | loss/acc = 0.758/0.250\n",
    "step:64 | loss/acc = 0.680/0.450\n",
    "step:65 | loss/acc = 0.727/0.450\n",
    "step:66 | loss/acc = 0.698/0.500\n",
    "step:67 | loss/acc = 0.733/0.400\n",
    "step:68 | loss/acc = 0.660/0.650\n",
    "step:69 | loss/acc = 0.623/0.700\n",
    "sentiment task:     69: [    0/    2], senti_loss/senti_acc = 0.69631069/0.5000000 \n",
    "step:70 | loss/acc = 0.736/0.450\n",
    "step:71 | loss/acc = 0.664/0.600\n",
    "step:72 | loss/acc = 0.688/0.550\n",
    "step:73 | loss/acc = 0.681/0.600\n",
    "step:74 | loss/acc = 0.672/0.550\n",
    "step:75 | loss/acc = 0.678/0.650\n",
    "step:76 | loss/acc = 0.664/0.650\n",
    "step:77 | loss/acc = 0.658/0.700\n",
    "step:78 | loss/acc = 0.700/0.500\n",
    "step:79 | loss/acc = 0.677/0.500\n",
    "sentiment task:     79: [    0/    2], senti_loss/senti_acc = 0.68184948/0.5750000 \n",
    "step:80 | loss/acc = 0.743/0.400\n",
    "step:81 | loss/acc = 0.695/0.650\n",
    "step:82 | loss/acc = 0.728/0.450\n",
    "step:83 | loss/acc = 0.678/0.550\n",
    "step:84 | loss/acc = 0.666/0.650\n",
    "step:85 | loss/acc = 0.603/0.900\n",
    "step:86 | loss/acc = 0.652/0.750\n",
    "step:87 | loss/acc = 0.693/0.450\n",
    "step:88 | loss/acc = 0.668/0.650\n",
    "step:89 | loss/acc = 0.685/0.600\n",
    "sentiment task:     89: [    0/    2], senti_loss/senti_acc = 0.68111634/0.6050000 \n",
    "step:90 | loss/acc = 0.679/0.650\n",
    "step:91 | loss/acc = 0.704/0.400\n",
    "step:92 | loss/acc = 0.662/0.650\n",
    "step:93 | loss/acc = 0.685/0.450\n",
    "step:94 | loss/acc = 0.662/0.650\n",
    "step:95 | loss/acc = 0.618/0.850\n",
    "step:96 | loss/acc = 0.681/0.550\n",
    "step:97 | loss/acc = 0.667/0.550\n",
    "step:98 | loss/acc = 0.669/0.650\n",
    "step:99 | loss/acc = 0.671/0.750\n",
    "sentiment task:     99: [    0/    2], senti_loss/senti_acc = 0.66978027/0.6150000 \n",
    "step:100 | loss/acc = 0.687/0.650\n",
    "step:101 | loss/acc = 0.663/0.600\n",
    "step:102 | loss/acc = 0.709/0.500\n",
    "step:103 | loss/acc = 0.679/0.500\n",
    "step:104 | loss/acc = 0.663/0.550\n",
    "step:105 | loss/acc = 0.685/0.550\n",
    "step:106 | loss/acc = 0.674/0.650\n",
    "step:107 | loss/acc = 0.670/0.700\n",
    "step:108 | loss/acc = 0.679/0.550\n",
    "step:109 | loss/acc = 0.642/0.650\n",
    "sentiment task:    109: [    0/    2], senti_loss/senti_acc = 0.67511485/0.5900000 \n",
    "step:110 | loss/acc = 0.656/0.650\n",
    "step:111 | loss/acc = 0.664/0.700\n",
    "step:112 | loss/acc = 0.662/0.700\n",
    "step:113 | loss/acc = 0.719/0.300\n",
    "step:114 | loss/acc = 0.710/0.400\n",
    "step:115 | loss/acc = 0.634/0.800\n",
    "step:116 | loss/acc = 0.636/0.650\n",
    "step:117 | loss/acc = 0.671/0.600\n",
    "step:118 | loss/acc = 0.672/0.550\n",
    "step:119 | loss/acc = 0.662/0.600\n",
    "sentiment task:    119: [    0/    2], senti_loss/senti_acc = 0.66869312/0.5950000 \n",
    "step:120 | loss/acc = 0.714/0.500\n",
    "step:121 | loss/acc = 0.698/0.450\n",
    "step:122 | loss/acc = 0.701/0.550\n",
    "step:123 | loss/acc = 0.682/0.600\n",
    "step:124 | loss/acc = 0.627/0.600\n",
    "step:125 | loss/acc = 0.649/0.700\n",
    "step:126 | loss/acc = 0.612/0.800\n",
    "step:127 | loss/acc = 0.616/0.750\n",
    "step:128 | loss/acc = 0.689/0.550\n",
    "step:129 | loss/acc = 0.648/0.700\n",
    "sentiment task:    129: [    0/    2], senti_loss/senti_acc = 0.66370292/0.6200000 \n",
    "step:130 | loss/acc = 0.675/0.600\n",
    "step:131 | loss/acc = 0.609/0.750\n",
    "step:132 | loss/acc = 0.647/0.750\n",
    "step:133 | loss/acc = 0.657/0.650\n",
    "step:134 | loss/acc = 0.679/0.500\n",
    "step:135 | loss/acc = 0.675/0.600\n",
    "step:136 | loss/acc = 0.655/0.650\n",
    "step:137 | loss/acc = 0.696/0.650\n",
    "step:138 | loss/acc = 0.674/0.600\n",
    "step:139 | loss/acc = 0.652/0.700\n",
    "sentiment task:    139: [    0/    2], senti_loss/senti_acc = 0.66198154/0.6450000 \n",
    "step:140 | loss/acc = 0.675/0.500\n",
    "step:141 | loss/acc = 0.638/0.700\n",
    "step:142 | loss/acc = 0.644/0.750\n",
    "step:143 | loss/acc = 0.660/0.550\n",
    "step:144 | loss/acc = 0.604/0.700\n",
    "step:145 | loss/acc = 0.644/0.700\n",
    "step:146 | loss/acc = 0.741/0.350\n",
    "step:147 | loss/acc = 0.658/0.500\n",
    "step:148 | loss/acc = 0.696/0.500\n",
    "step:149 | loss/acc = 0.684/0.550\n",
    "sentiment task:    149: [    0/    2], senti_loss/senti_acc = 0.66451840/0.5800000 \n",
    "step:150 | loss/acc = 0.746/0.350\n",
    "step:151 | loss/acc = 0.696/0.450\n",
    "step:152 | loss/acc = 0.704/0.650\n",
    "step:153 | loss/acc = 0.660/0.550\n",
    "step:154 | loss/acc = 0.644/0.600\n",
    "step:155 | loss/acc = 0.674/0.500\n",
    "step:156 | loss/acc = 0.689/0.600\n",
    "step:157 | loss/acc = 0.665/0.650\n",
    "step:158 | loss/acc = 0.732/0.300\n",
    "step:159 | loss/acc = 0.683/0.550\n",
    "sentiment task:    159: [    0/    2], senti_loss/senti_acc = 0.68921372/0.5200000 \n",
    "step:160 | loss/acc = 0.646/0.650\n",
    "step:161 | loss/acc = 0.616/0.800\n",
    "step:162 | loss/acc = 0.646/0.650\n",
    "step:163 | loss/acc = 0.650/0.550\n",
    "step:164 | loss/acc = 0.688/0.600\n",
    "step:165 | loss/acc = 0.660/0.700\n",
    "step:166 | loss/acc = 0.643/0.650\n",
    "step:167 | loss/acc = 0.687/0.500\n",
    "step:168 | loss/acc = 0.662/0.550\n",
    "step:169 | loss/acc = 0.649/0.650\n",
    "sentiment task:    169: [    0/    2], senti_loss/senti_acc = 0.65483198/0.6300000 \n",
    "step:170 | loss/acc = 0.669/0.600\n",
    "step:171 | loss/acc = 0.678/0.550\n",
    "step:172 | loss/acc = 0.615/0.750\n",
    "step:173 | loss/acc = 0.658/0.600\n",
    "step:174 | loss/acc = 0.646/0.750\n",
    "step:175 | loss/acc = 0.677/0.650\n",
    "step:176 | loss/acc = 0.683/0.450\n",
    "step:177 | loss/acc = 0.658/0.650\n",
    "step:178 | loss/acc = 0.661/0.600\n",
    "step:179 | loss/acc = 0.725/0.500\n",
    "sentiment task:    179: [    0/    2], senti_loss/senti_acc = 0.66686422/0.6100000 \n",
    "step:180 | loss/acc = 0.708/0.500\n",
    "step:181 | loss/acc = 0.615/0.700\n",
    "step:182 | loss/acc = 0.644/0.750\n",
    "step:183 | loss/acc = 0.668/0.450\n",
    "step:184 | loss/acc = 0.665/0.650\n",
    "step:185 | loss/acc = 0.622/0.650\n",
    "step:186 | loss/acc = 0.569/0.950\n",
    "step:187 | loss/acc = 0.666/0.600\n",
    "step:188 | loss/acc = 0.637/0.650\n",
    "step:189 | loss/acc = 0.618/0.750\n",
    "sentiment task:    189: [    0/    2], senti_loss/senti_acc = 0.64113842/0.6650000 \n",
    "step:190 | loss/acc = 0.710/0.550\n",
    "step:191 | loss/acc = 0.672/0.650\n",
    "step:192 | loss/acc = 0.667/0.600\n",
    "step:193 | loss/acc = 0.686/0.400\n",
    "step:194 | loss/acc = 0.584/0.750\n",
    "step:195 | loss/acc = 0.689/0.500\n",
    "step:196 | loss/acc = 0.701/0.500\n",
    "step:197 | loss/acc = 0.645/0.600\n",
    "step:198 | loss/acc = 0.665/0.600\n",
    "step:199 | loss/acc = 0.632/0.600\n",
    "sentiment task:    199: [    0/    2], senti_loss/senti_acc = 0.66506463/0.5750000 \n",
    "step:200 | loss/acc = 0.707/0.500\n",
    "step:201 | loss/acc = 0.600/0.750\n",
    "step:202 | loss/acc = 0.589/0.750\n",
    "step:203 | loss/acc = 0.668/0.550\n",
    "step:204 | loss/acc = 0.683/0.600\n",
    "step:205 | loss/acc = 0.707/0.500\n",
    "step:206 | loss/acc = 0.689/0.450\n",
    "step:207 | loss/acc = 0.589/0.800\n",
    "step:208 | loss/acc = 0.583/0.750\n",
    "step:209 | loss/acc = 0.703/0.500\n",
    "sentiment task:    209: [    0/    2], senti_loss/senti_acc = 0.65180305/0.6150000 \n",
    "step:210 | loss/acc = 0.700/0.400\n",
    "step:211 | loss/acc = 0.691/0.600\n",
    "step:212 | loss/acc = 0.661/0.700\n",
    "step:213 | loss/acc = 0.605/0.750\n",
    "step:214 | loss/acc = 0.672/0.550\n",
    "step:215 | loss/acc = 0.583/0.800\n",
    "step:216 | loss/acc = 0.695/0.450\n",
    "step:217 | loss/acc = 0.737/0.450\n",
    "step:218 | loss/acc = 0.673/0.550\n",
    "step:219 | loss/acc = 0.671/0.550\n",
    "sentiment task:    219: [    0/    2], senti_loss/senti_acc = 0.66885846/0.5800000 \n",
    "step:220 | loss/acc = 0.635/0.700\n",
    "step:221 | loss/acc = 0.693/0.550\n",
    "step:222 | loss/acc = 0.601/0.750\n",
    "step:223 | loss/acc = 0.639/0.650\n",
    "step:224 | loss/acc = 0.582/0.800\n",
    "step:225 | loss/acc = 0.673/0.600\n",
    "step:226 | loss/acc = 0.647/0.650\n",
    "step:227 | loss/acc = 0.665/0.600\n",
    "step:228 | loss/acc = 0.649/0.700\n",
    "step:229 | loss/acc = 0.609/0.700\n",
    "sentiment task:    229: [    0/    2], senti_loss/senti_acc = 0.63940636/0.6700000 \n",
    "step:230 | loss/acc = 0.674/0.750\n",
    "step:231 | loss/acc = 0.605/0.900\n",
    "step:232 | loss/acc = 0.669/0.650\n",
    "step:233 | loss/acc = 0.661/0.550\n",
    "step:234 | loss/acc = 0.694/0.500\n",
    "step:235 | loss/acc = 0.630/0.700\n",
    "step:236 | loss/acc = 0.651/0.600\n",
    "step:237 | loss/acc = 0.668/0.550\n",
    "step:238 | loss/acc = 0.725/0.500\n",
    "step:239 | loss/acc = 0.691/0.450\n",
    "sentiment task:    239: [    0/    2], senti_loss/senti_acc = 0.66687196/0.6150000 \n",
    "step:240 | loss/acc = 0.657/0.600\n",
    "step:241 | loss/acc = 0.620/0.800\n",
    "step:242 | loss/acc = 0.684/0.550\n",
    "step:243 | loss/acc = 0.695/0.600\n",
    "step:244 | loss/acc = 0.715/0.500\n",
    "step:245 | loss/acc = 0.629/0.650\n",
    "step:246 | loss/acc = 0.662/0.550\n",
    "step:247 | loss/acc = 0.619/0.700\n",
    "step:248 | loss/acc = 0.702/0.550\n",
    "step:249 | loss/acc = 0.623/0.700\n",
    "sentiment task:    249: [    0/    2], senti_loss/senti_acc = 0.66077549/0.6200000 \n",
    "step:250 | loss/acc = 0.584/0.750\n",
    "step:251 | loss/acc = 0.612/0.750\n",
    "step:252 | loss/acc = 0.639/0.600\n",
    "step:253 | loss/acc = 0.621/0.750\n",
    "step:254 | loss/acc = 0.700/0.450\n",
    "step:255 | loss/acc = 0.690/0.500\n",
    "step:256 | loss/acc = 0.619/0.650\n",
    "step:257 | loss/acc = 0.620/0.700\n",
    "step:258 | loss/acc = 0.626/0.700\n",
    "step:259 | loss/acc = 0.639/0.650\n",
    "sentiment task:    259: [    0/    2], senti_loss/senti_acc = 0.63497214/0.6500000 \n",
    "step:260 | loss/acc = 0.649/0.600\n",
    "step:261 | loss/acc = 0.660/0.700\n",
    "step:262 | loss/acc = 0.628/0.650\n",
    "step:263 | loss/acc = 0.579/0.800\n",
    "step:264 | loss/acc = 0.641/0.650\n",
    "step:265 | loss/acc = 0.622/0.700\n",
    "step:266 | loss/acc = 0.653/0.550\n",
    "step:267 | loss/acc = 0.625/0.700\n",
    "step:268 | loss/acc = 0.711/0.400\n",
    "step:269 | loss/acc = 0.664/0.500\n",
    "sentiment task:    269: [    0/    2], senti_loss/senti_acc = 0.64319305/0.6250000 \n",
    "step:270 | loss/acc = 0.625/0.700\n",
    "step:271 | loss/acc = 0.632/0.650\n",
    "step:272 | loss/acc = 0.679/0.500\n",
    "step:273 | loss/acc = 0.608/0.750\n",
    "step:274 | loss/acc = 0.576/0.800\n",
    "step:275 | loss/acc = 0.668/0.650\n",
    "step:276 | loss/acc = 0.628/0.550\n",
    "step:277 | loss/acc = 0.648/0.650\n",
    "step:278 | loss/acc = 0.588/0.800\n",
    "step:279 | loss/acc = 0.680/0.500\n",
    "sentiment task:    279: [    0/    2], senti_loss/senti_acc = 0.63328000/0.6550000 \n",
    "step:280 | loss/acc = 0.565/0.850\n",
    "step:281 | loss/acc = 0.584/0.750\n",
    "step:282 | loss/acc = 0.677/0.550\n",
    "step:283 | loss/acc = 0.656/0.600\n",
    "step:284 | loss/acc = 0.648/0.650\n",
    "step:285 | loss/acc = 0.627/0.700\n",
    "step:286 | loss/acc = 0.608/0.650\n",
    "step:287 | loss/acc = 0.674/0.600\n",
    "step:288 | loss/acc = 0.591/0.650\n",
    "step:289 | loss/acc = 0.607/0.750\n",
    "sentiment task:    289: [    0/    2], senti_loss/senti_acc = 0.62377896/0.6750000 \n",
    "step:290 | loss/acc = 0.639/0.550\n",
    "step:291 | loss/acc = 0.648/0.550\n",
    "step:292 | loss/acc = 0.550/0.800\n",
    "step:293 | loss/acc = 0.610/0.700\n",
    "step:294 | loss/acc = 0.662/0.650\n",
    "step:295 | loss/acc = 0.590/0.750\n",
    "step:296 | loss/acc = 0.652/0.600\n",
    "step:297 | loss/acc = 0.593/0.700\n",
    "step:298 | loss/acc = 0.597/0.700\n",
    "step:299 | loss/acc = 0.615/0.800\n",
    "sentiment task:    299: [    0/    2], senti_loss/senti_acc = 0.61562613/0.6800000 \n",
    "step:300 | loss/acc = 0.656/0.650\n",
    "step:301 | loss/acc = 0.685/0.600\n",
    "step:302 | loss/acc = 0.621/0.750\n",
    "step:303 | loss/acc = 0.627/0.650\n",
    "step:304 | loss/acc = 0.709/0.450\n",
    "step:305 | loss/acc = 0.677/0.550\n",
    "step:306 | loss/acc = 0.695/0.500\n",
    "step:307 | loss/acc = 0.631/0.650\n",
    "step:308 | loss/acc = 0.664/0.650\n",
    "step:309 | loss/acc = 0.647/0.600\n",
    "sentiment task:    309: [    0/    2], senti_loss/senti_acc = 0.66123003/0.6050000 \n",
    "step:310 | loss/acc = 0.667/0.550\n",
    "step:311 | loss/acc = 0.678/0.550\n",
    "step:312 | loss/acc = 0.657/0.600\n",
    "step:313 | loss/acc = 0.574/0.750\n",
    "step:314 | loss/acc = 0.577/0.750\n",
    "step:315 | loss/acc = 0.681/0.550\n",
    "step:316 | loss/acc = 0.692/0.550\n",
    "step:317 | loss/acc = 0.651/0.650\n",
    "step:318 | loss/acc = 0.682/0.500\n",
    "step:319 | loss/acc = 0.600/0.850\n",
    "sentiment task:    319: [    0/    2], senti_loss/senti_acc = 0.64592592/0.6300000 \n",
    "step:320 | loss/acc = 0.604/0.750\n",
    "step:321 | loss/acc = 0.600/0.750\n",
    "step:322 | loss/acc = 0.755/0.300\n",
    "step:323 | loss/acc = 0.584/0.700\n",
    "step:324 | loss/acc = 0.663/0.600\n",
    "step:325 | loss/acc = 0.629/0.600\n",
    "step:326 | loss/acc = 0.603/0.750\n",
    "step:327 | loss/acc = 0.632/0.600\n",
    "step:328 | loss/acc = 0.635/0.650\n",
    "step:329 | loss/acc = 0.652/0.650\n",
    "sentiment task:    329: [    0/    2], senti_loss/senti_acc = 0.63574392/0.6350000 \n",
    "step:330 | loss/acc = 0.589/0.850\n",
    "step:331 | loss/acc = 0.610/0.600\n",
    "step:332 | loss/acc = 0.681/0.600\n",
    "step:333 | loss/acc = 0.597/0.800\n",
    "step:334 | loss/acc = 0.639/0.650\n",
    "step:335 | loss/acc = 0.636/0.700\n",
    "step:336 | loss/acc = 0.637/0.700\n",
    "step:337 | loss/acc = 0.608/0.700\n",
    "step:338 | loss/acc = 0.655/0.500\n",
    "step:339 | loss/acc = 0.603/0.700\n",
    "sentiment task:    339: [    0/    2], senti_loss/senti_acc = 0.62550322/0.6800000 \n",
    "step:340 | loss/acc = 0.596/0.750\n",
    "step:341 | loss/acc = 0.636/0.750\n",
    "step:342 | loss/acc = 0.624/0.650\n",
    "step:343 | loss/acc = 0.574/0.800\n",
    "step:344 | loss/acc = 0.638/0.650\n",
    "step:345 | loss/acc = 0.644/0.650\n",
    "step:346 | loss/acc = 0.606/0.700\n",
    "step:347 | loss/acc = 0.695/0.450\n",
    "step:348 | loss/acc = 0.632/0.700\n",
    "step:349 | loss/acc = 0.607/0.750\n",
    "sentiment task:    349: [    0/    2], senti_loss/senti_acc = 0.62520358/0.6850000 \n",
    "step:350 | loss/acc = 0.628/0.650\n",
    "step:351 | loss/acc = 0.622/0.700\n",
    "step:352 | loss/acc = 0.638/0.550\n",
    "step:353 | loss/acc = 0.617/0.750\n",
    "step:354 | loss/acc = 0.615/0.700\n",
    "step:355 | loss/acc = 0.604/0.600\n",
    "step:356 | loss/acc = 0.577/0.750\n",
    "step:357 | loss/acc = 0.709/0.450\n",
    "step:358 | loss/acc = 0.613/0.750\n",
    "step:359 | loss/acc = 0.672/0.600\n",
    "sentiment task:    359: [    0/    2], senti_loss/senti_acc = 0.62955916/0.6500000 \n",
    "step:360 | loss/acc = 0.670/0.600\n",
    "step:361 | loss/acc = 0.696/0.450\n",
    "step:362 | loss/acc = 0.598/0.750\n",
    "step:363 | loss/acc = 0.671/0.600\n",
    "step:364 | loss/acc = 0.595/0.700\n",
    "step:365 | loss/acc = 0.691/0.500\n",
    "step:366 | loss/acc = 0.625/0.750\n",
    "step:367 | loss/acc = 0.665/0.500\n",
    "step:368 | loss/acc = 0.584/0.700\n",
    "step:369 | loss/acc = 0.653/0.550\n",
    "sentiment task:    369: [    0/    2], senti_loss/senti_acc = 0.64464960/0.6100000 \n",
    "step:370 | loss/acc = 0.661/0.600\n",
    "step:371 | loss/acc = 0.611/0.650\n",
    "step:372 | loss/acc = 0.666/0.450\n",
    "step:373 | loss/acc = 0.631/0.550\n",
    "step:374 | loss/acc = 0.551/0.850\n",
    "step:375 | loss/acc = 0.671/0.600\n",
    "step:376 | loss/acc = 0.652/0.500\n",
    "step:377 | loss/acc = 0.652/0.650\n",
    "step:378 | loss/acc = 0.646/0.550\n",
    "step:379 | loss/acc = 0.620/0.750\n",
    "sentiment task:    379: [    0/    2], senti_loss/senti_acc = 0.63593937/0.6150000 \n",
    "step:380 | loss/acc = 0.610/0.850\n",
    "step:381 | loss/acc = 0.565/0.900\n",
    "step:382 | loss/acc = 0.544/0.850\n",
    "step:383 | loss/acc = 0.589/0.750\n",
    "step:384 | loss/acc = 0.622/0.650\n",
    "step:385 | loss/acc = 0.637/0.650\n",
    "step:386 | loss/acc = 0.601/0.750\n",
    "step:387 | loss/acc = 0.608/0.700\n",
    "step:388 | loss/acc = 0.626/0.650\n",
    "step:389 | loss/acc = 0.673/0.600\n",
    "sentiment task:    389: [    0/    2], senti_loss/senti_acc = 0.60752185/0.7350000 \n",
    "step:390 | loss/acc = 0.645/0.600\n",
    "step:391 | loss/acc = 0.549/0.900\n",
    "step:392 | loss/acc = 0.641/0.650\n",
    "step:393 | loss/acc = 0.649/0.650\n",
    "step:394 | loss/acc = 0.599/0.650\n",
    "step:395 | loss/acc = 0.621/0.700\n",
    "step:396 | loss/acc = 0.627/0.550\n",
    "step:397 | loss/acc = 0.660/0.550\n",
    "step:398 | loss/acc = 0.644/0.650\n",
    "step:399 | loss/acc = 0.601/0.750\n",
    "sentiment task:    399: [    0/    2], senti_loss/senti_acc = 0.62363991/0.6650000 \n",
    "step:400 | loss/acc = 0.645/0.700\n",
    "step:401 | loss/acc = 0.576/0.750\n",
    "step:402 | loss/acc = 0.600/0.850\n",
    "step:403 | loss/acc = 0.587/0.650\n",
    "step:404 | loss/acc = 0.660/0.650\n",
    "step:405 | loss/acc = 0.611/0.600\n",
    "step:406 | loss/acc = 0.577/0.700\n",
    "step:407 | loss/acc = 0.675/0.450\n",
    "step:408 | loss/acc = 0.625/0.600\n",
    "step:409 | loss/acc = 0.672/0.500\n",
    "sentiment task:    409: [    0/    2], senti_loss/senti_acc = 0.62274832/0.6450000 \n",
    "step:410 | loss/acc = 0.593/0.800\n",
    "step:411 | loss/acc = 0.599/0.650\n",
    "step:412 | loss/acc = 0.616/0.700\n",
    "step:413 | loss/acc = 0.578/0.800\n",
    "step:414 | loss/acc = 0.654/0.600\n",
    "step:415 | loss/acc = 0.678/0.550\n",
    "step:416 | loss/acc = 0.553/0.800\n",
    "step:417 | loss/acc = 0.536/0.800\n",
    "step:418 | loss/acc = 0.577/0.800\n",
    "step:419 | loss/acc = 0.650/0.700\n",
    "sentiment task:    419: [    0/    2], senti_loss/senti_acc = 0.60333155/0.7200000 \n",
    "step:420 | loss/acc = 0.656/0.500\n",
    "step:421 | loss/acc = 0.691/0.450\n",
    "step:422 | loss/acc = 0.640/0.650\n",
    "step:423 | loss/acc = 0.584/0.850\n",
    "step:424 | loss/acc = 0.634/0.550\n",
    "step:425 | loss/acc = 0.659/0.650\n",
    "step:426 | loss/acc = 0.628/0.650\n",
    "step:427 | loss/acc = 0.630/0.700\n",
    "step:428 | loss/acc = 0.544/0.750\n",
    "step:429 | loss/acc = 0.606/0.550\n",
    "sentiment task:    429: [    0/    2], senti_loss/senti_acc = 0.62732565/0.6300000 \n",
    "step:430 | loss/acc = 0.567/0.750\n",
    "step:431 | loss/acc = 0.653/0.550\n",
    "step:432 | loss/acc = 0.592/0.750\n",
    "step:433 | loss/acc = 0.678/0.650\n",
    "step:434 | loss/acc = 0.658/0.700\n",
    "step:435 | loss/acc = 0.646/0.600\n",
    "step:436 | loss/acc = 0.622/0.600\n",
    "step:437 | loss/acc = 0.599/0.600\n",
    "step:438 | loss/acc = 0.638/0.600\n",
    "step:439 | loss/acc = 0.650/0.550\n",
    "sentiment task:    439: [    0/    2], senti_loss/senti_acc = 0.63022733/0.6350000 \n",
    "step:440 | loss/acc = 0.659/0.550\n",
    "step:441 | loss/acc = 0.568/0.700\n",
    "step:442 | loss/acc = 0.548/0.750\n",
    "step:443 | loss/acc = 0.605/0.650\n",
    "step:444 | loss/acc = 0.590/0.650\n",
    "step:445 | loss/acc = 0.633/0.600\n",
    "step:446 | loss/acc = 0.655/0.550\n",
    "step:447 | loss/acc = 0.591/0.700\n",
    "step:448 | loss/acc = 0.648/0.600\n",
    "step:449 | loss/acc = 0.551/0.800\n",
    "sentiment task:    449: [    0/    2], senti_loss/senti_acc = 0.60480673/0.6550000 \n",
    "step:450 | loss/acc = 0.659/0.550\n",
    "step:451 | loss/acc = 0.626/0.600\n",
    "step:452 | loss/acc = 0.739/0.500\n",
    "step:453 | loss/acc = 0.660/0.650\n",
    "step:454 | loss/acc = 0.594/0.700\n",
    "step:455 | loss/acc = 0.559/0.800\n",
    "step:456 | loss/acc = 0.574/0.800\n",
    "step:457 | loss/acc = 0.556/0.850\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调试emotion classification　任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = \"/home/hadoop/EmoNet-PyTorch/twitter30.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels, emotion_set = load_data_from_file(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoReader = EmotionReader(sentences, labels, 20, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_cls = nn.Linear(768, 6).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_weights = torch.tensor(\n",
    "            WeightsForUmbalanced(\n",
    "                emoReader.label\n",
    "            ),\n",
    "            dtype = torch.float32\n",
    "    )\n",
    "emo_loss_fn = nn.CrossEntropyLoss(weight=emo_weights.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0 | loss/acc = 2.288/0.250\n",
      "step:1 | loss/acc = 2.018/0.150\n",
      "step:2 | loss/acc = 1.782/0.350\n",
      "step:3 | loss/acc = 1.888/0.050\n",
      "step:4 | loss/acc = 1.767/0.100\n",
      "step:5 | loss/acc = 2.014/0.000\n",
      "step:6 | loss/acc = 1.778/0.150\n",
      "step:7 | loss/acc = 2.181/0.000\n",
      "step:8 | loss/acc = 1.739/0.050\n",
      "step:9 | loss/acc = 2.091/0.050\n",
      "emotion task:      9: [    0/    1], senti_loss/senti_acc = 1.95463120/0.1150000 \n",
      "step:10 | loss/acc = 2.162/0.050\n",
      "step:11 | loss/acc = 1.703/0.150\n",
      "step:12 | loss/acc = 2.002/0.050\n",
      "step:13 | loss/acc = 2.093/0.000\n",
      "step:14 | loss/acc = 2.017/0.100\n",
      "step:15 | loss/acc = 1.796/0.100\n",
      "step:16 | loss/acc = 1.822/0.150\n",
      "step:17 | loss/acc = 1.681/0.200\n",
      "step:18 | loss/acc = 1.757/0.100\n",
      "step:19 | loss/acc = 1.709/0.250\n",
      "emotion task:     19: [    0/    1], senti_loss/senti_acc = 1.87408050/0.1150000 \n",
      "step:20 | loss/acc = 1.793/0.050\n",
      "step:21 | loss/acc = 1.943/0.000\n",
      "step:22 | loss/acc = 1.869/0.100\n",
      "step:23 | loss/acc = 1.848/0.100\n",
      "step:24 | loss/acc = 1.726/0.200\n",
      "step:25 | loss/acc = 1.879/0.250\n",
      "step:26 | loss/acc = 1.589/0.500\n",
      "step:27 | loss/acc = 1.686/0.250\n",
      "step:28 | loss/acc = 1.689/0.300\n",
      "step:29 | loss/acc = 1.808/0.200\n",
      "emotion task:     29: [    0/    1], senti_loss/senti_acc = 1.78298928/0.1950000 \n",
      "step:30 | loss/acc = 1.577/0.200\n",
      "step:31 | loss/acc = 1.861/0.150\n",
      "step:32 | loss/acc = 1.878/0.350\n",
      "step:33 | loss/acc = 1.967/0.100\n",
      "step:34 | loss/acc = 1.876/0.250\n",
      "step:35 | loss/acc = 1.630/0.250\n",
      "step:36 | loss/acc = 1.997/0.150\n",
      "step:37 | loss/acc = 1.794/0.250\n",
      "step:38 | loss/acc = 1.891/0.400\n",
      "step:39 | loss/acc = 2.204/0.350\n",
      "emotion task:     39: [    0/    1], senti_loss/senti_acc = 1.86755782/0.2450000 \n",
      "step:40 | loss/acc = 2.208/0.200\n",
      "step:41 | loss/acc = 2.067/0.350\n",
      "step:42 | loss/acc = 1.853/0.350\n",
      "step:43 | loss/acc = 1.683/0.300\n",
      "step:44 | loss/acc = 1.774/0.300\n",
      "step:45 | loss/acc = 1.668/0.350\n",
      "step:46 | loss/acc = 1.962/0.150\n",
      "step:47 | loss/acc = 1.545/0.550\n",
      "step:48 | loss/acc = 1.893/0.150\n",
      "step:49 | loss/acc = 1.740/0.350\n",
      "emotion task:     49: [    0/    1], senti_loss/senti_acc = 1.83934318/0.3050000 \n",
      "step:50 | loss/acc = 1.901/0.150\n",
      "step:51 | loss/acc = 1.737/0.250\n",
      "step:52 | loss/acc = 1.661/0.250\n",
      "step:53 | loss/acc = 1.764/0.150\n",
      "step:54 | loss/acc = 1.920/0.100\n",
      "step:55 | loss/acc = 1.899/0.100\n",
      "step:56 | loss/acc = 1.773/0.200\n",
      "step:57 | loss/acc = 1.727/0.150\n",
      "step:58 | loss/acc = 1.879/0.100\n",
      "step:59 | loss/acc = 1.862/0.050\n",
      "emotion task:     59: [    0/    1], senti_loss/senti_acc = 1.81233386/0.1500000 \n",
      "step:60 | loss/acc = 1.790/0.100\n",
      "step:61 | loss/acc = 1.845/0.150\n",
      "step:62 | loss/acc = 1.891/0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7d9d098f5736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0memo_loss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-9-47183b753776>\u001b[0m in \u001b[0;36memo_cls_train\u001b[0;34m(emotion_reader, bert, transformer, task_embedding, emotion_classifier, train_epochs, emo_loss_fn, cuda)\u001b[0m\n\u001b[1;32m     26\u001b[0m                                             \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                    )\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0memo_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memo_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37_torch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emo_cls_train(\n",
    "        emoReader, \n",
    "        bert, \n",
    "        transformer, \n",
    "        task_embedding, \n",
    "        emo_cls, \n",
    "        1, \n",
    "        emo_loss_fn, \n",
    "        cuda=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0|MTL_Loss:1.10183227, senti_loss/senti_acc = 0.08993977/0.0500000 | subj_loss/subj_acc = 0.07299789/0.0500000 | emo_loss/emo_acc = 0.16794288/0.0200000\n",
      "     1|MTL_Loss:1.02234149, senti_loss/senti_acc = 0.16989808/0.1050000 | subj_loss/subj_acc = 0.14532826/0.1000000 | emo_loss/emo_acc = 0.32266364/0.0550000\n",
      "     2|MTL_Loss:1.21160579, senti_loss/senti_acc = 0.25413162/0.1550000 | subj_loss/subj_acc = 0.22356061/0.1200000 | emo_loss/emo_acc = 0.52404332/0.0700000\n",
      "     3|MTL_Loss:1.01831877, senti_loss/senti_acc = 0.32044030/0.2200000 | subj_loss/subj_acc = 0.29723995/0.1550000 | emo_loss/emo_acc = 0.68985673/0.1150000\n",
      "     4|MTL_Loss:1.10961294, senti_loss/senti_acc = 0.40935183/0.2650000 | subj_loss/subj_acc = 0.36816586/0.2000000 | emo_loss/emo_acc = 0.86323639/0.1600000\n",
      "     5|MTL_Loss:1.19264555, senti_loss/senti_acc = 0.48482938/0.3200000 | subj_loss/subj_acc = 0.44032022/0.2400000 | emo_loss/emo_acc = 1.07375630/0.2050000\n",
      "     6|MTL_Loss:0.97999442, senti_loss/senti_acc = 0.55023155/0.3850000 | subj_loss/subj_acc = 0.51197850/0.2800000 | emo_loss/emo_acc = 1.23098847/0.2400000\n",
      "     7|MTL_Loss:1.14952946, senti_loss/senti_acc = 0.64251615/0.4150000 | subj_loss/subj_acc = 0.58001361/0.3300000 | emo_loss/emo_acc = 1.41587281/0.2800000\n",
      "     8|MTL_Loss:1.13116324, senti_loss/senti_acc = 0.73074912/0.4500000 | subj_loss/subj_acc = 0.65487928/0.3600000 | emo_loss/emo_acc = 1.59246284/0.3200000\n",
      "     9|MTL_Loss:1.05394220, senti_loss/senti_acc = 0.79390534/0.5150000 | subj_loss/subj_acc = 0.72673922/0.4100000 | emo_loss/emo_acc = 1.77394583/0.3650000\n",
      "     9: [    0/  100], MTL_Loss|1.05394220, senti_loss/senti_acc = 0.79390534/0.5150000 | subj_loss/subj_acc = 0.72673922/0.4100000 | emo_loss/emo_acc = 1.77394583/0.3650000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.2727, 0.3425, 0.3848])\n",
      "    10|MTL_Loss:1.15580201, senti_loss/senti_acc = 0.78037514/0.5100000 | subj_loss/subj_acc = 0.72420672/0.4100000 | emo_loss/emo_acc = 1.78950804/0.3750000\n",
      "    11|MTL_Loss:1.13374448, senti_loss/senti_acc = 0.77148077/0.5100000 | subj_loss/subj_acc = 0.72681020/0.3950000 | emo_loss/emo_acc = 1.81237030/0.3650000\n",
      "    12|MTL_Loss:1.26476002, senti_loss/senti_acc = 0.76646707/0.5000000 | subj_loss/subj_acc = 0.72026641/0.4000000 | emo_loss/emo_acc = 1.81973302/0.3750000\n",
      "    13|MTL_Loss:1.07379532, senti_loss/senti_acc = 0.77033229/0.4900000 | subj_loss/subj_acc = 0.71757739/0.4050000 | emo_loss/emo_acc = 1.82006347/0.3750000\n",
      "    14|MTL_Loss:1.19009686, senti_loss/senti_acc = 0.74747804/0.5050000 | subj_loss/subj_acc = 0.71828409/0.4050000 | emo_loss/emo_acc = 1.84540002/0.3650000\n",
      "    15|MTL_Loss:1.21460223, senti_loss/senti_acc = 0.75187706/0.4900000 | subj_loss/subj_acc = 0.71687513/0.4100000 | emo_loss/emo_acc = 1.83096079/0.3600000\n",
      "    16|MTL_Loss:1.15440130, senti_loss/senti_acc = 0.76554198/0.4600000 | subj_loss/subj_acc = 0.71795118/0.4200000 | emo_loss/emo_acc = 1.85296627/0.3600000\n",
      "    17|MTL_Loss:1.08354509, senti_loss/senti_acc = 0.74875942/0.4650000 | subj_loss/subj_acc = 0.71939608/0.4250000 | emo_loss/emo_acc = 1.83432802/0.3800000\n",
      "    18|MTL_Loss:1.14092267, senti_loss/senti_acc = 0.72904524/0.4850000 | subj_loss/subj_acc = 0.72065647/0.4300000 | emo_loss/emo_acc = 1.83792911/0.3800000\n",
      "    19|MTL_Loss:1.14996004, senti_loss/senti_acc = 0.73436452/0.4750000 | subj_loss/subj_acc = 0.71993034/0.4200000 | emo_loss/emo_acc = 1.84346102/0.3600000\n",
      "    19: [    0/  100], MTL_Loss|1.14996004, senti_loss/senti_acc = 0.73436452/0.4750000 | subj_loss/subj_acc = 0.71993034/0.4200000 | emo_loss/emo_acc = 1.84346102/0.3600000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.2898, 0.3278, 0.3824])\n",
      "    20|MTL_Loss:1.13279676, senti_loss/senti_acc = 0.72727284/0.4700000 | subj_loss/subj_acc = 0.71777251/0.4250000 | emo_loss/emo_acc = 1.84510154/0.3550000\n",
      "    21|MTL_Loss:1.06208169, senti_loss/senti_acc = 0.73209789/0.4550000 | subj_loss/subj_acc = 0.71218835/0.4500000 | emo_loss/emo_acc = 1.82829844/0.3750000\n",
      "    22|MTL_Loss:1.14868629, senti_loss/senti_acc = 0.71953525/0.4800000 | subj_loss/subj_acc = 0.71133606/0.4750000 | emo_loss/emo_acc = 1.80870588/0.3900000\n",
      "    23|MTL_Loss:1.09821749, senti_loss/senti_acc = 0.71634804/0.4850000 | subj_loss/subj_acc = 0.71720498/0.4550000 | emo_loss/emo_acc = 1.81310182/0.3750000\n",
      "    24|MTL_Loss:1.20518923, senti_loss/senti_acc = 0.72558482/0.4600000 | subj_loss/subj_acc = 0.71496788/0.4650000 | emo_loss/emo_acc = 1.81300029/0.3700000\n",
      "    25|MTL_Loss:1.11122584, senti_loss/senti_acc = 0.71339754/0.4700000 | subj_loss/subj_acc = 0.71548130/0.4650000 | emo_loss/emo_acc = 1.79512901/0.3450000\n",
      "    26|MTL_Loss:1.16710925, senti_loss/senti_acc = 0.70639644/0.4800000 | subj_loss/subj_acc = 0.71162891/0.4650000 | emo_loss/emo_acc = 1.80743471/0.3300000\n",
      "    27|MTL_Loss:1.08875561, senti_loss/senti_acc = 0.69744197/0.5050000 | subj_loss/subj_acc = 0.71303064/0.4500000 | emo_loss/emo_acc = 1.81471050/0.3000000\n",
      "    28|MTL_Loss:1.10826194, senti_loss/senti_acc = 0.70944514/0.4700000 | subj_loss/subj_acc = 0.70619007/0.4600000 | emo_loss/emo_acc = 1.80391932/0.3050000\n",
      "    29|MTL_Loss:1.15381455, senti_loss/senti_acc = 0.70900561/0.4800000 | subj_loss/subj_acc = 0.70588679/0.4650000 | emo_loss/emo_acc = 1.80635524/0.3100000\n",
      "    29: [    0/  100], MTL_Loss|1.15381455, senti_loss/senti_acc = 0.70900561/0.4800000 | subj_loss/subj_acc = 0.70588679/0.4650000 | emo_loss/emo_acc = 1.80635524/0.3100000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.2793, 0.2883, 0.4324])\n",
      "    30|MTL_Loss:1.23589230, senti_loss/senti_acc = 0.70891774/0.4900000 | subj_loss/subj_acc = 0.70967636/0.4600000 | emo_loss/emo_acc = 1.81423390/0.3200000\n",
      "    31|MTL_Loss:1.19804597, senti_loss/senti_acc = 0.70143226/0.5100000 | subj_loss/subj_acc = 0.71058761/0.4500000 | emo_loss/emo_acc = 1.83948423/0.3150000\n",
      "    32|MTL_Loss:1.25116682, senti_loss/senti_acc = 0.70934278/0.4800000 | subj_loss/subj_acc = 0.71317924/0.4400000 | emo_loss/emo_acc = 1.84255646/0.3000000\n",
      "    33|MTL_Loss:1.29403830, senti_loss/senti_acc = 0.71179867/0.4700000 | subj_loss/subj_acc = 0.70934045/0.4700000 | emo_loss/emo_acc = 1.87773437/0.3000000\n",
      "    34|MTL_Loss:1.18915689, senti_loss/senti_acc = 0.70560074/0.4900000 | subj_loss/subj_acc = 0.70652602/0.4750000 | emo_loss/emo_acc = 1.86510025/0.3000000\n",
      "    35|MTL_Loss:1.11579490, senti_loss/senti_acc = 0.71054016/0.4850000 | subj_loss/subj_acc = 0.70675600/0.4700000 | emo_loss/emo_acc = 1.85035319/0.3350000\n",
      "    36|MTL_Loss:1.13939500, senti_loss/senti_acc = 0.71106851/0.4800000 | subj_loss/subj_acc = 0.70684586/0.4700000 | emo_loss/emo_acc = 1.82942989/0.3550000\n",
      "    37|MTL_Loss:1.14610887, senti_loss/senti_acc = 0.71438122/0.4600000 | subj_loss/subj_acc = 0.70698007/0.4800000 | emo_loss/emo_acc = 1.82848361/0.3650000\n",
      "    38|MTL_Loss:1.15898716, senti_loss/senti_acc = 0.70260698/0.4950000 | subj_loss/subj_acc = 0.71118065/0.4750000 | emo_loss/emo_acc = 1.83370918/0.3600000\n",
      "    39|MTL_Loss:1.21427011, senti_loss/senti_acc = 0.70515462/0.4750000 | subj_loss/subj_acc = 0.71109548/0.4800000 | emo_loss/emo_acc = 1.83230947/0.3550000\n",
      "    39: [    0/  100], MTL_Loss|1.21427011, senti_loss/senti_acc = 0.70515462/0.4750000 | subj_loss/subj_acc = 0.71109548/0.4800000 | emo_loss/emo_acc = 1.83230947/0.3550000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.3005, 0.2974, 0.4021])\n",
      "    40|MTL_Loss:1.07954419, senti_loss/senti_acc = 0.70556073/0.4800000 | subj_loss/subj_acc = 0.70824708/0.4900000 | emo_loss/emo_acc = 1.80450356/0.3600000\n",
      "    41|MTL_Loss:1.18558633, senti_loss/senti_acc = 0.70803729/0.4800000 | subj_loss/subj_acc = 0.71250838/0.4750000 | emo_loss/emo_acc = 1.80523397/0.3450000\n",
      "    42|MTL_Loss:1.07203305, senti_loss/senti_acc = 0.69829901/0.5050000 | subj_loss/subj_acc = 0.70450828/0.5000000 | emo_loss/emo_acc = 1.78278054/0.3450000\n",
      "    43|MTL_Loss:1.17109632, senti_loss/senti_acc = 0.70304652/0.4950000 | subj_loss/subj_acc = 0.70107917/0.4950000 | emo_loss/emo_acc = 1.76139292/0.3500000\n",
      "    44|MTL_Loss:1.16232967, senti_loss/senti_acc = 0.70403695/0.4750000 | subj_loss/subj_acc = 0.70785687/0.4700000 | emo_loss/emo_acc = 1.75784274/0.3450000\n",
      "    45|MTL_Loss:1.11747766, senti_loss/senti_acc = 0.70188960/0.4750000 | subj_loss/subj_acc = 0.70856721/0.4800000 | emo_loss/emo_acc = 1.76621885/0.3150000\n",
      "    46|MTL_Loss:1.13881373, senti_loss/senti_acc = 0.69800915/0.4800000 | subj_loss/subj_acc = 0.70532465/0.5050000 | emo_loss/emo_acc = 1.77884943/0.2950000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    47|MTL_Loss:1.17365432, senti_loss/senti_acc = 0.70376768/0.4800000 | subj_loss/subj_acc = 0.70536952/0.5150000 | emo_loss/emo_acc = 1.78908548/0.2750000\n",
      "    48|MTL_Loss:1.15756273, senti_loss/senti_acc = 0.70553722/0.4650000 | subj_loss/subj_acc = 0.70064408/0.5350000 | emo_loss/emo_acc = 1.79878364/0.2600000\n",
      "    49|MTL_Loss:1.14014649, senti_loss/senti_acc = 0.70688676/0.4500000 | subj_loss/subj_acc = 0.70046728/0.5250000 | emo_loss/emo_acc = 1.78832955/0.2750000\n",
      "    49: [    0/  100], MTL_Loss|1.14014649, senti_loss/senti_acc = 0.70688676/0.4500000 | subj_loss/subj_acc = 0.70046728/0.5250000 | emo_loss/emo_acc = 1.78832955/0.2750000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.2862, 0.2454, 0.4684])\n",
      "    50|MTL_Loss:1.21654522, senti_loss/senti_acc = 0.70895953/0.4400000 | subj_loss/subj_acc = 0.69777147/0.5250000 | emo_loss/emo_acc = 1.80415078/0.2600000\n",
      "    51|MTL_Loss:1.23796928, senti_loss/senti_acc = 0.70713717/0.4400000 | subj_loss/subj_acc = 0.69424139/0.5350000 | emo_loss/emo_acc = 1.80229845/0.2600000\n",
      "    52|MTL_Loss:1.24597812, senti_loss/senti_acc = 0.71157894/0.4250000 | subj_loss/subj_acc = 0.70042416/0.5100000 | emo_loss/emo_acc = 1.81869353/0.2750000\n",
      "    53|MTL_Loss:1.29517174, senti_loss/senti_acc = 0.70616137/0.4450000 | subj_loss/subj_acc = 0.70461054/0.5000000 | emo_loss/emo_acc = 1.83019921/0.2750000\n",
      "    54|MTL_Loss:1.31328988, senti_loss/senti_acc = 0.70564641/0.4600000 | subj_loss/subj_acc = 0.70317985/0.5100000 | emo_loss/emo_acc = 1.84795319/0.2700000\n",
      "    55|MTL_Loss:1.19463789, senti_loss/senti_acc = 0.70732843/0.4550000 | subj_loss/subj_acc = 0.70223026/0.5000000 | emo_loss/emo_acc = 1.84973941/0.2950000\n",
      "    56|MTL_Loss:1.28194427, senti_loss/senti_acc = 0.70915994/0.4550000 | subj_loss/subj_acc = 0.71020837/0.4550000 | emo_loss/emo_acc = 1.85845400/0.2850000\n",
      "    57|MTL_Loss:1.22075033, senti_loss/senti_acc = 0.70028467/0.4700000 | subj_loss/subj_acc = 0.71182885/0.4400000 | emo_loss/emo_acc = 1.85740401/0.2950000\n",
      "    58|MTL_Loss:1.22456884, senti_loss/senti_acc = 0.70165561/0.4850000 | subj_loss/subj_acc = 0.71579552/0.4250000 | emo_loss/emo_acc = 1.85248916/0.3050000\n",
      "    59|MTL_Loss:1.24722719, senti_loss/senti_acc = 0.70177391/0.5000000 | subj_loss/subj_acc = 0.71678871/0.4250000 | emo_loss/emo_acc = 1.85964906/0.2800000\n",
      "    59: [    0/  100], MTL_Loss|1.24722719, senti_loss/senti_acc = 0.70177391/0.5000000 | subj_loss/subj_acc = 0.71678871/0.4250000 | emo_loss/emo_acc = 1.85964906/0.2800000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.2524, 0.2969, 0.4507])\n",
      "    60|MTL_Loss:1.20330167, senti_loss/senti_acc = 0.70106839/0.5000000 | subj_loss/subj_acc = 0.72263907/0.4000000 | emo_loss/emo_acc = 1.85813799/0.2700000\n",
      "    61|MTL_Loss:1.26004601, senti_loss/senti_acc = 0.70564676/0.4650000 | subj_loss/subj_acc = 0.72458425/0.3900000 | emo_loss/emo_acc = 1.86352260/0.2750000\n",
      "    62|MTL_Loss:1.24876976, senti_loss/senti_acc = 0.70805063/0.4700000 | subj_loss/subj_acc = 0.72600335/0.3850000 | emo_loss/emo_acc = 1.86618713/0.2700000\n",
      "    63|MTL_Loss:1.20836639, senti_loss/senti_acc = 0.70843914/0.4650000 | subj_loss/subj_acc = 0.72656024/0.3900000 | emo_loss/emo_acc = 1.85076298/0.2650000\n",
      "    64|MTL_Loss:1.15779245, senti_loss/senti_acc = 0.70799308/0.4650000 | subj_loss/subj_acc = 0.72592350/0.3700000 | emo_loss/emo_acc = 1.82179360/0.2850000\n",
      "    65|MTL_Loss:1.21422553, senti_loss/senti_acc = 0.70175984/0.4850000 | subj_loss/subj_acc = 0.72792703/0.3700000 | emo_loss/emo_acc = 1.83240243/0.2550000\n",
      "    66|MTL_Loss:1.26024091, senti_loss/senti_acc = 0.70012940/0.5000000 | subj_loss/subj_acc = 0.72255053/0.3950000 | emo_loss/emo_acc = 1.83645208/0.2600000\n",
      "    67|MTL_Loss:1.17113185, senti_loss/senti_acc = 0.69852373/0.5250000 | subj_loss/subj_acc = 0.71888888/0.4050000 | emo_loss/emo_acc = 1.83259494/0.2500000\n",
      "    68|MTL_Loss:1.23271334, senti_loss/senti_acc = 0.69228953/0.5300000 | subj_loss/subj_acc = 0.71771109/0.4000000 | emo_loss/emo_acc = 1.84279875/0.2350000\n",
      "    69|MTL_Loss:1.16122866, senti_loss/senti_acc = 0.68643658/0.5500000 | subj_loss/subj_acc = 0.71356127/0.4350000 | emo_loss/emo_acc = 1.83421422/0.2350000\n",
      "    69: [    0/  100], MTL_Loss|1.16122866, senti_loss/senti_acc = 0.68643658/0.5500000 | subj_loss/subj_acc = 0.71356127/0.4350000 | emo_loss/emo_acc = 1.83421422/0.2350000\n",
      "\n",
      "\n",
      " loss_weight: tensor([0.2172, 0.2746, 0.5083])\n",
      "    70|MTL_Loss:1.30439949, senti_loss/senti_acc = 0.68401319/0.5600000 | subj_loss/subj_acc = 0.71040831/0.4500000 | emo_loss/emo_acc = 1.84461322/0.2500000\n",
      "    71|MTL_Loss:1.23239744, senti_loss/senti_acc = 0.67946448/0.6000000 | subj_loss/subj_acc = 0.70950115/0.4550000 | emo_loss/emo_acc = 1.82836280/0.2600000\n",
      "    72|MTL_Loss:1.24120498, senti_loss/senti_acc = 0.67122608/0.6300000 | subj_loss/subj_acc = 0.70669028/0.4650000 | emo_loss/emo_acc = 1.81870289/0.2650000\n",
      "    73|MTL_Loss:1.20701003, senti_loss/senti_acc = 0.66989610/0.6400000 | subj_loss/subj_acc = 0.70470189/0.4650000 | emo_loss/emo_acc = 1.80770488/0.2600000\n"
     ]
    }
   ],
   "source": [
    "JointLearning(senti_train_reader, subj_train_reader, emoReader, \n",
    "                  bert, transformer, task_embedding, \n",
    "                  senti_cls, subj_cls, emo_cls,\n",
    "                  cuda=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
