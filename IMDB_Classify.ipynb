{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "import tensorflow as tf\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "import IMDBLoader\n",
    "import numpy as np\n",
    "from tensorflow.losses import Reduction\n",
    "import chars2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/hadoop/IMDB/aclImdb/train/\"\n",
    "test_dir = \"/home/hadoop/IMDB/aclImdb/test/\"\n",
    "train_set, test_set = IMDBLoader.load_data(train_dir, test_dir)\n",
    "train_set.extend(test_set[:20000])\n",
    "valid_set = test_set[20000:21000]\n",
    "test_set = test_set[21000:]\n",
    "train_reader = IMDBLoader.IMDBReader(train_set, 20)\n",
    "valid_reader = IMDBLoader.IMDBReader(valid_set, 20)\n",
    "test_reader = IMDBLoader.IMDBReader(test_set, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(input_, output_size, scope=None):\n",
    "    '''\n",
    "    Linear map: output[k] = sum_i(Matrix[k, i] * args[i] ) + Bias[k]\n",
    "\n",
    "    Args:\n",
    "        args: a tensor or a list of 2D, batch x n, Tensors.\n",
    "    output_size: int, second dimension of W[i].\n",
    "    scope: VariableScope for the created subgraph; defaults to \"Linear\".\n",
    "  Returns:\n",
    "    A 2D Tensor with shape [batch x output_size] equal to\n",
    "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
    "  Raises:\n",
    "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
    "  '''\n",
    "\n",
    "    shape = input_.get_shape().as_list()\n",
    "    if len(shape) != 2:\n",
    "        raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shape))\n",
    "    if not shape[1]:\n",
    "        raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shape))\n",
    "    input_size = shape[1]\n",
    "\n",
    "    # Now the computation.\n",
    "    with tf.variable_scope(scope or \"SimpleLinear\", reuse=tf.AUTO_REUSE):\n",
    "        matrix = tf.get_variable(\"Matrix\", [output_size, input_size], dtype=input_.dtype)\n",
    "        bias_term = tf.get_variable(\"Bias\", [output_size], dtype=input_.dtype)\n",
    "    return tf.matmul(input_, tf.transpose(matrix)) + bias_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentiModel:\n",
    "    def __init__(self, max_word_length, kernels, kernel_features,\n",
    "                            num_highway_layers, embedding_dim):\n",
    "        self.max_word_length = max_word_length\n",
    "        self.kernels = kernels\n",
    "        self.kernel_features = kernel_features\n",
    "        self.num_highway_layers = num_highway_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "    \n",
    "    def __call__(self, input_words):\n",
    "        with tf.variable_scope('Embedding', reuse=tf.AUTO_REUSE):\n",
    "            # [batch_size x max_word_length, num_unroll_steps, char_embed_size]\n",
    "            input_cnn = self.tdnn(input_words, self.kernels, self.kernel_features)\n",
    "            ''' Maybe apply Highway '''\n",
    "    #             if num_highway_layers > 0:\n",
    "            assert self.num_highway_layers > 0\n",
    "            input_cnn = self.highway(input_cnn, input_cnn.get_shape()[-1], num_layers=self.num_highway_layers, scope=\"CNN_OUT\")\n",
    "            # fcn_layer = tf.layers.Dense(self.embedding_dim, activation=tf.keras.activations.sigmoid, trainable=True)\n",
    "            # final_embedding = fcn_layer(input_cnn) # [None, max_word_num, hidden_dim]\n",
    "        print(\"input_cnn:\", input_cnn)\n",
    "        # print(\"final_embedding\", input_cnn)\n",
    "        return input_cnn\n",
    "    \n",
    "    def conv2d(self, input_, output_dim, k_h, k_w, name=\"conv2d\"):\n",
    "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "            w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim])\n",
    "            b = tf.get_variable('b', [output_dim])\n",
    "        return tf.nn.conv2d(input_, w, strides=[1, 1, 1, 1], padding='VALID') + b\n",
    "\n",
    "    def highway(self, input_, size, num_layers=1, bias=-2.0, f=tf.nn.relu, scope='Highway'):\n",
    "        \"\"\"Highway Network (cf. http://arxiv.org/abs/1505.00387).\n",
    "        t = sigmoid(Wy + b)\n",
    "        z = t * g(Wy + b) + (1 - t) * y\n",
    "        where g is nonlinearity, t is transform gate, and (1 - t) is carry gate.\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "            for idx in range(num_layers):\n",
    "                g = f(linear(input_, size, scope='highway_lin_%d' % idx))\n",
    "\n",
    "                t = tf.sigmoid(linear(input_, size, scope='highway_gate_%d' % idx) + bias)\n",
    "\n",
    "                output = t * g + (1. - t) * input_\n",
    "                input_ = output\n",
    "        return output\n",
    "\n",
    "    def tdnn(self, input_, kernels, kernel_features, scope='TDNN'):\n",
    "        '''\n",
    "        :input:           input float tensor of shape [(batch_size*num_unroll_steps), max_word_length, embed_size]\n",
    "        :kernels:         array of kernel sizes\n",
    "        :kernel_features: array of kernel feature sizes (parallel to kernels)\n",
    "        '''\n",
    "        assert len(kernels) == len(kernel_features), 'Kernel and Features must have the same size'\n",
    "        max_word_length = input_.get_shape()[1]\n",
    "        embed_size = input_.get_shape()[-1]\n",
    "        # input_: [batch_size*num_unroll_steps, 1, max_word_length, embed_size]\n",
    "        input_ = tf.expand_dims(input_, 1)\n",
    "        layers = []\n",
    "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "            for kernel_size, kernel_feature_size in zip(kernels, kernel_features):\n",
    "                reduced_length = max_word_length - kernel_size + 1\n",
    "                # [batch_size*num_unroll_steps, 1, reduced_length, kernel_feature_size]\n",
    "                conv = self.conv2d(input_, kernel_feature_size, 1, kernel_size, name=\"kernel_%d\" % kernel_size)\n",
    "                # [batch_size*num_unroll_steps, 1, 1, kernel_feature_size]\n",
    "                pool = tf.nn.max_pool(tf.tanh(conv), [1, 1, reduced_length, 1], [1, 1, 1, 1], 'VALID')\n",
    "                layers.append(tf.squeeze(pool, [1, 2]))\n",
    "            if len(kernels) > 1:\n",
    "                output = tf.concat(layers, 1)\n",
    "            else:\n",
    "                output = layers[0]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel:\n",
    "    def __init__(self, hidden_dim):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.drop_out_prob_keep = tf.placeholder(tf.float32, name=\"lstm_char_net_dp\")\n",
    "        self.fw_cell = self.create_rnn_cell(self.hidden_dim)\n",
    "        self.bw_cell = self.create_rnn_cell(self.hidden_dim)\n",
    "    \n",
    "    def __call__(self, sentence, x_len, fw_init, bw_init): \n",
    "    #sentence: [batchsize, max_word_num, embedding_dim]\n",
    "    #x_len: [batch_size]\n",
    "        with tf.variable_scope('Embedding', reuse=tf.AUTO_REUSE):\n",
    "            (fw_outs, bw_outs), (fw_final, bw_final) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                        self.fw_cell,\n",
    "                                        self.bw_cell,\n",
    "                                        sentence,\n",
    "                                        sequence_length=x_len,\n",
    "                                        initial_state_fw=fw_init,\n",
    "                                        initial_state_bw=bw_init,\n",
    "                                        dtype=None,\n",
    "                                        parallel_iterations=None,\n",
    "                                        swap_memory=False,\n",
    "                                        time_major=False,\n",
    "                                        scope=None\n",
    "                                    )\n",
    "        return fw_outs, bw_outs, fw_final, bw_final\n",
    "    \n",
    "    def create_rnn_cell(self, rnn_size):\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(rnn_size, state_is_tuple=True, forget_bias=0.0, reuse=False)\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=self.drop_out_prob_keep)\n",
    "        return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 09:32:13.288387 139669057967936 deprecation_wrapper.py:119] From /home/hadoop/ERD/model.py:6: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0904 09:32:13.319870 139669057967936 deprecation_wrapper.py:119] From /home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0904 09:32:13.320659 139669057967936 deprecation_wrapper.py:119] From /home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0904 09:32:13.322491 139669057967936 deprecation_wrapper.py:119] From /home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0904 09:32:14.102209 139669057967936 deprecation_wrapper.py:119] From /home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0904 09:32:14.126850 139669057967936 deprecation_wrapper.py:119] From /home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0904 09:32:14.127396 139669057967936 deprecation_wrapper.py:119] From /home/hadoop/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.losses import Reduction\n",
    "from model import adict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InferSentiTrainGraph(senti_model,batch_size, max_word_num, embedding_dim, hidden_dim, sent_num):\n",
    "    sent_x = tf.placeholder(tf.float32, shape = [batch_size, max_word_num, embedding_dim])\n",
    "    sent_y = tf.placeholder(tf.float32, shape = [batch_size, sent_num])\n",
    "#     x_len = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    \n",
    "#     fw_init = senti_model.fw_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "#     bw_init = senti_model.bw_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "#     fw_outs, bw_outs, fw_final, bw_final = senti_model(sent_x, x_len, fw_init, bw_init)\n",
    "#     print(\"fw_out:\", fw_outs)\n",
    "#     fw_final = fw_final[-1]\n",
    "#     bw_final = bw_final[-1]\n",
    "    \n",
    "#     # add to final tensor\n",
    "#     out_merge = fw_final + bw_final\n",
    "    \n",
    "    # concat two tensor\n",
    "#     senti_features = tf.concat([fw_final+tf.reduce_max(fw_outs, axis=1),                            \n",
    "#                                 bw_final+tf.reduce_max(fw_outs, axis=1)], axis = -1)\n",
    "    \n",
    "#     # max_pooling two tensor\n",
    "#     out_merge = tf.reduce_max(\n",
    "#         tf.transpose(\n",
    "#             tf.identity([fw_final, bw_final]),\n",
    "#             [1, 0, 2]\n",
    "#         ),\n",
    "#         axis = 1\n",
    "#     )\n",
    "    senti_features = senti_model(sent_x)\n",
    "    \n",
    "    w_t = tf.Variable(tf.random_uniform([1100, sent_num], -1.0, 1.0), name=\"w_t\")\n",
    "    w_t = tf.Print(w_t, [w_t[0], w_t[1], w_t[2]], message=\"w_t:\")\n",
    "    b_t = tf.Variable(tf.constant(0.01, shape=[sent_num]), name=\"b_t\")\n",
    "    b_t = tf.Print(b_t, [b_t[0], b_t[1]], message=\"b_t:\")\n",
    "    senti_rst = tf.nn.relu(\n",
    "        tf.nn.xw_plus_b(senti_features, w_t, b_t, name=\"senti_rst\")\n",
    "    )\n",
    "    \n",
    "#     classifier = tf.layers.Dense(sent_num, activation=tf.nn.relu, trainable=True)\n",
    "#     senti_rst = classifier(senti_features)\n",
    "    \n",
    "    sent_scores = tf.nn.softmax(senti_rst, axis=1)\n",
    "    sent_pred = tf.argmax(sent_scores, 1, name=\"predictions\")\n",
    "    sent_loss = tf.losses.softmax_cross_entropy(\n",
    "                        sent_y,\n",
    "                        senti_rst,\n",
    "                        weights=1.0,\n",
    "                        label_smoothing=0,\n",
    "                        scope=None,\n",
    "                        loss_collection=tf.GraphKeys.LOSSES,\n",
    "                        reduction=Reduction.SUM_BY_NONZERO_WEIGHTS\n",
    "                    )\n",
    "    sent_correct_predictions = tf.equal(sent_pred, tf.argmax(sent_y, 1))\n",
    "    sent_acc = tf.reduce_mean(tf.cast(sent_correct_predictions, \"float\"), name=\"accuracy\")\n",
    "    sent_global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "    sent_train_op = tf.train.AdagradOptimizer(0.5).minimize(sent_loss, sent_global_step)        \n",
    "    return adict(\n",
    "                sent_x = sent_x,\n",
    "                sent_y = sent_y,\n",
    "                feature = senti_features,\n",
    "                sent_scores = sent_scores,\n",
    "                sent_pred = sent_pred,\n",
    "                sent_loss = sent_loss,\n",
    "                sent_acc = sent_acc,\n",
    "                sent_global_step = sent_global_step,\n",
    "                sent_train_op = sent_train_op\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts2matrix(texts, c2vec, max_sent_len, embedding_dim):\n",
    "    def words2arr(words):\n",
    "        rst = np.zeros([max_sent_len, embedding_dim])\n",
    "        arr = c2vec.vectorize_words(words)\n",
    "        rst[:len(arr)] = arr\n",
    "        return rst\n",
    "    embedding = np.array([words2arr(words).tolist() for words in texts])\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainSentiModel(sess, saver, summary_writer, logger, train_model, c2vec, \n",
    "                    train_reader, valid_reader, test_reader,\n",
    "                    train_batch, test_batch, embedding_dim):\n",
    "    train_epoch = 50\n",
    "    for epoch in range(train_epoch):\n",
    "        # for validation\n",
    "        sum_acc = 0.0\n",
    "        sum_loss = 0.0\n",
    "        count = 0\n",
    "        for texts, labels, ratings, lens  in train_reader.iter():\n",
    "            data_X = texts2matrix(texts, c2vec, train_reader.max_sent_len, embedding_dim)\n",
    "            feed_dic = {\n",
    "                        train_model.sent_x: data_X, \n",
    "                        train_model.sent_y: labels                     \n",
    "            }\n",
    "            _, step, loss, acc, pred, score, feat= sess.run(\n",
    "                                        [train_model.sent_train_op, \n",
    "                                         train_model.sent_global_step, \n",
    "                                         train_model.sent_loss, \n",
    "                                         train_model.sent_acc,\n",
    "                                         train_model.sent_pred, \n",
    "                                         train_model.sent_scores,\n",
    "                                         train_model.feature\n",
    "                                        ], \n",
    "                                        feed_dic)\n",
    "            print(\"prediction:\", pred)\n",
    "            print(\"scores:\", score[:3].tolist())\n",
    "            logger.info(\"feat1:\" + str(feat[0].tolist()[:10]) + \"\\nfeat2:\" + str(feat[1].tolist()[:10]) + \"\\nfeat3:\" + str(feat[2].tolist()[:10]))\n",
    "            count += 1\n",
    "            sum_loss += loss\n",
    "            sum_acc += acc\n",
    "            if count % 10 == 9:\n",
    "                sum_loss = sum_loss / 10\n",
    "                sum_acc = sum_acc / 10\n",
    "                ret_acc = sum_acc\n",
    "                print('%6d: %d [%5d/%5d], train_loss/accuracy = %6.8f/%6.7f' % (step,\n",
    "                                                        epoch, count,\n",
    "                                                        train_reader.label.shape[0],\n",
    "                                                        sum_loss, sum_acc,\n",
    "                                                        ))\n",
    "                logger.info('%6d: %d [%5d/%5d], train_loss/accuracy = %6.8f/%6.7f' % (step,\n",
    "                                                        epoch, count,\n",
    "                                                        train_reader.label.shape[0],\n",
    "                                                        sum_loss, sum_acc,\n",
    "                                                        ))\n",
    "                sum_acc = 0.0\n",
    "                sum_loss = 0.0\n",
    "                summary = tf.Summary(value=[\n",
    "                    tf.Summary.Value(tag=\"step_train_loss\", simple_value=sum_loss),\n",
    "                    tf.Summary.Value(tag=\"step_train_accuracy\", simple_value=sum_acc),\n",
    "                ])\n",
    "                summary_writer.add_summary(summary, step)\n",
    "\n",
    "        # for validation\n",
    "        sum_acc = 0.0\n",
    "        sum_loss = 0.0\n",
    "        for texts, labels, ratings, lens  in valid_reader.iter():\n",
    "            data_X = texts2matrix(texts, c2vec, valid_reader.max_sent_len, embedding_dim)\n",
    "            feed_dic = {\n",
    "                        train_model.sent_x: data_X, \n",
    "                        train_model.sent_y: labels                      \n",
    "            }\n",
    "            _, step, loss, acc = sess.run(\n",
    "                                        [\n",
    "                                         train_model.sent_loss, \n",
    "                                         train_model.sent_acc], \n",
    "                                        feed_dic)\n",
    "            sum_loss += loss\n",
    "            sum_acc += acc\n",
    "        sum_loss = sum_loss / (1.0*valid_reader.label.shape[0])\n",
    "        sum_acc = sum_acc / (1.0*valid_reader.label.shape[0])\n",
    "        ret_acc = sum_acc\n",
    "        print('[%5d/%5d], valid_loss/accuracy = %6.8f/%6.7f' % (epoch, train_epoch,\n",
    "                                                                sum_loss, sum_acc,\n",
    "                                                                ))\n",
    "        logger.info('[%5d/%5d], valid_loss/accuracy = %6.8f/%6.7f' % (epoch, train_epoch,\n",
    "                                                                sum_loss, sum_acc,\n",
    "                                                                ))\n",
    "        summary = tf.Summary(value=[\n",
    "                    tf.Summary.Value(tag=\"epoch_valid_loss\", simple_value=sum_loss),\n",
    "                    tf.Summary.Value(tag=\"epoch_valid_accuracy\", simple_value=sum_acc),\n",
    "                ])\n",
    "        summary_writer.add_summary(summary, epoch)\n",
    "        sum_acc = 0.0\n",
    "        sum_loss = 0.0\n",
    "        saver.save(sess, \"IMDBReports/\")\n",
    "    \n",
    "    # for validation\n",
    "    sum_acc = 0.0\n",
    "    sum_loss = 0.0\n",
    "    for texts, labels, ratings, lens  in valid_reader.iter():\n",
    "        data_X = texts2matrix(texts, c2vec, valid_reader.max_sent_len, embedding_dim)\n",
    "        feed_dic = {\n",
    "                    train_model.sent_x: data_X, \n",
    "                    train_model.sent_y: labels                       \n",
    "        }\n",
    "        _, step, loss, acc = sess.run(\n",
    "                                    [\n",
    "                                     train_model.sent_loss, \n",
    "                                     train_model.sent_acc], \n",
    "                                    feed_dic)\n",
    "        sum_loss += loss\n",
    "        sum_acc += acc\n",
    "    print('Training Ended! #test_loss/accuracy = %6.8f/%6.7f' % (sum_loss, sum_acc))\n",
    "    logger.info('Training Ended! #test_loss/accuracy = %6.8f/%6.7f' % (sum_loss, sum_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import MyLogger\n",
    "logger = MyLogger(\"IMDBSentiModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_cnn: Tensor(\"Embedding/CNN_OUT/add_7:0\", shape=(20, 1100), dtype=float32, device=/device:GPU:0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:24.029239 139669057967936 logger.py:24] feat1:[-0.05206857994198799, -0.08402467519044876, 0.15650062263011932, -0.06343629956245422, 0.043652597814798355, 0.15307141840457916, 0.11379000544548035, 0.1216433197259903, -0.03424294665455818, 0.13517090678215027]\n",
      "feat2:[-0.05564611777663231, -0.08265110850334167, 0.15593001246452332, -0.06655476242303848, 0.036800045520067215, 0.15139809250831604, 0.11387063562870026, 0.1212642565369606, -0.0357990488409996, 0.1353151500225067]\n",
      "feat3:[-0.05637918785214424, -0.08173474669456482, 0.1536109447479248, -0.06696655601263046, 0.0380835197865963, 0.15130707621574402, 0.11331826448440552, 0.12115437537431717, -0.03607778623700142, 0.1364312320947647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:25.331845 139669057967936 logger.py:24] feat1:[-0.05495750159025192, -0.08257828652858734, 0.1539868712425232, -0.06732626259326935, 0.03559203818440437, 0.14916929602622986, 0.11045101284980774, 0.11635219305753708, -0.0359332337975502, 0.13266493380069733]\n",
      "feat2:[-0.05497051775455475, -0.07953786104917526, 0.15428586304187775, -0.06634335219860077, 0.03758054971694946, 0.15624096989631653, 0.11325681954622269, 0.12448704987764359, -0.03404149413108826, 0.13678698241710663]\n",
      "feat3:[-0.05494477227330208, -0.08462868630886078, 0.1529572308063507, -0.06628786772489548, 0.03525780141353607, 0.14889554679393768, 0.11219670623540878, 0.12163718044757843, -0.03589022904634476, 0.13410022854804993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:26.439421 139669057967936 logger.py:24] feat1:[-0.05561497062444687, -0.08200749009847641, 0.15260514616966248, -0.06819228082895279, 0.035583361983299255, 0.15109829604625702, 0.11228518187999725, 0.11791545897722244, -0.03397532179951668, 0.1359582096338272]\n",
      "feat2:[-0.05098043382167816, -0.07857158035039902, 0.1547427475452423, -0.06450348347425461, 0.03836856409907341, 0.1505497694015503, 0.11338258534669876, 0.1186913251876831, -0.036919381469488144, 0.13450932502746582]\n",
      "feat3:[-0.05867703631520271, -0.08033102750778198, 0.1545810103416443, -0.060624707490205765, 0.046193841844797134, 0.15186244249343872, 0.1141006201505661, 0.11778946965932846, -0.03608659282326698, 0.13855397701263428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:27.911801 139669057967936 logger.py:24] feat1:[-0.057307168841362, -0.08231350034475327, 0.15463896095752716, -0.06877889484167099, 0.033520713448524475, 0.14959119260311127, 0.11085641384124756, 0.11728747189044952, -0.036805182695388794, 0.13380247354507446]\n",
      "feat2:[-0.057296108454465866, -0.08410276472568512, 0.15505024790763855, -0.06811896711587906, 0.036674290895462036, 0.15467321872711182, 0.11021294444799423, 0.12269197404384613, -0.03692510724067688, 0.1361244171857834]\n",
      "feat3:[-0.05577820912003517, -0.08218580484390259, 0.16284000873565674, -0.066069096326828, 0.03944532573223114, 0.150450199842453, 0.11398158222436905, 0.11992458999156952, -0.036317918449640274, 0.13566498458385468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:29.079265 139669057967936 logger.py:24] feat1:[-0.047479841858148575, -0.08231800049543381, 0.15745604038238525, -0.06764505803585052, 0.03996776416897774, 0.15163707733154297, 0.11178077012300491, 0.12362071126699448, -0.03423371538519859, 0.1371203511953354]\n",
      "feat2:[-0.057433124631643295, -0.08465012162923813, 0.15522736310958862, -0.07058367133140564, 0.03550106659531593, 0.151030495762825, 0.11083995550870895, 0.12173368036746979, -0.03456117957830429, 0.1341179758310318]\n",
      "feat3:[-0.05483623594045639, -0.07493747025728226, 0.1562553495168686, -0.06644916534423828, 0.040316030383110046, 0.15433166921138763, 0.11379020661115646, 0.12200246006250381, -0.03459988161921501, 0.13714151084423065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:30.139708 139669057967936 logger.py:24] feat1:[-0.05810452997684479, -0.0848202258348465, 0.15655584633350372, -0.06529204547405243, 0.044031910598278046, 0.1515224575996399, 0.11386395990848541, 0.11798016726970673, -0.03396196290850639, 0.13550984859466553]\n",
      "feat2:[-0.05501166358590126, -0.08264351636171341, 0.15624216198921204, -0.0672336146235466, 0.03913760930299759, 0.1540534645318985, 0.11299731582403183, 0.12422699481248856, -0.034132931381464005, 0.1385466456413269]\n",
      "feat3:[-0.05405397340655327, -0.07830245792865753, 0.15434467792510986, -0.0700284019112587, 0.03745472431182861, 0.148742213845253, 0.11036685109138489, 0.12102258950471878, -0.03648035600781441, 0.13619980216026306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:31.144087 139669057967936 logger.py:24] feat1:[-0.04860766604542732, -0.07836351543664932, 0.15586985647678375, -0.06554582715034485, 0.034916952252388, 0.15244081616401672, 0.11324421316385269, 0.11908052116632462, -0.036079540848731995, 0.1377648562192917]\n",
      "feat2:[-0.06031055375933647, -0.08188160508871078, 0.15862804651260376, -0.06445899605751038, 0.04168905317783356, 0.14895449578762054, 0.11288821697235107, 0.12158364802598953, -0.03389237821102142, 0.13763491809368134]\n",
      "feat3:[-0.05494174361228943, -0.08006945997476578, 0.15648013353347778, -0.0682842954993248, 0.0376734584569931, 0.1507866531610489, 0.1122450903058052, 0.11995558440685272, -0.035373348742723465, 0.1344205141067505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:32.375794 139669057967936 logger.py:24] feat1:[-0.05479053035378456, -0.07521617412567139, 0.1557072550058365, -0.06633316725492477, 0.035457488149404526, 0.14963114261627197, 0.11279197037220001, 0.12018535286188126, -0.030738670378923416, 0.135920912027359]\n",
      "feat2:[-0.05498219281435013, -0.07990751415491104, 0.15617522597312927, -0.06705938279628754, 0.04324682056903839, 0.1542712301015854, 0.1132398471236229, 0.12312528491020203, -0.03072284907102585, 0.13755077123641968]\n",
      "feat3:[-0.054983384907245636, -0.07733806222677231, 0.15739598870277405, -0.06669312715530396, 0.03721550852060318, 0.1497037708759308, 0.11424894630908966, 0.12068863213062286, -0.03350460156798363, 0.1375744342803955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:33.588081 139669057967936 logger.py:24] feat1:[-0.05499512702226639, -0.07487285137176514, 0.15739355981349945, -0.06840408593416214, 0.038372159004211426, 0.15129385888576508, 0.11362364143133163, 0.12189023196697235, -0.030758151784539223, 0.13762898743152618]\n",
      "feat2:[-0.05748569965362549, -0.07999254018068314, 0.15475505590438843, -0.06944708526134491, 0.03534574806690216, 0.15191520750522614, 0.11218280345201492, 0.12059220671653748, -0.03647570312023163, 0.1339753270149231]\n",
      "feat3:[-0.057426419109106064, -0.07914625108242035, 0.15390712022781372, -0.06782793998718262, 0.041425734758377075, 0.15056033432483673, 0.11330568790435791, 0.1230827122926712, -0.036086905747652054, 0.1359589695930481]\n",
      "I0904 10:59:33.589190 139669057967936 logger.py:24]      9: 0 [    9/ 2250], train_loss/accuracy = 0.62383246/0.4750000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n",
      "     9: 0 [    9/ 2250], train_loss/accuracy = 0.62383246/0.4750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:34.846632 139669057967936 logger.py:24] feat1:[-0.05492248386144638, -0.08267735689878464, 0.15693460404872894, -0.06995255500078201, 0.03535939380526543, 0.14900197088718414, 0.11058676242828369, 0.11601044237613678, -0.03691011294722557, 0.1353909969329834]\n",
      "feat2:[-0.05012579634785652, -0.07534382492303848, 0.15681172907352448, -0.06691662967205048, 0.037253402173519135, 0.15346771478652954, 0.11246365308761597, 0.12034454196691513, -0.03103502467274666, 0.13859158754348755]\n",
      "feat3:[-0.054989077150821686, -0.07723769545555115, 0.15503661334514618, -0.0673547014594078, 0.04081117361783981, 0.15003164112567902, 0.1128634586930275, 0.12006780505180359, -0.03505769744515419, 0.13541120290756226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:35.853336 139669057967936 logger.py:24] feat1:[-0.05010334402322769, -0.08191879838705063, 0.15568572282791138, -0.06586062163114548, 0.03862664848566055, 0.15067102015018463, 0.11567246168851852, 0.11857215315103531, -0.03439917415380478, 0.13856784999370575]\n",
      "feat2:[-0.05633765086531639, -0.08832085877656937, 0.15336768329143524, -0.07064545899629593, 0.03169603273272514, 0.14832884073257446, 0.10947590321302414, 0.11665254086256027, -0.036795154213905334, 0.1329158991575241]\n",
      "feat3:[-0.05566082149744034, -0.0808972492814064, 0.15450169146060944, -0.06837078183889389, 0.03792431950569153, 0.15050913393497467, 0.11236868053674698, 0.12150674313306808, -0.03403966873884201, 0.13584958016872406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:36.900952 139669057967936 logger.py:24] feat1:[-0.04544807970523834, -0.07558879256248474, 0.15304827690124512, -0.06560655683279037, 0.041550327092409134, 0.14994099736213684, 0.11384768784046173, 0.1219739019870758, -0.030749844387173653, 0.13588209450244904]\n",
      "feat2:[-0.05351287126541138, -0.08454612642526627, 0.158161923289299, -0.06872092187404633, 0.03297581896185875, 0.15114673972129822, 0.1101774051785469, 0.1188625916838646, -0.035387180745601654, 0.13320215046405792]\n",
      "feat3:[-0.05491451174020767, -0.0842343270778656, 0.15572050213813782, -0.06771612167358398, 0.03801753744482994, 0.15328752994537354, 0.11316429823637009, 0.11964724957942963, -0.0386723056435585, 0.13780157268047333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:37.984022 139669057967936 logger.py:24] feat1:[-0.05103687569499016, -0.08017446100711823, 0.15637247264385223, -0.06322365999221802, 0.04415740817785263, 0.15068896114826202, 0.11354411393404007, 0.1220131516456604, -0.03603089600801468, 0.13718818128108978]\n",
      "feat2:[-0.0573270209133625, -0.08345777541399002, 0.15542803704738617, -0.067783422768116, 0.034871239215135574, 0.14740963280200958, 0.11105398833751678, 0.11946504563093185, -0.03471505269408226, 0.13575640320777893]\n",
      "feat3:[-0.05499923601746559, -0.08141429722309113, 0.15695080161094666, -0.06850659847259521, 0.038162097334861755, 0.14981840550899506, 0.11224489659070969, 0.12160110473632812, -0.03459735959768295, 0.13758553564548492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:39.611501 139669057967936 logger.py:24] feat1:[-0.057309314608573914, -0.08158272504806519, 0.15509094297885895, -0.06843085587024689, 0.03697989881038666, 0.14959828555583954, 0.11266259849071503, 0.11840245127677917, -0.03557432442903519, 0.13861756026744843]\n",
      "feat2:[-0.05434874817728996, -0.07936891168355942, 0.15278522670269012, -0.06763506680727005, 0.03417515009641647, 0.15171609818935394, 0.1128215566277504, 0.11507683247327805, -0.03689183294773102, 0.13587506115436554]\n",
      "feat3:[-0.061472102999687195, -0.08336280286312103, 0.15290287137031555, -0.06798162311315536, 0.03565189987421036, 0.1510280966758728, 0.11151798814535141, 0.11894629150629044, -0.0351363830268383, 0.13584022223949432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:40.605242 139669057967936 logger.py:24] feat1:[-0.056084275245666504, -0.081703320145607, 0.15675053000450134, -0.06696539372205734, 0.04266486316919327, 0.1520591527223587, 0.11196481436491013, 0.12412948906421661, -0.03418601676821709, 0.13862770795822144]\n",
      "feat2:[-0.05008682981133461, -0.08155964314937592, 0.15882496535778046, -0.06689178943634033, 0.03642214089632034, 0.14982832968235016, 0.11214858293533325, 0.11911517381668091, -0.03539715334773064, 0.13590475916862488]\n",
      "feat3:[-0.05360299348831177, -0.080112524330616, 0.15569372475147247, -0.06888419389724731, 0.03769085556268692, 0.15211383998394012, 0.11194863170385361, 0.12068424373865128, -0.0338967926800251, 0.1383134126663208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:41.757984 139669057967936 logger.py:24] feat1:[-0.0588381253182888, -0.07885008305311203, 0.15611864626407623, -0.06761126220226288, 0.04288719594478607, 0.15071535110473633, 0.11244821548461914, 0.11965306103229523, -0.035615015774965286, 0.1352740377187729]\n",
      "feat2:[-0.05495423078536987, -0.08217591047286987, 0.15428495407104492, -0.06975850462913513, 0.03389741852879524, 0.14917340874671936, 0.112803615629673, 0.11870642006397247, -0.03845202550292015, 0.1353212147951126]\n",
      "feat3:[-0.05713026598095894, -0.08239507675170898, 0.15568579733371735, -0.06868071109056473, 0.03443596512079239, 0.1513570100069046, 0.1123662143945694, 0.11900773644447327, -0.03722420707345009, 0.1408478021621704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:42.956599 139669057967936 logger.py:24] feat1:[-0.05399728938937187, -0.08221731334924698, 0.15514253079891205, -0.06889595091342926, 0.03574097901582718, 0.1492728441953659, 0.11206390708684921, 0.12329114973545074, -0.03637886419892311, 0.14047691226005554]\n",
      "feat2:[-0.05879344418644905, -0.0822964459657669, 0.1553703099489212, -0.06680982559919357, 0.042922958731651306, 0.14972861111164093, 0.11261241137981415, 0.11777997016906738, -0.03525930643081665, 0.13534939289093018]\n",
      "feat3:[-0.05891873314976692, -0.08218489587306976, 0.15661486983299255, -0.06715524941682816, 0.03727458417415619, 0.14980825781822205, 0.11344752460718155, 0.11866360157728195, -0.03650825843214989, 0.1341991126537323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:44.086840 139669057967936 logger.py:24] feat1:[-0.05497707799077034, -0.07890376448631287, 0.15454551577568054, -0.06414327025413513, 0.03978276252746582, 0.15220165252685547, 0.113676056265831, 0.12140312790870667, -0.0350613109767437, 0.13864700496196747]\n",
      "feat2:[-0.05640808120369911, -0.07088078558444977, 0.1568869799375534, -0.06740033626556396, 0.03890743479132652, 0.15253591537475586, 0.11316081136465073, 0.12435713410377502, -0.03403333202004433, 0.13568873703479767]\n",
      "feat3:[-0.055611010640859604, -0.07268183678388596, 0.15562063455581665, -0.06316571682691574, 0.04402931034564972, 0.15061092376708984, 0.11366777867078781, 0.12334395200014114, -0.03102671168744564, 0.13543812930583954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:45.218503 139669057967936 logger.py:24] feat1:[-0.06019267067313194, -0.0827128142118454, 0.1555972546339035, -0.07023965567350388, 0.03362063691020012, 0.14757999777793884, 0.1091979444026947, 0.12443151324987411, -0.03653924912214279, 0.13315530121326447]\n",
      "feat2:[-0.05494408681988716, -0.07784860581159592, 0.15661677718162537, -0.06778544932603836, 0.037797994911670685, 0.15264827013015747, 0.11482813209295273, 0.12109299749135971, -0.03429429605603218, 0.1363750398159027]\n",
      "feat3:[-0.05497466027736664, -0.08123278617858887, 0.15566600859165192, -0.07003451883792877, 0.03985891491174698, 0.1491498053073883, 0.11241032183170319, 0.11902949213981628, -0.03524545952677727, 0.1326339691877365]\n",
      "I0904 10:59:45.219515 139669057967936 logger.py:24]     19: 0 [   19/ 2250], train_loss/accuracy = 0.69314718/0.5300000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n",
      "    19: 0 [   19/ 2250], train_loss/accuracy = 0.69314718/0.5300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:46.330100 139669057967936 logger.py:24] feat1:[-0.05480258911848068, -0.07556908577680588, 0.15458334982395172, -0.06883508712053299, 0.03918690234422684, 0.15022912621498108, 0.11307454854249954, 0.11706230044364929, -0.03387337923049927, 0.13536663353443146]\n",
      "feat2:[-0.0557396300137043, -0.0749988704919815, 0.1564805507659912, -0.06692468374967575, 0.042605768889188766, 0.15209521353244781, 0.1129695326089859, 0.12432751804590225, -0.033473655581474304, 0.13859479129314423]\n",
      "feat3:[-0.055270470678806305, -0.07510794699192047, 0.153803288936615, -0.06738100200891495, 0.03731522709131241, 0.15039393305778503, 0.11290028691291809, 0.11893921345472336, -0.03104371204972267, 0.13723187148571014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:47.385686 139669057967936 logger.py:24] feat1:[-0.05309108644723892, -0.08144039660692215, 0.15654782950878143, -0.06409702450037003, 0.038745880126953125, 0.15068885684013367, 0.11101528257131577, 0.12145677953958511, -0.035625070333480835, 0.13287006318569183]\n",
      "feat2:[-0.04960651695728302, -0.08231780678033829, 0.1541566252708435, -0.06736934930086136, 0.036902837455272675, 0.15071846544742584, 0.1129714846611023, 0.12193872779607773, -0.03554221987724304, 0.13622303307056427]\n",
      "feat3:[-0.05361975356936455, -0.08293809741735458, 0.15821963548660278, -0.06872688978910446, 0.03843452036380768, 0.15090574324131012, 0.11013054102659225, 0.1217348724603653, -0.034066297113895416, 0.13758093118667603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:48.402080 139669057967936 logger.py:24] feat1:[-0.05718925595283508, -0.08214669674634933, 0.15820983052253723, -0.06702646613121033, 0.04211084544658661, 0.15097036957740784, 0.11077109724283218, 0.12172085046768188, -0.03517244756221771, 0.13593025505542755]\n",
      "feat2:[-0.05011415481567383, -0.08175572007894516, 0.15930598974227905, -0.06692353636026382, 0.03830869495868683, 0.15146441757678986, 0.11434324830770493, 0.12107402831315994, -0.03229576721787453, 0.13576844334602356]\n",
      "feat3:[-0.05404433608055115, -0.0801156759262085, 0.15764926373958588, -0.06642407178878784, 0.03768491744995117, 0.15225210785865784, 0.1115083321928978, 0.12183541059494019, -0.03714408725500107, 0.1376013606786728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:49.412826 139669057967936 logger.py:24] feat1:[-0.054991938173770905, -0.0750446692109108, 0.15369033813476562, -0.0677129402756691, 0.04116283357143402, 0.1508036106824875, 0.11304828524589539, 0.12203812599182129, -0.03363829851150513, 0.13782168924808502]\n",
      "feat2:[-0.05494823306798935, -0.08480288088321686, 0.15490736067295074, -0.06917451322078705, 0.03560158237814903, 0.15106834471225739, 0.11225302517414093, 0.11838380992412567, -0.03924171254038811, 0.13573452830314636]\n",
      "feat3:[-0.057503048330545425, -0.08322746306657791, 0.15605466067790985, -0.06660135835409164, 0.038069576025009155, 0.15393857657909393, 0.11317675560712814, 0.12023646384477615, -0.03071592003107071, 0.13593539595603943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:50.400793 139669057967936 logger.py:24] feat1:[-0.05197405815124512, -0.08235464990139008, 0.15423937141895294, -0.06626120209693909, 0.04007846117019653, 0.14966847002506256, 0.11350291222333908, 0.12141645699739456, -0.03457058221101761, 0.13293275237083435]\n",
      "feat2:[-0.05771121010184288, -0.07762990146875381, 0.15352842211723328, -0.0704726129770279, 0.036272913217544556, 0.15197843313217163, 0.11104858666658401, 0.12141967564821243, -0.03648308664560318, 0.13768938183784485]\n",
      "feat3:[-0.0554390475153923, -0.08211030811071396, 0.15944857895374298, -0.06300388276576996, 0.04058676213026047, 0.14878062903881073, 0.11251628398895264, 0.11912496387958527, -0.03724456578493118, 0.13413190841674805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:51.381419 139669057967936 logger.py:24] feat1:[-0.05011199414730072, -0.07530894875526428, 0.15969519317150116, -0.06294944137334824, 0.03708258271217346, 0.1511252522468567, 0.10987257212400436, 0.1205771416425705, -0.034986719489097595, 0.1334928572177887]\n",
      "feat2:[-0.058468133211135864, -0.08166463673114777, 0.15491193532943726, -0.06682328134775162, 0.03820476308465004, 0.15092866122722626, 0.11359058320522308, 0.12224973738193512, -0.034580133855342865, 0.13774727284908295]\n",
      "feat3:[-0.05260632932186127, -0.08226019889116287, 0.15564990043640137, -0.06888286769390106, 0.04238037019968033, 0.1533346325159073, 0.11095156520605087, 0.11856833100318909, -0.03517526388168335, 0.1349005252122879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:52.371567 139669057967936 logger.py:24] feat1:[-0.05400363355875015, -0.07616391032934189, 0.15644702315330505, -0.06890597194433212, 0.03385024890303612, 0.1506340205669403, 0.11052797734737396, 0.12078310549259186, -0.033977292478084564, 0.13546451926231384]\n",
      "feat2:[-0.05009762570261955, -0.0774274691939354, 0.15783554315567017, -0.06274933367967606, 0.044160354882478714, 0.15150859951972961, 0.11451487988233566, 0.12094029039144516, -0.03406103700399399, 0.13834643363952637]\n",
      "feat3:[-0.055774107575416565, -0.08535201847553253, 0.15333640575408936, -0.06952472776174545, 0.037023868411779404, 0.15144287049770355, 0.11306094378232956, 0.11957021057605743, -0.035679224878549576, 0.13497421145439148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:53.369365 139669057967936 logger.py:24] feat1:[-0.055449727922677994, -0.08369642496109009, 0.1562255322933197, -0.06706099957227707, 0.038127150386571884, 0.14917850494384766, 0.1147417277097702, 0.1193927526473999, -0.035576172173023224, 0.1353384405374527]\n",
      "feat2:[-0.05738584324717522, -0.07947540283203125, 0.1551409512758255, -0.06591356545686722, 0.03839424252510071, 0.1536077857017517, 0.11431607604026794, 0.12045062333345413, -0.03367023542523384, 0.1363569051027298]\n",
      "feat3:[-0.054928094148635864, -0.07476666569709778, 0.1564817577600479, -0.06330900639295578, 0.04406820237636566, 0.15560077130794525, 0.11296698451042175, 0.12434221059083939, -0.03245679661631584, 0.13868401944637299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:54.336980 139669057967936 logger.py:24] feat1:[-0.05425106734037399, -0.07728441059589386, 0.1554715484380722, -0.06469669193029404, 0.039544958621263504, 0.15618345141410828, 0.11285940557718277, 0.12434150278568268, -0.03396744653582573, 0.1372803896665573]\n",
      "feat2:[-0.056842029094696045, -0.0820450484752655, 0.15466144680976868, -0.06997089087963104, 0.03691256791353226, 0.15415239334106445, 0.11035915464162827, 0.12309211492538452, -0.03457875922322273, 0.1342744082212448]\n",
      "feat3:[-0.0543668307363987, -0.07565440982580185, 0.15437807142734528, -0.06583219021558762, 0.037012845277786255, 0.15022660791873932, 0.11207649856805801, 0.11919169127941132, -0.03488488495349884, 0.1353829950094223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:55.308306 139669057967936 logger.py:24] feat1:[-0.057758040726184845, -0.08234868943691254, 0.1574997454881668, -0.06989694386720657, 0.03703940659761429, 0.151169091463089, 0.11143998801708221, 0.1189088448882103, -0.03692382201552391, 0.13586105406284332]\n",
      "feat2:[-0.05319778248667717, -0.0821225717663765, 0.15225836634635925, -0.07022826373577118, 0.036512523889541626, 0.15068702399730682, 0.11266247183084488, 0.1198478564620018, -0.034306272864341736, 0.13567706942558289]\n",
      "feat3:[-0.05865016207098961, -0.08163274824619293, 0.156509131193161, -0.06714735180139542, 0.03760693967342377, 0.15180973708629608, 0.11125330626964569, 0.11903446912765503, -0.03607601672410965, 0.137394979596138]\n",
      "I0904 10:59:55.309143 139669057967936 logger.py:24]     29: 0 [   29/ 2250], train_loss/accuracy = 0.69314718/0.5200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n",
      "    29: 0 [   29/ 2250], train_loss/accuracy = 0.69314718/0.5200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:56.291535 139669057967936 logger.py:24] feat1:[-0.05326586589217186, -0.08226270973682404, 0.1575911045074463, -0.06592461466789246, 0.04691451042890549, 0.15519820153713226, 0.11244149506092072, 0.12354350090026855, -0.034040145576000214, 0.1362934410572052]\n",
      "feat2:[-0.054958898574113846, -0.08241283893585205, 0.15510119497776031, -0.06994728744029999, 0.03591331094503403, 0.14652986824512482, 0.11228079348802567, 0.1170598566532135, -0.03846405819058418, 0.13569234311580658]\n",
      "feat3:[-0.055231738835573196, -0.08178301900625229, 0.1531406193971634, -0.0673397108912468, 0.03819185495376587, 0.14952044188976288, 0.1129302829504013, 0.12073781341314316, -0.03648523613810539, 0.13774089515209198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:57.312166 139669057967936 logger.py:24] feat1:[-0.054040271788835526, -0.08161558955907822, 0.15596799552440643, -0.06431373208761215, 0.037463560700416565, 0.15063491463661194, 0.11396928876638412, 0.12260732054710388, -0.03389519825577736, 0.13862736523151398]\n",
      "feat2:[-0.05497051775455475, -0.08263486623764038, 0.15488801896572113, -0.07021547853946686, 0.034853897988796234, 0.1509111076593399, 0.1110510379076004, 0.1170838251709938, -0.03633484989404678, 0.13486935198307037]\n",
      "feat3:[-0.05489262565970421, -0.08132142573595047, 0.15598654747009277, -0.06835902482271194, 0.03764485567808151, 0.15443739295005798, 0.11252154409885406, 0.12113182246685028, -0.03608454763889313, 0.13414685428142548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:58.317412 139669057967936 logger.py:24] feat1:[-0.05497090518474579, -0.08188585191965103, 0.1557251363992691, -0.06287387013435364, 0.043568048626184464, 0.14916695654392242, 0.11360005289316177, 0.11871036142110825, -0.03764397278428078, 0.13871626555919647]\n",
      "feat2:[-0.05494819954037666, -0.08239865303039551, 0.15486904978752136, -0.06656527519226074, 0.03485582023859024, 0.15301136672496796, 0.11401316523551941, 0.11877457052469254, -0.034981194883584976, 0.13684138655662537]\n",
      "feat3:[-0.05771902948617935, -0.08080293983221054, 0.15476781129837036, -0.06896647065877914, 0.03516383469104767, 0.15418003499507904, 0.11176930367946625, 0.12178260833024979, -0.03074355237185955, 0.13571037352085114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 10:59:59.429717 139669057967936 logger.py:24] feat1:[-0.058496106415987015, -0.0838417336344719, 0.15585820376873016, -0.06895992159843445, 0.03682806342840195, 0.15054836869239807, 0.11164051294326782, 0.11784780770540237, -0.03529087454080582, 0.13771158456802368]\n",
      "feat2:[-0.05499276891350746, -0.07946449518203735, 0.15631233155727386, -0.06805378943681717, 0.038314223289489746, 0.15330997109413147, 0.11318516731262207, 0.12267043441534042, -0.0345279723405838, 0.13785259425640106]\n",
      "feat3:[-0.05227978155016899, -0.08245579898357391, 0.1545206606388092, -0.06435641646385193, 0.0391136109828949, 0.14765411615371704, 0.1123533844947815, 0.11599244922399521, -0.036255039274692535, 0.13678058981895447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scores: [[0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-903908d881bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             TrainSentiModel(sess, saver, summary_writer, logger, IMDB_train_graph, c2vec, \n\u001b[1;32m     32\u001b[0m                     \u001b[0mtrain_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_reader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     FLAGS.batch_size, FLAGS.batch_size, FLAGS.embedding_dim)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-49ddc2dfcda6>\u001b[0m in \u001b[0;36mTrainSentiModel\u001b[0;34m(sess, saver, summary_writer, logger, train_model, c2vec, train_reader, valid_reader, test_reader, train_batch, test_batch, embedding_dim)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mtrain_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mdata_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts2matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sent_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             feed_dic = {\n\u001b[1;32m     13\u001b[0m                         \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-363a11da4cec>\u001b[0m in \u001b[0;36mtexts2matrix\u001b[0;34m(texts, c2vec, max_sent_len, embedding_dim)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords2arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-363a11da4cec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords2arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-363a11da4cec>\u001b[0m in \u001b[0;36mwords2arr\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords2arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mrst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_sent_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/chars2vec/model.py\u001b[0m in \u001b[0;36mvectorize_words\u001b[0;34m(self, words, maxlen_padseq)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0membeddings_pad_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen_padseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mnew_words_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membeddings_pad_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF_GPU/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpu_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "gpu_config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# device = '/GPU:0'\n",
    "with tf.Graph().as_default() as g:\n",
    "    with tf.Session(graph=g, config=gpu_config) as sess:\n",
    "        with tf.device('/GPU:0'):\n",
    "            c2vec = chars2vec.load_model('eng_300')\n",
    "#             senti_model = SentimentModel( FLAGS.hidden_dim )\n",
    "            senti_model = SentiModel(max_word_length = max([train_reader.max_sent_len, \n",
    "                                                             valid_reader.max_sent_len, \n",
    "                                                             test_reader.max_sent_len]),\n",
    "                                       kernels = eval(FLAGS.kernels), \n",
    "                                       kernel_features = eval(FLAGS.kernel_features),\n",
    "                                       num_highway_layers = FLAGS.highway_layers,\n",
    "                                       embedding_dim = FLAGS.embedding_dim\n",
    "                                      )\n",
    "            IMDB_train_graph =  InferSentiTrainGraph(\n",
    "                                                         senti_model = senti_model,\n",
    "                                                         batch_size = FLAGS.batch_size, \n",
    "                                                         max_word_num = max([train_reader.max_sent_len, \n",
    "                                                                             valid_reader.max_sent_len, \n",
    "                                                                             test_reader.max_sent_len]), \n",
    "                                                         embedding_dim = FLAGS.embedding_dim, \n",
    "                                                         hidden_dim = FLAGS.hidden_dim, \n",
    "                                                         sent_num = FLAGS.sent_num\n",
    "                                                    )\n",
    "            val_list1 = tf.global_variables()\n",
    "            saver = tf.train.Saver(val_list1, max_to_keep=4)\n",
    "            sess.run(tf.variables_initializer(val_list1))\n",
    "            summary_writer = tf.summary.FileWriter(\"IMDBReports/\", graph=sess.graph)\n",
    "            TrainSentiModel(sess, saver, summary_writer, logger, IMDB_train_graph, c2vec, \n",
    "                    train_reader, valid_reader, test_reader,\n",
    "                    FLAGS.batch_size, FLAGS.batch_size, FLAGS.embedding_dim)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
