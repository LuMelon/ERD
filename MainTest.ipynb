{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 14:47:14.211623 140154599094080 deprecation_wrapper.py:119] From /home/hadoop/ERD/model.py:6: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import model\n",
    "from dataUtils import *\n",
    "from logger import MyLogger\n",
    "import sys\n",
    "import PTB_data_reader\n",
    "import time\n",
    "import numpy as np\n",
    "import lstm_char_cnn\n",
    "import config\n",
    "import pickle\n",
    "import dataloader\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "logger = MyLogger(\"ERDMain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0827 14:47:32.684508 140154599094080 logger.py:24] (300, 200, 101, 31, 2, 2)\n",
      "I0827 14:47:32.685089 140154599094080 logger.py:24] 2019-08-27 14:47:32 Data loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sent: 31 ,  max_seq_len: 101\n",
      "5802 data loaded\n",
      "300 200 101 31 2 2\n",
      "2019-08-27 14:47:32 Data loaded.\n"
     ]
    }
   ],
   "source": [
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    " #load PTB data\n",
    "# word_vocab, char_vocab, word_tensors, char_tensors, max_word_length = \\\n",
    "#     PTB_data_reader.load_data(FLAGS.data_dir, FLAGS.max_word_length, char_vocab, eos=FLAGS.EOS)\n",
    "word_vocab, char_vocab, word_tensors, char_tensors = \\\n",
    "    PTB_data_reader.load_data_fast()\n",
    "max_word_length = FLAGS.max_word_length\n",
    "train_reader = PTB_data_reader.DataReader(word_tensors['train'], char_tensors['train'],\n",
    "                          FLAGS.batch_size, FLAGS.num_unroll_steps) \n",
    "\n",
    "#load sentiment analysis data\n",
    "sentiReader = dataloader.SentiDataLoader(\n",
    "                                        dirpath = '/home/hadoop/trainingandtestdata',\n",
    "                                        trainfile = 'training.1600000.processed.noemoticon.csv', \n",
    "                                        testfile = 'testdata.manual.2009.06.14.csv', \n",
    "                                        charVocab = char_vocab\n",
    "                        )\n",
    "# sentiReader.load_data()\n",
    "sentiReader.load_data_fast(\n",
    "                        '/home/hadoop/ERD/data/senti_train_data.pickle',\n",
    "                        '/home/hadoop/ERD/data/senti_train_label.pickle',\n",
    "                        '/home/hadoop/ERD/data/senti_test_data.pickle',\n",
    "                        '/home/hadoop/ERD/data/senti_test_label.pickle'\n",
    "                          )\n",
    "\n",
    "# load twitter data\n",
    "# load_data(FLAGS.data_file_path)\n",
    "load_data_fast()\n",
    "\n",
    "# (self, input_dim, hidden_dim, max_seq_len, max_word_num, class_num, action_num):\n",
    "print(  FLAGS.embedding_dim, FLAGS.hidden_dim, \n",
    "            FLAGS.max_seq_len, FLAGS.max_sent_len, \n",
    "                FLAGS.class_num, FLAGS.action_num   )\n",
    "logger.info(    (FLAGS.embedding_dim, FLAGS.hidden_dim, \n",
    "                    FLAGS.max_seq_len, FLAGS.max_sent_len, \n",
    "                        FLAGS.class_num, FLAGS.action_num)  )\n",
    "\n",
    "print(get_curtime() + \" Data loaded.\")\n",
    "logger.info(get_curtime() + \" Data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the Twitter data\n",
    "# data = get_data()\n",
    "# with open('data/data_dict.txt', 'wb') as handle:\n",
    "#     pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # save the PTB data\n",
    "# with open('data/char_tensors.txt', 'wb') as handle:\n",
    "#     pickle.dump(char_tensors, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('data/word_tensors.txt', 'wb') as handle:\n",
    "#     pickle.dump(word_tensors, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open('data/char_vocab.txt', 'wb') as handle:\n",
    "#     pickle.dump(char_vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('data/word_vocab.txt', 'wb') as handle:\n",
    "#     pickle.dump(word_vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# save the senti data\n",
    "# with open('data/senti_train_data.pickle', 'wb') as handle:\n",
    "#     pickle.dump(sentiReader.train_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('data/senti_train_label.pickle', 'wb') as handle:\n",
    "#     pickle.dump(sentiReader.train_label, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open('data/senti_test_data.pickle', 'wb') as handle:\n",
    "#     pickle.dump(sentiReader.test_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('data/senti_test_label.pickle', 'wb') as handle:\n",
    "#     pickle.dump(sentiReader.test_label, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_: Tensor(\"input:0\", shape=(20, 35, 21), dtype=int32)\n",
      "input_cnn: Tensor(\"Embedding_1/CNN_OUT/add_7:0\", shape=(700, 1100), dtype=float32)\n",
      "final_embedding Tensor(\"Embedding_1/dense/Sigmoid:0\", shape=(700, 300), dtype=float32)\n",
      "input_: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "input_cnn: Tensor(\"Embedding_2/CNN_OUT/add_7:0\", shape=(?, 1100), dtype=float32)\n",
      "final_embedding Tensor(\"Embedding_2/dense/Sigmoid:0\", shape=(?, 300), dtype=float32)\n",
      "input_: Tensor(\"Reshape_2:0\", shape=(?, 31, 21), dtype=int32)\n",
      "input_cnn: Tensor(\"Embedding_3/CNN_OUT/add_7:0\", shape=(?, 1100), dtype=float32)\n",
      "final_embedding Tensor(\"Embedding_3/dense/Sigmoid:0\", shape=(?, 300), dtype=float32)\n",
      "pooled_rl_input: Tensor(\"Reshape_5:0\", shape=(?, 200), dtype=float32)\n",
      "rl_state: Tensor(\"rl_states:0\", shape=(?, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w2v = lstm_char_cnn.WordEmbedding(\n",
    "                max_word_length = FLAGS.max_char_num , \n",
    "                char_vocab_size = char_vocab.size, \n",
    "                char_embed_size = FLAGS.char_embed_size, \n",
    "                kernels = eval(FLAGS.kernels), \n",
    "                kernel_features = eval(FLAGS.kernel_features), \n",
    "                num_highway_layers = FLAGS.highway_layers,\n",
    "                embedding_dim = FLAGS.embedding_dim\n",
    "            )\n",
    "lstm_lm = lstm_char_cnn.LSTM_LM(\n",
    "            batch_size = FLAGS.batch_size, \n",
    "            num_unroll_steps = FLAGS.num_unroll_steps, \n",
    "            rnn_size = FLAGS.rnn_size, \n",
    "            num_rnn_layers = FLAGS.rnn_layers, \n",
    "            word_vocab_size = word_vocab.size\n",
    "        )\n",
    "\n",
    "char_train_graph = lstm_char_cnn.infer_train_model(\n",
    "                    w2v, lstm_lm, \n",
    "                    batch_size = FLAGS.batch_size, \n",
    "                    num_unroll_steps = FLAGS.num_unroll_steps, \n",
    "                    max_word_length = FLAGS.max_char_num, \n",
    "                    learning_rate = FLAGS.learning_rate,\n",
    "                    max_grad_norm = FLAGS.max_grad_norm\n",
    "                 )\n",
    "#sentiment analysis model\n",
    "s_model = model.SentiModel(FLAGS.hidden_dim, 5)\n",
    "senti_train_graph = model.InferSentiTrainGraph(\n",
    "                        w2v, \n",
    "                        s_model, \n",
    "                        max_word_num = FLAGS.max_sent_len, \n",
    "                        max_char_num = FLAGS.max_char_num, \n",
    "                        hidden_dim = FLAGS.hidden_dim, \n",
    "                        sent_num = FLAGS.sent_num,\n",
    "                        embedding_dim = FLAGS.embedding_dim\n",
    "                    )\n",
    "# df model\n",
    "rdm_model = model.RDM_Model(\n",
    "                max_seq_len = FLAGS.max_seq_len, \n",
    "                max_word_num = FLAGS.max_sent_len, \n",
    "                embedding_dim = FLAGS.embedding_dim, \n",
    "                hidden_dim = FLAGS.hidden_dim\n",
    "            )\n",
    "rdm_train_graph = model.InferRDMTrainGraph(\n",
    "                        w2v, s_model, rdm_model, \n",
    "                        max_seq_len = FLAGS.max_seq_len, \n",
    "                        max_word_num = FLAGS.max_sent_len, \n",
    "                        max_char_num = FLAGS.max_char_num, \n",
    "                        hidden_dim = FLAGS.hidden_dim, \n",
    "                        embedding_dim = FLAGS.embedding_dim,\n",
    "                        class_num = FLAGS.class_num\n",
    "                )\n",
    "\n",
    "# rl model\n",
    "cm_model = model.CM_Model(\n",
    "                    max_word_num = FLAGS.max_sent_len, \n",
    "                    embedding_dim = FLAGS.embedding_dim, \n",
    "                    hidden_dim = FLAGS.hidden_dim, \n",
    "                    action_num = FLAGS.action_num\n",
    "            )\n",
    "cm_train_graph = model.InferCMTrainGraph(\n",
    "                        w2v, s_model, rdm_model, cm_model, \n",
    "                        max_word_num = FLAGS.max_sent_len, \n",
    "                        embedding_dim = FLAGS.embedding_dim, \n",
    "                        hidden_dim = FLAGS.hidden_dim, \n",
    "                        action_num = FLAGS.action_num\n",
    "                    )\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=4)\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(FLAGS.train_dir, graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lstm_char_cnn' from '/home/hadoop/ERD/lstm_char_cnn.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(lstm_char_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    34: 0 [    5/ 1327], train_loss/perplexity = 7.00820255/1105.6652832 secs/batch = 1.3773s, grad.norm=1.10350180\n",
      "    39: 0 [   10/ 1327], train_loss/perplexity = 6.94740629/1040.4476318 secs/batch = 1.2614s, grad.norm=2.40912032\n",
      "    44: 0 [   15/ 1327], train_loss/perplexity = 7.09035158/1200.3297119 secs/batch = 1.2492s, grad.norm=0.62322396\n",
      "    49: 0 [   20/ 1327], train_loss/perplexity = 7.16882467/1298.3177490 secs/batch = 1.2724s, grad.norm=1.75169051\n",
      "    54: 0 [   25/ 1327], train_loss/perplexity = 6.97885656/1073.6899414 secs/batch = 1.2633s, grad.norm=0.52654147\n",
      "    59: 0 [   30/ 1327], train_loss/perplexity = 6.75696754/860.0302124 secs/batch = 1.2567s, grad.norm=0.55534643\n",
      "    64: 0 [   35/ 1327], train_loss/perplexity = 6.96802521/1062.1231689 secs/batch = 1.3029s, grad.norm=0.75841022\n",
      "    69: 0 [   40/ 1327], train_loss/perplexity = 6.80093956/898.6912842 secs/batch = 1.4808s, grad.norm=0.50612611\n",
      "    74: 0 [   45/ 1327], train_loss/perplexity = 6.57951593/720.1906128 secs/batch = 1.2461s, grad.norm=0.43654180\n",
      "    79: 0 [   50/ 1327], train_loss/perplexity = 7.28676462/1460.8366699 secs/batch = 1.3221s, grad.norm=1.05241466\n",
      "    84: 0 [   55/ 1327], train_loss/perplexity = 7.04554892/1147.7386475 secs/batch = 1.2452s, grad.norm=0.67185444\n",
      "    89: 0 [   60/ 1327], train_loss/perplexity = 6.91985273/1012.1708984 secs/batch = 1.2397s, grad.norm=1.94297230\n",
      "    94: 0 [   65/ 1327], train_loss/perplexity = 6.61671162/747.4830322 secs/batch = 1.3077s, grad.norm=0.42996213\n",
      "    99: 0 [   70/ 1327], train_loss/perplexity = 6.61206341/744.0166626 secs/batch = 1.2469s, grad.norm=1.04512393\n",
      "   104: 0 [   75/ 1327], train_loss/perplexity = 6.66404390/783.7138062 secs/batch = 1.2465s, grad.norm=0.82011700\n",
      "   109: 0 [   80/ 1327], train_loss/perplexity = 6.74298334/848.0870972 secs/batch = 1.2553s, grad.norm=0.53942293\n",
      "   114: 0 [   85/ 1327], train_loss/perplexity = 6.89038992/982.7845459 secs/batch = 1.2449s, grad.norm=1.23176622\n",
      "   119: 0 [   90/ 1327], train_loss/perplexity = 6.88190556/974.4815063 secs/batch = 1.2485s, grad.norm=0.53741604\n",
      "   124: 0 [   95/ 1327], train_loss/perplexity = 6.69839334/811.1016235 secs/batch = 1.2483s, grad.norm=0.52228802\n",
      "   129: 0 [  100/ 1327], train_loss/perplexity = 6.89480972/987.1378784 secs/batch = 1.2722s, grad.norm=0.56531703\n",
      "   134: 0 [  105/ 1327], train_loss/perplexity = 6.89546585/987.7857666 secs/batch = 1.2523s, grad.norm=0.56298459\n",
      "   139: 0 [  110/ 1327], train_loss/perplexity = 6.65546227/777.0170288 secs/batch = 1.2485s, grad.norm=0.65388924\n",
      "   144: 0 [  115/ 1327], train_loss/perplexity = 6.53664923/689.9707642 secs/batch = 1.2442s, grad.norm=0.57484114\n",
      "   149: 0 [  120/ 1327], train_loss/perplexity = 6.75840473/861.2671509 secs/batch = 1.2426s, grad.norm=0.48663262\n",
      "   154: 0 [  125/ 1327], train_loss/perplexity = 6.80753326/904.6365356 secs/batch = 1.2417s, grad.norm=0.46537387\n",
      "   159: 0 [  130/ 1327], train_loss/perplexity = 6.81321144/909.7878418 secs/batch = 1.2759s, grad.norm=0.83708894\n",
      "   164: 0 [  135/ 1327], train_loss/perplexity = 6.79714298/895.2857666 secs/batch = 1.2378s, grad.norm=0.62150419\n",
      "   169: 0 [  140/ 1327], train_loss/perplexity = 6.79963017/897.5153198 secs/batch = 1.2436s, grad.norm=0.42842558\n",
      "   174: 0 [  145/ 1327], train_loss/perplexity = 6.85989046/953.2626343 secs/batch = 1.4165s, grad.norm=0.63517797\n",
      "   179: 0 [  150/ 1327], train_loss/perplexity = 6.63698673/762.7930298 secs/batch = 1.2366s, grad.norm=0.39089519\n",
      "   184: 0 [  155/ 1327], train_loss/perplexity = 6.82161951/917.4696655 secs/batch = 1.2409s, grad.norm=0.56893837\n",
      "   189: 0 [  160/ 1327], train_loss/perplexity = 6.52179193/679.7954712 secs/batch = 1.2522s, grad.norm=0.81006736\n",
      "   194: 0 [  165/ 1327], train_loss/perplexity = 6.69847918/811.1712646 secs/batch = 1.2491s, grad.norm=0.68828523\n",
      "   199: 0 [  170/ 1327], train_loss/perplexity = 6.73125219/838.1961670 secs/batch = 1.2389s, grad.norm=0.45877302\n",
      "   204: 0 [  175/ 1327], train_loss/perplexity = 6.80052948/898.3228149 secs/batch = 1.2390s, grad.norm=0.48106745\n",
      "   209: 0 [  180/ 1327], train_loss/perplexity = 6.76800871/869.5786133 secs/batch = 1.2337s, grad.norm=0.70366216\n",
      "   214: 0 [  185/ 1327], train_loss/perplexity = 6.80363846/901.1199951 secs/batch = 1.2306s, grad.norm=0.37499216\n",
      "   219: 0 [  190/ 1327], train_loss/perplexity = 6.66872931/787.3944092 secs/batch = 1.2592s, grad.norm=0.40735754\n",
      "   224: 0 [  195/ 1327], train_loss/perplexity = 6.70640230/817.6237793 secs/batch = 1.2477s, grad.norm=0.62449980\n",
      "   229: 0 [  200/ 1327], train_loss/perplexity = 6.86786985/960.8995361 secs/batch = 1.2289s, grad.norm=0.57754099\n",
      "   234: 0 [  205/ 1327], train_loss/perplexity = 6.66636372/785.5339966 secs/batch = 1.2399s, grad.norm=0.43390080\n",
      "   239: 0 [  210/ 1327], train_loss/perplexity = 6.57013178/713.4638672 secs/batch = 1.2367s, grad.norm=0.53660417\n",
      "   244: 0 [  215/ 1327], train_loss/perplexity = 6.75690365/859.9752808 secs/batch = 1.2464s, grad.norm=0.97123396\n",
      "   249: 0 [  220/ 1327], train_loss/perplexity = 6.67838097/795.0308838 secs/batch = 1.2298s, grad.norm=0.39180756\n",
      "   254: 0 [  225/ 1327], train_loss/perplexity = 6.82991886/925.1157227 secs/batch = 1.2352s, grad.norm=0.44203213\n",
      "   259: 0 [  230/ 1327], train_loss/perplexity = 6.66855764/787.2592773 secs/batch = 1.2434s, grad.norm=0.51859647\n",
      "   264: 0 [  235/ 1327], train_loss/perplexity = 6.67912722/795.6243896 secs/batch = 1.2320s, grad.norm=0.70169771\n",
      "   269: 0 [  240/ 1327], train_loss/perplexity = 6.50106573/665.8508911 secs/batch = 1.2409s, grad.norm=0.56382447\n",
      "   274: 0 [  245/ 1327], train_loss/perplexity = 6.77497339/875.6560669 secs/batch = 1.2324s, grad.norm=0.41801512\n",
      "   279: 0 [  250/ 1327], train_loss/perplexity = 6.60120249/735.9796753 secs/batch = 1.2380s, grad.norm=0.41423082\n",
      "   284: 0 [  255/ 1327], train_loss/perplexity = 6.69199228/805.9262695 secs/batch = 1.2286s, grad.norm=0.34940344\n",
      "   289: 0 [  260/ 1327], train_loss/perplexity = 6.80994511/906.8210449 secs/batch = 1.2354s, grad.norm=0.32819483\n",
      "   294: 0 [  265/ 1327], train_loss/perplexity = 6.79974461/897.6180420 secs/batch = 1.2319s, grad.norm=0.48091587\n",
      "   299: 0 [  270/ 1327], train_loss/perplexity = 6.70237160/814.3348389 secs/batch = 1.2468s, grad.norm=0.59104216\n",
      "   304: 0 [  275/ 1327], train_loss/perplexity = 6.93105888/1023.5772705 secs/batch = 1.2358s, grad.norm=0.69697839\n",
      "   309: 0 [  280/ 1327], train_loss/perplexity = 6.58213520/722.0794678 secs/batch = 1.2363s, grad.norm=0.48675311\n",
      "   314: 0 [  285/ 1327], train_loss/perplexity = 6.73084545/837.8553467 secs/batch = 1.2339s, grad.norm=0.38033658\n",
      "   319: 0 [  290/ 1327], train_loss/perplexity = 6.76143408/863.8801880 secs/batch = 1.2350s, grad.norm=0.57018405\n",
      "   324: 0 [  295/ 1327], train_loss/perplexity = 6.76927471/870.6801758 secs/batch = 1.2321s, grad.norm=0.58902943\n",
      "   329: 0 [  300/ 1327], train_loss/perplexity = 6.58730412/725.8214722 secs/batch = 1.2334s, grad.norm=0.51082623\n",
      "   334: 0 [  305/ 1327], train_loss/perplexity = 6.54026461/692.4697876 secs/batch = 1.2337s, grad.norm=0.38893792\n",
      "   339: 0 [  310/ 1327], train_loss/perplexity = 6.61031389/742.7161255 secs/batch = 1.2356s, grad.norm=0.33569404\n",
      "   344: 0 [  315/ 1327], train_loss/perplexity = 6.44442081/629.1821289 secs/batch = 1.2438s, grad.norm=0.34016949\n",
      "   349: 0 [  320/ 1327], train_loss/perplexity = 6.74878550/853.0221558 secs/batch = 1.2398s, grad.norm=0.65398222\n",
      "   354: 0 [  325/ 1327], train_loss/perplexity = 6.51200056/673.1718140 secs/batch = 1.2595s, grad.norm=0.59266704\n",
      "   359: 0 [  330/ 1327], train_loss/perplexity = 6.73308754/839.7359619 secs/batch = 1.2385s, grad.norm=0.55680346\n",
      "   364: 0 [  335/ 1327], train_loss/perplexity = 6.25174809/518.9191284 secs/batch = 1.2392s, grad.norm=0.47968751\n",
      "   369: 0 [  340/ 1327], train_loss/perplexity = 6.65181065/774.1848145 secs/batch = 1.2589s, grad.norm=0.41979158\n",
      "   374: 0 [  345/ 1327], train_loss/perplexity = 6.63118649/758.3814697 secs/batch = 1.2273s, grad.norm=0.30041540\n",
      "   379: 0 [  350/ 1327], train_loss/perplexity = 6.60245895/736.9049683 secs/batch = 1.2565s, grad.norm=0.46540916\n",
      "   384: 0 [  355/ 1327], train_loss/perplexity = 6.71114254/821.5087280 secs/batch = 1.2310s, grad.norm=0.70860022\n",
      "   389: 0 [  360/ 1327], train_loss/perplexity = 6.73782730/843.7255859 secs/batch = 1.2320s, grad.norm=0.32927683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   394: 0 [  365/ 1327], train_loss/perplexity = 6.65772533/778.7774658 secs/batch = 1.2299s, grad.norm=0.33532420\n",
      "   399: 0 [  370/ 1327], train_loss/perplexity = 6.78186893/881.7150269 secs/batch = 1.2431s, grad.norm=0.51567829\n",
      "   404: 0 [  375/ 1327], train_loss/perplexity = 6.50124311/665.9689941 secs/batch = 1.2314s, grad.norm=0.37611791\n",
      "   409: 0 [  380/ 1327], train_loss/perplexity = 6.66318798/783.0432739 secs/batch = 1.2312s, grad.norm=0.43182096\n",
      "   414: 0 [  385/ 1327], train_loss/perplexity = 6.83460808/929.4639893 secs/batch = 1.2305s, grad.norm=0.48492444\n",
      "   419: 0 [  390/ 1327], train_loss/perplexity = 6.60802317/741.0167236 secs/batch = 1.2325s, grad.norm=0.35548833\n",
      "   424: 0 [  395/ 1327], train_loss/perplexity = 6.83409309/928.9854736 secs/batch = 1.2346s, grad.norm=0.38335186\n",
      "   429: 0 [  400/ 1327], train_loss/perplexity = 6.53138828/686.3504028 secs/batch = 1.2310s, grad.norm=0.70329678\n",
      "   434: 0 [  405/ 1327], train_loss/perplexity = 6.78411198/883.6950073 secs/batch = 1.2291s, grad.norm=0.91220909\n",
      "   439: 0 [  410/ 1327], train_loss/perplexity = 6.66513443/784.5689087 secs/batch = 1.2258s, grad.norm=0.51071548\n",
      "   444: 0 [  415/ 1327], train_loss/perplexity = 6.50918579/671.2796631 secs/batch = 1.2341s, grad.norm=0.32398364\n",
      "   449: 0 [  420/ 1327], train_loss/perplexity = 6.57296324/715.4868774 secs/batch = 1.2365s, grad.norm=0.35723749\n",
      "   454: 0 [  425/ 1327], train_loss/perplexity = 6.75456476/857.9662476 secs/batch = 1.2433s, grad.norm=0.34374061\n",
      "   459: 0 [  430/ 1327], train_loss/perplexity = 6.69359398/807.2181396 secs/batch = 1.2341s, grad.norm=0.34751436\n",
      "   464: 0 [  435/ 1327], train_loss/perplexity = 6.72736835/834.9470825 secs/batch = 1.2287s, grad.norm=0.61883831\n",
      "   469: 0 [  440/ 1327], train_loss/perplexity = 6.65059710/773.2459106 secs/batch = 1.2343s, grad.norm=1.01039982\n",
      "   474: 0 [  445/ 1327], train_loss/perplexity = 6.71124220/821.5905762 secs/batch = 1.2320s, grad.norm=1.03774965\n",
      "   479: 0 [  450/ 1327], train_loss/perplexity = 6.60887814/741.6505127 secs/batch = 1.2396s, grad.norm=0.35172558\n",
      "   484: 0 [  455/ 1327], train_loss/perplexity = 6.37765217/588.5443115 secs/batch = 1.2276s, grad.norm=0.43168998\n",
      "   489: 0 [  460/ 1327], train_loss/perplexity = 6.63773489/763.3639526 secs/batch = 1.2292s, grad.norm=0.34827632\n",
      "   494: 0 [  465/ 1327], train_loss/perplexity = 6.56753922/711.6165771 secs/batch = 1.2352s, grad.norm=0.42155907\n",
      "   499: 0 [  470/ 1327], train_loss/perplexity = 6.73353243/840.1096802 secs/batch = 1.2304s, grad.norm=0.39664927\n",
      "   504: 0 [  475/ 1327], train_loss/perplexity = 6.73848486/844.2805786 secs/batch = 1.2315s, grad.norm=0.30618387\n",
      "   509: 0 [  480/ 1327], train_loss/perplexity = 6.61260176/744.4172974 secs/batch = 1.2281s, grad.norm=0.40811846\n",
      "   514: 0 [  485/ 1327], train_loss/perplexity = 6.63594818/762.0012207 secs/batch = 1.2590s, grad.norm=0.38283175\n",
      "   519: 0 [  490/ 1327], train_loss/perplexity = 6.64965057/772.5143433 secs/batch = 1.2464s, grad.norm=0.47556967\n",
      "   524: 0 [  495/ 1327], train_loss/perplexity = 6.37135172/584.8478394 secs/batch = 1.2323s, grad.norm=0.79659009\n",
      "   529: 0 [  500/ 1327], train_loss/perplexity = 6.71719170/826.4932251 secs/batch = 1.2298s, grad.norm=0.46623710\n",
      "   534: 0 [  505/ 1327], train_loss/perplexity = 6.61154509/743.6311035 secs/batch = 1.2363s, grad.norm=0.47923267\n",
      "   539: 0 [  510/ 1327], train_loss/perplexity = 6.65197611/774.3129272 secs/batch = 1.2387s, grad.norm=0.33426890\n",
      "   544: 0 [  515/ 1327], train_loss/perplexity = 6.51699352/676.5413208 secs/batch = 1.2452s, grad.norm=0.48211914\n",
      "   549: 0 [  520/ 1327], train_loss/perplexity = 6.69142914/805.4725342 secs/batch = 1.2315s, grad.norm=0.53604126\n",
      "   554: 0 [  525/ 1327], train_loss/perplexity = 6.55286741/701.2520752 secs/batch = 1.2400s, grad.norm=0.35883620\n",
      "   559: 0 [  530/ 1327], train_loss/perplexity = 6.59245825/729.5721436 secs/batch = 1.2352s, grad.norm=0.58563995\n",
      "   564: 0 [  535/ 1327], train_loss/perplexity = 6.66064024/781.0508423 secs/batch = 1.2354s, grad.norm=0.29833615\n",
      "   569: 0 [  540/ 1327], train_loss/perplexity = 6.69010115/804.4036255 secs/batch = 1.2386s, grad.norm=0.30074504\n",
      "   574: 0 [  545/ 1327], train_loss/perplexity = 6.70412159/815.7611084 secs/batch = 1.2410s, grad.norm=0.33384791\n",
      "   579: 0 [  550/ 1327], train_loss/perplexity = 6.71612930/825.6156006 secs/batch = 1.2322s, grad.norm=0.39216721\n",
      "   584: 0 [  555/ 1327], train_loss/perplexity = 6.60457230/738.4639282 secs/batch = 1.2406s, grad.norm=0.43048126\n",
      "   589: 0 [  560/ 1327], train_loss/perplexity = 6.71797371/827.1397705 secs/batch = 1.2261s, grad.norm=0.34433082\n",
      "   594: 0 [  565/ 1327], train_loss/perplexity = 6.64630032/769.9305420 secs/batch = 1.2284s, grad.norm=0.40321520\n",
      "   599: 0 [  570/ 1327], train_loss/perplexity = 6.56167698/707.4570923 secs/batch = 1.2320s, grad.norm=0.39225331\n",
      "   604: 0 [  575/ 1327], train_loss/perplexity = 6.60324478/737.4843140 secs/batch = 1.2382s, grad.norm=0.45074180\n",
      "   609: 0 [  580/ 1327], train_loss/perplexity = 6.62436152/753.2231445 secs/batch = 1.2331s, grad.norm=0.40975615\n",
      "   614: 0 [  585/ 1327], train_loss/perplexity = 6.54547644/696.0882568 secs/batch = 1.2337s, grad.norm=0.45693514\n",
      "   619: 0 [  590/ 1327], train_loss/perplexity = 6.71639109/825.8317871 secs/batch = 1.2436s, grad.norm=0.38579094\n",
      "   624: 0 [  595/ 1327], train_loss/perplexity = 6.64706182/770.5170898 secs/batch = 1.2411s, grad.norm=0.34100100\n",
      "   629: 0 [  600/ 1327], train_loss/perplexity = 6.71578407/825.3306274 secs/batch = 1.2318s, grad.norm=0.38183579\n",
      "   634: 0 [  605/ 1327], train_loss/perplexity = 6.66482353/784.3250732 secs/batch = 1.2314s, grad.norm=0.45205238\n",
      "   639: 0 [  610/ 1327], train_loss/perplexity = 6.82487440/920.4608154 secs/batch = 1.2283s, grad.norm=0.49674496\n",
      "   644: 0 [  615/ 1327], train_loss/perplexity = 6.34421682/569.1914673 secs/batch = 1.2429s, grad.norm=0.35264257\n",
      "   649: 0 [  620/ 1327], train_loss/perplexity = 6.55607700/703.5064087 secs/batch = 1.2367s, grad.norm=0.33311331\n",
      "   654: 0 [  625/ 1327], train_loss/perplexity = 6.68390417/799.4341431 secs/batch = 1.2420s, grad.norm=0.28806397\n",
      "   659: 0 [  630/ 1327], train_loss/perplexity = 6.68594027/801.0635376 secs/batch = 1.2397s, grad.norm=0.34087572\n",
      "   664: 0 [  635/ 1327], train_loss/perplexity = 6.62869263/756.4924927 secs/batch = 1.2344s, grad.norm=0.55866063\n",
      "   669: 0 [  640/ 1327], train_loss/perplexity = 6.55093336/699.8971558 secs/batch = 1.2296s, grad.norm=0.69072813\n",
      "   674: 0 [  645/ 1327], train_loss/perplexity = 6.64503193/768.9545898 secs/batch = 1.2296s, grad.norm=0.31284577\n",
      "   679: 0 [  650/ 1327], train_loss/perplexity = 6.53230047/686.9767456 secs/batch = 1.2309s, grad.norm=0.53005683\n",
      "   684: 0 [  655/ 1327], train_loss/perplexity = 6.51668406/676.3319702 secs/batch = 1.2378s, grad.norm=0.39086682\n",
      "   689: 0 [  660/ 1327], train_loss/perplexity = 6.55717611/704.2800903 secs/batch = 1.2428s, grad.norm=0.33272156\n",
      "   694: 0 [  665/ 1327], train_loss/perplexity = 6.67758799/794.4006958 secs/batch = 1.2431s, grad.norm=0.38049963\n",
      "   699: 0 [  670/ 1327], train_loss/perplexity = 6.61699152/747.6923218 secs/batch = 1.2354s, grad.norm=0.36016443\n",
      "   704: 0 [  675/ 1327], train_loss/perplexity = 6.43520498/623.4103394 secs/batch = 1.2336s, grad.norm=0.33791140\n",
      "   709: 0 [  680/ 1327], train_loss/perplexity = 6.80368948/901.1660156 secs/batch = 1.2580s, grad.norm=0.52411461\n",
      "   714: 0 [  685/ 1327], train_loss/perplexity = 6.73120880/838.1598511 secs/batch = 1.2471s, grad.norm=0.53670454\n",
      "   719: 0 [  690/ 1327], train_loss/perplexity = 6.69721317/810.1449585 secs/batch = 1.2502s, grad.norm=0.43026981\n",
      "   724: 0 [  695/ 1327], train_loss/perplexity = 6.56591177/710.4593506 secs/batch = 1.2288s, grad.norm=0.37755862\n",
      "   729: 0 [  700/ 1327], train_loss/perplexity = 6.61730194/747.9244385 secs/batch = 1.2313s, grad.norm=0.28318015\n",
      "   734: 0 [  705/ 1327], train_loss/perplexity = 6.46227264/640.5150757 secs/batch = 1.2286s, grad.norm=0.40874997\n",
      "   739: 0 [  710/ 1327], train_loss/perplexity = 6.57476616/716.7780151 secs/batch = 1.2339s, grad.norm=0.28274029\n",
      "   744: 0 [  715/ 1327], train_loss/perplexity = 6.61010885/742.5638428 secs/batch = 1.2408s, grad.norm=0.37713343\n",
      "   749: 0 [  720/ 1327], train_loss/perplexity = 6.62388134/752.8615723 secs/batch = 1.2321s, grad.norm=0.47092104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   754: 0 [  725/ 1327], train_loss/perplexity = 6.43489265/623.2156982 secs/batch = 1.2393s, grad.norm=0.61607856\n",
      "   759: 0 [  730/ 1327], train_loss/perplexity = 6.44006634/626.4483643 secs/batch = 1.2326s, grad.norm=0.32190192\n",
      "   764: 0 [  735/ 1327], train_loss/perplexity = 6.59856844/734.0435791 secs/batch = 1.2255s, grad.norm=0.30069298\n",
      "   769: 0 [  740/ 1327], train_loss/perplexity = 6.46184969/640.2442017 secs/batch = 1.2343s, grad.norm=0.42999017\n",
      "   774: 0 [  745/ 1327], train_loss/perplexity = 6.60869551/741.5150757 secs/batch = 1.2357s, grad.norm=0.40313420\n",
      "   779: 0 [  750/ 1327], train_loss/perplexity = 6.45271969/634.4254150 secs/batch = 1.2383s, grad.norm=0.40159151\n",
      "   784: 0 [  755/ 1327], train_loss/perplexity = 6.49926567/664.6533813 secs/batch = 1.2403s, grad.norm=0.29774725\n",
      "   789: 0 [  760/ 1327], train_loss/perplexity = 6.42754793/618.6550903 secs/batch = 1.2359s, grad.norm=0.41735300\n",
      "   794: 0 [  765/ 1327], train_loss/perplexity = 6.45896769/638.4016724 secs/batch = 1.2351s, grad.norm=0.51858675\n",
      "   799: 0 [  770/ 1327], train_loss/perplexity = 6.46616650/643.0139771 secs/batch = 1.2402s, grad.norm=0.32485208\n",
      "   804: 0 [  775/ 1327], train_loss/perplexity = 6.53824615/691.0734863 secs/batch = 1.2318s, grad.norm=0.34858057\n",
      "   809: 0 [  780/ 1327], train_loss/perplexity = 6.65678787/778.0477295 secs/batch = 1.2280s, grad.norm=0.34590027\n",
      "   814: 0 [  785/ 1327], train_loss/perplexity = 6.52590609/682.5979614 secs/batch = 1.2300s, grad.norm=0.34379214\n",
      "   819: 0 [  790/ 1327], train_loss/perplexity = 6.40343809/603.9177856 secs/batch = 1.2436s, grad.norm=0.41233876\n",
      "   824: 0 [  795/ 1327], train_loss/perplexity = 6.62905693/756.7681274 secs/batch = 1.2527s, grad.norm=0.34455863\n",
      "   829: 0 [  800/ 1327], train_loss/perplexity = 6.58451986/723.8034668 secs/batch = 1.2300s, grad.norm=0.35209575\n",
      "   834: 0 [  805/ 1327], train_loss/perplexity = 6.69943476/811.9467773 secs/batch = 1.2358s, grad.norm=0.40483767\n",
      "   839: 0 [  810/ 1327], train_loss/perplexity = 6.64536905/769.2138672 secs/batch = 1.2589s, grad.norm=0.41163418\n",
      "   844: 0 [  815/ 1327], train_loss/perplexity = 6.45273161/634.4329224 secs/batch = 1.2351s, grad.norm=0.41746581\n",
      "   849: 0 [  820/ 1327], train_loss/perplexity = 6.31480694/552.6953735 secs/batch = 1.2388s, grad.norm=0.41741678\n",
      "   854: 0 [  825/ 1327], train_loss/perplexity = 6.45615005/636.6054077 secs/batch = 1.2679s, grad.norm=0.30173108\n",
      "   859: 0 [  830/ 1327], train_loss/perplexity = 6.32500124/558.3585205 secs/batch = 1.2359s, grad.norm=0.36931601\n",
      "   864: 0 [  835/ 1327], train_loss/perplexity = 6.55179739/700.5021362 secs/batch = 1.2298s, grad.norm=0.30779228\n",
      "   869: 0 [  840/ 1327], train_loss/perplexity = 6.63805246/763.6063843 secs/batch = 1.2370s, grad.norm=0.27832901\n",
      "   874: 0 [  845/ 1327], train_loss/perplexity = 6.57184076/714.6842041 secs/batch = 1.2232s, grad.norm=0.33882731\n",
      "   879: 0 [  850/ 1327], train_loss/perplexity = 6.51108742/672.5573730 secs/batch = 1.2320s, grad.norm=0.37986758\n",
      "   884: 0 [  855/ 1327], train_loss/perplexity = 6.54726362/697.3333740 secs/batch = 1.2469s, grad.norm=0.33986121\n",
      "   889: 0 [  860/ 1327], train_loss/perplexity = 6.34621716/570.3311768 secs/batch = 1.2391s, grad.norm=0.34780100\n",
      "   894: 0 [  865/ 1327], train_loss/perplexity = 6.65800238/778.9932251 secs/batch = 1.2461s, grad.norm=0.32772592\n",
      "   899: 0 [  870/ 1327], train_loss/perplexity = 6.71276665/822.8439941 secs/batch = 1.2360s, grad.norm=0.37689003\n",
      "   904: 0 [  875/ 1327], train_loss/perplexity = 6.39607191/599.4855957 secs/batch = 1.2247s, grad.norm=0.27245373\n",
      "   909: 0 [  880/ 1327], train_loss/perplexity = 6.59501314/731.4384766 secs/batch = 1.2389s, grad.norm=0.36169535\n",
      "   914: 0 [  885/ 1327], train_loss/perplexity = 6.45769596/637.5903320 secs/batch = 1.2288s, grad.norm=0.37835661\n",
      "   919: 0 [  890/ 1327], train_loss/perplexity = 6.60607338/739.5733032 secs/batch = 1.2345s, grad.norm=0.49142992\n",
      "   924: 0 [  895/ 1327], train_loss/perplexity = 6.60356855/737.7230835 secs/batch = 1.2369s, grad.norm=0.37321955\n",
      "   929: 0 [  900/ 1327], train_loss/perplexity = 6.56577492/710.3621826 secs/batch = 1.2323s, grad.norm=0.43039781\n",
      "   934: 0 [  905/ 1327], train_loss/perplexity = 6.48166990/653.0606079 secs/batch = 1.2371s, grad.norm=0.33276278\n",
      "   939: 0 [  910/ 1327], train_loss/perplexity = 6.46340895/641.2432861 secs/batch = 1.2295s, grad.norm=0.40814584\n",
      "   944: 0 [  915/ 1327], train_loss/perplexity = 6.74490452/849.7180176 secs/batch = 1.2367s, grad.norm=0.38880205\n",
      "   949: 0 [  920/ 1327], train_loss/perplexity = 6.71781969/827.0123901 secs/batch = 1.2369s, grad.norm=0.40959471\n",
      "   954: 0 [  925/ 1327], train_loss/perplexity = 6.54107857/693.0336304 secs/batch = 1.2255s, grad.norm=0.42923185\n",
      "   959: 0 [  930/ 1327], train_loss/perplexity = 6.47111416/646.2033081 secs/batch = 1.2356s, grad.norm=0.49156204\n",
      "   964: 0 [  935/ 1327], train_loss/perplexity = 6.57737780/718.6524048 secs/batch = 1.2352s, grad.norm=0.27276254\n",
      "   969: 0 [  940/ 1327], train_loss/perplexity = 6.52842474/684.3193970 secs/batch = 1.2250s, grad.norm=0.40547523\n",
      "   974: 0 [  945/ 1327], train_loss/perplexity = 6.64695740/770.4366455 secs/batch = 1.2439s, grad.norm=0.29898253\n",
      "   979: 0 [  950/ 1327], train_loss/perplexity = 6.50137186/666.0547485 secs/batch = 1.2435s, grad.norm=0.30689800\n",
      "   984: 0 [  955/ 1327], train_loss/perplexity = 6.64298534/767.3825073 secs/batch = 1.2476s, grad.norm=0.32450637\n",
      "   989: 0 [  960/ 1327], train_loss/perplexity = 6.69833136/811.0513306 secs/batch = 1.2264s, grad.norm=0.34720302\n",
      "   994: 0 [  965/ 1327], train_loss/perplexity = 6.58437347/723.6975098 secs/batch = 1.2286s, grad.norm=0.37150091\n",
      "   999: 0 [  970/ 1327], train_loss/perplexity = 6.61286354/744.6121826 secs/batch = 1.2438s, grad.norm=0.37905478\n",
      "  1004: 0 [  975/ 1327], train_loss/perplexity = 6.56180716/707.5491943 secs/batch = 1.2332s, grad.norm=0.34539893\n",
      "  1009: 0 [  980/ 1327], train_loss/perplexity = 6.46014643/639.1546631 secs/batch = 1.2448s, grad.norm=0.26387483\n",
      "  1014: 0 [  985/ 1327], train_loss/perplexity = 6.63264513/759.4884644 secs/batch = 1.2350s, grad.norm=0.31461060\n",
      "  1019: 0 [  990/ 1327], train_loss/perplexity = 6.68793440/802.6625366 secs/batch = 1.2406s, grad.norm=0.33807224\n",
      "  1024: 0 [  995/ 1327], train_loss/perplexity = 6.68799877/802.7142334 secs/batch = 1.2347s, grad.norm=0.35051754\n",
      "  1029: 0 [ 1000/ 1327], train_loss/perplexity = 6.40766382/606.4752197 secs/batch = 1.2392s, grad.norm=0.37725151\n",
      "  1034: 0 [ 1005/ 1327], train_loss/perplexity = 6.64590406/769.6255493 secs/batch = 1.2337s, grad.norm=0.31170931\n",
      "  1039: 0 [ 1010/ 1327], train_loss/perplexity = 6.39459276/598.5994873 secs/batch = 1.2380s, grad.norm=0.35055211\n",
      "  1044: 0 [ 1015/ 1327], train_loss/perplexity = 6.59641314/732.4631958 secs/batch = 1.2449s, grad.norm=0.35410589\n",
      "  1049: 0 [ 1020/ 1327], train_loss/perplexity = 6.69395781/807.5119019 secs/batch = 1.2498s, grad.norm=0.39022711\n",
      "  1054: 0 [ 1025/ 1327], train_loss/perplexity = 6.56959963/713.0842896 secs/batch = 1.2309s, grad.norm=0.26999277\n",
      "  1059: 0 [ 1030/ 1327], train_loss/perplexity = 6.54478025/695.6038208 secs/batch = 1.2358s, grad.norm=0.27625349\n",
      "  1064: 0 [ 1035/ 1327], train_loss/perplexity = 6.51269579/673.6399536 secs/batch = 1.2347s, grad.norm=0.40346974\n",
      "  1069: 0 [ 1040/ 1327], train_loss/perplexity = 6.51069832/672.2957153 secs/batch = 1.2381s, grad.norm=0.24510780\n",
      "  1074: 0 [ 1045/ 1327], train_loss/perplexity = 6.32911539/560.6604004 secs/batch = 1.2385s, grad.norm=0.31817850\n",
      "  1079: 0 [ 1050/ 1327], train_loss/perplexity = 6.55460739/702.4733276 secs/batch = 1.2396s, grad.norm=0.30924487\n",
      "  1084: 0 [ 1055/ 1327], train_loss/perplexity = 6.72059917/829.3142700 secs/batch = 1.2233s, grad.norm=0.41857231\n",
      "  1089: 0 [ 1060/ 1327], train_loss/perplexity = 6.45570612/636.3228760 secs/batch = 1.2450s, grad.norm=0.41337824\n",
      "  1094: 0 [ 1065/ 1327], train_loss/perplexity = 6.51078939/672.3569336 secs/batch = 1.2336s, grad.norm=0.32335842\n",
      "  1099: 0 [ 1070/ 1327], train_loss/perplexity = 6.66424370/783.8704224 secs/batch = 1.2304s, grad.norm=0.31560954\n",
      "  1104: 0 [ 1075/ 1327], train_loss/perplexity = 6.54753971/697.5259399 secs/batch = 1.2307s, grad.norm=0.31235892\n",
      "  1109: 0 [ 1080/ 1327], train_loss/perplexity = 6.46199274/640.3358154 secs/batch = 1.2363s, grad.norm=0.31114376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1114: 0 [ 1085/ 1327], train_loss/perplexity = 6.51777220/677.0683594 secs/batch = 1.2374s, grad.norm=0.43099278\n",
      "  1119: 0 [ 1090/ 1327], train_loss/perplexity = 6.59897041/734.3387451 secs/batch = 1.2277s, grad.norm=0.25774765\n",
      "  1124: 0 [ 1095/ 1327], train_loss/perplexity = 6.57662868/718.1142578 secs/batch = 1.2458s, grad.norm=0.43169427\n",
      "  1129: 0 [ 1100/ 1327], train_loss/perplexity = 6.64209700/766.7010498 secs/batch = 1.2550s, grad.norm=0.44264206\n",
      "  1134: 0 [ 1105/ 1327], train_loss/perplexity = 6.46751690/643.8829346 secs/batch = 1.2243s, grad.norm=0.38996848\n",
      "  1139: 0 [ 1110/ 1327], train_loss/perplexity = 6.77181292/872.8929443 secs/batch = 1.2325s, grad.norm=0.33179608\n",
      "  1144: 0 [ 1115/ 1327], train_loss/perplexity = 6.52630568/682.8707886 secs/batch = 1.2326s, grad.norm=0.35794267\n",
      "  1149: 0 [ 1120/ 1327], train_loss/perplexity = 6.50986242/671.7340088 secs/batch = 1.2319s, grad.norm=0.33255973\n",
      "  1154: 0 [ 1125/ 1327], train_loss/perplexity = 6.71059990/821.0630493 secs/batch = 1.2331s, grad.norm=0.30726501\n",
      "  1159: 0 [ 1130/ 1327], train_loss/perplexity = 6.53620243/689.6625366 secs/batch = 1.2335s, grad.norm=0.25545809\n",
      "  1164: 0 [ 1135/ 1327], train_loss/perplexity = 6.57201290/714.8072510 secs/batch = 1.2381s, grad.norm=0.30772826\n",
      "  1169: 0 [ 1140/ 1327], train_loss/perplexity = 6.64111900/765.9515991 secs/batch = 1.2362s, grad.norm=0.33959422\n",
      "  1174: 0 [ 1145/ 1327], train_loss/perplexity = 6.51096487/672.4749756 secs/batch = 1.2376s, grad.norm=0.28633860\n",
      "  1179: 0 [ 1150/ 1327], train_loss/perplexity = 6.45340490/634.8602295 secs/batch = 1.2398s, grad.norm=0.31617180\n",
      "  1184: 0 [ 1155/ 1327], train_loss/perplexity = 6.55181551/700.5148315 secs/batch = 1.2386s, grad.norm=0.26335189\n",
      "  1189: 0 [ 1160/ 1327], train_loss/perplexity = 6.58783007/726.2033691 secs/batch = 1.2288s, grad.norm=0.39161387\n",
      "  1194: 0 [ 1165/ 1327], train_loss/perplexity = 6.66726685/786.2437134 secs/batch = 1.2618s, grad.norm=0.31363544\n",
      "  1199: 0 [ 1170/ 1327], train_loss/perplexity = 6.55319452/701.4815063 secs/batch = 1.2388s, grad.norm=0.40075704\n",
      "  1204: 0 [ 1175/ 1327], train_loss/perplexity = 6.41224957/609.2626953 secs/batch = 1.2365s, grad.norm=0.37814963\n",
      "  1209: 0 [ 1180/ 1327], train_loss/perplexity = 6.30879068/549.3801880 secs/batch = 1.2319s, grad.norm=0.29290572\n",
      "  1214: 0 [ 1185/ 1327], train_loss/perplexity = 6.56691313/711.1711426 secs/batch = 1.2293s, grad.norm=0.30910811\n",
      "  1219: 0 [ 1190/ 1327], train_loss/perplexity = 6.60790586/740.9298096 secs/batch = 1.2338s, grad.norm=0.27762648\n",
      "  1224: 0 [ 1195/ 1327], train_loss/perplexity = 6.49091864/659.1286011 secs/batch = 1.2489s, grad.norm=0.43320739\n",
      "  1229: 0 [ 1200/ 1327], train_loss/perplexity = 6.35239410/573.8649292 secs/batch = 1.2401s, grad.norm=0.31943282\n",
      "  1234: 0 [ 1205/ 1327], train_loss/perplexity = 6.55991268/706.2100220 secs/batch = 1.2349s, grad.norm=0.35420638\n",
      "  1239: 0 [ 1210/ 1327], train_loss/perplexity = 6.41134787/608.7136230 secs/batch = 1.2308s, grad.norm=0.37614268\n",
      "  1244: 0 [ 1215/ 1327], train_loss/perplexity = 6.37510824/587.0489502 secs/batch = 1.2244s, grad.norm=0.30462196\n",
      "  1249: 0 [ 1220/ 1327], train_loss/perplexity = 6.44290829/628.2312012 secs/batch = 1.2289s, grad.norm=0.33891049\n",
      "  1254: 0 [ 1225/ 1327], train_loss/perplexity = 6.42547369/617.3731689 secs/batch = 1.2328s, grad.norm=0.27479297\n",
      "  1259: 0 [ 1230/ 1327], train_loss/perplexity = 6.54864836/698.2996826 secs/batch = 1.2349s, grad.norm=0.30142355\n",
      "  1264: 0 [ 1235/ 1327], train_loss/perplexity = 6.54034042/692.5222778 secs/batch = 1.2425s, grad.norm=0.27576301\n",
      "  1269: 0 [ 1240/ 1327], train_loss/perplexity = 6.55041218/699.5324707 secs/batch = 1.2495s, grad.norm=0.25483441\n",
      "  1274: 0 [ 1245/ 1327], train_loss/perplexity = 6.40718937/606.1875000 secs/batch = 1.2276s, grad.norm=0.29498303\n",
      "  1279: 0 [ 1250/ 1327], train_loss/perplexity = 6.55016375/699.3587036 secs/batch = 1.2321s, grad.norm=0.36991516\n",
      "  1284: 0 [ 1255/ 1327], train_loss/perplexity = 6.52868605/684.4982300 secs/batch = 1.2348s, grad.norm=0.48219776\n",
      "  1289: 0 [ 1260/ 1327], train_loss/perplexity = 6.62923527/756.9031372 secs/batch = 1.2283s, grad.norm=0.32423326\n",
      "  1294: 0 [ 1265/ 1327], train_loss/perplexity = 6.49343348/660.7882690 secs/batch = 1.2405s, grad.norm=0.28484291\n",
      "  1299: 0 [ 1270/ 1327], train_loss/perplexity = 6.52730894/683.5562744 secs/batch = 1.2267s, grad.norm=0.32469332\n",
      "  1304: 0 [ 1275/ 1327], train_loss/perplexity = 6.71856785/827.6313477 secs/batch = 1.2369s, grad.norm=0.38595864\n",
      "  1309: 0 [ 1280/ 1327], train_loss/perplexity = 6.50909472/671.2185059 secs/batch = 1.2413s, grad.norm=0.36195317\n",
      "  1314: 0 [ 1285/ 1327], train_loss/perplexity = 6.40947914/607.5771484 secs/batch = 1.2348s, grad.norm=0.40046439\n",
      "  1319: 0 [ 1290/ 1327], train_loss/perplexity = 6.47613621/649.4567261 secs/batch = 1.2297s, grad.norm=0.28039950\n",
      "  1324: 0 [ 1295/ 1327], train_loss/perplexity = 6.63513184/761.3794556 secs/batch = 1.2809s, grad.norm=0.28827119\n",
      "  1329: 0 [ 1300/ 1327], train_loss/perplexity = 6.57315779/715.6260986 secs/batch = 1.2391s, grad.norm=0.34926572\n",
      "  1334: 0 [ 1305/ 1327], train_loss/perplexity = 6.69628191/809.3908081 secs/batch = 1.2320s, grad.norm=0.35096657\n",
      "  1339: 0 [ 1310/ 1327], train_loss/perplexity = 6.71795416/827.1235962 secs/batch = 1.2548s, grad.norm=0.29672003\n",
      "  1344: 0 [ 1315/ 1327], train_loss/perplexity = 6.67647123/793.5140381 secs/batch = 1.2320s, grad.norm=0.25878304\n",
      "  1349: 0 [ 1320/ 1327], train_loss/perplexity = 6.70135975/813.5112305 secs/batch = 1.2298s, grad.norm=0.27884170\n",
      "  1354: 0 [ 1325/ 1327], train_loss/perplexity = 6.61240387/744.2700195 secs/batch = 1.2382s, grad.norm=0.34005651\n",
      "Epoch training time: 1649.205799818039\n",
      "Saved char model cv/epoch000_6.5791.model\n",
      "  1361: 1 [    5/ 1327], train_loss/perplexity = 6.72123241/829.8395996 secs/batch = 1.2343s, grad.norm=0.37370259\n",
      "  1366: 1 [   10/ 1327], train_loss/perplexity = 6.39890766/601.1879883 secs/batch = 1.2393s, grad.norm=0.37433103\n",
      "  1371: 1 [   15/ 1327], train_loss/perplexity = 6.40101147/602.4541016 secs/batch = 1.2272s, grad.norm=0.27476481\n",
      "  1376: 1 [   20/ 1327], train_loss/perplexity = 6.80342484/900.9275513 secs/batch = 1.2327s, grad.norm=0.52086824\n",
      "  1381: 1 [   25/ 1327], train_loss/perplexity = 6.65226650/774.5378418 secs/batch = 1.2289s, grad.norm=0.26680863\n",
      "  1386: 1 [   30/ 1327], train_loss/perplexity = 6.48707581/656.6005249 secs/batch = 1.2367s, grad.norm=0.29995579\n",
      "  1391: 1 [   35/ 1327], train_loss/perplexity = 6.45407772/635.2875366 secs/batch = 1.2365s, grad.norm=0.26391774\n",
      "  1396: 1 [   40/ 1327], train_loss/perplexity = 6.54489374/695.6827393 secs/batch = 1.2299s, grad.norm=0.31042820\n",
      "  1401: 1 [   45/ 1327], train_loss/perplexity = 6.35681295/576.4063721 secs/batch = 1.2349s, grad.norm=0.27016363\n",
      "  1406: 1 [   50/ 1327], train_loss/perplexity = 6.61280489/744.5685425 secs/batch = 1.2298s, grad.norm=0.36051908\n",
      "  1411: 1 [   55/ 1327], train_loss/perplexity = 6.55171442/700.4440308 secs/batch = 1.2414s, grad.norm=0.32975423\n",
      "  1416: 1 [   60/ 1327], train_loss/perplexity = 6.57026291/713.5574341 secs/batch = 1.2278s, grad.norm=0.31438738\n",
      "  1421: 1 [   65/ 1327], train_loss/perplexity = 6.48151159/652.9572144 secs/batch = 1.2397s, grad.norm=0.44895974\n",
      "  1426: 1 [   70/ 1327], train_loss/perplexity = 6.35148668/573.3444824 secs/batch = 1.2335s, grad.norm=0.37464631\n",
      "  1431: 1 [   75/ 1327], train_loss/perplexity = 6.44247961/627.9619751 secs/batch = 1.2386s, grad.norm=0.32246962\n",
      "  1436: 1 [   80/ 1327], train_loss/perplexity = 6.58578348/724.7186279 secs/batch = 1.2560s, grad.norm=0.33439150\n",
      "  1441: 1 [   85/ 1327], train_loss/perplexity = 6.69159937/805.6096802 secs/batch = 1.2399s, grad.norm=0.90277761\n",
      "  1446: 1 [   90/ 1327], train_loss/perplexity = 6.62182283/751.3133545 secs/batch = 1.2385s, grad.norm=0.27040350\n",
      "  1451: 1 [   95/ 1327], train_loss/perplexity = 6.50709343/669.8765259 secs/batch = 1.2367s, grad.norm=0.45352182\n",
      "  1456: 1 [  100/ 1327], train_loss/perplexity = 6.64575338/769.5095825 secs/batch = 1.2372s, grad.norm=0.38624084\n",
      "  1461: 1 [  105/ 1327], train_loss/perplexity = 6.70270252/814.6043091 secs/batch = 1.2322s, grad.norm=0.38307822\n",
      "  1466: 1 [  110/ 1327], train_loss/perplexity = 6.49635029/662.7185059 secs/batch = 1.2418s, grad.norm=0.36298904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1471: 1 [  115/ 1327], train_loss/perplexity = 6.32652473/559.2098389 secs/batch = 1.2294s, grad.norm=0.40722099\n",
      "  1476: 1 [  120/ 1327], train_loss/perplexity = 6.58059645/720.9692383 secs/batch = 1.2343s, grad.norm=0.30056882\n",
      "  1481: 1 [  125/ 1327], train_loss/perplexity = 6.68163872/797.6251221 secs/batch = 1.2250s, grad.norm=0.28531429\n",
      "  1486: 1 [  130/ 1327], train_loss/perplexity = 6.63264322/759.4869995 secs/batch = 1.2340s, grad.norm=0.39011109\n",
      "  1491: 1 [  135/ 1327], train_loss/perplexity = 6.54185390/693.5712280 secs/batch = 1.2427s, grad.norm=0.33109444\n",
      "  1496: 1 [  140/ 1327], train_loss/perplexity = 6.62974548/757.2894287 secs/batch = 1.2249s, grad.norm=0.26770481\n",
      "  1501: 1 [  145/ 1327], train_loss/perplexity = 6.72822762/835.6648560 secs/batch = 1.2409s, grad.norm=0.30021721\n",
      "  1506: 1 [  150/ 1327], train_loss/perplexity = 6.53570032/689.3163452 secs/batch = 1.2301s, grad.norm=0.24829717\n",
      "  1511: 1 [  155/ 1327], train_loss/perplexity = 6.63650131/762.4228516 secs/batch = 1.2359s, grad.norm=0.28685895\n",
      "  1516: 1 [  160/ 1327], train_loss/perplexity = 6.43827486/625.3270874 secs/batch = 1.2420s, grad.norm=0.49448270\n",
      "  1521: 1 [  165/ 1327], train_loss/perplexity = 6.60321236/737.4603882 secs/batch = 1.2323s, grad.norm=0.37738553\n",
      "  1526: 1 [  170/ 1327], train_loss/perplexity = 6.63811302/763.6526489 secs/batch = 1.2392s, grad.norm=0.37021035\n",
      "  1531: 1 [  175/ 1327], train_loss/perplexity = 6.69133043/805.3930664 secs/batch = 1.2290s, grad.norm=0.27413380\n",
      "  1536: 1 [  180/ 1327], train_loss/perplexity = 6.65089130/773.4733887 secs/batch = 1.2272s, grad.norm=0.36534089\n",
      "  1541: 1 [  185/ 1327], train_loss/perplexity = 6.72908497/836.3815918 secs/batch = 1.2280s, grad.norm=0.26990971\n",
      "  1546: 1 [  190/ 1327], train_loss/perplexity = 6.58512545/724.2418823 secs/batch = 1.2314s, grad.norm=0.25777709\n",
      "  1551: 1 [  195/ 1327], train_loss/perplexity = 6.43168163/621.2177124 secs/batch = 1.2329s, grad.norm=0.29640681\n",
      "  1556: 1 [  200/ 1327], train_loss/perplexity = 6.60942316/742.0548706 secs/batch = 1.2247s, grad.norm=0.27196705\n",
      "  1561: 1 [  205/ 1327], train_loss/perplexity = 6.56828690/712.1488037 secs/batch = 1.2357s, grad.norm=0.31819618\n",
      "  1566: 1 [  210/ 1327], train_loss/perplexity = 6.49661255/662.8923340 secs/batch = 1.2371s, grad.norm=0.29459816\n",
      "  1571: 1 [  215/ 1327], train_loss/perplexity = 6.56260824/708.1162109 secs/batch = 1.2346s, grad.norm=0.30545264\n",
      "  1576: 1 [  220/ 1327], train_loss/perplexity = 6.61370039/745.2355957 secs/batch = 1.2346s, grad.norm=0.30179161\n",
      "  1581: 1 [  225/ 1327], train_loss/perplexity = 6.74881840/853.0501709 secs/batch = 1.2455s, grad.norm=0.29320031\n",
      "  1586: 1 [  230/ 1327], train_loss/perplexity = 6.59681511/732.7576904 secs/batch = 1.2936s, grad.norm=0.25428450\n",
      "  1591: 1 [  235/ 1327], train_loss/perplexity = 6.56738281/711.5052490 secs/batch = 1.2893s, grad.norm=0.40092716\n",
      "  1596: 1 [  240/ 1327], train_loss/perplexity = 6.40360546/604.0188599 secs/batch = 1.2339s, grad.norm=0.30070469\n",
      "  1601: 1 [  245/ 1327], train_loss/perplexity = 6.62956524/757.1528931 secs/batch = 1.2307s, grad.norm=0.25377801\n",
      "  1606: 1 [  250/ 1327], train_loss/perplexity = 6.50526667/668.6539307 secs/batch = 1.2287s, grad.norm=0.26601988\n",
      "  1611: 1 [  255/ 1327], train_loss/perplexity = 6.62762785/755.6874390 secs/batch = 1.2302s, grad.norm=0.28391171\n",
      "  1616: 1 [  260/ 1327], train_loss/perplexity = 6.76468658/866.6945190 secs/batch = 1.2404s, grad.norm=0.25690597\n",
      "  1621: 1 [  265/ 1327], train_loss/perplexity = 6.58884621/726.9416504 secs/batch = 1.2383s, grad.norm=0.24961159\n",
      "  1626: 1 [  270/ 1327], train_loss/perplexity = 6.63232088/759.2422485 secs/batch = 1.2329s, grad.norm=0.35826164\n",
      "  1631: 1 [  275/ 1327], train_loss/perplexity = 6.85665798/950.1862183 secs/batch = 1.2364s, grad.norm=0.44640478\n",
      "  1636: 1 [  280/ 1327], train_loss/perplexity = 6.50611401/669.2207642 secs/batch = 1.2410s, grad.norm=0.32225090\n",
      "  1641: 1 [  285/ 1327], train_loss/perplexity = 6.66787195/786.7196655 secs/batch = 1.2397s, grad.norm=0.29135212\n",
      "  1646: 1 [  290/ 1327], train_loss/perplexity = 6.61940241/749.4970703 secs/batch = 1.2343s, grad.norm=0.30735344\n",
      "  1651: 1 [  295/ 1327], train_loss/perplexity = 6.48502493/655.2553101 secs/batch = 1.2414s, grad.norm=0.32124677\n",
      "  1656: 1 [  300/ 1327], train_loss/perplexity = 6.43459320/623.0291138 secs/batch = 1.2453s, grad.norm=0.38192487\n",
      "  1661: 1 [  305/ 1327], train_loss/perplexity = 6.49969959/664.9418335 secs/batch = 1.2343s, grad.norm=0.32998249\n",
      "  1666: 1 [  310/ 1327], train_loss/perplexity = 6.56004477/706.3032837 secs/batch = 1.2365s, grad.norm=0.25893721\n",
      "  1671: 1 [  315/ 1327], train_loss/perplexity = 6.40758801/606.4291992 secs/batch = 1.2316s, grad.norm=0.30792302\n",
      "  1676: 1 [  320/ 1327], train_loss/perplexity = 6.50363302/667.5625000 secs/batch = 1.2394s, grad.norm=0.36161837\n",
      "  1681: 1 [  325/ 1327], train_loss/perplexity = 6.38464499/592.6743164 secs/batch = 1.2396s, grad.norm=0.28953835\n",
      "  1686: 1 [  330/ 1327], train_loss/perplexity = 6.65680122/778.0581055 secs/batch = 1.2370s, grad.norm=0.34147882\n",
      "  1691: 1 [  335/ 1327], train_loss/perplexity = 6.16017771/473.5122070 secs/batch = 1.2323s, grad.norm=0.30073559\n",
      "  1696: 1 [  340/ 1327], train_loss/perplexity = 6.57311249/715.5936279 secs/batch = 1.2321s, grad.norm=0.27807048\n",
      "  1701: 1 [  345/ 1327], train_loss/perplexity = 6.61175632/743.7882080 secs/batch = 1.2341s, grad.norm=0.27694523\n",
      "  1706: 1 [  350/ 1327], train_loss/perplexity = 6.54702282/697.1654663 secs/batch = 1.2419s, grad.norm=0.32282594\n",
      "  1711: 1 [  355/ 1327], train_loss/perplexity = 6.63335609/760.0286255 secs/batch = 1.2808s, grad.norm=0.33797944\n",
      "  1716: 1 [  360/ 1327], train_loss/perplexity = 6.69485569/808.2373047 secs/batch = 1.2405s, grad.norm=0.23233430\n",
      "  1721: 1 [  365/ 1327], train_loss/perplexity = 6.61808300/748.5088501 secs/batch = 1.2359s, grad.norm=0.23058403\n",
      "  1726: 1 [  370/ 1327], train_loss/perplexity = 6.65119696/773.7098389 secs/batch = 1.2412s, grad.norm=0.36247754\n",
      "  1731: 1 [  375/ 1327], train_loss/perplexity = 6.46626234/643.0756226 secs/batch = 1.2276s, grad.norm=0.27474713\n",
      "  1736: 1 [  380/ 1327], train_loss/perplexity = 6.58197117/721.9610596 secs/batch = 1.2323s, grad.norm=0.28553265\n",
      "  1741: 1 [  385/ 1327], train_loss/perplexity = 6.68872833/803.3000488 secs/batch = 1.2427s, grad.norm=0.36433139\n",
      "  1746: 1 [  390/ 1327], train_loss/perplexity = 6.58147192/721.6007080 secs/batch = 1.2338s, grad.norm=0.28271201\n",
      "  1751: 1 [  395/ 1327], train_loss/perplexity = 6.78885460/887.8959961 secs/batch = 1.2424s, grad.norm=0.35133559\n",
      "  1756: 1 [  400/ 1327], train_loss/perplexity = 6.46558571/642.6406250 secs/batch = 1.2411s, grad.norm=0.35994908\n",
      "  1761: 1 [  405/ 1327], train_loss/perplexity = 6.67915678/795.6479492 secs/batch = 1.2330s, grad.norm=0.34004670\n",
      "  1766: 1 [  410/ 1327], train_loss/perplexity = 6.51528120/675.3838501 secs/batch = 1.2538s, grad.norm=0.30016571\n",
      "  1771: 1 [  415/ 1327], train_loss/perplexity = 6.48580647/655.7675781 secs/batch = 1.2369s, grad.norm=0.28823149\n",
      "  1776: 1 [  420/ 1327], train_loss/perplexity = 6.53310204/687.5276489 secs/batch = 1.2360s, grad.norm=0.27657056\n",
      "  1781: 1 [  425/ 1327], train_loss/perplexity = 6.71758032/826.8144531 secs/batch = 1.2380s, grad.norm=0.25819403\n",
      "  1786: 1 [  430/ 1327], train_loss/perplexity = 6.65745401/778.5662231 secs/batch = 1.2301s, grad.norm=0.28897318\n",
      "  1791: 1 [  435/ 1327], train_loss/perplexity = 6.67382097/791.4138184 secs/batch = 1.2662s, grad.norm=0.33845368\n",
      "  1796: 1 [  440/ 1327], train_loss/perplexity = 6.57586336/717.5648804 secs/batch = 1.3675s, grad.norm=0.56381375\n",
      "  1801: 1 [  445/ 1327], train_loss/perplexity = 6.57709122/718.4464722 secs/batch = 1.2818s, grad.norm=0.51815587\n",
      "  1806: 1 [  450/ 1327], train_loss/perplexity = 6.55999660/706.2692871 secs/batch = 1.4334s, grad.norm=0.25128162\n",
      "  1811: 1 [  455/ 1327], train_loss/perplexity = 6.34405327/569.0983276 secs/batch = 1.3822s, grad.norm=0.28499129\n",
      "  1816: 1 [  460/ 1327], train_loss/perplexity = 6.60757589/740.6853638 secs/batch = 1.3881s, grad.norm=0.28745621\n",
      "  1821: 1 [  465/ 1327], train_loss/perplexity = 6.53552580/689.1960449 secs/batch = 1.3770s, grad.norm=0.29691496\n",
      "  1826: 1 [  470/ 1327], train_loss/perplexity = 6.68524265/800.5048828 secs/batch = 1.3841s, grad.norm=0.29404372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1831: 1 [  475/ 1327], train_loss/perplexity = 6.70674896/817.9072876 secs/batch = 1.3773s, grad.norm=0.24585821\n",
      "  1836: 1 [  480/ 1327], train_loss/perplexity = 6.57352114/715.8861694 secs/batch = 1.2402s, grad.norm=0.25724071\n",
      "  1841: 1 [  485/ 1327], train_loss/perplexity = 6.58073807/721.0713501 secs/batch = 1.2351s, grad.norm=0.24688831\n",
      "  1846: 1 [  490/ 1327], train_loss/perplexity = 6.57985497/720.4348145 secs/batch = 1.2341s, grad.norm=0.35970405\n",
      "  1851: 1 [  495/ 1327], train_loss/perplexity = 6.33926010/566.3770752 secs/batch = 1.2392s, grad.norm=0.58208752\n",
      "  1856: 1 [  500/ 1327], train_loss/perplexity = 6.65291929/775.0435791 secs/batch = 1.2320s, grad.norm=0.26059037\n",
      "  1861: 1 [  505/ 1327], train_loss/perplexity = 6.50278234/666.9948730 secs/batch = 1.2628s, grad.norm=0.32713780\n",
      "  1866: 1 [  510/ 1327], train_loss/perplexity = 6.61168671/743.7364502 secs/batch = 1.2302s, grad.norm=0.24800083\n",
      "  1871: 1 [  515/ 1327], train_loss/perplexity = 6.48112869/652.7072144 secs/batch = 1.2387s, grad.norm=0.28226793\n",
      "  1876: 1 [  520/ 1327], train_loss/perplexity = 6.65530062/776.8914185 secs/batch = 1.2320s, grad.norm=0.35210222\n",
      "  1881: 1 [  525/ 1327], train_loss/perplexity = 6.51756573/676.9285278 secs/batch = 1.2331s, grad.norm=0.27139920\n",
      "  1886: 1 [  530/ 1327], train_loss/perplexity = 6.54871511/698.3463135 secs/batch = 1.2389s, grad.norm=0.36990789\n",
      "  1891: 1 [  535/ 1327], train_loss/perplexity = 6.62937689/757.0103149 secs/batch = 1.2362s, grad.norm=0.25658292\n",
      "  1896: 1 [  540/ 1327], train_loss/perplexity = 6.65871382/779.5476685 secs/batch = 1.2304s, grad.norm=0.23050246\n",
      "  1901: 1 [  545/ 1327], train_loss/perplexity = 6.67322111/790.9392090 secs/batch = 1.2356s, grad.norm=0.25955784\n",
      "  1906: 1 [  550/ 1327], train_loss/perplexity = 6.66894579/787.5648804 secs/batch = 1.2386s, grad.norm=0.29809916\n",
      "  1911: 1 [  555/ 1327], train_loss/perplexity = 6.57157660/714.4954224 secs/batch = 1.2467s, grad.norm=0.33289111\n",
      "  1916: 1 [  560/ 1327], train_loss/perplexity = 6.68848610/803.1055298 secs/batch = 1.2400s, grad.norm=0.26930839\n",
      "  1921: 1 [  565/ 1327], train_loss/perplexity = 6.62132120/750.9365845 secs/batch = 1.2372s, grad.norm=0.38014048\n",
      "  1926: 1 [  570/ 1327], train_loss/perplexity = 6.51346874/674.1608276 secs/batch = 1.2229s, grad.norm=0.29316556\n",
      "  1931: 1 [  575/ 1327], train_loss/perplexity = 6.55394650/702.0092163 secs/batch = 1.2325s, grad.norm=0.28348580\n",
      "  1936: 1 [  580/ 1327], train_loss/perplexity = 6.59409857/730.7698364 secs/batch = 1.2326s, grad.norm=0.31581900\n",
      "  1941: 1 [  585/ 1327], train_loss/perplexity = 6.51873970/677.7236938 secs/batch = 1.2317s, grad.norm=0.29336861\n",
      "  1946: 1 [  590/ 1327], train_loss/perplexity = 6.66039753/780.8612671 secs/batch = 1.2335s, grad.norm=0.24902622\n",
      "  1951: 1 [  595/ 1327], train_loss/perplexity = 6.61026859/742.6824951 secs/batch = 1.2295s, grad.norm=0.28804046\n",
      "  1956: 1 [  600/ 1327], train_loss/perplexity = 6.69487095/808.2496338 secs/batch = 1.2413s, grad.norm=0.27378368\n",
      "  1961: 1 [  605/ 1327], train_loss/perplexity = 6.63564157/761.7676392 secs/batch = 1.2487s, grad.norm=0.33960947\n",
      "  1966: 1 [  610/ 1327], train_loss/perplexity = 6.73772049/843.6354370 secs/batch = 1.2284s, grad.norm=0.37857655\n",
      "  1971: 1 [  615/ 1327], train_loss/perplexity = 6.30659866/548.1772461 secs/batch = 1.2357s, grad.norm=0.27378654\n",
      "  1976: 1 [  620/ 1327], train_loss/perplexity = 6.54212379/693.7584229 secs/batch = 1.2356s, grad.norm=0.31635496\n",
      "  1981: 1 [  625/ 1327], train_loss/perplexity = 6.67138243/789.4862671 secs/batch = 1.2356s, grad.norm=0.23518778\n",
      "  1986: 1 [  630/ 1327], train_loss/perplexity = 6.64036560/765.3747559 secs/batch = 1.2355s, grad.norm=0.27111101\n",
      "  1991: 1 [  635/ 1327], train_loss/perplexity = 6.57708073/718.4389648 secs/batch = 1.2326s, grad.norm=0.36293137\n",
      "  1996: 1 [  640/ 1327], train_loss/perplexity = 6.48653316/656.2443237 secs/batch = 1.2450s, grad.norm=0.31768441\n",
      "  2001: 1 [  645/ 1327], train_loss/perplexity = 6.63264990/759.4920654 secs/batch = 1.2437s, grad.norm=0.34035257\n",
      "  2006: 1 [  650/ 1327], train_loss/perplexity = 6.43741417/624.7891235 secs/batch = 1.2425s, grad.norm=0.37288082\n",
      "  2011: 1 [  655/ 1327], train_loss/perplexity = 6.48301268/653.9381104 secs/batch = 1.2383s, grad.norm=0.27541256\n",
      "  2016: 1 [  660/ 1327], train_loss/perplexity = 6.52721834/683.4943237 secs/batch = 1.2431s, grad.norm=0.24932675\n",
      "  2021: 1 [  665/ 1327], train_loss/perplexity = 6.62175226/751.2603760 secs/batch = 1.2336s, grad.norm=0.24256144\n",
      "  2026: 1 [  670/ 1327], train_loss/perplexity = 6.58339214/722.9876709 secs/batch = 1.2451s, grad.norm=0.27667281\n",
      "  2031: 1 [  675/ 1327], train_loss/perplexity = 6.41263342/609.4966431 secs/batch = 1.2320s, grad.norm=0.29607773\n",
      "  2036: 1 [  680/ 1327], train_loss/perplexity = 6.66188955/782.0272217 secs/batch = 1.2268s, grad.norm=0.33710316\n",
      "  2041: 1 [  685/ 1327], train_loss/perplexity = 6.69441748/807.8831787 secs/batch = 1.2338s, grad.norm=0.33627948\n",
      "  2046: 1 [  690/ 1327], train_loss/perplexity = 6.60962343/742.2034912 secs/batch = 1.2305s, grad.norm=0.32706323\n",
      "  2051: 1 [  695/ 1327], train_loss/perplexity = 6.55431843/702.2703247 secs/batch = 1.2468s, grad.norm=0.29217824\n",
      "  2056: 1 [  700/ 1327], train_loss/perplexity = 6.60820055/741.1481323 secs/batch = 1.2505s, grad.norm=0.24480219\n",
      "  2061: 1 [  705/ 1327], train_loss/perplexity = 6.44041729/626.6682739 secs/batch = 1.2413s, grad.norm=0.33000761\n",
      "  2066: 1 [  710/ 1327], train_loss/perplexity = 6.56373310/708.9132080 secs/batch = 1.2423s, grad.norm=0.24044761\n",
      "  2071: 1 [  715/ 1327], train_loss/perplexity = 6.57079172/713.9348755 secs/batch = 1.2485s, grad.norm=0.26458549\n",
      "  2076: 1 [  720/ 1327], train_loss/perplexity = 6.59109783/728.5802612 secs/batch = 1.2464s, grad.norm=0.31478465\n",
      "  2081: 1 [  725/ 1327], train_loss/perplexity = 6.39488268/598.7730713 secs/batch = 1.2424s, grad.norm=0.40700155\n",
      "  2086: 1 [  730/ 1327], train_loss/perplexity = 6.42366982/616.2605591 secs/batch = 1.2397s, grad.norm=0.29372603\n",
      "  2091: 1 [  735/ 1327], train_loss/perplexity = 6.58192921/721.9307251 secs/batch = 1.2338s, grad.norm=0.25085026\n",
      "  2096: 1 [  740/ 1327], train_loss/perplexity = 6.39820814/600.7675781 secs/batch = 1.2353s, grad.norm=0.31292415\n",
      "  2101: 1 [  745/ 1327], train_loss/perplexity = 6.57238436/715.0728149 secs/batch = 1.2415s, grad.norm=0.26465663\n",
      "  2106: 1 [  750/ 1327], train_loss/perplexity = 6.41001177/607.9008179 secs/batch = 1.2295s, grad.norm=0.28819111\n",
      "  2111: 1 [  755/ 1327], train_loss/perplexity = 6.48484468/655.1372070 secs/batch = 1.2354s, grad.norm=0.24763358\n",
      "  2116: 1 [  760/ 1327], train_loss/perplexity = 6.40208578/603.1016846 secs/batch = 1.2452s, grad.norm=0.32021606\n",
      "  2121: 1 [  765/ 1327], train_loss/perplexity = 6.43109608/620.8540649 secs/batch = 1.2470s, grad.norm=0.34694868\n",
      "  2126: 1 [  770/ 1327], train_loss/perplexity = 6.45112801/633.4163818 secs/batch = 1.2316s, grad.norm=0.29896605\n",
      "  2131: 1 [  775/ 1327], train_loss/perplexity = 6.50623798/669.3037720 secs/batch = 1.2551s, grad.norm=0.26615456\n",
      "  2136: 1 [  780/ 1327], train_loss/perplexity = 6.62857819/756.4059448 secs/batch = 1.2429s, grad.norm=0.27360365\n",
      "  2141: 1 [  785/ 1327], train_loss/perplexity = 6.50983667/671.7166748 secs/batch = 1.2395s, grad.norm=0.28631899\n",
      "  2146: 1 [  790/ 1327], train_loss/perplexity = 6.33738470/565.3159180 secs/batch = 1.2396s, grad.norm=0.27911749\n",
      "  2151: 1 [  795/ 1327], train_loss/perplexity = 6.61069965/743.0026855 secs/batch = 1.2451s, grad.norm=0.28847945\n",
      "  2156: 1 [  800/ 1327], train_loss/perplexity = 6.55877733/705.4086914 secs/batch = 1.2415s, grad.norm=0.28087389\n",
      "  2161: 1 [  805/ 1327], train_loss/perplexity = 6.68354130/799.1441040 secs/batch = 1.2325s, grad.norm=0.31306019\n",
      "  2166: 1 [  810/ 1327], train_loss/perplexity = 6.62330437/752.4273071 secs/batch = 1.2369s, grad.norm=0.34616777\n",
      "  2171: 1 [  815/ 1327], train_loss/perplexity = 6.42269135/615.6578369 secs/batch = 1.2403s, grad.norm=0.32641664\n",
      "  2176: 1 [  820/ 1327], train_loss/perplexity = 6.29234028/540.4165649 secs/batch = 1.2357s, grad.norm=0.28663939\n",
      "  2181: 1 [  825/ 1327], train_loss/perplexity = 6.44389486/628.8513184 secs/batch = 1.2388s, grad.norm=0.29977167\n",
      "  2186: 1 [  830/ 1327], train_loss/perplexity = 6.31073952/550.4518433 secs/batch = 1.2298s, grad.norm=0.30186474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2191: 1 [  835/ 1327], train_loss/perplexity = 6.53464365/688.5883789 secs/batch = 1.2860s, grad.norm=0.25252813\n",
      "  2196: 1 [  840/ 1327], train_loss/perplexity = 6.62997770/757.4652710 secs/batch = 1.2373s, grad.norm=0.24340096\n",
      "  2201: 1 [  845/ 1327], train_loss/perplexity = 6.54539347/696.0305176 secs/batch = 1.2340s, grad.norm=0.24778137\n",
      "  2206: 1 [  850/ 1327], train_loss/perplexity = 6.49467134/661.6067505 secs/batch = 1.2313s, grad.norm=0.32443711\n",
      "  2211: 1 [  855/ 1327], train_loss/perplexity = 6.52807188/684.0779419 secs/batch = 1.2310s, grad.norm=0.27082652\n",
      "  2216: 1 [  860/ 1327], train_loss/perplexity = 6.34172773/567.7764282 secs/batch = 1.2339s, grad.norm=0.27613324\n",
      "  2221: 1 [  865/ 1327], train_loss/perplexity = 6.64010096/765.1722412 secs/batch = 1.2359s, grad.norm=0.25073794\n",
      "  2226: 1 [  870/ 1327], train_loss/perplexity = 6.69114876/805.2467651 secs/batch = 1.2288s, grad.norm=0.30703300\n",
      "  2231: 1 [  875/ 1327], train_loss/perplexity = 6.38293600/591.6622925 secs/batch = 1.2327s, grad.norm=0.25827083\n",
      "  2236: 1 [  880/ 1327], train_loss/perplexity = 6.57713366/718.4769897 secs/batch = 1.2420s, grad.norm=0.28649861\n",
      "  2241: 1 [  885/ 1327], train_loss/perplexity = 6.43735552/624.7524414 secs/batch = 1.2395s, grad.norm=0.34507817\n",
      "  2246: 1 [  890/ 1327], train_loss/perplexity = 6.51182747/673.0552979 secs/batch = 1.2302s, grad.norm=0.34952426\n",
      "  2251: 1 [  895/ 1327], train_loss/perplexity = 6.60946703/742.0874023 secs/batch = 1.2341s, grad.norm=0.49582940\n",
      "  2256: 1 [  900/ 1327], train_loss/perplexity = 6.54427576/695.2529907 secs/batch = 1.2529s, grad.norm=0.31185177\n",
      "  2261: 1 [  905/ 1327], train_loss/perplexity = 6.46384478/641.5228271 secs/batch = 1.2346s, grad.norm=0.28316304\n",
      "  2266: 1 [  910/ 1327], train_loss/perplexity = 6.43489885/623.2195435 secs/batch = 1.2360s, grad.norm=0.31294665\n",
      "  2271: 1 [  915/ 1327], train_loss/perplexity = 6.67600727/793.1459351 secs/batch = 1.2338s, grad.norm=0.25299400\n",
      "  2276: 1 [  920/ 1327], train_loss/perplexity = 6.67426109/791.7622070 secs/batch = 1.2293s, grad.norm=0.30312234\n",
      "  2281: 1 [  925/ 1327], train_loss/perplexity = 6.52431870/681.5153198 secs/batch = 1.2475s, grad.norm=0.30865082\n",
      "  2286: 1 [  930/ 1327], train_loss/perplexity = 6.48918390/657.9861450 secs/batch = 1.2327s, grad.norm=0.45768511\n",
      "  2291: 1 [  935/ 1327], train_loss/perplexity = 6.56708145/711.2908936 secs/batch = 1.2329s, grad.norm=0.24504468\n",
      "  2296: 1 [  940/ 1327], train_loss/perplexity = 6.49632263/662.7001343 secs/batch = 1.2326s, grad.norm=0.29348788\n",
      "  2301: 1 [  945/ 1327], train_loss/perplexity = 6.61702967/747.7208252 secs/batch = 1.2307s, grad.norm=0.24216010\n",
      "  2306: 1 [  950/ 1327], train_loss/perplexity = 6.48153257/652.9708862 secs/batch = 1.2426s, grad.norm=0.26281336\n",
      "  2311: 1 [  955/ 1327], train_loss/perplexity = 6.61620808/747.1067505 secs/batch = 1.2367s, grad.norm=0.25978124\n",
      "  2316: 1 [  960/ 1327], train_loss/perplexity = 6.67361212/791.2485352 secs/batch = 1.2310s, grad.norm=0.26517174\n",
      "  2321: 1 [  965/ 1327], train_loss/perplexity = 6.55271006/701.1417236 secs/batch = 1.2388s, grad.norm=0.28049862\n",
      "  2326: 1 [  970/ 1327], train_loss/perplexity = 6.58235979/722.2416382 secs/batch = 1.2428s, grad.norm=0.27515802\n",
      "  2331: 1 [  975/ 1327], train_loss/perplexity = 6.54784966/697.7421875 secs/batch = 1.2315s, grad.norm=0.29236561\n",
      "  2336: 1 [  980/ 1327], train_loss/perplexity = 6.45107365/633.3819580 secs/batch = 1.2444s, grad.norm=0.24570677\n",
      "  2341: 1 [  985/ 1327], train_loss/perplexity = 6.61780405/748.3000488 secs/batch = 1.2283s, grad.norm=0.28486481\n",
      "  2346: 1 [  990/ 1327], train_loss/perplexity = 6.67916489/795.6543579 secs/batch = 1.2400s, grad.norm=0.31156394\n",
      "  2351: 1 [  995/ 1327], train_loss/perplexity = 6.65413523/775.9865723 secs/batch = 1.2368s, grad.norm=0.27698830\n",
      "  2356: 1 [ 1000/ 1327], train_loss/perplexity = 6.39133930/596.6551514 secs/batch = 1.2315s, grad.norm=0.30287391\n",
      "  2361: 1 [ 1005/ 1327], train_loss/perplexity = 6.62779427/755.8132324 secs/batch = 1.2437s, grad.norm=0.27883911\n",
      "  2366: 1 [ 1010/ 1327], train_loss/perplexity = 6.37160158/584.9940186 secs/batch = 1.2342s, grad.norm=0.27215329\n",
      "  2371: 1 [ 1015/ 1327], train_loss/perplexity = 6.58472586/723.9525757 secs/batch = 1.2411s, grad.norm=0.30810523\n",
      "  2376: 1 [ 1020/ 1327], train_loss/perplexity = 6.67341661/791.0938721 secs/batch = 1.2308s, grad.norm=0.29979041\n",
      "  2381: 1 [ 1025/ 1327], train_loss/perplexity = 6.55214500/700.7456665 secs/batch = 1.2404s, grad.norm=0.22809966\n",
      "  2386: 1 [ 1030/ 1327], train_loss/perplexity = 6.53219461/686.9040527 secs/batch = 1.2305s, grad.norm=0.22645992\n",
      "  2391: 1 [ 1035/ 1327], train_loss/perplexity = 6.44895029/632.0385132 secs/batch = 1.2477s, grad.norm=0.32552433\n",
      "  2396: 1 [ 1040/ 1327], train_loss/perplexity = 6.48820877/657.3448486 secs/batch = 1.2779s, grad.norm=0.23142621\n",
      "  2401: 1 [ 1045/ 1327], train_loss/perplexity = 6.32662725/559.2671509 secs/batch = 1.2409s, grad.norm=0.26621774\n",
      "  2406: 1 [ 1050/ 1327], train_loss/perplexity = 6.54462957/695.4990234 secs/batch = 1.2376s, grad.norm=0.27931559\n",
      "  2411: 1 [ 1055/ 1327], train_loss/perplexity = 6.69741297/810.3068237 secs/batch = 1.2360s, grad.norm=0.31490278\n",
      "  2416: 1 [ 1060/ 1327], train_loss/perplexity = 6.42913151/619.6355591 secs/batch = 1.2332s, grad.norm=0.28672686\n",
      "  2421: 1 [ 1065/ 1327], train_loss/perplexity = 6.49672651/662.9678345 secs/batch = 1.2408s, grad.norm=0.24747661\n",
      "  2426: 1 [ 1070/ 1327], train_loss/perplexity = 6.65552711/777.0674438 secs/batch = 1.2295s, grad.norm=0.29399508\n",
      "  2431: 1 [ 1075/ 1327], train_loss/perplexity = 6.53778458/690.7545776 secs/batch = 1.2441s, grad.norm=0.26146227\n",
      "  2436: 1 [ 1080/ 1327], train_loss/perplexity = 6.45100927/633.3411865 secs/batch = 1.2322s, grad.norm=0.23779178\n",
      "  2441: 1 [ 1085/ 1327], train_loss/perplexity = 6.47406960/648.1159668 secs/batch = 1.2341s, grad.norm=0.29941314\n",
      "  2446: 1 [ 1090/ 1327], train_loss/perplexity = 6.58972168/727.5783691 secs/batch = 1.2256s, grad.norm=0.25484809\n",
      "  2451: 1 [ 1095/ 1327], train_loss/perplexity = 6.53280973/687.3267212 secs/batch = 1.2346s, grad.norm=0.34747940\n",
      "  2456: 1 [ 1100/ 1327], train_loss/perplexity = 6.61389589/745.3812866 secs/batch = 1.2282s, grad.norm=0.34303913\n",
      "  2461: 1 [ 1105/ 1327], train_loss/perplexity = 6.45027828/632.8783569 secs/batch = 1.2371s, grad.norm=0.33426240\n",
      "  2466: 1 [ 1110/ 1327], train_loss/perplexity = 6.74520636/849.9744873 secs/batch = 1.2430s, grad.norm=0.27712342\n",
      "  2471: 1 [ 1115/ 1327], train_loss/perplexity = 6.49107933/659.2344971 secs/batch = 1.2346s, grad.norm=0.28158212\n",
      "  2476: 1 [ 1120/ 1327], train_loss/perplexity = 6.48561049/655.6390991 secs/batch = 1.2431s, grad.norm=0.25916907\n",
      "  2481: 1 [ 1125/ 1327], train_loss/perplexity = 6.69789696/810.6990967 secs/batch = 1.2807s, grad.norm=0.27774262\n",
      "  2486: 1 [ 1130/ 1327], train_loss/perplexity = 6.52073050/679.0742798 secs/batch = 1.2321s, grad.norm=0.23005535\n",
      "  2491: 1 [ 1135/ 1327], train_loss/perplexity = 6.56083727/706.8632812 secs/batch = 1.2328s, grad.norm=0.26215383\n",
      "  2496: 1 [ 1140/ 1327], train_loss/perplexity = 6.62225294/751.6365967 secs/batch = 1.2327s, grad.norm=0.27649909\n",
      "  2501: 1 [ 1145/ 1327], train_loss/perplexity = 6.49586296/662.3956299 secs/batch = 1.2305s, grad.norm=0.26800153\n",
      "  2506: 1 [ 1150/ 1327], train_loss/perplexity = 6.43828487/625.3333740 secs/batch = 1.2439s, grad.norm=0.25675029\n",
      "  2511: 1 [ 1155/ 1327], train_loss/perplexity = 6.54562235/696.1898193 secs/batch = 1.2403s, grad.norm=0.23495068\n",
      "  2516: 1 [ 1160/ 1327], train_loss/perplexity = 6.54478455/695.6068115 secs/batch = 1.2377s, grad.norm=0.28967473\n",
      "  2521: 1 [ 1165/ 1327], train_loss/perplexity = 6.65434504/776.1494141 secs/batch = 1.2296s, grad.norm=0.26459789\n",
      "  2526: 1 [ 1170/ 1327], train_loss/perplexity = 6.53298473/687.4470215 secs/batch = 1.2350s, grad.norm=0.32997003\n",
      "  2531: 1 [ 1175/ 1327], train_loss/perplexity = 6.38970757/595.6823730 secs/batch = 1.2369s, grad.norm=0.31283358\n",
      "  2536: 1 [ 1180/ 1327], train_loss/perplexity = 6.30225945/545.8037109 secs/batch = 1.2331s, grad.norm=0.25878289\n",
      "  2541: 1 [ 1185/ 1327], train_loss/perplexity = 6.56480694/709.6748657 secs/batch = 1.2465s, grad.norm=0.27416980\n",
      "  2546: 1 [ 1190/ 1327], train_loss/perplexity = 6.59640408/732.4566040 secs/batch = 1.2306s, grad.norm=0.23507462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2551: 1 [ 1195/ 1327], train_loss/perplexity = 6.43788576/625.0838013 secs/batch = 1.2303s, grad.norm=0.31877652\n",
      "  2556: 1 [ 1200/ 1327], train_loss/perplexity = 6.34520531/569.7543335 secs/batch = 1.2345s, grad.norm=0.27659506\n",
      "  2561: 1 [ 1205/ 1327], train_loss/perplexity = 6.54696417/697.1246338 secs/batch = 1.2435s, grad.norm=0.30317974\n",
      "  2566: 1 [ 1210/ 1327], train_loss/perplexity = 6.39561939/599.2143555 secs/batch = 1.2360s, grad.norm=0.30880177\n",
      "  2571: 1 [ 1215/ 1327], train_loss/perplexity = 6.35530043/575.5352173 secs/batch = 1.2375s, grad.norm=0.25070745\n",
      "  2576: 1 [ 1220/ 1327], train_loss/perplexity = 6.43706703/624.5722656 secs/batch = 1.2380s, grad.norm=0.28803396\n",
      "  2581: 1 [ 1225/ 1327], train_loss/perplexity = 6.41720152/612.2872314 secs/batch = 1.2466s, grad.norm=0.26119637\n",
      "  2586: 1 [ 1230/ 1327], train_loss/perplexity = 6.53040028/685.6726074 secs/batch = 1.2293s, grad.norm=0.25357679\n",
      "  2591: 1 [ 1235/ 1327], train_loss/perplexity = 6.52770519/683.8271484 secs/batch = 1.2421s, grad.norm=0.24186534\n",
      "  2596: 1 [ 1240/ 1327], train_loss/perplexity = 6.53758669/690.6179199 secs/batch = 1.2402s, grad.norm=0.22414485\n",
      "  2601: 1 [ 1245/ 1327], train_loss/perplexity = 6.39760399/600.4047241 secs/batch = 1.2388s, grad.norm=0.27158931\n",
      "  2606: 1 [ 1250/ 1327], train_loss/perplexity = 6.51419067/674.6477051 secs/batch = 1.2344s, grad.norm=0.27639869\n",
      "  2611: 1 [ 1255/ 1327], train_loss/perplexity = 6.51040268/672.0969849 secs/batch = 1.2317s, grad.norm=0.39040640\n",
      "  2616: 1 [ 1260/ 1327], train_loss/perplexity = 6.61342764/745.0323486 secs/batch = 1.2350s, grad.norm=0.27228430\n",
      "  2621: 1 [ 1265/ 1327], train_loss/perplexity = 6.47451305/648.4034424 secs/batch = 1.2431s, grad.norm=0.22646737\n",
      "  2626: 1 [ 1270/ 1327], train_loss/perplexity = 6.51225042/673.3400269 secs/batch = 1.2384s, grad.norm=0.25536320\n",
      "  2631: 1 [ 1275/ 1327], train_loss/perplexity = 6.68257380/798.3713379 secs/batch = 1.2353s, grad.norm=0.30771512\n",
      "  2636: 1 [ 1280/ 1327], train_loss/perplexity = 6.49747753/663.4659424 secs/batch = 1.2354s, grad.norm=0.28283083\n",
      "  2641: 1 [ 1285/ 1327], train_loss/perplexity = 6.39858341/600.9931030 secs/batch = 1.2368s, grad.norm=0.28865173\n",
      "  2646: 1 [ 1290/ 1327], train_loss/perplexity = 6.46215677/640.4408569 secs/batch = 1.2386s, grad.norm=0.23082346\n",
      "  2651: 1 [ 1295/ 1327], train_loss/perplexity = 6.61861801/748.9094238 secs/batch = 1.2354s, grad.norm=0.26015428\n",
      "  2656: 1 [ 1300/ 1327], train_loss/perplexity = 6.55505514/702.7879028 secs/batch = 1.2374s, grad.norm=0.28375146\n",
      "  2661: 1 [ 1305/ 1327], train_loss/perplexity = 6.67654371/793.5715332 secs/batch = 1.2286s, grad.norm=0.29132232\n",
      "  2666: 1 [ 1310/ 1327], train_loss/perplexity = 6.70640850/817.6288452 secs/batch = 1.2277s, grad.norm=0.24881703\n",
      "  2671: 1 [ 1315/ 1327], train_loss/perplexity = 6.65548754/777.0366821 secs/batch = 1.2376s, grad.norm=0.22059387\n",
      "  2676: 1 [ 1320/ 1327], train_loss/perplexity = 6.69215822/806.0600586 secs/batch = 1.2390s, grad.norm=0.23738065\n",
      "  2681: 1 [ 1325/ 1327], train_loss/perplexity = 6.58904028/727.0827637 secs/batch = 1.2354s, grad.norm=0.26341227\n",
      "Epoch training time: 1649.3392100334167\n",
      "Saved char model cv/epoch001_6.5655.model\n",
      "  2688: 2 [    5/ 1327], train_loss/perplexity = 6.72516203/833.1069336 secs/batch = 1.2343s, grad.norm=0.30088276\n",
      "  2693: 2 [   10/ 1327], train_loss/perplexity = 6.38669920/593.8930054 secs/batch = 1.2351s, grad.norm=0.26851168\n",
      "  2698: 2 [   15/ 1327], train_loss/perplexity = 6.40160656/602.8127441 secs/batch = 1.2313s, grad.norm=0.25463253\n",
      "  2703: 2 [   20/ 1327], train_loss/perplexity = 6.78450203/884.0397339 secs/batch = 1.2396s, grad.norm=0.39952093\n",
      "  2708: 2 [   25/ 1327], train_loss/perplexity = 6.64817524/771.3754883 secs/batch = 1.2274s, grad.norm=0.24941906\n",
      "  2713: 2 [   30/ 1327], train_loss/perplexity = 6.47151995/646.4655762 secs/batch = 1.2319s, grad.norm=0.24560007\n",
      "  2718: 2 [   35/ 1327], train_loss/perplexity = 6.43935919/626.0054932 secs/batch = 1.2402s, grad.norm=0.23007731\n",
      "  2723: 2 [   40/ 1327], train_loss/perplexity = 6.53840590/691.1838989 secs/batch = 1.2316s, grad.norm=0.26585004\n",
      "  2728: 2 [   45/ 1327], train_loss/perplexity = 6.35569954/575.7649536 secs/batch = 1.2396s, grad.norm=0.25168994\n",
      "  2733: 2 [   50/ 1327], train_loss/perplexity = 6.60767460/740.7584839 secs/batch = 1.2324s, grad.norm=0.28227583\n",
      "  2738: 2 [   55/ 1327], train_loss/perplexity = 6.52546263/682.2953491 secs/batch = 1.2266s, grad.norm=0.26806837\n",
      "  2743: 2 [   60/ 1327], train_loss/perplexity = 6.55293369/701.2985229 secs/batch = 1.2370s, grad.norm=0.28643462\n",
      "  2748: 2 [   65/ 1327], train_loss/perplexity = 6.45361519/634.9937744 secs/batch = 1.2270s, grad.norm=0.35829642\n",
      "  2753: 2 [   70/ 1327], train_loss/perplexity = 6.33607626/564.5767212 secs/batch = 1.2268s, grad.norm=0.29089725\n",
      "  2758: 2 [   75/ 1327], train_loss/perplexity = 6.43160629/621.1709595 secs/batch = 1.2410s, grad.norm=0.30263233\n",
      "  2763: 2 [   80/ 1327], train_loss/perplexity = 6.58074856/721.0789185 secs/batch = 1.2283s, grad.norm=0.28490382\n",
      "  2768: 2 [   85/ 1327], train_loss/perplexity = 6.65768480/778.7459106 secs/batch = 1.2319s, grad.norm=0.59161222\n",
      "  2773: 2 [   90/ 1327], train_loss/perplexity = 6.61068296/742.9902954 secs/batch = 1.2329s, grad.norm=0.24331538\n",
      "  2778: 2 [   95/ 1327], train_loss/perplexity = 6.48644733/656.1879883 secs/batch = 1.2300s, grad.norm=0.31392670\n",
      "  2783: 2 [  100/ 1327], train_loss/perplexity = 6.62466240/753.4498291 secs/batch = 1.2437s, grad.norm=0.32612276\n",
      "  2788: 2 [  105/ 1327], train_loss/perplexity = 6.67821932/794.9024048 secs/batch = 1.2381s, grad.norm=0.30959812\n",
      "  2793: 2 [  110/ 1327], train_loss/perplexity = 6.47341299/647.6904907 secs/batch = 1.2369s, grad.norm=0.28426650\n",
      "  2798: 2 [  115/ 1327], train_loss/perplexity = 6.31449366/552.5222168 secs/batch = 1.2284s, grad.norm=0.34549835\n",
      "  2803: 2 [  120/ 1327], train_loss/perplexity = 6.57204294/714.8287354 secs/batch = 1.2362s, grad.norm=0.25865123\n",
      "  2808: 2 [  125/ 1327], train_loss/perplexity = 6.66807413/786.8787231 secs/batch = 1.2258s, grad.norm=0.24682815\n",
      "  2813: 2 [  130/ 1327], train_loss/perplexity = 6.61487770/746.1134644 secs/batch = 1.2354s, grad.norm=0.30845892\n",
      "  2818: 2 [  135/ 1327], train_loss/perplexity = 6.52193642/679.8936768 secs/batch = 1.2322s, grad.norm=0.25515422\n",
      "  2823: 2 [  140/ 1327], train_loss/perplexity = 6.62345362/752.5396118 secs/batch = 1.2293s, grad.norm=0.25181735\n",
      "  2828: 2 [  145/ 1327], train_loss/perplexity = 6.72328043/831.5408325 secs/batch = 1.2340s, grad.norm=0.26702958\n",
      "  2833: 2 [  150/ 1327], train_loss/perplexity = 6.53189802/686.7003174 secs/batch = 1.2289s, grad.norm=0.22151317\n",
      "  2838: 2 [  155/ 1327], train_loss/perplexity = 6.63327026/759.9633789 secs/batch = 1.2330s, grad.norm=0.27503890\n",
      "  2843: 2 [  160/ 1327], train_loss/perplexity = 6.40239620/603.2888794 secs/batch = 1.2338s, grad.norm=0.37197196\n",
      "  2848: 2 [  165/ 1327], train_loss/perplexity = 6.58250332/722.3453369 secs/batch = 1.2393s, grad.norm=0.30323336\n",
      "  2853: 2 [  170/ 1327], train_loss/perplexity = 6.63051462/757.8720703 secs/batch = 1.2299s, grad.norm=0.29390708\n",
      "  2858: 2 [  175/ 1327], train_loss/perplexity = 6.68476200/800.1202393 secs/batch = 1.2275s, grad.norm=0.23867860\n",
      "  2863: 2 [  180/ 1327], train_loss/perplexity = 6.64541149/769.2465210 secs/batch = 1.2355s, grad.norm=0.28500789\n",
      "  2868: 2 [  185/ 1327], train_loss/perplexity = 6.72386456/832.0267334 secs/batch = 1.2405s, grad.norm=0.24620290\n",
      "  2873: 2 [  190/ 1327], train_loss/perplexity = 6.59381294/730.5611572 secs/batch = 1.2423s, grad.norm=0.23788910\n",
      "  2878: 2 [  195/ 1327], train_loss/perplexity = 6.42902756/619.5711670 secs/batch = 1.2389s, grad.norm=0.22530465\n",
      "  2883: 2 [  200/ 1327], train_loss/perplexity = 6.60195875/736.5364990 secs/batch = 1.2296s, grad.norm=0.22803807\n",
      "  2888: 2 [  205/ 1327], train_loss/perplexity = 6.54927683/698.7387085 secs/batch = 1.2420s, grad.norm=0.26268041\n",
      "  2893: 2 [  210/ 1327], train_loss/perplexity = 6.48436022/654.8198853 secs/batch = 1.2394s, grad.norm=0.26959988\n",
      "  2898: 2 [  215/ 1327], train_loss/perplexity = 6.54698801/697.1412354 secs/batch = 1.2411s, grad.norm=0.23317958\n",
      "  2903: 2 [  220/ 1327], train_loss/perplexity = 6.60773182/740.8008423 secs/batch = 1.2309s, grad.norm=0.26477793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2908: 2 [  225/ 1327], train_loss/perplexity = 6.73987913/845.4585571 secs/batch = 1.2227s, grad.norm=0.25893515\n",
      "  2913: 2 [  230/ 1327], train_loss/perplexity = 6.58998203/727.7678223 secs/batch = 1.2332s, grad.norm=0.23121093\n",
      "  2918: 2 [  235/ 1327], train_loss/perplexity = 6.55292845/701.2948608 secs/batch = 1.2308s, grad.norm=0.31671274\n",
      "  2923: 2 [  240/ 1327], train_loss/perplexity = 6.39782238/600.5358887 secs/batch = 1.2419s, grad.norm=0.26700005\n",
      "  2928: 2 [  245/ 1327], train_loss/perplexity = 6.62627649/754.6669312 secs/batch = 1.2321s, grad.norm=0.22942637\n",
      "  2933: 2 [  250/ 1327], train_loss/perplexity = 6.49691010/663.0895996 secs/batch = 1.2316s, grad.norm=0.23893878\n",
      "  2938: 2 [  255/ 1327], train_loss/perplexity = 6.61726332/747.8955688 secs/batch = 1.2364s, grad.norm=0.23716564\n",
      "  2943: 2 [  260/ 1327], train_loss/perplexity = 6.76350307/865.6693726 secs/batch = 1.2335s, grad.norm=0.24310717\n",
      "  2948: 2 [  265/ 1327], train_loss/perplexity = 6.58656931/725.2883301 secs/batch = 1.2339s, grad.norm=0.22266857\n",
      "  2953: 2 [  270/ 1327], train_loss/perplexity = 6.62568235/754.2186890 secs/batch = 1.2382s, grad.norm=0.30399510\n",
      "  2958: 2 [  275/ 1327], train_loss/perplexity = 6.84492350/939.1014404 secs/batch = 1.2290s, grad.norm=0.36417988\n",
      "  2963: 2 [  280/ 1327], train_loss/perplexity = 6.51433182/674.7429810 secs/batch = 1.2372s, grad.norm=0.30673143\n",
      "  2968: 2 [  285/ 1327], train_loss/perplexity = 6.66718769/786.1815186 secs/batch = 1.2293s, grad.norm=0.26470542\n",
      "  2973: 2 [  290/ 1327], train_loss/perplexity = 6.61597109/746.9296875 secs/batch = 1.2323s, grad.norm=0.25445175\n",
      "  2978: 2 [  295/ 1327], train_loss/perplexity = 6.47492170/648.6684570 secs/batch = 1.2425s, grad.norm=0.27719772\n",
      "  2983: 2 [  300/ 1327], train_loss/perplexity = 6.40469170/604.6753540 secs/batch = 1.2389s, grad.norm=0.31900731\n",
      "  2988: 2 [  305/ 1327], train_loss/perplexity = 6.48928308/658.0514526 secs/batch = 1.2271s, grad.norm=0.26240200\n",
      "  2993: 2 [  310/ 1327], train_loss/perplexity = 6.55033112/699.4757690 secs/batch = 1.2332s, grad.norm=0.22897002\n",
      "  2998: 2 [  315/ 1327], train_loss/perplexity = 6.40428019/604.4265747 secs/batch = 1.2347s, grad.norm=0.27506131\n",
      "  3003: 2 [  320/ 1327], train_loss/perplexity = 6.48463011/654.9966431 secs/batch = 1.2293s, grad.norm=0.25535011\n",
      "  3008: 2 [  325/ 1327], train_loss/perplexity = 6.37269592/585.6345215 secs/batch = 1.2313s, grad.norm=0.25624928\n",
      "  3013: 2 [  330/ 1327], train_loss/perplexity = 6.64503431/768.9564209 secs/batch = 1.2307s, grad.norm=0.28813082\n",
      "  3018: 2 [  335/ 1327], train_loss/perplexity = 6.15104628/469.2080383 secs/batch = 1.2407s, grad.norm=0.26186875\n",
      "  3023: 2 [  340/ 1327], train_loss/perplexity = 6.57090521/714.0158691 secs/batch = 1.2352s, grad.norm=0.24753147\n",
      "  3028: 2 [  345/ 1327], train_loss/perplexity = 6.61044931/742.8167114 secs/batch = 1.2452s, grad.norm=0.25190628\n",
      "  3033: 2 [  350/ 1327], train_loss/perplexity = 6.54391813/695.0043945 secs/batch = 1.2418s, grad.norm=0.29604927\n",
      "  3038: 2 [  355/ 1327], train_loss/perplexity = 6.62210989/751.5290527 secs/batch = 1.2367s, grad.norm=0.25773618\n",
      "  3043: 2 [  360/ 1327], train_loss/perplexity = 6.69309092/806.8121948 secs/batch = 1.2381s, grad.norm=0.21584739\n",
      "  3048: 2 [  365/ 1327], train_loss/perplexity = 6.62245417/751.7878418 secs/batch = 1.2391s, grad.norm=0.22069749\n",
      "  3053: 2 [  370/ 1327], train_loss/perplexity = 6.64060688/765.5594482 secs/batch = 1.2338s, grad.norm=0.31947419\n",
      "  3058: 2 [  375/ 1327], train_loss/perplexity = 6.46971416/645.2992554 secs/batch = 1.2354s, grad.norm=0.25023088\n",
      "  3063: 2 [  380/ 1327], train_loss/perplexity = 6.56557846/710.2225952 secs/batch = 1.2810s, grad.norm=0.24832302\n",
      "  3068: 2 [  385/ 1327], train_loss/perplexity = 6.67519617/792.5029297 secs/batch = 1.2373s, grad.norm=0.29061911\n",
      "  3073: 2 [  390/ 1327], train_loss/perplexity = 6.57659101/718.0872192 secs/batch = 1.2435s, grad.norm=0.25785217\n",
      "  3078: 2 [  395/ 1327], train_loss/perplexity = 6.78509140/884.5609131 secs/batch = 1.2455s, grad.norm=0.30709571\n",
      "  3083: 2 [  400/ 1327], train_loss/perplexity = 6.45546436/636.1690674 secs/batch = 1.2282s, grad.norm=0.27210388\n",
      "  3088: 2 [  405/ 1327], train_loss/perplexity = 6.67605114/793.1807861 secs/batch = 1.2413s, grad.norm=0.29905394\n",
      "  3093: 2 [  410/ 1327], train_loss/perplexity = 6.50552607/668.8274536 secs/batch = 1.2335s, grad.norm=0.24517545\n",
      "  3098: 2 [  415/ 1327], train_loss/perplexity = 6.48214722/653.3723755 secs/batch = 1.2392s, grad.norm=0.25888851\n",
      "  3103: 2 [  420/ 1327], train_loss/perplexity = 6.51428652/674.7124023 secs/batch = 1.2328s, grad.norm=0.25022307\n",
      "  3108: 2 [  425/ 1327], train_loss/perplexity = 6.71724939/826.5408936 secs/batch = 1.2331s, grad.norm=0.23573276\n",
      "  3113: 2 [  430/ 1327], train_loss/perplexity = 6.65557814/777.1070557 secs/batch = 1.2457s, grad.norm=0.26493439\n",
      "  3118: 2 [  435/ 1327], train_loss/perplexity = 6.66484594/784.3426514 secs/batch = 1.2330s, grad.norm=0.28769669\n",
      "  3123: 2 [  440/ 1327], train_loss/perplexity = 6.55830765/705.0774536 secs/batch = 1.2313s, grad.norm=0.45340869\n",
      "  3128: 2 [  445/ 1327], train_loss/perplexity = 6.55947542/705.9013062 secs/batch = 1.2326s, grad.norm=0.41539130\n",
      "  3133: 2 [  450/ 1327], train_loss/perplexity = 6.54844236/698.1558838 secs/batch = 1.2375s, grad.norm=0.23033123\n",
      "  3138: 2 [  455/ 1327], train_loss/perplexity = 6.33672428/564.9426880 secs/batch = 1.2346s, grad.norm=0.25427645\n",
      "  3143: 2 [  460/ 1327], train_loss/perplexity = 6.59676456/732.7207031 secs/batch = 1.2295s, grad.norm=0.25386450\n",
      "  3148: 2 [  465/ 1327], train_loss/perplexity = 6.52314091/680.7130737 secs/batch = 1.2369s, grad.norm=0.26725906\n",
      "  3153: 2 [  470/ 1327], train_loss/perplexity = 6.68585014/800.9913330 secs/batch = 1.2347s, grad.norm=0.26540670\n",
      "  3158: 2 [  475/ 1327], train_loss/perplexity = 6.69969511/812.1581421 secs/batch = 1.2374s, grad.norm=0.22545204\n",
      "  3163: 2 [  480/ 1327], train_loss/perplexity = 6.56435966/709.3575439 secs/batch = 1.2391s, grad.norm=0.22648644\n",
      "  3168: 2 [  485/ 1327], train_loss/perplexity = 6.57446003/716.5585938 secs/batch = 1.2346s, grad.norm=0.21607663\n",
      "  3173: 2 [  490/ 1327], train_loss/perplexity = 6.56664419/710.9799194 secs/batch = 1.2352s, grad.norm=0.31220013\n",
      "  3178: 2 [  495/ 1327], train_loss/perplexity = 6.32036686/555.7768555 secs/batch = 1.2250s, grad.norm=0.45391011\n",
      "  3183: 2 [  500/ 1327], train_loss/perplexity = 6.65257931/774.7801514 secs/batch = 1.2300s, grad.norm=0.23604514\n",
      "  3188: 2 [  505/ 1327], train_loss/perplexity = 6.49818516/663.9356079 secs/batch = 1.2391s, grad.norm=0.28648812\n",
      "  3193: 2 [  510/ 1327], train_loss/perplexity = 6.60793686/740.9527588 secs/batch = 1.2304s, grad.norm=0.23265021\n",
      "  3198: 2 [  515/ 1327], train_loss/perplexity = 6.47253895/647.1246338 secs/batch = 1.2406s, grad.norm=0.25246587\n",
      "  3203: 2 [  520/ 1327], train_loss/perplexity = 6.64127493/766.0710449 secs/batch = 1.2433s, grad.norm=0.28997138\n",
      "  3208: 2 [  525/ 1327], train_loss/perplexity = 6.51554203/675.5600586 secs/batch = 1.2350s, grad.norm=0.24824044\n",
      "  3213: 2 [  530/ 1327], train_loss/perplexity = 6.53388166/688.0638428 secs/batch = 1.2350s, grad.norm=0.30650979\n",
      "  3218: 2 [  535/ 1327], train_loss/perplexity = 6.63649988/762.4217529 secs/batch = 1.2375s, grad.norm=0.23631607\n",
      "  3223: 2 [  540/ 1327], train_loss/perplexity = 6.65775204/778.7982788 secs/batch = 1.2387s, grad.norm=0.21290153\n",
      "  3228: 2 [  545/ 1327], train_loss/perplexity = 6.67113066/789.2875366 secs/batch = 1.2314s, grad.norm=0.22901876\n",
      "  3233: 2 [  550/ 1327], train_loss/perplexity = 6.65091038/773.4881592 secs/batch = 1.2295s, grad.norm=0.24866946\n",
      "  3238: 2 [  555/ 1327], train_loss/perplexity = 6.55862522/705.3013916 secs/batch = 1.2272s, grad.norm=0.28544149\n",
      "  3243: 2 [  560/ 1327], train_loss/perplexity = 6.68193102/797.8582764 secs/batch = 1.2277s, grad.norm=0.25042182\n",
      "  3248: 2 [  565/ 1327], train_loss/perplexity = 6.62366152/752.6960449 secs/batch = 1.2277s, grad.norm=0.33678794\n",
      "  3253: 2 [  570/ 1327], train_loss/perplexity = 6.51206827/673.2173462 secs/batch = 1.2426s, grad.norm=0.27512929\n",
      "  3258: 2 [  575/ 1327], train_loss/perplexity = 6.54730129/697.3596802 secs/batch = 1.2819s, grad.norm=0.26441988\n",
      "  3263: 2 [  580/ 1327], train_loss/perplexity = 6.58379030/723.2755737 secs/batch = 1.2338s, grad.norm=0.27431208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3268: 2 [  585/ 1327], train_loss/perplexity = 6.50682831/669.6989746 secs/batch = 1.2395s, grad.norm=0.25608003\n",
      "  3273: 2 [  590/ 1327], train_loss/perplexity = 6.64904022/772.0429688 secs/batch = 1.2304s, grad.norm=0.23008487\n",
      "  3278: 2 [  595/ 1327], train_loss/perplexity = 6.60936642/742.0127563 secs/batch = 1.2302s, grad.norm=0.26488990\n",
      "  3283: 2 [  600/ 1327], train_loss/perplexity = 6.69617414/809.3035889 secs/batch = 1.2351s, grad.norm=0.24738255\n",
      "  3288: 2 [  605/ 1327], train_loss/perplexity = 6.62617874/754.5931396 secs/batch = 1.2261s, grad.norm=0.30213320\n",
      "  3293: 2 [  610/ 1327], train_loss/perplexity = 6.72709799/834.7213745 secs/batch = 1.2299s, grad.norm=0.31999016\n",
      "  3298: 2 [  615/ 1327], train_loss/perplexity = 6.30682945/548.3037720 secs/batch = 1.2344s, grad.norm=0.25813970\n",
      "  3303: 2 [  620/ 1327], train_loss/perplexity = 6.54195738/693.6429443 secs/batch = 1.2197s, grad.norm=0.28953561\n",
      "  3308: 2 [  625/ 1327], train_loss/perplexity = 6.66586637/785.1433716 secs/batch = 1.2338s, grad.norm=0.22519167\n",
      "  3313: 2 [  630/ 1327], train_loss/perplexity = 6.63406801/760.5698853 secs/batch = 1.2336s, grad.norm=0.23725934\n",
      "  3318: 2 [  635/ 1327], train_loss/perplexity = 6.57190275/714.7285156 secs/batch = 1.2296s, grad.norm=0.33393160\n",
      "  3323: 2 [  640/ 1327], train_loss/perplexity = 6.47626829/649.5425415 secs/batch = 1.2212s, grad.norm=0.26899505\n",
      "  3328: 2 [  645/ 1327], train_loss/perplexity = 6.62171268/751.2305908 secs/batch = 1.2420s, grad.norm=0.27727115\n",
      "  3333: 2 [  650/ 1327], train_loss/perplexity = 6.42281723/615.7353516 secs/batch = 1.2300s, grad.norm=0.32638982\n",
      "  3338: 2 [  655/ 1327], train_loss/perplexity = 6.47526360/648.8902588 secs/batch = 1.2339s, grad.norm=0.25548747\n",
      "  3343: 2 [  660/ 1327], train_loss/perplexity = 6.52416563/681.4110107 secs/batch = 1.2297s, grad.norm=0.22803359\n",
      "  3348: 2 [  665/ 1327], train_loss/perplexity = 6.62316751/752.3243408 secs/batch = 1.2365s, grad.norm=0.21152060\n",
      "  3353: 2 [  670/ 1327], train_loss/perplexity = 6.57630730/717.8834839 secs/batch = 1.2407s, grad.norm=0.24465792\n",
      "  3358: 2 [  675/ 1327], train_loss/perplexity = 6.41327906/609.8902588 secs/batch = 1.2373s, grad.norm=0.27560967\n",
      "  3363: 2 [  680/ 1327], train_loss/perplexity = 6.65270805/774.8798828 secs/batch = 1.2269s, grad.norm=0.29574075\n",
      "  3368: 2 [  685/ 1327], train_loss/perplexity = 6.69314861/806.8587646 secs/batch = 1.2372s, grad.norm=0.29111409\n",
      "  3373: 2 [  690/ 1327], train_loss/perplexity = 6.59659338/732.5952759 secs/batch = 1.2406s, grad.norm=0.28039011\n",
      "  3378: 2 [  695/ 1327], train_loss/perplexity = 6.54895926/698.5168457 secs/batch = 1.2270s, grad.norm=0.27401030\n",
      "  3383: 2 [  700/ 1327], train_loss/perplexity = 6.60569334/739.2922974 secs/batch = 1.2422s, grad.norm=0.22590265\n",
      "  3388: 2 [  705/ 1327], train_loss/perplexity = 6.43570662/623.7231445 secs/batch = 1.2282s, grad.norm=0.28626326\n",
      "  3393: 2 [  710/ 1327], train_loss/perplexity = 6.55033779/699.4804077 secs/batch = 1.2306s, grad.norm=0.22408940\n",
      "  3398: 2 [  715/ 1327], train_loss/perplexity = 6.56792068/711.8880615 secs/batch = 1.2277s, grad.norm=0.23990120\n",
      "  3403: 2 [  720/ 1327], train_loss/perplexity = 6.58488989/724.0712891 secs/batch = 1.2358s, grad.norm=0.27783924\n",
      "  3408: 2 [  725/ 1327], train_loss/perplexity = 6.38836622/594.8838501 secs/batch = 1.2273s, grad.norm=0.34851834\n",
      "  3413: 2 [  730/ 1327], train_loss/perplexity = 6.41510582/611.0054321 secs/batch = 1.2309s, grad.norm=0.26258618\n",
      "  3418: 2 [  735/ 1327], train_loss/perplexity = 6.57886934/719.7250977 secs/batch = 1.2329s, grad.norm=0.23899008\n",
      "  3423: 2 [  740/ 1327], train_loss/perplexity = 6.38111258/590.5844116 secs/batch = 1.2211s, grad.norm=0.26545575\n",
      "  3428: 2 [  745/ 1327], train_loss/perplexity = 6.56245041/708.0044556 secs/batch = 1.2377s, grad.norm=0.24306902\n",
      "  3433: 2 [  750/ 1327], train_loss/perplexity = 6.41040230/608.1383057 secs/batch = 1.2325s, grad.norm=0.26285201\n",
      "  3438: 2 [  755/ 1327], train_loss/perplexity = 6.47029877/645.6765747 secs/batch = 1.2347s, grad.norm=0.23761794\n",
      "  3443: 2 [  760/ 1327], train_loss/perplexity = 6.39790201/600.5836792 secs/batch = 1.2320s, grad.norm=0.30925182\n",
      "  3448: 2 [  765/ 1327], train_loss/perplexity = 6.42055607/614.3446655 secs/batch = 1.2302s, grad.norm=0.29773882\n",
      "  3453: 2 [  770/ 1327], train_loss/perplexity = 6.45146894/633.6323853 secs/batch = 1.2291s, grad.norm=0.28328335\n",
      "  3458: 2 [  775/ 1327], train_loss/perplexity = 6.50587130/669.0583496 secs/batch = 1.2298s, grad.norm=0.25132063\n",
      "  3463: 2 [  780/ 1327], train_loss/perplexity = 6.61700964/747.7058105 secs/batch = 1.2319s, grad.norm=0.24789457\n",
      "  3468: 2 [  785/ 1327], train_loss/perplexity = 6.49747849/663.4665527 secs/batch = 1.2284s, grad.norm=0.25855061\n",
      "  3473: 2 [  790/ 1327], train_loss/perplexity = 6.32671547/559.3164673 secs/batch = 1.2328s, grad.norm=0.23831551\n",
      "  3478: 2 [  795/ 1327], train_loss/perplexity = 6.60166359/736.3190918 secs/batch = 1.2322s, grad.norm=0.25986195\n",
      "  3483: 2 [  800/ 1327], train_loss/perplexity = 6.55037546/699.5067749 secs/batch = 1.2339s, grad.norm=0.24567711\n",
      "  3488: 2 [  805/ 1327], train_loss/perplexity = 6.67305946/790.8113403 secs/batch = 1.2393s, grad.norm=0.28954029\n",
      "  3493: 2 [  810/ 1327], train_loss/perplexity = 6.61743784/748.0260620 secs/batch = 1.2452s, grad.norm=0.32072154\n",
      "  3498: 2 [  815/ 1327], train_loss/perplexity = 6.41765785/612.5667114 secs/batch = 1.2405s, grad.norm=0.28292349\n",
      "  3503: 2 [  820/ 1327], train_loss/perplexity = 6.29221630/540.3496094 secs/batch = 1.2344s, grad.norm=0.26561624\n",
      "  3508: 2 [  825/ 1327], train_loss/perplexity = 6.43656588/624.2593384 secs/batch = 1.2307s, grad.norm=0.27267584\n",
      "  3513: 2 [  830/ 1327], train_loss/perplexity = 6.30526590/547.4471436 secs/batch = 1.2311s, grad.norm=0.28141478\n",
      "  3518: 2 [  835/ 1327], train_loss/perplexity = 6.53193998/686.7291870 secs/batch = 1.2343s, grad.norm=0.23223419\n",
      "  3523: 2 [  840/ 1327], train_loss/perplexity = 6.63131428/758.4783936 secs/batch = 1.2332s, grad.norm=0.22818418\n",
      "  3528: 2 [  845/ 1327], train_loss/perplexity = 6.54259062/694.0823364 secs/batch = 1.2327s, grad.norm=0.23308422\n",
      "  3533: 2 [  850/ 1327], train_loss/perplexity = 6.48457193/654.9585571 secs/batch = 1.2428s, grad.norm=0.28163764\n",
      "  3538: 2 [  855/ 1327], train_loss/perplexity = 6.51690722/676.4829102 secs/batch = 1.2382s, grad.norm=0.24846303\n",
      "  3543: 2 [  860/ 1327], train_loss/perplexity = 6.33670902/564.9340820 secs/batch = 1.2371s, grad.norm=0.25252825\n",
      "  3548: 2 [  865/ 1327], train_loss/perplexity = 6.63229418/759.2219849 secs/batch = 1.2419s, grad.norm=0.23045076\n",
      "  3553: 2 [  870/ 1327], train_loss/perplexity = 6.68967915/804.0642090 secs/batch = 1.2310s, grad.norm=0.28786576\n",
      "  3558: 2 [  875/ 1327], train_loss/perplexity = 6.38195181/591.0802612 secs/batch = 1.2325s, grad.norm=0.24835587\n",
      "  3563: 2 [  880/ 1327], train_loss/perplexity = 6.56794834/711.9077759 secs/batch = 1.2300s, grad.norm=0.25365439\n",
      "  3568: 2 [  885/ 1327], train_loss/perplexity = 6.42963123/619.9453125 secs/batch = 1.2490s, grad.norm=0.30673665\n",
      "  3573: 2 [  890/ 1327], train_loss/perplexity = 6.49338961/660.7592773 secs/batch = 1.2363s, grad.norm=0.28553689\n",
      "  3578: 2 [  895/ 1327], train_loss/perplexity = 6.58746862/725.9409180 secs/batch = 1.2324s, grad.norm=0.38942784\n",
      "  3583: 2 [  900/ 1327], train_loss/perplexity = 6.54037714/692.5477295 secs/batch = 1.2248s, grad.norm=0.27959117\n",
      "  3588: 2 [  905/ 1327], train_loss/perplexity = 6.45639420/636.7608643 secs/batch = 1.2315s, grad.norm=0.25780502\n",
      "  3593: 2 [  910/ 1327], train_loss/perplexity = 6.43309355/622.0954590 secs/batch = 1.2321s, grad.norm=0.30109534\n",
      "  3598: 2 [  915/ 1327], train_loss/perplexity = 6.67606354/793.1906128 secs/batch = 1.2377s, grad.norm=0.23709451\n",
      "  3603: 2 [  920/ 1327], train_loss/perplexity = 6.67098713/789.1742554 secs/batch = 1.2309s, grad.norm=0.26777396\n",
      "  3608: 2 [  925/ 1327], train_loss/perplexity = 6.51380777/674.3894653 secs/batch = 1.2604s, grad.norm=0.26483908\n",
      "  3613: 2 [  930/ 1327], train_loss/perplexity = 6.48764038/656.9713135 secs/batch = 1.2442s, grad.norm=0.41257679\n",
      "  3618: 2 [  935/ 1327], train_loss/perplexity = 6.56026363/706.4578857 secs/batch = 1.2338s, grad.norm=0.22283219\n",
      "  3623: 2 [  940/ 1327], train_loss/perplexity = 6.48568058/655.6850586 secs/batch = 1.2311s, grad.norm=0.24875566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3628: 2 [  945/ 1327], train_loss/perplexity = 6.60652685/739.9087524 secs/batch = 1.2288s, grad.norm=0.22155601\n",
      "  3633: 2 [  950/ 1327], train_loss/perplexity = 6.47243500/647.0573730 secs/batch = 1.2389s, grad.norm=0.24117804\n",
      "  3638: 2 [  955/ 1327], train_loss/perplexity = 6.61302376/744.7315063 secs/batch = 1.2340s, grad.norm=0.24087793\n",
      "  3643: 2 [  960/ 1327], train_loss/perplexity = 6.66039848/780.8620605 secs/batch = 1.2438s, grad.norm=0.23963091\n",
      "  3648: 2 [  965/ 1327], train_loss/perplexity = 6.54907084/698.5947876 secs/batch = 1.2301s, grad.norm=0.24977641\n",
      "  3653: 2 [  970/ 1327], train_loss/perplexity = 6.58518362/724.2840576 secs/batch = 1.2333s, grad.norm=0.23458621\n",
      "  3658: 2 [  975/ 1327], train_loss/perplexity = 6.54317379/694.4872437 secs/batch = 1.2354s, grad.norm=0.27399260\n",
      "  3663: 2 [  980/ 1327], train_loss/perplexity = 6.44207191/627.7059937 secs/batch = 1.2418s, grad.norm=0.23347902\n",
      "  3668: 2 [  985/ 1327], train_loss/perplexity = 6.61138725/743.5137329 secs/batch = 1.2399s, grad.norm=0.25930011\n",
      "  3673: 2 [  990/ 1327], train_loss/perplexity = 6.67228222/790.1969604 secs/batch = 1.2372s, grad.norm=0.29094592\n",
      "  3678: 2 [  995/ 1327], train_loss/perplexity = 6.64648294/770.0711670 secs/batch = 1.2422s, grad.norm=0.24992113\n",
      "  3683: 2 [ 1000/ 1327], train_loss/perplexity = 6.37912798/589.4135132 secs/batch = 1.2245s, grad.norm=0.27429822\n",
      "  3688: 2 [ 1005/ 1327], train_loss/perplexity = 6.62645769/754.8037109 secs/batch = 1.2304s, grad.norm=0.26659954\n",
      "  3693: 2 [ 1010/ 1327], train_loss/perplexity = 6.36384821/580.4758301 secs/batch = 1.2953s, grad.norm=0.24311724\n",
      "  3698: 2 [ 1015/ 1327], train_loss/perplexity = 6.57466173/716.7031250 secs/batch = 1.4042s, grad.norm=0.28147504\n",
      "  3703: 2 [ 1020/ 1327], train_loss/perplexity = 6.66191816/782.0496216 secs/batch = 1.5049s, grad.norm=0.26548487\n",
      "  3708: 2 [ 1025/ 1327], train_loss/perplexity = 6.55145788/700.2643433 secs/batch = 1.2802s, grad.norm=0.21563621\n",
      "  3713: 2 [ 1030/ 1327], train_loss/perplexity = 6.53093958/686.0424805 secs/batch = 1.2224s, grad.norm=0.20992728\n",
      "  3718: 2 [ 1035/ 1327], train_loss/perplexity = 6.43329668/622.2218628 secs/batch = 1.2375s, grad.norm=0.28574482\n",
      "  3723: 2 [ 1040/ 1327], train_loss/perplexity = 6.49079466/659.0468750 secs/batch = 1.2406s, grad.norm=0.22014064\n",
      "  3728: 2 [ 1045/ 1327], train_loss/perplexity = 6.31104851/550.6219482 secs/batch = 1.2300s, grad.norm=0.25435725\n",
      "  3733: 2 [ 1050/ 1327], train_loss/perplexity = 6.54057121/692.6821289 secs/batch = 1.2270s, grad.norm=0.26362747\n",
      "  3738: 2 [ 1055/ 1327], train_loss/perplexity = 6.69501400/808.3652344 secs/batch = 1.2243s, grad.norm=0.28101757\n",
      "  3743: 2 [ 1060/ 1327], train_loss/perplexity = 6.42512417/617.1574707 secs/batch = 1.2307s, grad.norm=0.25341722\n",
      "  3748: 2 [ 1065/ 1327], train_loss/perplexity = 6.49433517/661.3843994 secs/batch = 1.2375s, grad.norm=0.22375953\n",
      "  3753: 2 [ 1070/ 1327], train_loss/perplexity = 6.65694809/778.1724243 secs/batch = 1.2355s, grad.norm=0.26482221\n",
      "  3758: 2 [ 1075/ 1327], train_loss/perplexity = 6.52957821/685.1091919 secs/batch = 1.2294s, grad.norm=0.23855203\n",
      "  3763: 2 [ 1080/ 1327], train_loss/perplexity = 6.45009089/632.7598267 secs/batch = 1.2349s, grad.norm=0.22807062\n",
      "  3768: 2 [ 1085/ 1327], train_loss/perplexity = 6.46536970/642.5018311 secs/batch = 1.2421s, grad.norm=0.25568807\n",
      "  3773: 2 [ 1090/ 1327], train_loss/perplexity = 6.59058714/728.2083130 secs/batch = 1.2345s, grad.norm=0.24011149\n",
      "  3778: 2 [ 1095/ 1327], train_loss/perplexity = 6.51532316/675.4121704 secs/batch = 1.2340s, grad.norm=0.30348757\n",
      "  3783: 2 [ 1100/ 1327], train_loss/perplexity = 6.60491133/738.7143555 secs/batch = 1.2413s, grad.norm=0.30696252\n",
      "  3788: 2 [ 1105/ 1327], train_loss/perplexity = 6.44481850/629.4324341 secs/batch = 1.2293s, grad.norm=0.31224185\n",
      "  3793: 2 [ 1110/ 1327], train_loss/perplexity = 6.74054670/846.0231323 secs/batch = 1.2303s, grad.norm=0.25412390\n",
      "  3798: 2 [ 1115/ 1327], train_loss/perplexity = 6.48072672/652.4449463 secs/batch = 1.2366s, grad.norm=0.25235072\n",
      "  3803: 2 [ 1120/ 1327], train_loss/perplexity = 6.48203421/653.2985229 secs/batch = 1.2335s, grad.norm=0.23482893\n",
      "  3808: 2 [ 1125/ 1327], train_loss/perplexity = 6.69105768/805.1734009 secs/batch = 1.2344s, grad.norm=0.26152489\n",
      "  3813: 2 [ 1130/ 1327], train_loss/perplexity = 6.51700735/676.5506592 secs/batch = 1.2363s, grad.norm=0.21668731\n",
      "  3818: 2 [ 1135/ 1327], train_loss/perplexity = 6.56047916/706.6101685 secs/batch = 1.2333s, grad.norm=0.24514982\n",
      "  3823: 2 [ 1140/ 1327], train_loss/perplexity = 6.61738157/747.9840088 secs/batch = 1.2316s, grad.norm=0.25827044\n",
      "  3828: 2 [ 1145/ 1327], train_loss/perplexity = 6.49989796/665.0737915 secs/batch = 1.2351s, grad.norm=0.25649717\n",
      "  3833: 2 [ 1150/ 1327], train_loss/perplexity = 6.43309689/622.0975342 secs/batch = 1.2346s, grad.norm=0.24118848\n",
      "  3838: 2 [ 1155/ 1327], train_loss/perplexity = 6.54401875/695.0742798 secs/batch = 1.2981s, grad.norm=0.22424695\n",
      "  3843: 2 [ 1160/ 1327], train_loss/perplexity = 6.53625822/689.7010498 secs/batch = 1.2394s, grad.norm=0.26259738\n",
      "  3848: 2 [ 1165/ 1327], train_loss/perplexity = 6.65006828/772.8370972 secs/batch = 1.2321s, grad.norm=0.25333691\n",
      "  3853: 2 [ 1170/ 1327], train_loss/perplexity = 6.53015566/685.5048828 secs/batch = 1.2282s, grad.norm=0.28987119\n",
      "  3858: 2 [ 1175/ 1327], train_loss/perplexity = 6.38852596/594.9788818 secs/batch = 1.2325s, grad.norm=0.29046410\n",
      "  3863: 2 [ 1180/ 1327], train_loss/perplexity = 6.30349350/546.4777222 secs/batch = 1.2400s, grad.norm=0.24040172\n",
      "  3868: 2 [ 1185/ 1327], train_loss/perplexity = 6.55817747/704.9856567 secs/batch = 1.2255s, grad.norm=0.25125161\n",
      "  3873: 2 [ 1190/ 1327], train_loss/perplexity = 6.59626389/732.3539429 secs/batch = 1.2375s, grad.norm=0.22115187\n",
      "  3878: 2 [ 1195/ 1327], train_loss/perplexity = 6.43366623/622.4518433 secs/batch = 1.2290s, grad.norm=0.28458369\n",
      "  3883: 2 [ 1200/ 1327], train_loss/perplexity = 6.33156395/562.0349121 secs/batch = 1.2315s, grad.norm=0.25431845\n",
      "  3888: 2 [ 1205/ 1327], train_loss/perplexity = 6.54177475/693.5162964 secs/batch = 1.2458s, grad.norm=0.27921170\n",
      "  3893: 2 [ 1210/ 1327], train_loss/perplexity = 6.38441038/592.5352783 secs/batch = 1.2337s, grad.norm=0.28485486\n",
      "  3898: 2 [ 1215/ 1327], train_loss/perplexity = 6.35148382/573.3428345 secs/batch = 1.2289s, grad.norm=0.23693208\n",
      "  3903: 2 [ 1220/ 1327], train_loss/perplexity = 6.43673611/624.3656006 secs/batch = 1.2330s, grad.norm=0.26497391\n",
      "  3908: 2 [ 1225/ 1327], train_loss/perplexity = 6.42161226/614.9938354 secs/batch = 1.2420s, grad.norm=0.25189859\n",
      "  3913: 2 [ 1230/ 1327], train_loss/perplexity = 6.52354908/680.9909668 secs/batch = 1.2265s, grad.norm=0.23619105\n",
      "  3918: 2 [ 1235/ 1327], train_loss/perplexity = 6.51798677/677.2136230 secs/batch = 1.2332s, grad.norm=0.22663759\n",
      "  3923: 2 [ 1240/ 1327], train_loss/perplexity = 6.53222370/686.9240112 secs/batch = 1.2369s, grad.norm=0.21040949\n",
      "  3928: 2 [ 1245/ 1327], train_loss/perplexity = 6.39580917/599.3280640 secs/batch = 1.2381s, grad.norm=0.24763231\n",
      "  3933: 2 [ 1250/ 1327], train_loss/perplexity = 6.51192379/673.1201172 secs/batch = 1.2442s, grad.norm=0.24829818\n",
      "  3938: 2 [ 1255/ 1327], train_loss/perplexity = 6.49881697/664.3552246 secs/batch = 1.2349s, grad.norm=0.32754523\n",
      "  3943: 2 [ 1260/ 1327], train_loss/perplexity = 6.60915804/741.8581543 secs/batch = 1.2326s, grad.norm=0.25149506\n",
      "  3948: 2 [ 1265/ 1327], train_loss/perplexity = 6.47588730/649.2951050 secs/batch = 1.2292s, grad.norm=0.21406354\n",
      "  3953: 2 [ 1270/ 1327], train_loss/perplexity = 6.50913668/671.2466431 secs/batch = 1.2398s, grad.norm=0.24563611\n",
      "  3958: 2 [ 1275/ 1327], train_loss/perplexity = 6.66887426/787.5086060 secs/batch = 1.2313s, grad.norm=0.26845351\n",
      "  3963: 2 [ 1280/ 1327], train_loss/perplexity = 6.49437904/661.4133911 secs/batch = 1.2360s, grad.norm=0.26382643\n",
      "  3968: 2 [ 1285/ 1327], train_loss/perplexity = 6.39059591/596.2117920 secs/batch = 1.2436s, grad.norm=0.25573260\n",
      "  3973: 2 [ 1290/ 1327], train_loss/perplexity = 6.46455574/641.9790649 secs/batch = 1.2282s, grad.norm=0.21663360\n",
      "  3978: 2 [ 1295/ 1327], train_loss/perplexity = 6.62006855/749.9965210 secs/batch = 1.2321s, grad.norm=0.24217783\n",
      "  3983: 2 [ 1300/ 1327], train_loss/perplexity = 6.54670143/696.9414673 secs/batch = 1.2440s, grad.norm=0.25502989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3988: 2 [ 1305/ 1327], train_loss/perplexity = 6.67845345/795.0885010 secs/batch = 1.2274s, grad.norm=0.26380280\n",
      "  3993: 2 [ 1310/ 1327], train_loss/perplexity = 6.70523834/816.6726685 secs/batch = 1.2353s, grad.norm=0.23391783\n",
      "  3998: 2 [ 1315/ 1327], train_loss/perplexity = 6.65894175/779.7253418 secs/batch = 1.2332s, grad.norm=0.20513377\n",
      "  4003: 2 [ 1320/ 1327], train_loss/perplexity = 6.68859291/803.1912842 secs/batch = 1.2366s, grad.norm=0.22227649\n",
      "  4008: 2 [ 1325/ 1327], train_loss/perplexity = 6.58517790/724.2799072 secs/batch = 1.2314s, grad.norm=0.23450808\n",
      "Epoch training time: 1642.2195327281952\n",
      "Saved char model cv/epoch002_6.5612.model\n",
      "  4015: 3 [    5/ 1327], train_loss/perplexity = 6.72036886/829.1232910 secs/batch = 1.2305s, grad.norm=0.26981661\n",
      "  4020: 3 [   10/ 1327], train_loss/perplexity = 6.38104057/590.5418701 secs/batch = 1.2357s, grad.norm=0.23193634\n",
      "  4025: 3 [   15/ 1327], train_loss/perplexity = 6.39675140/599.8930664 secs/batch = 1.2378s, grad.norm=0.24173068\n",
      "  4030: 3 [   20/ 1327], train_loss/perplexity = 6.77805519/878.3588257 secs/batch = 1.2687s, grad.norm=0.35125345\n",
      "  4035: 3 [   25/ 1327], train_loss/perplexity = 6.64976931/772.6060791 secs/batch = 1.2260s, grad.norm=0.24181780\n",
      "  4040: 3 [   30/ 1327], train_loss/perplexity = 6.47365952/647.8502197 secs/batch = 1.2380s, grad.norm=0.22640616\n",
      "  4045: 3 [   35/ 1327], train_loss/perplexity = 6.43139601/621.0403442 secs/batch = 1.2364s, grad.norm=0.21917492\n",
      "  4050: 3 [   40/ 1327], train_loss/perplexity = 6.54108620/693.0389404 secs/batch = 1.2335s, grad.norm=0.25059175\n",
      "  4055: 3 [   45/ 1327], train_loss/perplexity = 6.35382271/574.6853638 secs/batch = 1.2381s, grad.norm=0.24668491\n",
      "  4060: 3 [   50/ 1327], train_loss/perplexity = 6.60361671/737.7586060 secs/batch = 1.2389s, grad.norm=0.25359389\n",
      "  4065: 3 [   55/ 1327], train_loss/perplexity = 6.51677513/676.3935547 secs/batch = 1.2277s, grad.norm=0.24220814\n",
      "  4070: 3 [   60/ 1327], train_loss/perplexity = 6.55349207/701.6902466 secs/batch = 1.2357s, grad.norm=0.28217000\n",
      "  4075: 3 [   65/ 1327], train_loss/perplexity = 6.43835402/625.3765869 secs/batch = 1.2394s, grad.norm=0.31510660\n",
      "  4080: 3 [   70/ 1327], train_loss/perplexity = 6.33499670/563.9675293 secs/batch = 1.2278s, grad.norm=0.26972076\n",
      "  4085: 3 [   75/ 1327], train_loss/perplexity = 6.43806934/625.1986084 secs/batch = 1.2265s, grad.norm=0.30070770\n",
      "  4090: 3 [   80/ 1327], train_loss/perplexity = 6.57542849/717.2528687 secs/batch = 1.2387s, grad.norm=0.25919583\n",
      "  4095: 3 [   85/ 1327], train_loss/perplexity = 6.64373255/767.9560547 secs/batch = 1.2365s, grad.norm=0.49807301\n",
      "  4100: 3 [   90/ 1327], train_loss/perplexity = 6.61083364/743.1022339 secs/batch = 1.2231s, grad.norm=0.23850776\n",
      "  4105: 3 [   95/ 1327], train_loss/perplexity = 6.48109579/652.6857910 secs/batch = 1.2274s, grad.norm=0.28760740\n",
      "  4110: 3 [  100/ 1327], train_loss/perplexity = 6.60805082/741.0371704 secs/batch = 1.2353s, grad.norm=0.28123549\n",
      "  4115: 3 [  105/ 1327], train_loss/perplexity = 6.66545200/784.8181152 secs/batch = 1.2256s, grad.norm=0.27907154\n",
      "  4120: 3 [  110/ 1327], train_loss/perplexity = 6.46286392/640.8939209 secs/batch = 1.2378s, grad.norm=0.25475487\n",
      "  4125: 3 [  115/ 1327], train_loss/perplexity = 6.30079031/545.0024414 secs/batch = 1.2298s, grad.norm=0.31143770\n",
      "  4130: 3 [  120/ 1327], train_loss/perplexity = 6.56139421/707.2570801 secs/batch = 1.2360s, grad.norm=0.24041627\n",
      "  4135: 3 [  125/ 1327], train_loss/perplexity = 6.66881847/787.4646606 secs/batch = 1.2321s, grad.norm=0.23178659\n",
      "  4140: 3 [  130/ 1327], train_loss/perplexity = 6.60682678/740.1306763 secs/batch = 1.2424s, grad.norm=0.27513027\n",
      "  4145: 3 [  135/ 1327], train_loss/perplexity = 6.52005243/678.6139526 secs/batch = 1.2363s, grad.norm=0.23944011\n",
      "  4150: 3 [  140/ 1327], train_loss/perplexity = 6.62225914/751.6412354 secs/batch = 1.2372s, grad.norm=0.23290344\n",
      "  4155: 3 [  145/ 1327], train_loss/perplexity = 6.71657705/825.9853516 secs/batch = 1.2312s, grad.norm=0.25343472\n",
      "  4160: 3 [  150/ 1327], train_loss/perplexity = 6.53340197/687.7338867 secs/batch = 1.2276s, grad.norm=0.20985281\n",
      "  4165: 3 [  155/ 1327], train_loss/perplexity = 6.63631821/762.2832642 secs/batch = 1.2291s, grad.norm=0.26979715\n",
      "  4170: 3 [  160/ 1327], train_loss/perplexity = 6.38772249/594.5010376 secs/batch = 1.2360s, grad.norm=0.31877983\n",
      "  4175: 3 [  165/ 1327], train_loss/perplexity = 6.57356787/715.9196167 secs/batch = 1.2370s, grad.norm=0.27154785\n",
      "  4180: 3 [  170/ 1327], train_loss/perplexity = 6.62309408/752.2691040 secs/batch = 1.2277s, grad.norm=0.26938313\n",
      "  4185: 3 [  175/ 1327], train_loss/perplexity = 6.68361616/799.2039185 secs/batch = 1.2241s, grad.norm=0.22350363\n",
      "  4190: 3 [  180/ 1327], train_loss/perplexity = 6.63808107/763.6282349 secs/batch = 1.2399s, grad.norm=0.25354266\n",
      "  4195: 3 [  185/ 1327], train_loss/perplexity = 6.71573448/825.2897339 secs/batch = 1.2275s, grad.norm=0.24090101\n",
      "  4200: 3 [  190/ 1327], train_loss/perplexity = 6.58335733/722.9624634 secs/batch = 1.2242s, grad.norm=0.22695300\n",
      "  4205: 3 [  195/ 1327], train_loss/perplexity = 6.42260695/615.6058960 secs/batch = 1.2366s, grad.norm=0.20430820\n",
      "  4210: 3 [  200/ 1327], train_loss/perplexity = 6.60557985/739.2083740 secs/batch = 1.2323s, grad.norm=0.21284556\n",
      "  4215: 3 [  205/ 1327], train_loss/perplexity = 6.54877186/698.3859253 secs/batch = 1.2314s, grad.norm=0.24404159\n",
      "  4220: 3 [  210/ 1327], train_loss/perplexity = 6.47855377/651.0287476 secs/batch = 1.2374s, grad.norm=0.24762478\n",
      "  4225: 3 [  215/ 1327], train_loss/perplexity = 6.54978609/699.0946045 secs/batch = 1.2574s, grad.norm=0.21204382\n",
      "  4230: 3 [  220/ 1327], train_loss/perplexity = 6.59792948/733.5747070 secs/batch = 1.2309s, grad.norm=0.24909425\n",
      "  4235: 3 [  225/ 1327], train_loss/perplexity = 6.73749590/843.4460449 secs/batch = 1.2283s, grad.norm=0.23867977\n",
      "  4240: 3 [  230/ 1327], train_loss/perplexity = 6.58530617/724.3728027 secs/batch = 1.2239s, grad.norm=0.21940416\n",
      "  4245: 3 [  235/ 1327], train_loss/perplexity = 6.54270792/694.1637573 secs/batch = 1.2352s, grad.norm=0.28106797\n",
      "  4250: 3 [  240/ 1327], train_loss/perplexity = 6.39529228/599.0183716 secs/batch = 1.2358s, grad.norm=0.24824969\n",
      "  4255: 3 [  245/ 1327], train_loss/perplexity = 6.62401867/752.9649658 secs/batch = 1.2344s, grad.norm=0.22021191\n",
      "  4260: 3 [  250/ 1327], train_loss/perplexity = 6.49799538/663.8096313 secs/batch = 1.2407s, grad.norm=0.22648545\n",
      "  4265: 3 [  255/ 1327], train_loss/perplexity = 6.61637545/747.2318115 secs/batch = 1.2383s, grad.norm=0.22342438\n",
      "  4270: 3 [  260/ 1327], train_loss/perplexity = 6.75846815/861.3217773 secs/batch = 1.2369s, grad.norm=0.23430119\n",
      "  4275: 3 [  265/ 1327], train_loss/perplexity = 6.58085442/721.1552124 secs/batch = 1.2324s, grad.norm=0.21306653\n",
      "  4280: 3 [  270/ 1327], train_loss/perplexity = 6.61823082/748.6195068 secs/batch = 1.2488s, grad.norm=0.27930540\n",
      "  4285: 3 [  275/ 1327], train_loss/perplexity = 6.83886147/933.4257812 secs/batch = 1.2260s, grad.norm=0.33221635\n",
      "  4290: 3 [  280/ 1327], train_loss/perplexity = 6.50405073/667.8414307 secs/batch = 1.2305s, grad.norm=0.29346380\n",
      "  4295: 3 [  285/ 1327], train_loss/perplexity = 6.66277838/782.7225952 secs/batch = 1.2291s, grad.norm=0.24937877\n",
      "  4300: 3 [  290/ 1327], train_loss/perplexity = 6.61681652/747.5614624 secs/batch = 1.2300s, grad.norm=0.23875654\n",
      "  4305: 3 [  295/ 1327], train_loss/perplexity = 6.47056484/645.8484497 secs/batch = 1.2324s, grad.norm=0.25701162\n",
      "  4310: 3 [  300/ 1327], train_loss/perplexity = 6.39734983/600.2521362 secs/batch = 1.2318s, grad.norm=0.29081869\n",
      "  4315: 3 [  305/ 1327], train_loss/perplexity = 6.48869467/657.6643066 secs/batch = 1.2446s, grad.norm=0.23464613\n",
      "  4320: 3 [  310/ 1327], train_loss/perplexity = 6.55580997/703.3186035 secs/batch = 1.2333s, grad.norm=0.22164299\n",
      "  4325: 3 [  315/ 1327], train_loss/perplexity = 6.40267563/603.4575195 secs/batch = 1.2434s, grad.norm=0.25866598\n",
      "  4330: 3 [  320/ 1327], train_loss/perplexity = 6.48113966/652.7144165 secs/batch = 1.2287s, grad.norm=0.22999899\n",
      "  4335: 3 [  325/ 1327], train_loss/perplexity = 6.37975502/589.7832031 secs/batch = 1.2431s, grad.norm=0.24292821\n",
      "  4340: 3 [  330/ 1327], train_loss/perplexity = 6.64294243/767.3495483 secs/batch = 1.2292s, grad.norm=0.26593024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4345: 3 [  335/ 1327], train_loss/perplexity = 6.14304399/465.4682922 secs/batch = 1.2244s, grad.norm=0.24833871\n",
      "  4350: 3 [  340/ 1327], train_loss/perplexity = 6.56716251/711.3485107 secs/batch = 1.2286s, grad.norm=0.23554575\n",
      "  4355: 3 [  345/ 1327], train_loss/perplexity = 6.60878134/741.5787354 secs/batch = 1.2349s, grad.norm=0.23562001\n",
      "  4360: 3 [  350/ 1327], train_loss/perplexity = 6.53795671/690.8734741 secs/batch = 1.2482s, grad.norm=0.28343269\n",
      "  4365: 3 [  355/ 1327], train_loss/perplexity = 6.62040329/750.2476196 secs/batch = 1.2260s, grad.norm=0.23852426\n",
      "  4370: 3 [  360/ 1327], train_loss/perplexity = 6.68972111/804.0979614 secs/batch = 1.2319s, grad.norm=0.20762087\n",
      "  4375: 3 [  365/ 1327], train_loss/perplexity = 6.61235619/744.2344971 secs/batch = 1.2300s, grad.norm=0.21111192\n",
      "  4380: 3 [  370/ 1327], train_loss/perplexity = 6.63595152/762.0037842 secs/batch = 1.2311s, grad.norm=0.29862106\n",
      "  4385: 3 [  375/ 1327], train_loss/perplexity = 6.46285629/640.8890381 secs/batch = 1.2258s, grad.norm=0.23883580\n",
      "  4390: 3 [  380/ 1327], train_loss/perplexity = 6.56747818/711.5731201 secs/batch = 1.2364s, grad.norm=0.23374182\n",
      "  4395: 3 [  385/ 1327], train_loss/perplexity = 6.66658068/785.7044067 secs/batch = 1.2278s, grad.norm=0.26109666\n",
      "  4400: 3 [  390/ 1327], train_loss/perplexity = 6.57997561/720.5217285 secs/batch = 1.2341s, grad.norm=0.24786547\n",
      "  4405: 3 [  395/ 1327], train_loss/perplexity = 6.76799679/869.5682373 secs/batch = 1.2297s, grad.norm=0.27995881\n",
      "  4410: 3 [  400/ 1327], train_loss/perplexity = 6.45344114/634.8832397 secs/batch = 1.2427s, grad.norm=0.24743022\n",
      "  4415: 3 [  405/ 1327], train_loss/perplexity = 6.66990709/788.3223877 secs/batch = 1.2382s, grad.norm=0.28349087\n",
      "  4420: 3 [  410/ 1327], train_loss/perplexity = 6.50238132/666.7274170 secs/batch = 1.2828s, grad.norm=0.23669311\n",
      "  4425: 3 [  415/ 1327], train_loss/perplexity = 6.47904158/651.3463745 secs/batch = 1.2489s, grad.norm=0.24892195\n",
      "  4430: 3 [  420/ 1327], train_loss/perplexity = 6.51259470/673.5718994 secs/batch = 1.2333s, grad.norm=0.24117121\n",
      "  4435: 3 [  425/ 1327], train_loss/perplexity = 6.71244478/822.5792236 secs/batch = 1.2382s, grad.norm=0.22857001\n",
      "  4440: 3 [  430/ 1327], train_loss/perplexity = 6.65083981/773.4335938 secs/batch = 1.2402s, grad.norm=0.25196674\n",
      "  4445: 3 [  435/ 1327], train_loss/perplexity = 6.66300011/782.8961792 secs/batch = 1.2357s, grad.norm=0.27397034\n",
      "  4450: 3 [  440/ 1327], train_loss/perplexity = 6.55127716/700.1378174 secs/batch = 1.2339s, grad.norm=0.40921500\n",
      "  4455: 3 [  445/ 1327], train_loss/perplexity = 6.54547358/696.0862427 secs/batch = 1.2439s, grad.norm=0.37213174\n",
      "  4460: 3 [  450/ 1327], train_loss/perplexity = 6.54543829/696.0617065 secs/batch = 1.2256s, grad.norm=0.22059776\n",
      "  4465: 3 [  455/ 1327], train_loss/perplexity = 6.33343840/563.0894165 secs/batch = 1.2313s, grad.norm=0.24464785\n",
      "  4470: 3 [  460/ 1327], train_loss/perplexity = 6.58593559/724.8288574 secs/batch = 1.2419s, grad.norm=0.24108052\n",
      "  4475: 3 [  465/ 1327], train_loss/perplexity = 6.52371740/681.1056519 secs/batch = 1.2316s, grad.norm=0.25628635\n",
      "  4480: 3 [  470/ 1327], train_loss/perplexity = 6.68206072/797.9617920 secs/batch = 1.2404s, grad.norm=0.25454021\n",
      "  4485: 3 [  475/ 1327], train_loss/perplexity = 6.69608545/809.2318115 secs/batch = 1.2398s, grad.norm=0.21893360\n",
      "  4490: 3 [  480/ 1327], train_loss/perplexity = 6.56031132/706.4915771 secs/batch = 1.2622s, grad.norm=0.21758896\n",
      "  4495: 3 [  485/ 1327], train_loss/perplexity = 6.57152414/714.4579468 secs/batch = 1.2532s, grad.norm=0.20832194\n",
      "  4500: 3 [  490/ 1327], train_loss/perplexity = 6.55621529/703.6036987 secs/batch = 1.2903s, grad.norm=0.29143047\n",
      "  4505: 3 [  495/ 1327], train_loss/perplexity = 6.31651735/553.6414795 secs/batch = 1.2577s, grad.norm=0.41676152\n",
      "  4510: 3 [  500/ 1327], train_loss/perplexity = 6.64618111/769.8387451 secs/batch = 1.2788s, grad.norm=0.22872546\n",
      "  4515: 3 [  505/ 1327], train_loss/perplexity = 6.48888588/657.7901001 secs/batch = 1.2992s, grad.norm=0.27267161\n",
      "  4520: 3 [  510/ 1327], train_loss/perplexity = 6.61430311/745.6848755 secs/batch = 1.2348s, grad.norm=0.22601385\n",
      "  4525: 3 [  515/ 1327], train_loss/perplexity = 6.47493362/648.6761475 secs/batch = 1.2329s, grad.norm=0.24374460\n",
      "  4530: 3 [  520/ 1327], train_loss/perplexity = 6.63857222/764.0033569 secs/batch = 1.2450s, grad.norm=0.27897462\n",
      "  4535: 3 [  525/ 1327], train_loss/perplexity = 6.51018572/671.9511719 secs/batch = 1.4402s, grad.norm=0.24269708\n",
      "  4540: 3 [  530/ 1327], train_loss/perplexity = 6.53442669/688.4389648 secs/batch = 1.2769s, grad.norm=0.29128167\n",
      "  4545: 3 [  535/ 1327], train_loss/perplexity = 6.63148069/758.6046143 secs/batch = 1.5090s, grad.norm=0.22908469\n",
      "  4550: 3 [  540/ 1327], train_loss/perplexity = 6.65334845/775.3762817 secs/batch = 1.3017s, grad.norm=0.20774651\n",
      "  4555: 3 [  545/ 1327], train_loss/perplexity = 6.66290236/782.8196411 secs/batch = 1.3348s, grad.norm=0.22119932\n",
      "  4560: 3 [  550/ 1327], train_loss/perplexity = 6.64883661/771.8858032 secs/batch = 1.3335s, grad.norm=0.23866864\n",
      "  4565: 3 [  555/ 1327], train_loss/perplexity = 6.55418110/702.1738892 secs/batch = 1.2454s, grad.norm=0.26760542\n",
      "  4570: 3 [  560/ 1327], train_loss/perplexity = 6.67810678/794.8129272 secs/batch = 1.3550s, grad.norm=0.24705920\n",
      "  4575: 3 [  565/ 1327], train_loss/perplexity = 6.61342621/745.0313110 secs/batch = 1.2648s, grad.norm=0.32542500\n",
      "  4580: 3 [  570/ 1327], train_loss/perplexity = 6.50894737/671.1196289 secs/batch = 1.3368s, grad.norm=0.27049339\n",
      "  4585: 3 [  575/ 1327], train_loss/perplexity = 6.53774118/690.7246094 secs/batch = 1.3368s, grad.norm=0.25428569\n",
      "  4590: 3 [  580/ 1327], train_loss/perplexity = 6.58187914/721.8945923 secs/batch = 1.3238s, grad.norm=0.27072951\n",
      "  4595: 3 [  585/ 1327], train_loss/perplexity = 6.49989653/665.0728149 secs/batch = 1.3390s, grad.norm=0.25240684\n",
      "  4600: 3 [  590/ 1327], train_loss/perplexity = 6.64971590/772.5648193 secs/batch = 1.3303s, grad.norm=0.22615384\n",
      "  4605: 3 [  595/ 1327], train_loss/perplexity = 6.60808516/741.0626221 secs/batch = 1.2494s, grad.norm=0.25786850\n",
      "  4610: 3 [  600/ 1327], train_loss/perplexity = 6.68897200/803.4958496 secs/batch = 1.3680s, grad.norm=0.24054296\n",
      "  4615: 3 [  605/ 1327], train_loss/perplexity = 6.62212563/751.5408936 secs/batch = 1.2995s, grad.norm=0.29546580\n",
      "  4620: 3 [  610/ 1327], train_loss/perplexity = 6.71769953/826.9130249 secs/batch = 1.2645s, grad.norm=0.30737427\n",
      "  4625: 3 [  615/ 1327], train_loss/perplexity = 6.30396461/546.7352295 secs/batch = 1.2354s, grad.norm=0.25304091\n",
      "  4630: 3 [  620/ 1327], train_loss/perplexity = 6.53536224/689.0833740 secs/batch = 1.2438s, grad.norm=0.28729525\n",
      "  4635: 3 [  625/ 1327], train_loss/perplexity = 6.66412878/783.7803345 secs/batch = 1.2496s, grad.norm=0.22122526\n",
      "  4640: 3 [  630/ 1327], train_loss/perplexity = 6.62536192/753.9770508 secs/batch = 1.2782s, grad.norm=0.22885139\n",
      "  4645: 3 [  635/ 1327], train_loss/perplexity = 6.57203960/714.8262939 secs/batch = 1.2744s, grad.norm=0.32466355\n",
      "  4650: 3 [  640/ 1327], train_loss/perplexity = 6.46868706/644.6367798 secs/batch = 1.2437s, grad.norm=0.25746498\n",
      "  4655: 3 [  645/ 1327], train_loss/perplexity = 6.61914825/749.3065796 secs/batch = 1.3010s, grad.norm=0.26429424\n",
      "  4660: 3 [  650/ 1327], train_loss/perplexity = 6.42139769/614.8618774 secs/batch = 1.2982s, grad.norm=0.31322473\n",
      "  4665: 3 [  655/ 1327], train_loss/perplexity = 6.47080135/646.0012207 secs/batch = 1.2423s, grad.norm=0.24655756\n",
      "  4670: 3 [  660/ 1327], train_loss/perplexity = 6.51797628/677.2065430 secs/batch = 1.2434s, grad.norm=0.22229153\n",
      "  4675: 3 [  665/ 1327], train_loss/perplexity = 6.61796236/748.4185181 secs/batch = 1.2534s, grad.norm=0.20404443\n",
      "  4680: 3 [  670/ 1327], train_loss/perplexity = 6.56795740/711.9141846 secs/batch = 1.3035s, grad.norm=0.23651725\n",
      "  4685: 3 [  675/ 1327], train_loss/perplexity = 6.40941143/607.5360107 secs/batch = 1.2790s, grad.norm=0.26707545\n",
      "  4690: 3 [  680/ 1327], train_loss/perplexity = 6.65203190/774.3561401 secs/batch = 1.2455s, grad.norm=0.28551921\n",
      "  4695: 3 [  685/ 1327], train_loss/perplexity = 6.68529034/800.5430908 secs/batch = 1.2613s, grad.norm=0.27811947\n",
      "  4700: 3 [  690/ 1327], train_loss/perplexity = 6.59011030/727.8611450 secs/batch = 1.2784s, grad.norm=0.26864621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4705: 3 [  695/ 1327], train_loss/perplexity = 6.54666805/696.9182129 secs/batch = 1.2357s, grad.norm=0.26752213\n",
      "  4710: 3 [  700/ 1327], train_loss/perplexity = 6.60264921/737.0451660 secs/batch = 1.2531s, grad.norm=0.22076491\n",
      "  4715: 3 [  705/ 1327], train_loss/perplexity = 6.42459822/616.8329468 secs/batch = 1.2463s, grad.norm=0.27706805\n",
      "  4720: 3 [  710/ 1327], train_loss/perplexity = 6.55278254/701.1925659 secs/batch = 1.2586s, grad.norm=0.21886456\n",
      "  4725: 3 [  715/ 1327], train_loss/perplexity = 6.56244898/708.0034790 secs/batch = 1.2790s, grad.norm=0.23184837\n",
      "  4730: 3 [  720/ 1327], train_loss/perplexity = 6.58110762/721.3378296 secs/batch = 1.2403s, grad.norm=0.26381317\n",
      "  4735: 3 [  725/ 1327], train_loss/perplexity = 6.38118649/590.6280518 secs/batch = 1.2476s, grad.norm=0.32590616\n",
      "  4740: 3 [  730/ 1327], train_loss/perplexity = 6.40412664/604.3337402 secs/batch = 1.2312s, grad.norm=0.25269684\n",
      "  4745: 3 [  735/ 1327], train_loss/perplexity = 6.57075977/713.9120483 secs/batch = 1.2664s, grad.norm=0.23046985\n",
      "  4750: 3 [  740/ 1327], train_loss/perplexity = 6.37690830/588.1066284 secs/batch = 1.2430s, grad.norm=0.25022995\n",
      "  4755: 3 [  745/ 1327], train_loss/perplexity = 6.55137396/700.2055664 secs/batch = 1.2499s, grad.norm=0.23159139\n",
      "  4760: 3 [  750/ 1327], train_loss/perplexity = 6.40790033/606.6186523 secs/batch = 1.2555s, grad.norm=0.25362173\n",
      "  4765: 3 [  755/ 1327], train_loss/perplexity = 6.47314024/647.5139160 secs/batch = 1.2429s, grad.norm=0.23165828\n",
      "  4770: 3 [  760/ 1327], train_loss/perplexity = 6.39864206/601.0283203 secs/batch = 1.2407s, grad.norm=0.30356595\n",
      "  4775: 3 [  765/ 1327], train_loss/perplexity = 6.41281271/609.6058960 secs/batch = 1.2454s, grad.norm=0.26952708\n",
      "  4780: 3 [  770/ 1327], train_loss/perplexity = 6.44881630/631.9537964 secs/batch = 1.2480s, grad.norm=0.27725974\n",
      "  4785: 3 [  775/ 1327], train_loss/perplexity = 6.49908209/664.5313721 secs/batch = 1.3718s, grad.norm=0.24417827\n",
      "  4790: 3 [  780/ 1327], train_loss/perplexity = 6.61683464/747.5750122 secs/batch = 1.4142s, grad.norm=0.23792763\n",
      "  4795: 3 [  785/ 1327], train_loss/perplexity = 6.49826193/663.9865723 secs/batch = 1.2731s, grad.norm=0.24384959\n",
      "  4800: 3 [  790/ 1327], train_loss/perplexity = 6.32644129/559.1631470 secs/batch = 1.2462s, grad.norm=0.22370860\n",
      "  4805: 3 [  795/ 1327], train_loss/perplexity = 6.60091877/735.7708740 secs/batch = 1.2392s, grad.norm=0.25400150\n",
      "  4810: 3 [  800/ 1327], train_loss/perplexity = 6.55051136/699.6018066 secs/batch = 1.2473s, grad.norm=0.23306952\n",
      "  4815: 3 [  805/ 1327], train_loss/perplexity = 6.67255926/790.4158936 secs/batch = 1.2556s, grad.norm=0.27653316\n",
      "  4820: 3 [  810/ 1327], train_loss/perplexity = 6.60783482/740.8771362 secs/batch = 1.2397s, grad.norm=0.30640048\n",
      "  4825: 3 [  815/ 1327], train_loss/perplexity = 6.40596533/605.4459839 secs/batch = 1.2412s, grad.norm=0.26551506\n",
      "  4830: 3 [  820/ 1327], train_loss/perplexity = 6.28952265/538.8959961 secs/batch = 1.2957s, grad.norm=0.25705442\n",
      "  4835: 3 [  825/ 1327], train_loss/perplexity = 6.43542814/623.5494995 secs/batch = 1.2678s, grad.norm=0.25143531\n",
      "  4840: 3 [  830/ 1327], train_loss/perplexity = 6.30540466/547.5231323 secs/batch = 1.2694s, grad.norm=0.27248189\n",
      "  4845: 3 [  835/ 1327], train_loss/perplexity = 6.53155613/686.4656372 secs/batch = 1.4204s, grad.norm=0.22422235\n",
      "  4850: 3 [  840/ 1327], train_loss/perplexity = 6.63052940/757.8833008 secs/batch = 1.3119s, grad.norm=0.22072034\n",
      "  4855: 3 [  845/ 1327], train_loss/perplexity = 6.53518534/688.9614868 secs/batch = 1.4091s, grad.norm=0.22751398\n",
      "  4860: 3 [  850/ 1327], train_loss/perplexity = 6.47970343/651.7775879 secs/batch = 1.2801s, grad.norm=0.26240835\n",
      "  4865: 3 [  855/ 1327], train_loss/perplexity = 6.51753902/676.9104614 secs/batch = 1.5499s, grad.norm=0.23653142\n",
      "  4870: 3 [  860/ 1327], train_loss/perplexity = 6.33617544/564.6326904 secs/batch = 1.3404s, grad.norm=0.24094135\n",
      "  4875: 3 [  865/ 1327], train_loss/perplexity = 6.63401699/760.5310669 secs/batch = 1.3104s, grad.norm=0.22149439\n",
      "  4880: 3 [  870/ 1327], train_loss/perplexity = 6.68417263/799.6488037 secs/batch = 1.2356s, grad.norm=0.27189761\n",
      "  4885: 3 [  875/ 1327], train_loss/perplexity = 6.37941694/589.5838623 secs/batch = 1.3024s, grad.norm=0.24187024\n",
      "  4890: 3 [  880/ 1327], train_loss/perplexity = 6.57005882/713.4118042 secs/batch = 1.3470s, grad.norm=0.24298207\n",
      "  4895: 3 [  885/ 1327], train_loss/perplexity = 6.42093468/614.5772705 secs/batch = 1.3041s, grad.norm=0.28788596\n",
      "  4900: 3 [  890/ 1327], train_loss/perplexity = 6.48615170/655.9940186 secs/batch = 1.2407s, grad.norm=0.27045935\n",
      "  4905: 3 [  895/ 1327], train_loss/perplexity = 6.57587147/717.5706787 secs/batch = 1.2482s, grad.norm=0.35814744\n",
      "  4910: 3 [  900/ 1327], train_loss/perplexity = 6.53523779/688.9976196 secs/batch = 1.2439s, grad.norm=0.26112813\n",
      "  4915: 3 [  905/ 1327], train_loss/perplexity = 6.45450878/635.5614624 secs/batch = 1.2763s, grad.norm=0.24898973\n",
      "  4920: 3 [  910/ 1327], train_loss/perplexity = 6.43852329/625.4824829 secs/batch = 1.2378s, grad.norm=0.29295200\n",
      "  4925: 3 [  915/ 1327], train_loss/perplexity = 6.66766930/786.5602417 secs/batch = 1.2491s, grad.norm=0.22922476\n",
      "  4930: 3 [  920/ 1327], train_loss/perplexity = 6.66008997/780.6211548 secs/batch = 1.3786s, grad.norm=0.25493485\n",
      "  4935: 3 [  925/ 1327], train_loss/perplexity = 6.50769043/670.2765503 secs/batch = 1.3343s, grad.norm=0.25843716\n",
      "  4940: 3 [  930/ 1327], train_loss/perplexity = 6.47735023/650.2456665 secs/batch = 1.4514s, grad.norm=0.37619239\n",
      "  4945: 3 [  935/ 1327], train_loss/perplexity = 6.55686092/704.0581055 secs/batch = 1.3088s, grad.norm=0.21495403\n",
      "  4950: 3 [  940/ 1327], train_loss/perplexity = 6.48317719/654.0456543 secs/batch = 1.2704s, grad.norm=0.23411879\n",
      "  4955: 3 [  945/ 1327], train_loss/perplexity = 6.60749912/740.6284790 secs/batch = 1.2420s, grad.norm=0.21358459\n",
      "  4960: 3 [  950/ 1327], train_loss/perplexity = 6.47554827/649.0750122 secs/batch = 1.2450s, grad.norm=0.23294748\n",
      "  4965: 3 [  955/ 1327], train_loss/perplexity = 6.60928440/741.9519043 secs/batch = 1.2547s, grad.norm=0.23224047\n",
      "  4970: 3 [  960/ 1327], train_loss/perplexity = 6.65374184/775.6813965 secs/batch = 1.2405s, grad.norm=0.23259571\n",
      "  4975: 3 [  965/ 1327], train_loss/perplexity = 6.54620409/696.5949097 secs/batch = 1.2579s, grad.norm=0.23561150\n",
      "  4980: 3 [  970/ 1327], train_loss/perplexity = 6.58083916/721.1442261 secs/batch = 1.3188s, grad.norm=0.21921203\n",
      "  4985: 3 [  975/ 1327], train_loss/perplexity = 6.54639578/696.7284546 secs/batch = 1.2691s, grad.norm=0.26535389\n",
      "  4990: 3 [  980/ 1327], train_loss/perplexity = 6.44509697/629.6077271 secs/batch = 1.2801s, grad.norm=0.22512059\n",
      "  4995: 3 [  985/ 1327], train_loss/perplexity = 6.60764647/740.7376099 secs/batch = 1.3084s, grad.norm=0.24981532\n",
      "  5000: 3 [  990/ 1327], train_loss/perplexity = 6.66920137/787.7662354 secs/batch = 1.2698s, grad.norm=0.27802134\n",
      "  5005: 3 [  995/ 1327], train_loss/perplexity = 6.64585114/769.5847778 secs/batch = 1.2324s, grad.norm=0.23968707\n",
      "  5010: 3 [ 1000/ 1327], train_loss/perplexity = 6.37806082/588.7848511 secs/batch = 1.2470s, grad.norm=0.26085350\n",
      "  5015: 3 [ 1005/ 1327], train_loss/perplexity = 6.62192965/751.3936157 secs/batch = 1.2538s, grad.norm=0.26147932\n",
      "  5020: 3 [ 1010/ 1327], train_loss/perplexity = 6.36328077/580.1465454 secs/batch = 1.2476s, grad.norm=0.23374079\n",
      "  5025: 3 [ 1015/ 1327], train_loss/perplexity = 6.56910133/712.7290649 secs/batch = 1.2560s, grad.norm=0.26830322\n",
      "  5030: 3 [ 1020/ 1327], train_loss/perplexity = 6.66794872/786.7800293 secs/batch = 1.2398s, grad.norm=0.25427780\n",
      "  5035: 3 [ 1025/ 1327], train_loss/perplexity = 6.54912186/698.6304321 secs/batch = 1.2604s, grad.norm=0.20959193\n",
      "  5040: 3 [ 1030/ 1327], train_loss/perplexity = 6.52678013/683.1948853 secs/batch = 1.2518s, grad.norm=0.20447594\n",
      "  5045: 3 [ 1035/ 1327], train_loss/perplexity = 6.42402077/616.4768677 secs/batch = 1.2415s, grad.norm=0.26809582\n",
      "  5050: 3 [ 1040/ 1327], train_loss/perplexity = 6.48420000/654.7149658 secs/batch = 1.3442s, grad.norm=0.21999885\n",
      "  5055: 3 [ 1045/ 1327], train_loss/perplexity = 6.31163788/550.9465942 secs/batch = 1.2395s, grad.norm=0.25043243\n",
      "  5060: 3 [ 1050/ 1327], train_loss/perplexity = 6.54105902/693.0200806 secs/batch = 1.2430s, grad.norm=0.25755844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5065: 3 [ 1055/ 1327], train_loss/perplexity = 6.69435358/807.8315430 secs/batch = 1.2451s, grad.norm=0.27294999\n",
      "  5070: 3 [ 1060/ 1327], train_loss/perplexity = 6.42370605/616.2828369 secs/batch = 1.2550s, grad.norm=0.23974048\n"
     ]
    }
   ],
   "source": [
    "lstm_char_cnn.Train_Char_Model(sess, char_train_graph, train_reader, saver, summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "data_X shape: (20, 31, 21)\n",
      "data_Y shape: (20, 3)\n",
      "sentX shape: Tensor(\"Placeholder_1:0\", shape=(?, 31, 21), dtype=int32)\n",
      "sent_y, shape: Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "2019-08-27 14:24:43 Step: 10 Training loss: 0.09034851486794651 accuracy: 1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6da89ead7dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainSentiModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msenti_train_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ERD/model.py\u001b[0m in \u001b[0;36mTrainSentiModel\u001b[0;34m(sess, saver, train_model, senti_reader, train_batch, test_batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mret_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_curtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Step: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Training loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_curtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Step: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Training loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m                 \u001b[0msum_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(model)\n",
    "model.TrainSentiModel(sess, saver, senti_train_graph, sentiReader, FLAGS.batch_size, FLAGS.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: said..hes\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \"\n",
      "Word: a\"cleric\n",
      "Unknown char: \n",
      "Word: ministre\n",
      "Unknown char: \n",
      "Word: lintrieur\n",
      "Unknown char: \n",
      "Word: lintrieur\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: wouldnt\n",
      "Unknown char: \"\n",
      "Word: been\"justifying\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: okevery\n",
      "Unknown char: \n",
      "Word: jewsnow\n",
      "Unknown char: \n",
      "Word: jewsnow\n",
      "Unknown char: \n",
      "Word: therefoolish\n",
      "Unknown char: \n",
      "Word: wellposted\n",
      "Unknown char: \n",
      "Word: notethen\n",
      "Unknown char: \n",
      "Word: notethen\n",
      "Unknown char: \n",
      "Word: jewssoi\n",
      "Unknown char: \n",
      "Word: jewssoi\n",
      "Unknown char: \n",
      "Word: jewssoi\n",
      "Unknown char: \n",
      "Word: deplorableright\n",
      "Unknown char: \n",
      "Word: nownow\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: apologizefor\n",
      "Unknown char: \"\n",
      "Word: t\"...back\n",
      "Unknown char: \n",
      "Word: dernires\n",
      "Unknown char: \n",
      "Word: annes\n",
      "Unknown char: \n",
      "Word: dfendaient\n",
      "Unknown char: \n",
      "Word: if\n",
      "Unknown char: \n",
      "Word: zufllig\n",
      "Unknown char: \n",
      "Word: przyszo\n",
      "Unknown char: \"\n",
      "Word: god\"...if\n",
      "Unknown char: \"\n",
      "Word: shameful\"for\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: =\n",
      "Word: that=point\n",
      "Unknown char: \n",
      "Word: artw\n",
      "Unknown char: \n",
      "Word: vlgame\n",
      "Unknown char: \n",
      "Word: uuyor\n",
      "Unknown char: \n",
      "Word: therell\n",
      "Unknown char: \n",
      "Word: therell\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: whoevers\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: pars\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: perdn\n",
      "Unknown char: \n",
      "Word: slo\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: gjr\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: lrt\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: disposicin\n",
      "Unknown char: \n",
      "Word: iu\n",
      "Unknown char: \n",
      "Word: ha\n",
      "Unknown char: \n",
      "Word: trn\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: claim-theyre-super-rich-because-theyre-a-brand\n",
      "Unknown char: \n",
      "Word: claim-theyre-super-rich-because-theyre-a-brand\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \"\n",
      "Word: free\"-nsw\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \n",
      "Word: thats\n",
      "2019-08-27 12:25:59 Step: 10 Training loss: 32.675646018981936 accuracy: 1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2499f5393235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainRDMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdm_train_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ERD/model.py\u001b[0m in \u001b[0;36mTrainRDMModel\u001b[0;34m(sess, mm, t_acc, t_steps, new_data_len)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mret_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_curtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Step: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Training loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_curtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Step: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Training loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msum_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mt_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(model)\n",
    "model.TrainRDMModel(sess, rdm_train_graph, 0.7, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in RL the begining\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: said..hes\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \"\n",
      "Word: a\"cleric\n",
      "Unknown char: \n",
      "Word: ministre\n",
      "Unknown char: \n",
      "Word: lintrieur\n",
      "Unknown char: \n",
      "Word: lintrieur\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: wouldnt\n",
      "Unknown char: \"\n",
      "Word: been\"justifying\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: happy\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: week\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: end\n",
      "Unknown char: \n",
      "Word: okevery\n",
      "Unknown char: \n",
      "Word: jewsnow\n",
      "Unknown char: \n",
      "Word: jewsnow\n",
      "Unknown char: \n",
      "Word: therefoolish\n",
      "Unknown char: \n",
      "Word: wellposted\n",
      "Unknown char: \n",
      "Word: notethen\n",
      "Unknown char: \n",
      "Word: notethen\n",
      "Unknown char: \n",
      "Word: jewssoi\n",
      "Unknown char: \n",
      "Word: jewssoi\n",
      "Unknown char: \n",
      "Word: jewssoi\n",
      "Unknown char: \n",
      "Word: deplorableright\n",
      "Unknown char: \n",
      "Word: nownow\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: apologizefor\n",
      "Unknown char: \"\n",
      "Word: t\"...back\n",
      "Unknown char: \n",
      "Word: dernires\n",
      "Unknown char: \n",
      "Word: annes\n",
      "Unknown char: \n",
      "Word: dfendaient\n",
      "Unknown char: \n",
      "Word: if\n",
      "Unknown char: \n",
      "Word: zufllig\n",
      "Unknown char: \n",
      "Word: przyszo\n",
      "Unknown char: \"\n",
      "Word: god\"...if\n",
      "Unknown char: \"\n",
      "Word: shameful\"for\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: =\n",
      "Word: that=point\n",
      "Unknown char: \n",
      "Word: artw\n",
      "Unknown char: \n",
      "Word: vlgame\n",
      "Unknown char: \n",
      "Word: uuyor\n",
      "Unknown char: \n",
      "Word: therell\n",
      "Unknown char: \n",
      "Word: therell\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: whoevers\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: pars\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: perdn\n",
      "Unknown char: \n",
      "Word: slo\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: gjr\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: lrt\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: disposicin\n",
      "Unknown char: \n",
      "Word: iu\n",
      "Unknown char: \n",
      "Word: ha\n",
      "Unknown char: \n",
      "Word: trn\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: claim-theyre-super-rich-because-theyre-a-brand\n",
      "Unknown char: \n",
      "Word: claim-theyre-super-rich-because-theyre-a-brand\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \"\n",
      "Word: free\"-nsw\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \"\n",
      "Word: that\"s\n",
      "Unknown char: \n",
      "Word: rpublique\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: verstndnis\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \"\n",
      "Word: congressmen:\"i\n",
      "Unknown char: \n",
      "Word: dantay\n",
      "Unknown char: \n",
      "Word: dantay\n",
      "Unknown char: \"\n",
      "guess again\"...\n",
      "Unknown char: \n",
      "guess again\"...\n",
      "Unknown char: \n",
      "guess again\"...\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \"\n",
      "Word: trust\"ourselves\n",
      "Unknown char: \n",
      "Word: familire\n",
      "Unknown char: \n",
      "Word: vre\n",
      "Unknown char: \n",
      "Word: paranod\n",
      "Unknown char: =\n",
      "Word: black=sunni\n",
      "Unknown char: =\n",
      "Word: green=shia\n",
      "Unknown char: \"\n",
      "Word: just\"sick\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: samobjcy\n",
      "Unknown char: \n",
      "Word: jzykach\n",
      "Unknown char: \n",
      "Word: skadasz\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: erdoan\n",
      "Unknown char: \n",
      "Word: biiler\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: thisit's\n",
      "Unknown char: \n",
      "Word: tasteless/vulgar/pettyinhuman\n",
      "Unknown char: \n",
      "Word: evchs\n",
      "Unknown char: \n",
      "Word: evchs\n",
      "Unknown char: \n",
      "Word: ministers\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: peoples\n",
      "Unknown char: \n",
      "Word: lger\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \"\n",
      "Word: a\"riot\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: attaqus\n",
      "Unknown char: \n",
      "Word: ncessaire\n",
      "Unknown char: \n",
      "Word: polica\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: lches\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: autorits\n",
      "Unknown char: \n",
      "Word: d'enqute\n",
      "Unknown char: \n",
      "Word: fminin\n",
      "Unknown char: \n",
      "Word: rsistance\n",
      "Unknown char: \n",
      "Word: gnrale\n",
      "Unknown char: \n",
      "Word: gnrale\n",
      "Unknown char: \n",
      "Word: aperue\n",
      "Unknown char: \n",
      "Word: librt\n",
      "Unknown char: \n",
      "Word: prfre\n",
      "Unknown char: \n",
      "Word: prfre\n",
      "Unknown char: \n",
      "Word: franois\n",
      "Unknown char: \n",
      "Word: renvoye\n",
      "Unknown char: \n",
      "Word: zgnz\n",
      "Unknown char: \n",
      "Word: zgnz\n",
      "Unknown char: \n",
      "Word: belive\n",
      "Unknown char: \n",
      "Word: service\n",
      "Unknown char: \n",
      "Word: this\n",
      "Unknown char: \n",
      "Word: think\n",
      "Unknown char: \n",
      "Word: choque\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: protgs\n",
      "Unknown char: \n",
      "Word: protgs\n",
      "Unknown char: \"\n",
      "Word: hate\"defending\n",
      "Unknown char: \n",
      "Word: deberan\n",
      "Unknown char: \n",
      "Word: rservs\n",
      "Unknown char: \n",
      "Word: rservs\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: couldnt\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \"\n",
      "Word: guest:\"all\n",
      "Unknown char: \"\n",
      "Word: host:\"great\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \"\n",
      "Word: terror..\"glorious\"past\n",
      "Unknown char: \"\n",
      "Word: terror..\"glorious\"past\n",
      "Unknown char: \n",
      "Word: peut-tre\n",
      "Unknown char: \n",
      "Word: dj\n",
      "Unknown char: \n",
      "Word: cdric\n",
      "Unknown char: \n",
      "Word: erwhnt\n",
      "Unknown char: \n",
      "Word: hpital\n",
      "Unknown char: \n",
      "Word: c'tait\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: themirror.amen\n",
      "Unknown char: \n",
      "Word: castros\n",
      "Unknown char: \n",
      "Word: cubas\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: \n",
      "Word: omalley\n",
      "Unknown char: \n",
      "Word: carrment\n",
      "Unknown char: \n",
      "Word: dmesur\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \n",
      "Word: dbloquer\n",
      "Unknown char: \n",
      "Word: prsence\n",
      "Unknown char: \n",
      "Word: d'opration\n",
      "Unknown char: \n",
      "Word: armes\n",
      "Unknown char: \n",
      "Word: l'intrt\n",
      "Unknown char: \n",
      "Word: l'intrt\n",
      "Unknown char: \n",
      "Word: opration\n",
      "Unknown char: \n",
      "Word: l'tat\n",
      "Unknown char: \n",
      "Word: trs\n",
      "Unknown char: \n",
      "Word: intressante\n",
      "Unknown char: \n",
      "Word: prs\n",
      "Unknown char: \n",
      "Word: sret\n",
      "Unknown char: \n",
      "Word: ondaann\n",
      "Unknown char: \n",
      "Word: ondaann\n",
      "Unknown char: \n",
      "Word: ondaann\n",
      "Unknown char: \"\n",
      "Word: care.\"this\n",
      "Unknown char: \n",
      "Word: aplicacin\n",
      "Unknown char: \n",
      "Word: shara\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: theyd\n",
      "Unknown char: \n",
      "Word: da\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: tho.but\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: tambm\n",
      "Unknown char: \n",
      "Word: bsta\n",
      "Unknown char: \n",
      "Word: tnker\n",
      "Unknown char: \n",
      "Word: ngonsin\n",
      "Unknown char: \n",
      "Word: lser\n",
      "Unknown char: \n",
      "Word: ngon\n",
      "Unknown char: \n",
      "Word: bda\n",
      "Unknown char: \n",
      "Word: bda\n",
      "Unknown char: \n",
      "Word: ltsaskompis\n",
      "Unknown char: \n",
      "Word: hger\n",
      "Unknown char: \n",
      "Word: bekrftar\n",
      "Unknown char: \n",
      "Word: vnsters\n",
      "Unknown char: \n",
      "Word: vrldbild\n",
      "Unknown char: \n",
      "Word: nstan\n",
      "Unknown char: \n",
      "Word: sgas\n",
      "Unknown char: \n",
      "Word: gra\n",
      "Unknown char: \n",
      "Word: ppekar\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: jsses\n",
      "Unknown char: \n",
      "Word: ngon\n",
      "Unknown char: \n",
      "Word: hromdagen\n",
      "Unknown char: \n",
      "Word: vl\n",
      "Unknown char: \n",
      "Word: mrdaren\n",
      "Unknown char: \n",
      "Word: hmnas\n",
      "Unknown char: \n",
      "Word: gr\n",
      "Unknown char: \n",
      "Word: terrordden\n",
      "Unknown char: \n",
      "Word: utfrs\n",
      "Unknown char: \n",
      "Word: vnta\n",
      "Unknown char: \n",
      "Word: bestmmer\n",
      "Unknown char: \n",
      "Word: hller\n",
      "Unknown char: \n",
      "Word: str\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: bsta\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: hller\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: mnskliga\n",
      "Unknown char: \n",
      "Word: bda\n",
      "Unknown char: \n",
      "Word: lser\n",
      "Unknown char: \n",
      "Word: lsa\n",
      "Unknown char: \n",
      "Word: istllet\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: hrt\n",
      "Unknown char: \n",
      "Word: sjlvmordsbombare\n",
      "Unknown char: \n",
      "Word: mellanstern\n",
      "Unknown char: \n",
      "Word: religs\n",
      "Unknown char: \n",
      "Word: str\n",
      "Unknown char: \n",
      "Word: religs\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: ls\n",
      "Unknown char: \n",
      "Word: sga\n",
      "Unknown char: \n",
      "Word: frolmpning\n",
      "Unknown char: \n",
      "Word: frolmpning\n",
      "Unknown char: \n",
      "Word: dr\n",
      "Unknown char: \n",
      "Word: nr\n",
      "Unknown char: \n",
      "Word: avrttar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown char: \n",
      "Word: iu\n",
      "Unknown char: \n",
      "Word: ha\n",
      "Unknown char: \n",
      "Word: trn\n",
      "Unknown char: =\n",
      "Word: massmedia=junkfood\n",
      "Unknown char: \n",
      "Word: grard\n",
      "Unknown char: \n",
      "Word: frenchfrog\n",
      "Unknown char: \n",
      "Word: dfendre\n",
      "Unknown char: \n",
      "Word: dmocratie\n",
      "Unknown char: \n",
      "Word: gefhrlich\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: clbrits\n",
      "Unknown char: \n",
      "Word: clbrits\n",
      "Unknown char: \n",
      "Word: clbrits\n",
      "Unknown char: \n",
      "Word: ramnent\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \"\n",
      "Word: issues.\"i\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \"\n",
      "Word: unemplymt.\"they\"deserve\n",
      "Unknown char: \"\n",
      "Word: unemplymt.\"they\"deserve\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \"\n",
      "Word: i\"m\n",
      "Unknown char: \n",
      "Word: protgs\n",
      "Unknown char: \n",
      "Word: protgs\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \n",
      "Word: displayas\n",
      "Unknown char: \n",
      "Word: staffpublish\n",
      "Unknown char: \n",
      "Word: week1m\n",
      "Unknown char: \"\n",
      "Word: important\"...more\n",
      "Unknown char: \"\n",
      "Word: the\"religion\n",
      "Unknown char: \n",
      "Word: manqus\n",
      "Unknown char: \n",
      "Word: franais\n",
      "Unknown char: \n",
      "Word: pnico\n",
      "Unknown char: \n",
      "Word: estn\n",
      "Unknown char: \n",
      "Word: vergenza\n",
      "Unknown char: \n",
      "Word: debera\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: mdchen\n",
      "Unknown char: =\n",
      "Word: paris=israeli\n",
      "Unknown char: \n",
      "Word: iin\n",
      "Unknown char: \n",
      "Word: baskn\n",
      "Unknown char: \n",
      "Word: yapyor\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: mornings\n",
      "Unknown char: \n",
      "Word: mornings\n",
      "Unknown char: \n",
      "Word: mornings\n",
      "Unknown char: \n",
      "Word: commmoratif\n",
      "Unknown char: \n",
      "Word: bahrains\n",
      "Unknown char: \n",
      "Word: wont\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: \\\n",
      "Word: little\\no\n",
      "Unknown char: \n",
      "Word: pministerin\n",
      "Unknown char: \n",
      "Word: pministerin\n",
      "Unknown char: \n",
      "Word: pministeri\n",
      "Unknown char: \n",
      "Word: pministeri\n",
      "Unknown char: \n",
      "Word: sentn\n",
      "Unknown char: \n",
      "Word: sentn\n",
      "Unknown char: \n",
      "Word: tst\n",
      "Unknown char: \n",
      "Word: hpsis\n",
      "Unknown char: \"\n",
      "Word: and.get.a.job\"ignorance/complacency\n",
      "Unknown char: \n",
      "Word: worlds\n",
      "Unknown char: \n",
      "Word: worlds\n",
      "Unknown char: \n",
      "Word: worlds\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: heres\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: heres\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: heres\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: pilots\n",
      "Unknown char: =\n",
      "Word: about=minority\n",
      "Unknown char: =\n",
      "Word: thing=depending\n",
      "Unknown char: \n",
      "Word: tus\n",
      "Unknown char: \n",
      "Word: proccs\n",
      "Unknown char: \"\n",
      "Word: worked.\"multiculturalism\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: arme\n",
      "Unknown char: \n",
      "Word: ame\n",
      "Unknown char: \n",
      "Word: pleased\n",
      "Unknown char: \n",
      "Word: pleased\n",
      "Unknown char: \n",
      "Word: pleased\n",
      "Unknown char: \n",
      "Word: pleasep\n",
      "Unknown char: \n",
      "Word: pleasep\n",
      "Unknown char: \n",
      "Word: pleasep\n",
      "Unknown char: \"\n",
      "Word: translates\"by\n",
      "Unknown char: \n",
      "Word: mrdias\n",
      "Unknown char: \"\n",
      "Word: translates\"by\n",
      "Unknown char: \n",
      "Word: seal\n",
      "Unknown char: \n",
      "Word: poblacin\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \"\n",
      "Word: needy\"...such\n",
      "Unknown char: \n",
      "Word: hros\n",
      "Unknown char: =\n",
      "Word: b===d\n",
      "Unknown char: =\n",
      "Word: b===d\n",
      "Unknown char: =\n",
      "Word: b===d\n",
      "Unknown char: \n",
      "Word: esprons\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: extrmistes\n",
      "Unknown char: \n",
      "Word: speechit\n",
      "Unknown char: \n",
      "Word: speechit\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: frances\n",
      "Unknown char: \n",
      "Word: rvulse\n",
      "Unknown char: \n",
      "Word: franaise\n",
      "Unknown char: \n",
      "Word: vnement\n",
      "Unknown char: \n",
      "Word: l-bas\n",
      "Unknown char: \n",
      "Word: pense\n",
      "Unknown char: \n",
      "Word: palhaada\n",
      "Unknown char: \n",
      "Word: choque\n",
      "Unknown char: \n",
      "Word: skl\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: frsvarar\n",
      "Unknown char: \n",
      "Word: tnkte\n",
      "Unknown char: \n",
      "Word: islams\n",
      "Unknown char: \n",
      "Word: zgina\n",
      "Unknown char: \n",
      "Word: zgina\n",
      "Unknown char: \n",
      "Word: dzikuj\n",
      "Unknown char: \n",
      "Word: shouldnt\n",
      "Unknown char: \n",
      "Word: wyprbowanie\n",
      "Unknown char: \n",
      "Word: przyszo\n",
      "Unknown char: \n",
      "Word: myli\n",
      "Unknown char: \n",
      "Word: sowo\n",
      "Unknown char: \n",
      "Word: przyszo\n",
      "Unknown char: \n",
      "Word: stracia\n",
      "Unknown char: \n",
      "Word: przyszo\n",
      "Unknown char: \n",
      "Word: prfre\n",
      "Unknown char: \n",
      "Word: prfre\n",
      "Unknown char: \n",
      "Word: franais\n",
      "Unknown char: \n",
      "Word: franais\n",
      "Unknown char: \n",
      "Word: obamawould\n",
      "Unknown char: \n",
      "Word: grda\n",
      "Unknown char: \n",
      "Word: saighdiir\n",
      "Unknown char: \n",
      "Word: difrocht\n",
      "Unknown char: \n",
      "Word: estn\n",
      "Unknown char: \n",
      "Word: enseando\n",
      "Unknown char: \n",
      "Word: dernire\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: glen\n",
      "Unknown char: \n",
      "Word: balayn\n",
      "Unknown char: \n",
      "Word: balayn\n",
      "Unknown char: \n",
      "Word: grce\n",
      "Unknown char: \n",
      "Word: concrtement\n",
      "Unknown char: \n",
      "Word: ragissons\n",
      "Unknown char: \"\n",
      "Word: a\"dark\n",
      "Unknown char: \n",
      "Word: franais\n",
      "Unknown char: \n",
      "Word: sr\n",
      "Unknown char: \n",
      "Word: shouldnt\n",
      "Unknown char: \n",
      "Word: situao\n",
      "Unknown char: \n",
      "Word: situao\n",
      "Unknown char: \n",
      "Word: reporte\n",
      "Unknown char: \n",
      "Word: trouve\n",
      "Unknown char: \n",
      "Word: j'tais\n",
      "Unknown char: \n",
      "Word: colre\n",
      "Unknown char: \n",
      "Word: c'tait\n",
      "Unknown char: \n",
      "Word: islamici\n",
      "Unknown char: \n",
      "Word: zych\n",
      "Unknown char: \n",
      "Word: zdjcie\n",
      "Unknown char: \n",
      "Word: wiatw\n",
      "Unknown char: \n",
      "Word: pomyslaam\n",
      "Unknown char: \n",
      "Word: d'andras\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: unharmedxo\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: espre\n",
      "Unknown char: \n",
      "Word: tambin\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: thanks\n",
      "Unknown char: \"\n",
      "Word: say\"he\n",
      "Unknown char: \n",
      "Word: arrtes\n",
      "Unknown char: \n",
      "Word: lislam\n",
      "Unknown char: \n",
      "Word: newsmedia\n",
      "Unknown char: \n",
      "Word: sme\n",
      "Unknown char: \n",
      "Word: rcolte\n",
      "Unknown char: \n",
      "Word: tempte\n",
      "Unknown char: \n",
      "Word: trs\n",
      "Unknown char: \n",
      "Word: shithow\n",
      "Unknown char: =\n",
      "Word: brigade=terrorist's\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: sydneys\n",
      "Unknown char: \n",
      "Word: dernire\n",
      "Unknown char: \n",
      "Word: dcroch\n",
      "Unknown char: \n",
      "Word: alterao\n",
      "Unknown char: \n",
      "Word: alterao\n",
      "Unknown char: \n",
      "Word: wont\n",
      "Unknown char: \n",
      "Word: wont\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: magnficas\n",
      "Unknown char: \n",
      "Word: despus\n",
      "Unknown char: \n",
      "Word: atencin\n",
      "Unknown char: \n",
      "Word: despus\n",
      "Unknown char: \n",
      "Word: espaol\n",
      "Unknown char: \n",
      "Word: ingls\n",
      "Unknown char: \n",
      "Word: paradjico\n",
      "Unknown char: \n",
      "Word: tambin\n",
      "Unknown char: \n",
      "Word: rehn\n",
      "Unknown char: \n",
      "Word: polica\n",
      "Unknown char: \n",
      "Word: liberacin\n",
      "Unknown char: \n",
      "Word: rehn\n",
      "Unknown char: \n",
      "Word: fcil\n",
      "Unknown char: \n",
      "prayinginish....\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: itd\n",
      "Unknown char: \n",
      "Word: twtd\n",
      "Unknown char: \n",
      "Word: shouldnt\n",
      "Unknown char: \n",
      "Word: shouldnt\n",
      "Unknown char: \n",
      "Word: shouldnt\n",
      "Unknown char: \n",
      "Word: shouldnt\n",
      "Unknown char: \n",
      "Word: shouldnt\n",
      "Unknown char: \"\n",
      "Word: their\"nations\n",
      "Unknown char: =\n",
      "Word: piece==&gt\n",
      "Unknown char: =\n",
      "Word: piece==&gt\n",
      "Unknown char: \n",
      "Word: tus\n",
      "Unknown char: \n",
      "Word: cur\n",
      "Unknown char: \n",
      "Word: n'taient\n",
      "Unknown char: \n",
      "Word: arms\n",
      "Unknown char: \n",
      "Word: annes\n",
      "Unknown char: \n",
      "Word: peut-tre\n",
      "Unknown char: \n",
      "Word: tambm\n",
      "Unknown char: \n",
      "Word: muulmanos\n",
      "Unknown char: \"\n",
      "Word: martyrs\".i\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: kytt\n",
      "Unknown char: \n",
      "Word: kytt\n",
      "Unknown char: \n",
      "Word: online-kntj\n",
      "Unknown char: \n",
      "Word: online-kntj\n",
      "Unknown char: \n",
      "Word: online-kntj\n",
      "Unknown char: \n",
      "Word: kntmn\n",
      "Unknown char: \n",
      "Word: kntmn\n",
      "Unknown char: \n",
      "Word: kntmn\n",
      "Unknown char: \n",
      "Word: kntmn\n",
      "Unknown char: \n",
      "Word: kntmn\n",
      "Unknown char: \n",
      "Word: lhteest\n",
      "Unknown char: \n",
      "Word: elif\n",
      "Unknown char: \n",
      "Word: ltfen\n",
      "Unknown char: \n",
      "Word: takip\n",
      "Unknown char: \n",
      "Word: misiniz\n",
      "Unknown char: \n",
      "Word: misiniz\n",
      "Unknown char: \n",
      "Word: misiniz\n",
      "Unknown char: \n",
      "Word: whove\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \n",
      "Word: saldrlarnda\n",
      "Unknown char: \n",
      "Word: saldrlarnda\n",
      "Unknown char: \n",
      "Word: saldrlarnda\n",
      "Unknown char: \n",
      "Word: drmt...ayn\n",
      "Unknown char: \n",
      "Word: drmt...ayn\n",
      "Unknown char: \n",
      "Word: drmt...ayn\n",
      "Unknown char: \n",
      "Word: drmt...ayn\n",
      "Unknown char: \n",
      "Word: drmt...ayn\n",
      "Unknown char: \n",
      "Word: drmt...ayn\n",
      "Unknown char: \n",
      "Word: kapya\n",
      "Unknown char: \n",
      "Word: kyor\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: hed\n",
      "Unknown char: \n",
      "Word: wheres\n",
      "Unknown char: \"\n",
      "Word: allah\"to\n",
      "Unknown char: \n",
      "Word: allah\"to\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown char: \n",
      "Word: spisil\n",
      "Unknown char: \n",
      "Word: spisil\n",
      "Unknown char: \n",
      "Word: fill\n",
      "Unknown char: \n",
      "Word: shuomh\n",
      "Unknown char: \n",
      "Word: inscurit\n",
      "Unknown char: \n",
      "Word: mds\n",
      "Unknown char: \n",
      "Word: astrix\n",
      "Unknown char: \n",
      "Word: rsistant\n",
      "Unknown char: \n",
      "Word: trs\n",
      "Unknown char: \n",
      "Word: estn\n",
      "Unknown char: \n",
      "Word: expresin\n",
      "Unknown char: \n",
      "Word: tambin\n",
      "Unknown char: \n",
      "Word: crtica\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \"\n",
      "Word: article\"how\n",
      "Unknown char: =\n",
      "Word: it=a\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \"\n",
      "Word: you're*....\"as\n",
      "Unknown char: \"\n",
      "Word: faith\"when\n",
      "Unknown char: \n",
      "Word: angehrigen\n",
      "Unknown char: \n",
      "Word: mitgefhl\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: areos\n",
      "Unknown char: \n",
      "Word: arent\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: govt\n",
      "Unknown char: \n",
      "Word: norvgien\n",
      "Unknown char: \n",
      "Word: dgouts\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: allans\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: trs\n",
      "Unknown char: \n",
      "Word: frres\n",
      "Unknown char: \n",
      "Word: arrter\n",
      "Unknown char: \n",
      "Word: prfre\n",
      "Unknown char: \n",
      "Word: prfre\n",
      "Unknown char: \n",
      "Word: trs\n",
      "Unknown char: \n",
      "Word: c'est--dire\n",
      "Unknown char: \n",
      "Word: gzaltna\n",
      "Unknown char: \n",
      "Word: gzaltna\n",
      "Unknown char: \n",
      "Word: alnd\n",
      "Unknown char: \n",
      "Word: no\n",
      "Unknown char: \n",
      "Word: ento\n",
      "Unknown char: \n",
      "Word: padres\n",
      "Unknown char: \n",
      "Word: so\n",
      "Unknown char: \n",
      "Word: no\n",
      "Unknown char: \"\n",
      "Word: muslim...\"silent\n",
      "Unknown char: \"\n",
      "Word: majority\"...condemn\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: razn\n",
      "Unknown char: \n",
      "Word: frances\n",
      "Unknown char: \n",
      "Word: expresin\n",
      "Unknown char: \n",
      "Word: bytoday's\n",
      "Unknown char: \n",
      "Word: bytoday's\n",
      "Unknown char: \n",
      "Word: bytoday's\n",
      "Unknown char: \n",
      "Word: stck\n",
      "Unknown char: \n",
      "Word: kse\n",
      "Unknown char: \n",
      "Word: peaceit's\n",
      "Unknown char: \n",
      "Word: peaceit's\n",
      "Unknown char: =\n",
      "Word: uber=opportunistic\n",
      "Unknown char: \"\n",
      "Word: khanjar.\"a\n",
      "Unknown char: \"\n",
      "Word: case\"send\n",
      "Unknown char: \n",
      "Word: tomorrows\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: l'htel\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: pases\n",
      "Unknown char: \n",
      "Word: rpublique\n",
      "Unknown char: \n",
      "Word: prf\n",
      "Unknown char: \n",
      "Word: prsent\n",
      "Unknown char: \n",
      "Word: rpublique\n",
      "Unknown char: \n",
      "Word: europens\n",
      "Unknown char: \n",
      "Word: d'tre\n",
      "Unknown char: \n",
      "Word: chrtiens\n",
      "Unknown char: \n",
      "Word: rpublicains\n",
      "Unknown char: \n",
      "Word: rpondre\n",
      "Unknown char: \n",
      "Word: byle\n",
      "Unknown char: \n",
      "Word: terrist\n",
      "Unknown char: \n",
      "Word: terrist\n",
      "Unknown char: \n",
      "Word: dnya\n",
      "Unknown char: \n",
      "Word: baritan\n",
      "Unknown char: \n",
      "Word: geilmez\n",
      "Unknown char: \n",
      "Word: geilmez\n",
      "Unknown char: \n",
      "Word: kalrm\n",
      "Unknown char: \n",
      "Word: yannda\n",
      "Unknown char: \n",
      "Word: dn\n",
      "Unknown char: \n",
      "Word: sr\n",
      "Unknown char: \n",
      "Word: kyamam\n",
      "Unknown char: \n",
      "Word: biey\n",
      "Unknown char: \n",
      "Word: syleyemiyo\n",
      "Unknown char: \n",
      "Word: artk\n",
      "Unknown char: \n",
      "Word: stmze\n",
      "Unknown char: \n",
      "Word: stmze\n",
      "Unknown char: \n",
      "Word: stmze\n",
      "Unknown char: \n",
      "Word: stmze\n",
      "Unknown char: \n",
      "Word: anlyorum\n",
      "Unknown char: \n",
      "Word: konuuyorum\n",
      "Unknown char: \n",
      "Word: azndan\n",
      "Unknown char: \n",
      "Word: anlalmayalm\n",
      "Unknown char: \n",
      "Word: anlalmayalm\n",
      "Unknown char: \n",
      "Word: anlalmayalm\n",
      "Unknown char: \n",
      "Word: p-p\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: tambm\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \n",
      "Word: tambin\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: schieen\n",
      "Unknown char: \n",
      "Word: livebertragung\n",
      "Unknown char: \n",
      "Word: drfte\n",
      "Unknown char: \n",
      "Word: wre\n",
      "Unknown char: \n",
      "Word: tter\n",
      "Unknown char: \n",
      "Word: auszulschen\n",
      "Unknown char: \n",
      "Word: gbe\n",
      "Unknown char: \n",
      "Word: strenden\n",
      "Unknown char: \n",
      "Word: verrterischen\n",
      "Unknown char: \n",
      "Word: mrder\n",
      "Unknown char: \n",
      "Word: kmen\n",
      "Unknown char: \n",
      "Word: grber\n",
      "Unknown char: \n",
      "Word: flchtet\n",
      "Unknown char: \n",
      "Word: parittisch\n",
      "Unknown char: \n",
      "Word: australias\n",
      "Unknown char: \n",
      "Word: americas\n",
      "Unknown char: \n",
      "Word: n'tes\n",
      "Unknown char: \n",
      "Word: iin\n",
      "Unknown char: \n",
      "Word: basp\n",
      "Unknown char: \n",
      "Word: datmalsnz\n",
      "Unknown char: \n",
      "Word: datmalsnz\n",
      "Unknown char: \n",
      "Word: datmalsnz\n",
      "Unknown char: \n",
      "Word: datmalsnz\n",
      "Unknown char: \n",
      "Word: datmalsnz\n",
      "Unknown char: \"\n",
      "Word: afraid\"-thousands\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: tribresararivelesgentfaitesapoursuirejurtise\n",
      "Unknown char: \n",
      "Word: confiana\n",
      "Unknown char: \n",
      "Word: ns\n",
      "Unknown char: \n",
      "Word: to\n",
      "Unknown char: \n",
      "Word: difcil\n",
      "Unknown char: \n",
      "Word: condenao\n",
      "Unknown char: \n",
      "Word: condenao\n",
      "Unknown char: \n",
      "Word: habrn\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dsseldorf\n",
      "Unknown char: \n",
      "Word: gnration\n",
      "Unknown char: \n",
      "Word: gnration\n",
      "Unknown char: \n",
      "Word: hro\n",
      "Unknown char: \n",
      "Word: wasnt\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: yoll\n",
      "Unknown char: \"\n",
      "Word: euh...\"holletje\n",
      "Unknown char: \n",
      "Word: vrios\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: thisssrt\n",
      "Unknown char: \n",
      "Word: thisssrt\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: powana\n",
      "Unknown char: \n",
      "Word: zwyky\n",
      "Unknown char: \n",
      "Word: moe\n",
      "Unknown char: \n",
      "Word: moe\n",
      "Unknown char: \n",
      "Word: oczywicie\n",
      "Unknown char: \n",
      "Word: rne\n",
      "Unknown char: \n",
      "Word: rne\n",
      "Unknown char: \n",
      "Word: rda\n",
      "Unknown char: \n",
      "Word: rda\n",
      "Unknown char: \n",
      "Word: mona\n",
      "Unknown char: \n",
      "Word: wpadem\n",
      "Unknown char: \n",
      "Word: sida\n",
      "Unknown char: \n",
      "Word: wite\n",
      "Unknown char: \n",
      "Word: sowa\n",
      "Unknown char: \n",
      "Word: ostrzeenie\n",
      "Unknown char: \n",
      "Word: lotw\n",
      "Unknown char: \n",
      "Word: przeszkadzay\n",
      "Unknown char: \n",
      "Word: pkinois(nous\n",
      "Unknown char: \n",
      "Word: franais\n",
      "Unknown char: \n",
      "Word: franais\n",
      "Unknown char: \n",
      "Word: chre\n",
      "Unknown char: \n",
      "Word: prvert\n",
      "Unknown char: \n",
      "Word: youve\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \"\n",
      "Word: cellphoneshutdown\"evansolomonreporting\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: kii\n",
      "Unknown char: \n",
      "Word: ar\n",
      "Unknown char: \n",
      "Word: ar\n",
      "Unknown char: \n",
      "Word: kii\n",
      "Unknown char: \n",
      "Word: weve\n",
      "Unknown char: =\n",
      "Word: lt;=&gt\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: ive\n",
      "Unknown char: \n",
      "Word: rightno\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: gods\n",
      "Unknown char: =\n",
      "Word: religion=violence\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: translationno\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: situacin\n",
      "Unknown char: \n",
      "Word: pars\n",
      "Unknown char: \n",
      "Word: rehn\n",
      "Unknown char: \n",
      "Word: angehrigen\n",
      "Unknown char: \n",
      "Word: gzel\n",
      "Unknown char: \n",
      "Word: konuuyor\n",
      "Unknown char: \n",
      "Word: sanyor\n",
      "Unknown char: \n",
      "Word: islam\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \"\n",
      "Word: wrong\"~~mjs\n",
      "Unknown char: \n",
      "Word: seora\n",
      "Unknown char: \n",
      "Word: constncia\n",
      "Unknown char: \n",
      "Word: xenofbia\n",
      "Unknown char: \n",
      "Word: ents\n",
      "Unknown char: \n",
      "Word: sn\n",
      "Unknown char: \n",
      "Word: vctimas\n",
      "Unknown char: \n",
      "Word: tradut\n",
      "Unknown char: \n",
      "Word: dbarras\n",
      "Unknown char: \n",
      "Word: xrbi\n",
      "Unknown char: \n",
      "Word: xrbi\n",
      "Unknown char: \"\n",
      "Word: heroes.\"he\n",
      "Unknown char: \n",
      "Word: rpublique\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: indignacin\n",
      "Unknown char: \n",
      "Word: expresin\n",
      "Unknown char: \n",
      "Word: cafs\n",
      "Unknown char: \n",
      "excellent\n",
      "Unknown char: \n",
      "butd: idea\n",
      "Unknown char: \n",
      "they: about\n",
      "Unknown char: \n",
      "Word: headlesschookmpersonatingghekowithnotail\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: a320rt\n",
      "Unknown char: \n",
      "Word: bata\n",
      "Unknown char: \n",
      "Word: hepinizi\n",
      "Unknown char: \n",
      "Word: hepinizi\n",
      "Unknown char: \n",
      "Word: ak\n",
      "Unknown char: \n",
      "Word: ak\n",
      "Unknown char: \n",
      "Word: uularnz\n",
      "Unknown char: \n",
      "Word: uularnz\n",
      "Unknown char: \n",
      "Word: uularnz\n",
      "Unknown char: \n",
      "Word: uularnz\n",
      "Unknown char: \n",
      "Word: inileriniz\n",
      "Unknown char: \n",
      "Word: inileriniz\n",
      "Unknown char: \n",
      "Word: gvenli\n",
      "Unknown char: \n",
      "Word: wtend\n",
      "Unknown char: \n",
      "Word: hrt\n",
      "Unknown char: \n",
      "Word: storlengmlsch\n",
      "Unknown char: \n",
      "Word: mllerkrnerkleft\n",
      "Unknown char: \n",
      "Word: mllerkrnerkleft\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: guantnamo\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: methats\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown char: \n",
      "Word: wolinskis\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: wolinskis\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: wolinskis\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: wolinskis\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: wolinskis\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dmocratie\n",
      "Unknown char: \n",
      "Word: dcidment\n",
      "Unknown char: \n",
      "Word: dcidment\n",
      "Unknown char: \n",
      "Word: convictionjust\n",
      "Unknown char: \n",
      "Word: convictionjust\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dammartin-en-gol\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \n",
      "Word: arent\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: vctimas\n",
      "Unknown char: \n",
      "Word: dailyyour\n",
      "Unknown char: \n",
      "Word: dailyyour\n",
      "Unknown char: \n",
      "Word: dailyyour\n",
      "Unknown char: =\n",
      "Word: violations=dismissal\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: iid\n",
      "Unknown char: \n",
      "Word: iid\n",
      "Unknown char: \n",
      "Word: terristlerini\n",
      "Unknown char: \n",
      "Word: eiten\n",
      "Unknown char: \n",
      "Word: sayda\n",
      "Unknown char: \n",
      "Word: israilli\n",
      "Unknown char: \n",
      "Word: tmgeneral\n",
      "Unknown char: \n",
      "Word: koavi\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: glen's\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: iid\n",
      "Unknown char: \n",
      "Word: iid\n",
      "Unknown char: \n",
      "Word: terristlerini\n",
      "Unknown char: \n",
      "Word: eiten\n",
      "Unknown char: \n",
      "Word: sayda\n",
      "Unknown char: \n",
      "Word: kii\n",
      "Unknown char: \n",
      "Word: mnner\n",
      "Unknown char: \n",
      "Word: wet\n",
      "Unknown char: \n",
      "Word: bozuuna\n",
      "Unknown char: \n",
      "Word: policemans\n",
      "Unknown char: \n",
      "Word: policemans\n",
      "Unknown char: \n",
      "Word: policemans\n",
      "Unknown char: \n",
      "Word: policemans\n",
      "Unknown char: \"\n",
      "Word: were\"gardien\n",
      "Unknown char: \n",
      "Word: wyraam\n",
      "Unknown char: \n",
      "Word: najgbsze\n",
      "Unknown char: \n",
      "Word: najgbsze\n",
      "Unknown char: \n",
      "Word: wspczucie\n",
      "Unknown char: \n",
      "Word: wspczucie\n",
      "Unknown char: \n",
      "Word: bdziemy\n",
      "Unknown char: \n",
      "Word: l'poque\n",
      "Unknown char: \n",
      "Word: isral\n",
      "Unknown char: \n",
      "Word: doru\n",
      "Unknown char: \n",
      "Word: sylemi\n",
      "Unknown char: \n",
      "Word: castros\n",
      "Unknown char: \n",
      "Word: cubas\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: wasnt\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: d'arrter\n",
      "Unknown char: \n",
      "Word: d'tre\n",
      "Unknown char: \n",
      "Word: nause\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \"\n",
      "Word: jocks\"?for\n",
      "Unknown char: \n",
      "Word: corn\n",
      "Unknown char: \n",
      "Word: provocacin\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: polica\n",
      "Unknown char: \n",
      "Word: pars\n",
      "Unknown char: \n",
      "Word: gg\n",
      "Unknown char: \n",
      "Word: derrire\n",
      "Unknown char: \n",
      "Word: derrire\n",
      "Unknown char: \n",
      "Word: priphrique\n",
      "Unknown char: \n",
      "Word: priphrique\n",
      "Unknown char: \n",
      "Word: estn\n",
      "Unknown char: \n",
      "Word: democrticas\n",
      "Unknown char: \n",
      "Word: expulsin\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \"\n",
      "Word: confirmation?\"ask\n",
      "Unknown char: =\n",
      "Word: sorry=proven\n",
      "Unknown char: \n",
      "Word: cmon\n",
      "Unknown char: \"\n",
      "Word: topic-\"are\n",
      "Unknown char: \n",
      "Word: sad\n",
      "Unknown char: \n",
      "Word: cherf\n",
      "Unknown char: \n",
      "Word: crmer\n",
      "Unknown char: \\\n",
      "Word: way\\ave\\st\\rd\n",
      "Unknown char: \\\n",
      "Word: way\\ave\\st\\rd\n",
      "Unknown char: \\\n",
      "Word: way\\ave\\st\\rd\n",
      "Unknown char: \n",
      "Word: erdoan's\n",
      "Unknown char: \n",
      "Word: erdoan\n",
      "Unknown char: \n",
      "Word: trkiyenin\n",
      "Unknown char: \n",
      "Word: gvenilir\n",
      "Unknown char: \n",
      "Word: takipi\n",
      "Unknown char: \n",
      "Word: satn\n",
      "Unknown char: \n",
      "Word: penses\n",
      "Unknown char: \n",
      "Word: penses\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: expresin\n",
      "Unknown char: \n",
      "Word: provocacin\n",
      "Unknown char: \n",
      "Word: religin\n",
      "Unknown char: \n",
      "Word: sunni/shite\n",
      "Unknown char: \n",
      "Word: israeles\n",
      "Unknown char: \n",
      "Word: dsseldorf\n",
      "Unknown char: \n",
      "Word: dsseldorf\n",
      "Unknown char: \n",
      "Word: vctimas\n",
      "Unknown char: \n",
      "Word: a3204u\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: heres\n",
      "Unknown char: \n",
      "Word: engage\n",
      "Unknown char: \n",
      "Word: dcrit\n",
      "Unknown char: \n",
      "Word: trs\n",
      "Unknown char: \n",
      "Word: occupe\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \"\n",
      "Word: allah\"...and\n",
      "Unknown char: \n",
      "Word: well\n",
      "Unknown char: \n",
      "Word: anti-zoroastrianthe\n",
      "Unknown char: =\n",
      "Word: report=legal\n",
      "Unknown char: \"\n",
      "Word: so\"..wen\n",
      "Unknown char: \"\n",
      "i'md: yourselves\"\n",
      "Unknown char: \n",
      "i'md: yourselves\"\n",
      "Unknown char: \n",
      "i'md: yourselves\"\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: derrire\n",
      "Unknown char: \n",
      "Word: mnner\n",
      "Unknown char: \n",
      "Word: tambin\n",
      "Unknown char: \n",
      "Word: ideologas\n",
      "Unknown char: \n",
      "Word: polticos\n",
      "Unknown char: \n",
      "Word: pense\n",
      "Unknown char: \"\n",
      "Word: wifi\"...i\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: hlas\n",
      "Unknown char: \n",
      "Word: converthero\n",
      "Unknown char: \n",
      "ifrd: ism\n",
      "Unknown char: \"\n",
      "Word: here\"..generic\n",
      "Unknown char: \n",
      "Word: eraseris\n",
      "Unknown char: \n",
      "Word: eraseris\n",
      "Unknown char: \n",
      "Word: eraseris\n",
      "Unknown char: \n",
      "Word: eraseris\n",
      "Unknown char: \n",
      "Word: eraseris\n",
      "Unknown char: \n",
      "Word: eraseris\n",
      "Unknown char: \n",
      "Word: eraseris\n",
      "Unknown char: \n",
      "Word: eraseris\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \"\n",
      "Word: memorial:\"pray\n",
      "Unknown char: \n",
      "ifrd: ism\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: prire\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: nis\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: irans\n",
      "Unknown char: \n",
      "Word: irans\n",
      "Unknown char: \n",
      "Word: paraso\n",
      "Unknown char: \n",
      "Word: childs\n",
      "Unknown char: \"\n",
      "Word: wasn\"t\n",
      "Unknown char: \"\n",
      "Word: flags\"=\"psyops\"true\n",
      "Unknown char: =\n",
      "Word: flags\"=\"psyops\"true\n",
      "Unknown char: \"\n",
      "Word: flags\"=\"psyops\"true\n",
      "Unknown char: \"\n",
      "Word: flags\"=\"psyops\"true\n",
      "Unknown char: \n",
      "Word: mio\n",
      "Unknown char: \"\n",
      "Word: purposes\"is\n",
      "Unknown char: \n",
      "Word: schbig\n",
      "Unknown char: \n",
      "Word: gesprch\n",
      "Unknown char: \n",
      "Word: obrien\n",
      "Unknown char: \n",
      "Word: gzel\n",
      "Unknown char: \n",
      "Word: gldjande\n",
      "Unknown char: \n",
      "Word: no\n",
      "Unknown char: \n",
      "Word: matana\n",
      "Unknown char: \n",
      "Word: no\n",
      "Unknown char: \n",
      "Word: circulao\n",
      "Unknown char: \n",
      "Word: circulao\n",
      "Unknown char: \n",
      "Word: edio\n",
      "Unknown char: \n",
      "Word: edio\n",
      "Unknown char: \n",
      "Word: prxima\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: ill\n",
      "Unknown char: \"\n",
      "Word: dissidents/undesirables\"-run\n",
      "Unknown char: \"\n",
      "Word: date\"-the\n",
      "Unknown char: \n",
      "Word: ones\n",
      "Unknown char: \n",
      "Word: shouldnt\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: wasnt\n",
      "Unknown char: \n",
      "Word: gouverns\n",
      "Unknown char: \n",
      "Word: gallrie\n",
      "Unknown char: \n",
      "Word: fua\n",
      "Unknown char: \n",
      "Word: rtje\n",
      "Unknown char: \n",
      "Word: neutralised\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \"\n",
      "Word: not\"our\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \"\n",
      "Word: brush\"-i\n",
      "Unknown char: \n",
      "Word: villefranche-sur-sane\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: hasnt\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: wouldve\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: tt\n",
      "Unknown char: \n",
      "Word: hypothse\n",
      "Unknown char: \n",
      "Word: cre\n",
      "Unknown char: \n",
      "Word: dj\n",
      "Unknown char: \n",
      "Word: aprs\n",
      "Unknown char: \n",
      "Word: m'crire\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \n",
      "Word: l'tat\n",
      "Unknown char: \n",
      "Word: procderais\n",
      "Unknown char: \n",
      "Word: ct\n",
      "Unknown char: \n",
      "Word: d'coute\n",
      "Unknown char: \n",
      "Word: honntement\n",
      "Unknown char: \n",
      "Word: mdias\n",
      "Unknown char: \n",
      "Word: d'tre\n",
      "Unknown char: \n",
      "Word: l'vnement\n",
      "Unknown char: \n",
      "Word: l'vnement\n",
      "Unknown char: \n",
      "Word: prire\n",
      "Unknown char: \n",
      "Word: avrer\n",
      "Unknown char: \n",
      "Word: pice\n",
      "Unknown char: \n",
      "Word: mne\n",
      "Unknown char: \n",
      "Word: qubec\n",
      "Unknown char: \n",
      "Word: rellement\n",
      "Unknown char: \n",
      "Word: ct\n",
      "Unknown char: \n",
      "Word: toi-mme\n",
      "Unknown char: \n",
      "Word: mdia\n",
      "Unknown char: \n",
      "Word: mdias\n",
      "Unknown char: \n",
      "Word: gre\n",
      "Unknown char: \n",
      "Word: mdias\n",
      "Unknown char: \n",
      "Word: contrle\n",
      "Unknown char: \n",
      "Word: l'intrt\n",
      "Unknown char: \n",
      "Word: l'intrt\n",
      "Unknown char: \n",
      "Word: crer\n",
      "Unknown char: \n",
      "Word: infonde\n",
      "Unknown char: \n",
      "Word: errones\n",
      "Unknown char: \n",
      "Word: communiques\n",
      "Unknown char: \n",
      "Word: aprs\n",
      "Unknown char: \n",
      "Word: arrter\n",
      "Unknown char: \n",
      "Word: caractre\n",
      "Unknown char: \n",
      "Word: rponde\n",
      "Unknown char: \n",
      "Word: srement\n",
      "Unknown char: \n",
      "Word: t'inquite\n",
      "Unknown char: \n",
      "Word: plutt\n",
      "Unknown char: \n",
      "Word: boe\n",
      "Unknown char: \n",
      "Word: sauvaj\n",
      "Unknown char: \n",
      "Word: fantismo\n",
      "Unknown char: \n",
      "Word: brbaro\n",
      "Unknown char: \n",
      "Word: donnes\n",
      "Unknown char: \n",
      "Word: spcial\n",
      "Unknown char: \n",
      "Word: spciales\n",
      "Unknown char: \n",
      "Word: d'lite\n",
      "Unknown char: \n",
      "Word: diffrente\n",
      "Unknown char: \n",
      "Word: spciales\n",
      "Unknown char: \n",
      "Word: units\n",
      "Unknown char: \n",
      "Word: mriterait\n",
      "Unknown char: \n",
      "Word: rforme\n",
      "Unknown char: \n",
      "Word: dautres\n",
      "Unknown char: \n",
      "Word: units\n",
      "Unknown char: \n",
      "Word: dinterventions\n",
      "Unknown char: \n",
      "Word: spciales\n",
      "Unknown char: \n",
      "Word: prviens\n",
      "Unknown char: \n",
      "Word: dsinformation\n",
      "Unknown char: \n",
      "Word: peut-tre\n",
      "Unknown char: \n",
      "Word: exagrer\n",
      "Unknown char: \n",
      "Word: l'extrmisme\n",
      "Unknown char: \n",
      "Word: atpeaceful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown char: \n",
      "Word: priorits\n",
      "Unknown char: \n",
      "Word: dplac\n",
      "Unknown char: \n",
      "Word: mankind.ll\n",
      "Unknown char: =\n",
      "Word: sharialaw=hamas=isis\n",
      "Unknown char: =\n",
      "Word: sharialaw=hamas=isis\n",
      "Unknown char: =\n",
      "Word: haram=hezbollah\n",
      "Unknown char: \"\n",
      "Word: bold\"?...trying\n",
      "Unknown char: =\n",
      "Word: lies=lies=lies\n",
      "Unknown char: =\n",
      "Word: lies=lies=lies\n",
      "Unknown char: \n",
      "Word: wont\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: uss\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: uss\n",
      "Unknown char: =\n",
      "Word: suspects=more\n",
      "Unknown char: \n",
      "Word: tmraire\n",
      "Unknown char: \n",
      "Word: tmraire\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: wasnt\n",
      "Unknown char: \n",
      "Word: frre\n",
      "Unknown char: \n",
      "Word: monte\n",
      "Unknown char: \n",
      "Word: polica\n",
      "Unknown char: \n",
      "Word: polcia\n",
      "Unknown char: \n",
      "Word: austrlia\n",
      "Unknown char: \n",
      "Word: mantm\n",
      "Unknown char: \n",
      "Word: vrios\n",
      "Unknown char: \n",
      "Word: refns\n",
      "Unknown char: \n",
      "Word: wont\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \"\n",
      "Word: w/\"reported\n",
      "Unknown char: \n",
      "Word: sper\n",
      "Unknown char: \n",
      "Word: sr\n",
      "Unknown char: \n",
      "Word: sr\n",
      "Unknown char: \n",
      "Word: sr\n",
      "Unknown char: \"\n",
      "Word: world\"....great\n",
      "Unknown char: \n",
      "Word: exploses\n",
      "Unknown char: \n",
      "Word: downtowncrazy\n",
      "Unknown char: \"\n",
      "Word: it\"workplace\n",
      "Unknown char: \n",
      "Word: that's\n",
      "Unknown char: =\n",
      "Word: repeat=&gt;if\n",
      "Unknown char: =\n",
      "Word: repeat=&gt;if\n",
      "Unknown char: \n",
      "Word: terristlerin\n",
      "Unknown char: \n",
      "Word: stphane\n",
      "Unknown char: \n",
      "Word: stphane\n",
      "Unknown char: =\n",
      "Word: terrorismo=mafie\n",
      "Unknown char: \n",
      "Word: stphane\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \"\n",
      "Word: yes....\"accidents\n",
      "Unknown char: \"\n",
      "Word: i\"m\n",
      "Unknown char: \n",
      "Word: terrorfico\n",
      "Unknown char: \n",
      "Word: frmmestad\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \"\n",
      "Word: matter.\"..lol\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: rehn\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \n",
      "Word: tte\n",
      "Unknown char: \n",
      "Word: mdiatique\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: offices\n",
      "Unknown char: \\\n",
      "Word: nat\\f\n",
      "Unknown char: =\n",
      "Word: peace(globe)=58=all\n",
      "Unknown char: =\n",
      "Word: peace(globe)=58=all\n",
      "Unknown char: \n",
      "Word: offices\n",
      "Unknown char: \n",
      "Word: penses\n",
      "Unknown char: \n",
      "Word: franais\n",
      "Unknown char: \n",
      "Word: offices\n",
      "Unknown char: \"\n",
      "Word: islamist\"attacks\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: consistentmuch\n",
      "Unknown char: \n",
      "Word: havent\n",
      "Unknown char: \n",
      "Word: havent\n",
      "Unknown char: \n",
      "Word: hows\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: guessim\n",
      "Unknown char: \n",
      "Word: guessim\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: peoples\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: couldnt\n",
      "Unknown char: \n",
      "Word: rats\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: ive\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \"\n",
      "Word: do\"it\n",
      "Unknown char: \n",
      "Word: respects\n",
      "Unknown char: \n",
      "Word: assasins\n",
      "Unknown char: \n",
      "Word: brler\n",
      "Unknown char: \n",
      "Word: dnoncer\n",
      "Unknown char: \n",
      "Word: zaczo\n",
      "Unknown char: \n",
      "Word: zaczo\n",
      "Unknown char: \n",
      "Word: kady\n",
      "Unknown char: \n",
      "Word: bdzie\n",
      "Unknown char: \n",
      "Word: prbowa\n",
      "Unknown char: \n",
      "Word: rnych\n",
      "Unknown char: \n",
      "Word: rnych\n",
      "Unknown char: \n",
      "Word: zaktkach\n",
      "Unknown char: \n",
      "Word: zaczo\n",
      "Unknown char: \n",
      "Word: zaczo\n",
      "Unknown char: \n",
      "Word: kady\n",
      "Unknown char: \n",
      "Word: bdzie\n",
      "Unknown char: \n",
      "Word: prbowa\n",
      "Unknown char: \n",
      "Word: rnych\n",
      "Unknown char: \n",
      "Word: rnych\n",
      "Unknown char: \n",
      "Word: zaktkach\n",
      "Unknown char: \n",
      "Word: cytujc\n",
      "Unknown char: \"\n",
      "Word: returned:\"but\n",
      "Unknown char: \n",
      "Word: lches\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: iid\n",
      "Unknown char: \n",
      "Word: iid\n",
      "Unknown char: \n",
      "Word: terristlerini\n",
      "Unknown char: \n",
      "Word: eiten\n",
      "Unknown char: \n",
      "Word: sayda\n",
      "Unknown char: \n",
      "Word: cdez\n",
      "Unknown char: \n",
      "Word: dammartin-en-gole\n",
      "Unknown char: \n",
      "Word: dammartin-en-gole\n",
      "Unknown char: \n",
      "Word: dammartin-en-gole\n",
      "Unknown char: \n",
      "Word: dammartin-en-gole\n",
      "Unknown char: \"\n",
      "Word: him\"...what\n",
      "Unknown char: \"\n",
      "Word: security\"...from\n",
      "Unknown char: \"\n",
      "Word: him\"...what\n",
      "Unknown char: \"\n",
      "Word: saying...\"if\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \"\n",
      "Word: condulence\"-jebag\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: journe\n",
      "Unknown char: \n",
      "Word: yeahi\n",
      "Unknown char: \n",
      "Word: got\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: wren\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: wouldnt\n",
      "Unknown char: \n",
      "Word: wont\n",
      "Unknown char: \n",
      "Word: caazo\n",
      "Unknown char: \n",
      "Word: attaqus\n",
      "Unknown char: \n",
      "Word: dmissionne\n",
      "Unknown char: \n",
      "Word: l'indpendantiste\n",
      "Unknown char: \n",
      "Word: rviser\n",
      "Unknown char: \n",
      "Word: amricaine\n",
      "Unknown char: \"\n",
      "Word: attack:paris\"ll\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \"\n",
      "Word: cop/\"security\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: theydidn't\n",
      "Unknown char: \n",
      "Word: dport\n",
      "Unknown char: \"\n",
      "Word: believe\"from\n",
      "Unknown char: \"\n",
      "Word: order\":usjrno\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: too\n",
      "Unknown char: \n",
      "Word: canadas\n",
      "Unknown char: \"\n",
      "Word: martyrs\"french\n",
      "Unknown char: \n",
      "Word: podan\n",
      "Unknown char: \n",
      "Word: mrtires\n",
      "Unknown char: \n",
      "Word: pasamontaas\n",
      "Unknown char: \n",
      "Word: da\n",
      "Unknown char: \n",
      "Word: inmolndose.pero\n",
      "Unknown char: \n",
      "Word: pelcula\n",
      "Unknown char: \n",
      "Word: mrtires\n",
      "Unknown char: \n",
      "Word: slo\n",
      "Unknown char: \n",
      "Word: mrtires\n",
      "Unknown char: \n",
      "Word: mrtires\n",
      "Unknown char: \n",
      "Word: das\n",
      "Unknown char: \n",
      "Word: sultn\n",
      "Unknown char: \n",
      "Word: algn\n",
      "Unknown char: \n",
      "Word: partindose\n",
      "Unknown char: \n",
      "Word: rehn\n",
      "Unknown char: \n",
      "Word: pars\n",
      "Unknown char: \n",
      "Word: canadas\n",
      "Unknown char: \n",
      "Word: dj\n",
      "Unknown char: \n",
      "Word: dcd\n",
      "Unknown char: \n",
      "Word: dcd\n",
      "Unknown char: \n",
      "Word: leiil\n",
      "Unknown char: \n",
      "Word: plutt\n",
      "Unknown char: \n",
      "Word: dernire\n",
      "Unknown char: \n",
      "Word: c'tait\n",
      "Unknown char: \n",
      "Word: artculo\n",
      "Unknown char: \n",
      "Word: pars\n",
      "Unknown char: \n",
      "Word: fume\n",
      "Unknown char: \n",
      "Word: poasi\n",
      "Unknown char: \n",
      "Word: nesrena\n",
      "Unknown char: \n",
      "Word: sluaj\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: cuntas\n",
      "Unknown char: \n",
      "Word: pakistn\n",
      "Unknown char: \n",
      "Word: irn\n",
      "Unknown char: \n",
      "Word: hed\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: were\n",
      "Unknown char: \n",
      "Word: sera\n",
      "Unknown char: \n",
      "Word: dediimiz\n",
      "Unknown char: \n",
      "Word: ite\n",
      "Unknown char: \n",
      "Word: yazld\n",
      "Unknown char: \n",
      "Word: kardeim\n",
      "Unknown char: \n",
      "Word: kavgann\n",
      "Unknown char: \n",
      "Word: istanbul\n",
      "Unknown char: \n",
      "Word: kfr\n",
      "Unknown char: \n",
      "Word: kfr\n",
      "Unknown char: \n",
      "Word: eteine\n",
      "Unknown char: \n",
      "Word: ayaksn\n",
      "Unknown char: \n",
      "Word: gerek\n",
      "Unknown char: \n",
      "Word: nasl\n",
      "Unknown char: \n",
      "Word: yazk\n",
      "Unknown char: \n",
      "Word: yazk\n",
      "Unknown char: \n",
      "Word: karl\n",
      "Unknown char: \n",
      "Word: karl\n",
      "Unknown char: \n",
      "Word: satrlarnda\n",
      "Unknown char: \n",
      "Word: satrlarnda\n",
      "Unknown char: \n",
      "Word: trk\n",
      "Unknown char: \n",
      "Word: deil\n",
      "Unknown char: \n",
      "Word: hereyi\n",
      "Unknown char: \n",
      "Word: satyorlar\n",
      "Unknown char: \n",
      "Word: yz\n",
      "Unknown char: \n",
      "Word: trkl\n",
      "Unknown char: \n",
      "Word: hakknda\n",
      "Unknown char: \n",
      "Word: olmutur\n",
      "Unknown char: \n",
      "Word: manasyla\n",
      "Unknown char: \n",
      "Word: istediin\n",
      "Unknown char: \n",
      "Word: sakalndan\n",
      "Unknown char: \n",
      "Word: srkleneceksin\n",
      "Unknown char: \n",
      "Word: srkleneceksin\n",
      "Unknown char: \n",
      "Word: dnya'da\n",
      "Unknown char: \n",
      "Word: grelim\n",
      "Unknown char: \n",
      "Word: yoksunluu\n",
      "Unknown char: \n",
      "Word: mnafklk\n",
      "Unknown char: \n",
      "Word: mnafklk\n",
      "Unknown char: \n",
      "Word: mnafklk\n",
      "Unknown char: \n",
      "Word: hainlii\n",
      "Unknown char: \n",
      "Word: ahsn\n",
      "Unknown char: \n",
      "Word: tarafndan\n",
      "Unknown char: \n",
      "Word: istihbaratn\n",
      "Unknown char: \n",
      "Word: inaatna\n",
      "Unknown char: \n",
      "Word: inaatna\n",
      "Unknown char: \n",
      "Word: kat\n",
      "Unknown char: \n",
      "Word: anlayamadk\n",
      "Unknown char: \n",
      "Word: bulalm\n",
      "Unknown char: \n",
      "Word: yaptlar\n",
      "Unknown char: \n",
      "Word: baka\n",
      "Unknown char: \n",
      "Word: grmez\n",
      "Unknown char: \n",
      "Word: gzlerin\n",
      "Unknown char: \n",
      "Word: lam\n",
      "Unknown char: \n",
      "Word: lam\n",
      "Unknown char: \n",
      "Word: alrsan\n",
      "Unknown char: \n",
      "Word: ettiine\n",
      "Unknown char: \n",
      "Word: inandn\n",
      "Unknown char: \n",
      "Word: inandn\n",
      "Unknown char: \n",
      "Word: inandn\n",
      "Unknown char: \n",
      "Word: kiilerden(iki\n",
      "Unknown char: \n",
      "Word: kii\n",
      "Unknown char: \n",
      "Word: badatramyorum\n",
      "Unknown char: \n",
      "Word: badatramyorum\n",
      "Unknown char: \n",
      "Word: badatramyorum\n",
      "Unknown char: \n",
      "Word: badatramyorum\n",
      "Unknown char: \n",
      "Word: lam\n",
      "Unknown char: \n",
      "Word: lam\n",
      "Unknown char: \n",
      "Word: laflarn\n",
      "Unknown char: \n",
      "Word: yakksz\n",
      "Unknown char: \n",
      "Word: yakksz\n",
      "Unknown char: \n",
      "Word: yakksz\n",
      "Unknown char: \n",
      "Word: yakksz\n",
      "Unknown char: \n",
      "Word: byle\n",
      "Unknown char: \n",
      "Word: kfrlere\n",
      "Unknown char: \n",
      "Word: kfrlere\n",
      "Unknown char: \n",
      "Word: tenezzl\n",
      "Unknown char: \n",
      "Word: aklmda\n",
      "Unknown char: \n",
      "Word: kaldn\n",
      "Unknown char: \n",
      "Word: yazdan\n",
      "Unknown char: \n",
      "Word: yazdan\n",
      "Unknown char: \n",
      "Word: yazdan\n",
      "Unknown char: \n",
      "Word: bakp\n",
      "Unknown char: \n",
      "Word: ahlaksz\n",
      "Unknown char: \n",
      "Word: gndermelerini\n",
      "Unknown char: \n",
      "Word: okyacaksn\n",
      "Unknown char: \n",
      "Word: bakp\n",
      "Unknown char: \n",
      "Word: temil\n",
      "Unknown char: \n",
      "Word: alamazsn.kastl\n",
      "Unknown char: \n",
      "Word: alamazsn.kastl\n",
      "Unknown char: \n",
      "Word: yapyorsun\n",
      "Unknown char: \n",
      "Word: aryorsunuzki?emre\n",
      "Unknown char: \n",
      "Word: aryorsunuzki?emre\n",
      "Unknown char: \n",
      "Word: aryorsunuzki?emre\n",
      "Unknown char: \n",
      "Word: grevini\n",
      "Unknown char: \n",
      "Word: yapyor\n",
      "Unknown char: \n",
      "Word: yedii\n",
      "Unknown char: \n",
      "Word: ca\n",
      "Unknown char: \n",
      "Word: nn\n",
      "Unknown char: \n",
      "Word: ahlaksz\n",
      "Unknown char: \n",
      "Word: gnderme\n",
      "Unknown char: \n",
      "Word: yazmadm\n",
      "Unknown char: \n",
      "Word: yazdklarnla\n",
      "Unknown char: \n",
      "Word: yazdklarnla\n",
      "Unknown char: \n",
      "Word: noktasna\n",
      "Unknown char: \n",
      "Word: gidecein\n",
      "Unknown char: \n",
      "Word: uyarsnda\n",
      "Unknown char: \n",
      "Word: uyarsnda\n",
      "Unknown char: \n",
      "Word: hocasnn\n",
      "Unknown char: \n",
      "Word: hocasnn\n",
      "Unknown char: \n",
      "Word: gtrdn\n",
      "Unknown char: \n",
      "Word: gtrdn\n",
      "Unknown char: \n",
      "Word: gtrdn\n",
      "Unknown char: \n",
      "Word: gtrdn\n",
      "Unknown char: \n",
      "Word: gtrdn\n",
      "Unknown char: \n",
      "Word: deilmi\n",
      "Unknown char: \n",
      "Word: dnr\n",
      "Unknown char: \n",
      "Word: dnr\n",
      "Unknown char: \n",
      "Word: dnr\n",
      "Unknown char: \n",
      "Word: dnr\n",
      "Unknown char: \"\n",
      "Word: bitches...\"unless\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: va\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown char: =\n",
      "Word: americans=full\n",
      "Unknown char: \n",
      "Word: vl\n",
      "Unknown char: \n",
      "Word: sjlvklarhet\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: lhistoire\n",
      "Unknown char: \n",
      "Word: envoys\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: ive\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \"\n",
      "Word: indication\"of\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: peoples\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: ive\n",
      "Unknown char: \n",
      "Word: bushs\n",
      "Unknown char: \n",
      "Word: bushs\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: \n",
      "Word: someones\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: \n",
      "Word: someones\n",
      "Unknown char: \n",
      "Word: gun.its\n",
      "Unknown char: \n",
      "Word: sryor\n",
      "Unknown char: \n",
      "Word: sryor\n",
      "Unknown char: \n",
      "Word: dnonce\n",
      "Unknown char: \"\n",
      "Word: much\"im\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: persons\n",
      "Unknown char: \n",
      "Word: qubec\n",
      "Unknown char: \n",
      "Word: govt\n",
      "Unknown char: =\n",
      "Word: ideas=fair\n",
      "Unknown char: =\n",
      "Word: this=ridiculous.do\n",
      "Unknown char: \n",
      "Word: d'tre\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: comunicacin\n",
      "Unknown char: \n",
      "Word: islam\n",
      "Unknown char: \n",
      "Word: adna\n",
      "Unknown char: \n",
      "Word: terrn\n",
      "Unknown char: \n",
      "Word: terrn\n",
      "Unknown char: \n",
      "Word: saldrsnda\n",
      "Unknown char: \n",
      "Word: saldrsnda\n",
      "Unknown char: \n",
      "Word: saldrsnda\n",
      "Unknown char: \n",
      "Word: hayatn\n",
      "Unknown char: \n",
      "Word: mslman\n",
      "Unknown char: \n",
      "Word: mslman\n",
      "Unknown char: \n",
      "Word: reporters\n",
      "Unknown char: \"\n",
      "Word: truth\"-du-jour\n",
      "Unknown char: \n",
      "Word: cafs\n",
      "Unknown char: \n",
      "Word: tt\n",
      "Unknown char: \n",
      "herd: mention\n",
      "Unknown char: \n",
      "herd: mention\n",
      "Unknown char: \n",
      "Word: mans\n",
      "Unknown char: \n",
      "Word: hy\n",
      "Unknown char: \n",
      "Word: git\n",
      "Unknown char: \n",
      "Word: cht\n",
      "Unknown char: \n",
      "Word: bn\n",
      "Unknown char: \n",
      "Word: khng\n",
      "Unknown char: \n",
      "Word: youve\n",
      "Unknown char: =\n",
      "Word: innocent=kool\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: amrique\n",
      "Unknown char: \n",
      "Word: catstrofe\n",
      "Unknown char: \n",
      "Word: area\n",
      "Unknown char: \n",
      "Word: w/themiddle\n",
      "Unknown char: \n",
      "Word: polices\n",
      "Unknown char: \n",
      "Word: polices\n",
      "Unknown char: \n",
      "Word: polices\n",
      "Unknown char: \n",
      "Word: polices\n",
      "Unknown char: \n",
      "Word: polices\n",
      "Unknown char: \n",
      "Word: seor\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: econmico\n",
      "Unknown char: \n",
      "Word: previsvel\n",
      "Unknown char: \n",
      "Word: theyd\n",
      "Unknown char: \n",
      "Word: dorothe\n",
      "Unknown char: \n",
      "Word: enchan\n",
      "Unknown char: \n",
      "Word: bajn\n",
      "Unknown char: \n",
      "Word: psame\n",
      "Unknown char: \n",
      "Word: habls\n",
      "Unknown char: \n",
      "Word: tambin\n",
      "Unknown char: \n",
      "Word: obligacin\n",
      "Unknown char: \n",
      "Word: democrticos\n",
      "Unknown char: \"\n",
      "Word: skyline\"yourselves\n",
      "Unknown char: \"\n",
      "Word: christ-like\"....many\n",
      "Unknown char: \"\n",
      "Word: who\"the\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: mgalomane\n",
      "Unknown char: \n",
      "Word: order.the\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: naf\n",
      "Unknown char: \n",
      "Word: condolances\n",
      "Unknown char: \n",
      "Word: aprs\n",
      "Unknown char: =\n",
      "Word: religion=superstition\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \n",
      "Word: curs\n",
      "Unknown char: \n",
      "Word: prfre\n",
      "Unknown char: \n",
      "Word: prfre\n",
      "Unknown char: \"\n",
      "Word: rt\"why\n",
      "Unknown char: \n",
      "Word: dj\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: =\n",
      "Word: act=intelligent\n",
      "Unknown char: \n",
      "Word: bni\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \n",
      "Word: dlires\n",
      "Unknown char: \n",
      "Word: islamise\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: franois\n",
      "Unknown char: \n",
      "Word: tambm\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: sptzle\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \"\n",
      "Word: ferguson\"monday\n",
      "Unknown char: \n",
      "Word: mxico\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: ningum\n",
      "Unknown char: \n",
      "Word: to\n",
      "Unknown char: \n",
      "Word: dbr\n",
      "Unknown char: \n",
      "Word: dbr\n",
      "Unknown char: \n",
      "Word: deilsin\n",
      "Unknown char: \n",
      "Word: no\n",
      "Unknown char: \n",
      "Word: bji\n",
      "Unknown char: \n",
      "Word: krdistan\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: wt\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: well\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: well\n",
      "Unknown char: \n",
      "Word: sacrbleu\n",
      "Unknown char: \n",
      "Word: prophte\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: =\n",
      "Word: ability=no\n",
      "Unknown char: \"\n",
      "Word: negros\"when\n",
      "Unknown char: \"\n",
      "Word: surveillance-\"terrorism\n",
      "Unknown char: \n",
      "Word: lmites\n",
      "Unknown char: \n",
      "Word: expresin\n",
      "Unknown char: \n",
      "Word: mxico\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: journe...c'est\n",
      "Unknown char: \n",
      "Word: scurit\n",
      "Unknown char: \n",
      "Word: hros\n",
      "Unknown char: \n",
      "Word: tiet-sp\n",
      "Unknown char: =\n",
      "Word: isis=saudi=taliban=al-nusra\n",
      "Unknown char: =\n",
      "Word: isis=saudi=taliban=al-nusra\n",
      "Unknown char: =\n",
      "Word: isis=saudi=taliban=al-nusra\n",
      "Unknown char: =\n",
      "Word: england=jamaica=denmark=first\n",
      "Unknown char: =\n",
      "Word: england=jamaica=denmark=first\n",
      "Unknown char: =\n",
      "Word: england=jamaica=denmark=first\n",
      "Unknown char: =\n",
      "Word: aid=treasure\n",
      "Unknown char: =\n",
      "Word: isis=saudi=taliban=al-nusra\n",
      "Unknown char: =\n",
      "Word: isis=saudi=taliban=al-nusra\n",
      "Unknown char: =\n",
      "Word: isis=saudi=taliban=al-nusra\n",
      "Unknown char: \n",
      "Word: wont\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: terrorists\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: youll\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: comunicacin\n",
      "Unknown char: \n",
      "Word: havent\n",
      "Unknown char: \n",
      "Word: heres\n",
      "Unknown char: \n",
      "Word: havent\n",
      "Unknown char: \n",
      "Word: heres\n",
      "Unknown char: \n",
      "Word: havent\n",
      "Unknown char: \n",
      "Word: heres\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: frankrich\n",
      "Unknown char: \"\n",
      "Word: theres\"dryer\n",
      "Unknown char: \"\n",
      "Word: american\"..who\n",
      "Unknown char: \n",
      "Word: sonot\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \"\n",
      "Word: to\"heaven\n",
      "Unknown char: \n",
      "Word: tawhd\n",
      "Unknown char: \n",
      "Word: lve\n",
      "Unknown char: \n",
      "Word: cafetera\n",
      "Unknown char: \n",
      "Word: shooting.that\n",
      "Unknown char: \n",
      "Word: shooting.that\n",
      "Unknown char: \n",
      "Word: shooting.that\n",
      "Unknown char: \n",
      "Word: shooting.that\n",
      "Unknown char: \n",
      "Word: shooting.that\n",
      "Unknown char: \n",
      "Word: shooting.that\n",
      "Unknown char: \n",
      "Word: shooting.that\n",
      "Unknown char: \n",
      "Word: were\n",
      "Unknown char: \n",
      "Word: glen's\n",
      "Unknown char: \n",
      "Word: israilli\n",
      "Unknown char: \n",
      "Word: tmgeneral\n",
      "Unknown char: \n",
      "Word: koavi\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: iid\n",
      "Unknown char: \n",
      "Word: iid\n",
      "Unknown char: \n",
      "Word: terristlerini\n",
      "Unknown char: \n",
      "Word: eiten\n",
      "Unknown char: \n",
      "Word: sayda\n",
      "Unknown char: \n",
      "Word: ottawas\n",
      "Unknown char: \"\n",
      "Word: says:\"ray\n",
      "Unknown char: \"\n",
      "Word: k\"c\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: mdias\n",
      "Unknown char: \n",
      "Word: quelquun\n",
      "Unknown char: \n",
      "Word: premire\n",
      "Unknown char: \n",
      "Word: perscutions\n",
      "Unknown char: \n",
      "Word: perscuts\n",
      "Unknown char: \n",
      "Word: perscuts\n",
      "Unknown char: \n",
      "Word: mdias\n",
      "Unknown char: \n",
      "Word: dalgriens\n",
      "Unknown char: \n",
      "Word: dalgriens\n",
      "Unknown char: \n",
      "Word: franais\n",
      "Unknown char: \n",
      "Word: algrie\n",
      "Unknown char: \n",
      "Word: sicle\n",
      "Unknown char: \n",
      "Word: isral\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: prt\n",
      "Unknown char: \n",
      "Word: extrmistes\n",
      "Unknown char: \n",
      "Word: uks\n",
      "Unknown char: \n",
      "Word: frmmestad\n",
      "Unknown char: \n",
      "Word: were\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: solder\n",
      "Unknown char: \n",
      "Word: ddn't\n",
      "Unknown char: \n",
      "Word: ths\n",
      "Unknown char: \"\n",
      "Word: mere\"politics\"to\n",
      "Unknown char: \"\n",
      "Word: mere\"politics\"to\n",
      "Unknown char: \n",
      "Word: servio\n",
      "Unknown char: \n",
      "Word: wre\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: grere\n",
      "Unknown char: \n",
      "Word: grere\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown char: =\n",
      "Word: murder=intentional\n",
      "Unknown char: \n",
      "Word: canadas\n",
      "Unknown char: \n",
      "Word: jmfra\n",
      "Unknown char: \n",
      "Word: jmfra\n",
      "Unknown char: \n",
      "Word: ngon\n",
      "Unknown char: \n",
      "Word: frstr\n",
      "Unknown char: \n",
      "Word: frstr\n",
      "Unknown char: \n",
      "Word: snt\n",
      "Unknown char: \n",
      "Word: hr\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: frlorare\n",
      "Unknown char: \n",
      "Word: vldigt\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: derrire\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: mglich\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: islmico\n",
      "Unknown char: \n",
      "Word: so\n",
      "Unknown char: \n",
      "Word: esto\n",
      "Unknown char: \n",
      "Word: id\n",
      "Unknown char: \"\n",
      "Word: war.\"once\n",
      "Unknown char: \"\n",
      "Word: you\"re\n",
      "Unknown char: \"\n",
      "Word: in\"jean\n",
      "Unknown char: \n",
      "Word: barbrie\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: vietas\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: matarn\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: vendrn\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \"\n",
      "Word: pen.\"-stephane\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: =\n",
      "Word: is=not=a\n",
      "Unknown char: =\n",
      "Word: is=not=a\n",
      "Unknown char: =\n",
      "Word: western.......=not=here\n",
      "Unknown char: =\n",
      "Word: western.......=not=here\n",
      "Unknown char: \"\n",
      "Word: says..\"i\n",
      "Unknown char: \"\n",
      "Word: can\"t\n",
      "Unknown char: \"\n",
      "Word: breathe!\"...lol\n",
      "Unknown char: \n",
      "Word: lm\n",
      "Unknown char: \n",
      "Word: iekleri\n",
      "Unknown char: \n",
      "Word: iekte\n",
      "Unknown char: \n",
      "Word: klliyen\n",
      "Unknown char: \n",
      "Word: istiyorum\n",
      "Unknown char: \n",
      "Word: gzel\n",
      "Unknown char: \n",
      "Word: insanlarsnz\n",
      "Unknown char: \n",
      "Word: insanlarsnz\n",
      "Unknown char: \n",
      "Word: byle\n",
      "Unknown char: \n",
      "Word: gnlerde\n",
      "Unknown char: \n",
      "Word: tkanan\n",
      "Unknown char: \n",
      "Word: cierlerimize\n",
      "Unknown char: \n",
      "Word: varsnz\n",
      "Unknown char: \n",
      "Word: varsnz\n",
      "Unknown char: \n",
      "Word: olmayn\n",
      "Unknown char: \n",
      "Word: bey...sayglar\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \\\n",
      "Word: her\\his\n",
      "Unknown char: =\n",
      "Word: us=the\n",
      "Unknown char: \n",
      "Word: matterssophisticated\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: =\n",
      "Word: uber=ugly\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: =\n",
      "Word: snp=ira\n",
      "Unknown char: \n",
      "Word: krdish\n",
      "Unknown char: \n",
      "Word: bibis\n",
      "Unknown char: \"\n",
      "Word: muslim\"...never\n",
      "Unknown char: \"\n",
      "Word: false-flag\"...lol\n",
      "Unknown char: \"\n",
      "Word: danger\".and\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \n",
      "Word: tambm\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: lets\n",
      "Unknown char: \n",
      "Word: trocadro\n",
      "Unknown char: =\n",
      "Word: dss=grounds\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: atma\n",
      "Unknown char: \n",
      "Word: atma\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: muslims\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \"\n",
      "Word: the\"hijacking\"of\n",
      "Unknown char: \"\n",
      "Word: the\"hijacking\"of\n",
      "Unknown char: \"\n",
      "Word: insistent\"on\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: rsumer\n",
      "Unknown char: \n",
      "Word: aportacin\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \"\n",
      "Word: up?\"...\"find\n",
      "Unknown char: \"\n",
      "Word: up?\"...\"find\n",
      "Unknown char: \n",
      "Word: prophte\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: thatso\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: mediaand\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: deportacin\n",
      "Unknown char: \n",
      "Word: prvu\n",
      "Unknown char: \"\n",
      "Word: rumors\"...should\n",
      "Unknown char: \n",
      "Word: todays\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: whats\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: couldnt\n",
      "Unknown char: =\n",
      "Word: crime=wall\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: oughtnt\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: polticos\n",
      "Unknown char: \n",
      "Word: seguirn\n",
      "Unknown char: \n",
      "Word: sbado\n",
      "Unknown char: \n",
      "Word: odos\n",
      "Unknown char: \n",
      "Word: aos\n",
      "Unknown char: \n",
      "Word: adems\n",
      "Unknown char: \n",
      "Word: das\n",
      "Unknown char: \"\n",
      "Word: his...er...\"attention\n",
      "Unknown char: \n",
      "Word: weve\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: larticle\n",
      "Unknown char: \n",
      "Word: c'tait\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: couldnt\n",
      "Unknown char: \n",
      "Word: thiswell\n",
      "Unknown char: \n",
      "Word: iu\n",
      "Unknown char: \n",
      "Word: ha\n",
      "Unknown char: \n",
      "Word: trn\n",
      "Unknown char: =\n",
      "Word: muslims=no\n",
      "Unknown char: =\n",
      "Word: blacks=non\n",
      "Unknown char: =\n",
      "Word: muslims=no\n",
      "Unknown char: =\n",
      "Word: blacks=non\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \n",
      "Word: mme\n",
      "Unknown char: \"\n",
      "Word: his\"audience\"behind\n",
      "Unknown char: \"\n",
      "Word: his\"audience\"behind\n",
      "Unknown char: \"\n",
      "Word: and\"widescreen\"up\n",
      "Unknown char: \"\n",
      "Word: and\"widescreen\"up\n",
      "Unknown char: \n",
      "Word: mitgefhl\n",
      "Unknown char: \n",
      "Word: angehrigen\n",
      "Unknown char: \n",
      "Word: yazyor\n",
      "Unknown char: \n",
      "Word: na\n",
      "Unknown char: \n",
      "Word: judasm\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: =\n",
      "Word: lt;&lt;&lt;==================jew\n",
      "Unknown char: \n",
      "Word: julians\n",
      "Unknown char: \n",
      "Word: vctms\n",
      "Unknown char: \n",
      "Word: vctms\n",
      "Unknown char: \n",
      "Word: ther\n",
      "Unknown char: \n",
      "Word: famles\n",
      "Unknown char: \n",
      "Word: famles\n",
      "Unknown char: \n",
      "Word: wshes\n",
      "Unknown char: \n",
      "Word: ther\n",
      "Unknown char: \n",
      "Word: quck\n",
      "Unknown char: \n",
      "Word: prayng\n",
      "Unknown char: \n",
      "Word: solder\n",
      "Unknown char: \n",
      "Word: solder's\n",
      "Unknown char: \n",
      "Word: famly\n",
      "Unknown char: \n",
      "Word: chre\n",
      "Unknown char: \n",
      "Word: lcido\n",
      "Unknown char: \n",
      "Word: mritent\n",
      "Unknown char: \n",
      "Word: religionsdeserve\n",
      "Unknown char: \n",
      "Word: andour\n",
      "Unknown char: \"\n",
      "Word: disrespect\"...you\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \"\n",
      "Word: be\"fixed\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: hebdos\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: tragdia\n",
      "Unknown char: \n",
      "Word: comearem\n",
      "Unknown char: \n",
      "Word: pases\n",
      "Unknown char: \n",
      "Word: wed\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: quran\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: quran\n",
      "Unknown char: \n",
      "Word: schn\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: auer\n",
      "Unknown char: \n",
      "Word: palstinenser\n",
      "Unknown char: \"\n",
      "Word: victim\".everywhere\n",
      "Unknown char: \n",
      "Word: naeve\n",
      "Unknown char: \n",
      "Word: fernndez\n",
      "Unknown char: \n",
      "Word: were\n",
      "Unknown char: \n",
      "Word: vous-tes\n",
      "Unknown char: \n",
      "Word: vergenza\n",
      "Unknown char: \n",
      "Word: comparacin\n",
      "Unknown char: \n",
      "Word: aportacin\n",
      "Unknown char: \n",
      "Word: ms\n",
      "Unknown char: \n",
      "Word: psame\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: da\n",
      "Unknown char: \n",
      "Word: vctimas\n",
      "Unknown char: \n",
      "Word: da\n",
      "Unknown char: \n",
      "Word: da\n",
      "Unknown char: \n",
      "Word: hacis\n",
      "Unknown char: \n",
      "Word: penses\n",
      "Unknown char: \n",
      "Word: prires\n",
      "Unknown char: \n",
      "watd: feiten!\n",
      "Unknown char: \n",
      "Word: einsatzkrfte\n",
      "Unknown char: \"\n",
      "Word: paris\"pres.obama\n",
      "Unknown char: \"\n",
      "Word: off...\"i\n",
      "Unknown char: \n",
      "Word: estlles\n",
      "Unknown char: \n",
      "Word: sontdivischaque\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown char: =\n",
      "Word: dreadheads=savages\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: wouldnt\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: thats\n",
      "Unknown char: \n",
      "Word: chtiment\n",
      "Unknown char: \n",
      "Word: c'tait\n",
      "Unknown char: \n",
      "Word: vritable\n",
      "Unknown char: \n",
      "Word: succs\n",
      "Unknown char: =\n",
      "Word: hispanicsasians=democrat\n",
      "Unknown char: =\n",
      "Word: christians=republicans\n",
      "Unknown char: =\n",
      "Word: christians=dems\n",
      "Unknown char: \n",
      "Word: mitgefhl\n",
      "Unknown char: \n",
      "Word: gehrt\n",
      "Unknown char: \n",
      "Word: angehrigen\n",
      "Unknown char: \n",
      "Word: israilli\n",
      "Unknown char: \n",
      "Word: tmgeneral\n",
      "Unknown char: \n",
      "Word: koavi\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "Word: trkiyede\n",
      "Unknown char: \n",
      "make: gun\n",
      "Unknown char: \n",
      "rewardsun\n",
      "Unknown char: \n",
      "puttingead\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: kardelerim\n",
      "Unknown char: \n",
      "Word: cantrk\n",
      "Unknown char: \n",
      "Word: kardein\n",
      "Unknown char: \n",
      "Word: dmanlarna\n",
      "Unknown char: \n",
      "Word: dmanlarna\n",
      "Unknown char: \n",
      "Word: dmanlarna\n",
      "Unknown char: \n",
      "Word: lt;&lt;&lt;kardeimizin\n",
      "Unknown char: \n",
      "Word: ineallah\n",
      "Unknown char: \n",
      "Word: ineallah\n",
      "Unknown char: \n",
      "Word: ineallah\n",
      "Unknown char: \n",
      "Word: ineallah\n",
      "Unknown char: \n",
      "Word: ineallah\n",
      "Unknown char: \n",
      "Word: ineallah\n",
      "Unknown char: \n",
      "Word: ineallah\n",
      "Unknown char: \n",
      "Word: aln\n",
      "Unknown char: \n",
      "Word: terr\n",
      "Unknown char: \n",
      "Word: amberin\n",
      "Unknown char: \n",
      "Word: yaatsin\n",
      "Unknown char: \n",
      "Word: zalim\n",
      "Unknown char: \n",
      "Word: dimi\n",
      "Unknown char: \n",
      "Word: irmainin\n",
      "Unknown char: \n",
      "Word: baindadir\n",
      "Unknown char: \n",
      "Word: gnahsizlar\n",
      "Unknown char: \n",
      "Word: amn\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \n",
      "Word: isnt\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \n",
      "Word: astrix\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: cafs\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: =\n",
      "Word: search=ferguson\n",
      "Unknown char: =\n",
      "Word: tip=lesson\n",
      "Unknown char: \n",
      "Word: israels\n",
      "Unknown char: \n",
      "Word: polica\n",
      "Unknown char: \n",
      "Word: va\n",
      "Unknown char: \n",
      "Word: localizacin\n",
      "Unknown char: \n",
      "Word: despus\n",
      "Unknown char: \n",
      "Word: ridculos\n",
      "Unknown char: =\n",
      "Word: photos=boasting\n",
      "Unknown char: =\n",
      "Word: situation=acceptable\n",
      "Unknown char: \n",
      "Word: enneige\n",
      "Unknown char: \n",
      "Word: dbris\n",
      "Unknown char: \n",
      "Word: cest\n",
      "Unknown char: \n",
      "Word: valle\n",
      "Unknown char: \n",
      "Word: hlico\n",
      "Unknown char: \n",
      "Word: dcollent\n",
      "Unknown char: \n",
      "Word: dj\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: impresso\n",
      "Unknown char: \n",
      "Word: tambm\n",
      "Unknown char: \n",
      "Word: segurana\n",
      "Unknown char: \n",
      "Word: no\n",
      "Unknown char: \n",
      "Word: lamentvel\n",
      "Unknown char: \n",
      "Word: proteo\n",
      "Unknown char: \n",
      "Word: proteo\n",
      "Unknown char: \n",
      "Word: ameaas\n",
      "Unknown char: \n",
      "Word: islmicos\n",
      "Unknown char: \n",
      "Word: ameaas\n",
      "Unknown char: \n",
      "Word: tranqilas.tanto\n",
      "Unknown char: \n",
      "Word: sado\n",
      "Unknown char: \n",
      "Word: proteo\n",
      "Unknown char: \n",
      "Word: proteo\n",
      "Unknown char: \n",
      "Word: proteo\n",
      "Unknown char: \n",
      "Word: proteo\n",
      "Unknown char: \n",
      "Word: aps\n",
      "Unknown char: \n",
      "Word: lder\n",
      "Unknown char: \n",
      "Word: islmico\n",
      "Unknown char: \n",
      "Word: religies\n",
      "Unknown char: \n",
      "Word: redao\n",
      "Unknown char: \n",
      "Word: redao\n",
      "Unknown char: \n",
      "Word: horrio\n",
      "Unknown char: \n",
      "Word: reunio\n",
      "Unknown char: \n",
      "Word: vtimas\n",
      "Unknown char: \n",
      "Word: crashthoughts\n",
      "Unknown char: \"\n",
      "Word: radioshow\"=ain't\n",
      "Unknown char: =\n",
      "Word: radioshow\"=ain't\n",
      "Unknown char: =\n",
      "Word: account=prob\n",
      "Unknown char: \"\n",
      "Word: like\"riot\n",
      "Unknown char: \n",
      "Word: policires\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \"\n",
      "Word: recruits\"?first\n",
      "Unknown char: \"\n",
      "Word: terrorism\"&amp\n",
      "Unknown char: =\n",
      "Word: crime=police\n",
      "Unknown char: \n",
      "Word: theres\n",
      "Unknown char: \n",
      "Word: represin\n",
      "Unknown char: \n",
      "Word: l'amrique\n",
      "Unknown char: \"\n",
      "Word: to?\"you\n",
      "Unknown char: \n",
      "Word: cant\n",
      "Unknown char: \n",
      "Word: journe\n",
      "Unknown char: \n",
      "Word: smtliche\n",
      "Unknown char: \n",
      "Word: lt\n",
      "Unknown char: \n",
      "Word: lt\n",
      "Unknown char: \n",
      "Word: nmlich\n",
      "Unknown char: \n",
      "Word: didnt\n",
      "Unknown char: \n",
      "Word: im\n",
      "Unknown char: \n",
      "Word: luft\n",
      "Unknown char: \n",
      "Word: erzhlt\n",
      "Unknown char: \n",
      "Word: fr\n",
      "Unknown char: \n",
      "Word: lngst\n",
      "Unknown char: \n",
      "Word: berfllig\n",
      "Unknown char: \n",
      "Word: unglcke\n",
      "Unknown char: \n",
      "Word: whod\n",
      "Unknown char: \n",
      "Word: procs\n",
      "Unknown char: \n",
      "Word: pense\n",
      "Unknown char: \n",
      "Word: jrg\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: true?ilyy\n",
      "Unknown char: \n",
      "Word: francs\n",
      "Unknown char: \n",
      "Word: vctimas\n",
      "Unknown char: \n",
      "Word: juda\n",
      "Unknown char: \n",
      "Word: hes\n",
      "Unknown char: \n",
      "Word: youre\n",
      "Unknown char: \n",
      "Word: its\n",
      "Unknown char: \n",
      "Word: theyre\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: frances\n",
      "Unknown char: \n",
      "Word: estn\n",
      "Unknown char: \n",
      "Word: yesterdays\n",
      "Unknown char: \n",
      "Word: scholarmay\n",
      "Unknown char: =\n",
      "Word: words=action\n",
      "Unknown char: \n",
      "Word: mastersdo\n",
      "Unknown char: \n",
      "Word: card\n",
      "Unknown char: \n",
      "Word: dont\n",
      "Unknown char: \n",
      "Word: inquitant\n",
      "Unknown char: \n",
      "Word: doesnt\n",
      "Unknown char: \"\n",
      "Word: how\"...the\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ee5c2c10c07e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainCMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdm_train_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_train_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ERD/model.py\u001b[0m in \u001b[0;36mTrainCMModel\u001b[0;34m(sess, rdm_train, cm_train, t_rw, t_steps)\u001b[0m\n\u001b[1;32m    381\u001b[0m                      \u001b[0mrdm_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minit_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                      rdm_train.dropout_keep_prob: 1.0 }\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mt_ssq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdm_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# t_ssq = [batchsize, max_seq, scores]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mssq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_ssq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TF/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(model)\n",
    "model.TrainCMModel(sess, rdm_train_graph, cm_train_graph, 0.3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
